WEBVTT

00:00.000 --> 00:02.200
And so our goal was a natural looking gate.

00:02.200 --> 00:04.920
It was really, it was surprisingly hard

00:04.920 --> 00:06.760
to get that to work.

00:06.760 --> 00:09.460
And we, but we did build an early machine.

00:10.800 --> 00:12.440
We called it Pet Man prototype.

00:12.440 --> 00:15.180
It was the prototype before the Pet Man robot.

00:16.280 --> 00:20.560
And it had a really nice looking gate

00:20.560 --> 00:23.040
where, you know, it would stick the leg out.

00:23.040 --> 00:24.640
It would do heel strike first

00:24.640 --> 00:25.940
before it rolled onto the toe.

00:25.940 --> 00:27.500
So you didn't land with a flat foot.

00:27.500 --> 00:29.480
You extended your leg a little bit.

00:30.960 --> 00:33.560
But even then it was hard to get the robot to walk

00:33.560 --> 00:37.520
where when you were walking that it fully extended its leg.

00:37.520 --> 00:42.000
And getting that all to work well took such a long time.

00:42.000 --> 00:45.360
In fact, I probably didn't really see

00:45.360 --> 00:47.980
the nice natural walking that I expected

00:47.980 --> 00:51.900
out of our humanoids until maybe last year.

00:51.900 --> 00:53.720
And the team was developing

00:53.720 --> 00:55.960
on our newer generation of Atlas, you know,

00:55.960 --> 00:59.840
some new techniques for developing

00:59.840 --> 01:01.560
a walking control algorithm.

01:01.560 --> 01:04.320
And they got that natural looking motion

01:04.320 --> 01:07.640
as sort of a byproduct of just a different process

01:07.640 --> 01:11.080
they were applying to developing the control.

01:11.080 --> 01:14.760
So that probably took 15 years, 10 to 15 years

01:14.760 --> 01:17.600
to sort of get that from, you know,

01:17.600 --> 01:20.200
the Pet Man prototype was probably in 2008.

01:20.200 --> 01:21.040
And what was it?

01:21.040 --> 01:25.120
2022, last year that I think I saw a good walking on Atlas.

01:26.960 --> 01:30.360
The following is a conversation with Robert Plater,

01:30.360 --> 01:35.000
CEO of Boston Dynamics, a legendary robotics company

01:35.000 --> 01:39.040
that over 30 years has created some of the most elegant,

01:39.040 --> 01:42.960
dexterous and simply amazing robots ever built,

01:42.960 --> 01:45.820
including the humanoid robot Atlas

01:45.820 --> 01:48.880
and the robot dog Spot.

01:48.880 --> 01:52.760
One or both of whom you've probably seen on the internet,

01:52.800 --> 01:56.440
either dancing, doing backflips, opening doors

01:56.440 --> 01:58.960
or throwing around heavy objects.

01:59.820 --> 02:02.080
Robert has led both the development

02:02.080 --> 02:03.840
of Boston Dynamics humanoid robots

02:03.840 --> 02:07.280
and their physics based simulation software.

02:07.280 --> 02:10.520
He has been with the company from the very beginning,

02:10.520 --> 02:12.620
including its roots at MIT,

02:12.620 --> 02:16.340
where he received his PhD in aeronautical engineering.

02:16.340 --> 02:21.340
This was in 1994 at the legendary MIT leg lab.

02:21.340 --> 02:25.380
He wrote his PhD thesis on robot gymnastics,

02:25.380 --> 02:28.660
as part of which he programmed a bipedal robot

02:28.660 --> 02:32.460
to do the world's first 3D robotic somersault.

02:32.460 --> 02:35.300
Robert is a great engineer, roboticist and leader

02:35.300 --> 02:38.420
and Boston Dynamics to me as a roboticist

02:38.420 --> 02:40.460
is a truly inspiring company.

02:40.460 --> 02:43.180
This conversation was a big honor and pleasure.

02:43.180 --> 02:45.580
And I hope to do a lot of great work

02:45.580 --> 02:47.940
with these robots in the years to come.

02:47.940 --> 02:49.940
This is the Lex Fridman podcast.

02:49.940 --> 02:51.860
To support it, please check out our sponsors

02:51.860 --> 02:53.100
in the description.

02:53.100 --> 02:56.560
And now to your friends, here's Robert Plater.

02:57.500 --> 03:00.140
When did you first fall in love with robotics?

03:01.900 --> 03:04.780
Let's start with love and robots.

03:04.780 --> 03:09.780
Well, love is relevant because I think the fascination,

03:09.780 --> 03:12.780
the deep fascination is really about movement.

03:12.780 --> 03:17.780
And I was visiting MIT looking for a place to get a PhD

03:18.780 --> 03:21.820
and I wanted to do some laboratory work.

03:21.820 --> 03:24.660
And one of my professors in the aerodepartment said,

03:24.660 --> 03:26.020
go see this guy, Mark Rabert,

03:26.020 --> 03:29.180
down in the basement of the AI lab.

03:29.180 --> 03:31.500
And so I walked down there and saw him.

03:31.500 --> 03:32.900
He showed me his robots

03:33.900 --> 03:37.060
and he showed me this robot doing a somersault.

03:37.060 --> 03:40.540
And I just immediately went, whoa, you know?

03:40.540 --> 03:41.740
Robots can do that.

03:41.740 --> 03:44.580
And because of my own interest in gymnastics,

03:44.580 --> 03:46.900
there was like this immediate connection.

03:46.940 --> 03:51.340
And I was interested in, I was in an aero-astro degree

03:51.340 --> 03:55.580
because flight and movement was all so fascinating to me.

03:55.580 --> 03:59.180
And then it turned out that robotics had this big challenge.

03:59.180 --> 04:01.100
How do you balance?

04:01.100 --> 04:04.740
How do you build a legged robot that can really get around?

04:04.740 --> 04:07.820
And that just, that was a fascination.

04:07.820 --> 04:09.380
And it still exists today.

04:09.380 --> 04:13.080
You're still working on perfecting motion in robots.

04:13.080 --> 04:15.140
What about the elegance and the beauty

04:15.140 --> 04:16.380
of the movement itself?

04:16.620 --> 04:19.220
Is there something maybe grounded

04:19.220 --> 04:23.860
in your appreciation of movement from your gymnastics days?

04:23.860 --> 04:28.340
Did you, was there something you just fundamentally

04:28.340 --> 04:31.220
appreciate about the elegance and beauty of movement?

04:31.220 --> 04:34.220
You know, we had this concept in gymnastics

04:34.220 --> 04:38.260
of letting your body do what it wanted to do.

04:38.260 --> 04:42.020
When you get really good at gymnastics,

04:43.060 --> 04:45.580
part of what you're doing is putting your body

04:45.580 --> 04:48.980
into a position where the physics and the body's inertia

04:48.980 --> 04:52.100
and momentum will kind of push you in the right direction

04:52.100 --> 04:54.740
in a very natural and organic way.

04:54.740 --> 04:56.780
And the thing that Mark was doing, you know,

04:56.780 --> 05:00.820
in the basement of that laboratory was trying to figure out

05:00.820 --> 05:03.380
how to build machines to take advantage of those ideas.

05:03.380 --> 05:05.500
How do you build something so that the physics

05:05.500 --> 05:08.980
of the machine just kind of inherently wants to do

05:08.980 --> 05:09.860
what it wants to do?

05:09.860 --> 05:13.500
And he was building these springy pogo stick type.

05:13.700 --> 05:16.700
His first cut at legged locomotion was a pogo stick

05:16.700 --> 05:20.540
where it's bouncing and there's a spring mass system

05:20.540 --> 05:23.380
that's oscillating, has its own sort of natural frequency

05:23.380 --> 05:26.340
there and sort of figuring out how to augment

05:26.340 --> 05:29.980
those natural physics with also intent.

05:29.980 --> 05:33.180
How do you then control that, but not overpower it?

05:33.180 --> 05:37.380
It's that coordination that I think creates real potential.

05:37.380 --> 05:38.700
We could call it beauty.

05:38.700 --> 05:41.620
You know, you could call it, I don't know, synergy.

05:41.620 --> 05:43.580
People have different words for it,

05:43.580 --> 05:46.260
but I think that that was inherent from the beginning.

05:46.260 --> 05:48.540
That was clear to me that that's part of what Mark

05:48.540 --> 05:49.380
was trying to do.

05:49.380 --> 05:51.580
He asked me to do that in my research work.

05:51.580 --> 05:53.980
So, you know, that's where it got going.

05:53.980 --> 05:56.180
So part of the thing that I think I'm calling elegance

05:56.180 --> 05:58.740
and beauty in this case, which was there,

05:58.740 --> 06:01.900
even with the pogo stick is maybe the efficiency.

06:01.900 --> 06:04.580
So letting the body do what it wants to do,

06:04.580 --> 06:06.820
trying to discover the efficient movement.

06:06.820 --> 06:08.380
It's definitely more efficient.

06:08.380 --> 06:12.220
It also becomes easier to control in its own way

06:12.220 --> 06:15.340
because the physics are solving some of the problem itself.

06:15.340 --> 06:18.180
It's not like you have to do all this calculation

06:18.180 --> 06:19.500
and overpower the physics.

06:19.500 --> 06:23.620
The physics naturally inherently want to do the right thing.

06:23.620 --> 06:26.820
There can even be, you know, feedback mechanisms,

06:26.820 --> 06:31.220
stabilizing mechanisms that occur simply by virtue

06:31.220 --> 06:32.660
of the physics of the body.

06:32.660 --> 06:36.540
And it's, you know, not all in the computer

06:36.540 --> 06:39.540
or not even all in your mind as a person.

06:39.540 --> 06:43.700
And there's something interesting in that melding.

06:43.700 --> 06:46.020
You were with Mark for many, many, many years,

06:46.020 --> 06:49.100
but you were there in this kind of legendary space

06:49.100 --> 06:53.540
of a leg lab at MIT in the basement.

06:53.540 --> 06:55.340
All great things happen in the basement.

06:55.340 --> 07:00.340
Is there some memories from that time that you have

07:00.660 --> 07:05.660
because it's such cutting edge work in robotics

07:06.700 --> 07:09.060
and artificial intelligence?

07:09.060 --> 07:12.180
The memories, the distinctive lessons, I would say,

07:12.180 --> 07:15.260
I learned in that time period

07:15.260 --> 07:19.300
and that I think Mark was a great teacher of

07:19.300 --> 07:24.260
was it's okay to pursue your interests, your curiosity,

07:24.260 --> 07:25.860
do something because you love it.

07:27.180 --> 07:29.180
You'll do it a lot better if you love it.

07:31.380 --> 07:36.380
That is a lasting lesson that I think we apply

07:36.740 --> 07:41.740
at the company still and really is a core value.

07:41.740 --> 07:43.740
So the interesting thing is I got to

07:46.380 --> 07:50.100
with people like Russ Cedric and others,

07:50.100 --> 07:52.660
like the students that work at those robotics labs

07:52.660 --> 07:55.220
are like some of the happiest people I've ever met.

07:55.220 --> 07:56.460
I don't know what that is.

07:57.340 --> 07:58.700
I meet a lot of PhD students.

07:58.700 --> 08:01.740
A lot of them are kind of broken by the wear and tear

08:01.740 --> 08:04.660
of the process, but roboticists are,

08:04.660 --> 08:06.140
while they work extremely hard

08:06.700 --> 08:11.700
and work long hours, there's a happiness there.

08:12.380 --> 08:14.140
The only other group of people I've met like that

08:14.140 --> 08:15.580
are people that skydive a lot.

08:17.220 --> 08:19.260
For some reason, there's a deep fulfilling happiness,

08:19.260 --> 08:22.340
maybe from like a long period of struggle

08:22.340 --> 08:23.940
to get a thing to work and it works

08:23.940 --> 08:24.940
and there's a magic to it.

08:24.940 --> 08:29.220
I don't know exactly because it's so fundamentally hands on

08:29.220 --> 08:30.660
and you're bringing a thing to life.

08:30.660 --> 08:33.060
I don't know what it is, but they're happy.

08:33.060 --> 08:37.060
We see our attrition at the company is really low.

08:37.060 --> 08:40.420
People come and they love the pursuit.

08:40.420 --> 08:43.420
And I think part of that is that there's perhaps

08:43.420 --> 08:45.140
a natural connection to it.

08:45.140 --> 08:46.620
It's a little bit easier to connect

08:46.620 --> 08:49.300
when you have a robot that's moving around in the world.

08:49.300 --> 08:52.260
And part of your goal is to make it move around in the world.

08:52.260 --> 08:53.980
You can identify with that.

08:53.980 --> 08:56.700
And this is one of the unique things

08:56.700 --> 08:58.260
about the kinds of robots we're building

08:58.260 --> 09:01.140
is this physical interaction

09:01.420 --> 09:03.900
lets you perhaps identify with it.

09:03.900 --> 09:05.860
So I think that is a source of happiness.

09:05.860 --> 09:07.300
I don't think it's unique to robotics.

09:07.300 --> 09:10.300
I think anybody also who is just pursuing

09:10.300 --> 09:13.740
something they love, it's easier to work hard at it

09:13.740 --> 09:14.660
and be good at it.

09:14.660 --> 09:19.580
And not everybody gets to find that.

09:19.580 --> 09:21.260
I do feel lucky in that way.

09:21.260 --> 09:23.820
And I think we're lucky as an organization

09:23.820 --> 09:27.100
that we've been able to build a business around this

09:27.100 --> 09:29.420
and that keeps people engaged.

09:29.420 --> 09:31.940
So if it's all right, let's linger on Mark

09:31.940 --> 09:33.820
for a little bit longer, Mark Kraybert.

09:33.820 --> 09:35.220
So he's a legend.

09:36.940 --> 09:39.020
He's a legendary engineer and roboticist.

09:39.020 --> 09:42.860
What have you learned about life about robotics from Mark

09:42.860 --> 09:45.180
through all the many years you worked with him?

09:45.180 --> 09:47.260
I think the most important lesson,

09:47.260 --> 09:49.460
which was have the courage of your convictions

09:49.460 --> 09:51.420
and do what you think is interesting.

09:53.660 --> 09:58.660
Be willing to try to find big, big problems to go after.

09:58.980 --> 10:01.220
And at the time, like at locomotion,

10:02.660 --> 10:06.940
especially in a dynamic machine, nobody had solved it.

10:06.940 --> 10:11.940
And that felt like a multi-decade problem to go after.

10:12.460 --> 10:15.260
And so have the courage to go after that

10:15.260 --> 10:17.180
because you're interested.

10:17.180 --> 10:19.780
Don't worry if it's gonna make money.

10:19.780 --> 10:21.180
That's been a theme.

10:21.180 --> 10:26.020
So that's really probably the most important lesson

10:26.020 --> 10:28.180
I think that I got from Mark.

10:28.220 --> 10:32.740
How crazy is the effort of doing legged robotics

10:32.740 --> 10:34.460
at that time especially?

10:35.580 --> 10:40.140
Mark got some stuff to work starting from the simple ideas.

10:40.140 --> 10:42.700
So maybe the other, another important idea

10:42.700 --> 10:45.300
that has really become a value of the company

10:45.300 --> 10:50.300
is try to simplify a thing to the core essence.

10:50.300 --> 10:53.780
And while Mark was showing videos of animals

10:53.780 --> 10:58.780
running across the savanna or climbing mountains,

10:59.140 --> 11:00.900
what he started with was a pogo stick

11:00.900 --> 11:03.220
because he was trying to reduce the problem

11:03.220 --> 11:04.660
to something that was manageable

11:04.660 --> 11:07.460
and getting the pogo stick to balance.

11:07.460 --> 11:11.420
Had in it the fundamental problems that if we solve those,

11:11.420 --> 11:12.900
you could eventually extrapolate

11:12.900 --> 11:15.660
to something that galloped like a horse.

11:15.660 --> 11:18.580
And so look for those simplifying principles.

11:19.820 --> 11:22.660
How tough is the job of simplifying a robot?

11:22.660 --> 11:24.620
So I'd say in the early days,

11:24.620 --> 11:27.220
the thing that made Boston,

11:27.220 --> 11:29.940
the researchers at Boston Dynamics special

11:29.940 --> 11:33.780
is that we worked on figuring out

11:33.780 --> 11:38.460
what that central principle was.

11:38.460 --> 11:42.060
And then building software or machines around that principle.

11:42.060 --> 11:44.260
And that was not easy in the early days.

11:44.260 --> 11:48.060
And it took real expertise

11:48.060 --> 11:51.940
in understanding the dynamics of motion

11:51.980 --> 11:55.700
and feedback control principles.

11:55.700 --> 11:58.780
How to build, and with the computers at the time,

11:58.780 --> 12:00.620
how to build a feedback control algorithm

12:00.620 --> 12:02.780
that was simple enough that it could run in real time

12:02.780 --> 12:06.300
at 1,000 hertz and actually get that machine to work.

12:08.140 --> 12:10.900
And that was not something everybody was doing

12:10.900 --> 12:12.300
at that time.

12:12.300 --> 12:13.580
Now the world's changing now.

12:13.580 --> 12:16.580
And I think the approaches to controlling robots

12:16.580 --> 12:17.660
are going to change.

12:18.620 --> 12:23.620
And they're going to become more broadly available.

12:26.020 --> 12:28.420
But at the time, there weren't many groups

12:28.420 --> 12:31.660
who could really sort of work at that principled level

12:32.540 --> 12:36.500
with both the software and make the hardware work.

12:37.620 --> 12:38.860
And I'll say one other thing about,

12:38.860 --> 12:41.900
you were sort of talking about what are the special things.

12:41.900 --> 12:45.580
The other thing was, it's good to break stuff.

12:48.580 --> 12:51.380
Use the robots, break them, repair them,

12:53.860 --> 12:56.180
fix and repeat, test, fix and repeat.

12:56.180 --> 12:59.100
And that's also a core principle

12:59.100 --> 13:01.700
that has become part of the company.

13:01.700 --> 13:05.540
And it lets you be fearless in your work.

13:05.540 --> 13:09.260
Too often, if you are working with a very expensive robot,

13:09.260 --> 13:11.060
maybe one that you bought from somebody else

13:11.060 --> 13:12.740
or that you don't know how to fix,

13:12.740 --> 13:15.340
then you treat it with kit gloves

13:15.340 --> 13:17.540
and you can't actually make progress.

13:18.420 --> 13:19.260
You have to be able to break something.

13:19.260 --> 13:22.500
And so I think that's been a principle as well.

13:22.500 --> 13:24.220
So just to linger on that psychologically,

13:24.220 --> 13:25.140
how do you deal with that?

13:25.140 --> 13:30.260
Because I remember I built a RC car

13:30.260 --> 13:34.660
with some, it had some custom stuff,

13:34.660 --> 13:37.260
like compute on it and all that kind of stuff, cameras.

13:37.260 --> 13:40.660
And because I didn't sleep much,

13:40.660 --> 13:42.620
the code I wrote had an issue

13:42.620 --> 13:44.540
where it didn't stop the car

13:44.540 --> 13:47.460
and the car got confused and at full speed

13:48.380 --> 13:51.340
at like 20, 25 miles an hour slammed into a wall.

13:51.340 --> 13:55.100
And I just remember sitting there alone in a deep sadness,

13:56.740 --> 14:01.460
sort of full of regret, I think, almost anger,

14:03.700 --> 14:06.340
but also like sadness because you think about,

14:06.340 --> 14:09.020
well, these robots, especially for autonomous vehicles,

14:09.020 --> 14:12.020
like you should be taking safety very seriously

14:12.020 --> 14:14.460
even in these kinds of things,

14:14.460 --> 14:17.020
but just no good feelings.

14:17.540 --> 14:18.620
And it made me more afraid probably

14:18.620 --> 14:20.860
to do this kind of experiments in the future.

14:20.860 --> 14:24.060
Perhaps the right way to have seen that is positively.

14:25.820 --> 14:27.740
It depends if you could have built that car

14:27.740 --> 14:29.660
or just gotten another one, right?

14:29.660 --> 14:32.140
That would have been the approach.

14:32.140 --> 14:37.140
I remember when I got to grad school,

14:39.100 --> 14:43.380
I got some training about operating a lathe and a mill

14:43.380 --> 14:45.140
up in the machine shop

14:45.140 --> 14:47.620
and I could start to make my own parts.

14:47.620 --> 14:52.220
And I remember breaking some piece of equipment in the lab

14:52.220 --> 14:54.020
and then realizing,

14:54.020 --> 14:55.620
because maybe this was a unique part

14:55.620 --> 14:57.100
and I couldn't go buy it.

14:57.100 --> 15:00.260
And I realized, oh, I can just go make it.

15:00.260 --> 15:02.820
That was an enabling feeling.

15:02.820 --> 15:04.300
Then you're not afraid.

15:04.300 --> 15:05.900
Yeah, it might take time.

15:05.900 --> 15:07.900
It might take more work than you thought

15:07.900 --> 15:10.660
it was gonna be required to get this thing done,

15:10.660 --> 15:12.100
but you can just go make it.

15:12.100 --> 15:16.740
And that's freeing in a way that nothing else is.

15:16.740 --> 15:20.820
You mentioned the feedback control, the dynamics.

15:20.820 --> 15:22.540
Sorry for the romantic question,

15:22.540 --> 15:25.020
but in the early days and even now,

15:25.020 --> 15:27.780
is the dynamics probably more appropriate

15:27.780 --> 15:28.860
for the early days?

15:28.860 --> 15:30.820
Is it more art or science?

15:33.220 --> 15:35.700
There's a lot of science around it.

15:35.700 --> 15:40.300
And trying to develop scientific principles

15:40.340 --> 15:41.780
that let you extrapolate

15:41.780 --> 15:44.300
from one legged machine to another.

15:45.340 --> 15:47.660
Develop a core set of principles

15:47.660 --> 15:51.580
like a spring mass bouncing system.

15:51.580 --> 15:53.860
And then figure out how to apply that

15:53.860 --> 15:55.460
from a one legged machine to a two

15:55.460 --> 15:56.860
or a four legged machine.

15:56.860 --> 15:58.580
Those principles are really important.

15:58.580 --> 16:03.100
And we're definitely a core part of our work.

16:04.940 --> 16:09.940
There's also, when we started to pursue humanoid robots,

16:11.180 --> 16:14.340
there was so much complexity in that machine

16:14.340 --> 16:18.060
that one of the benefits of the humanoid form

16:18.060 --> 16:20.940
is you have some intuition about how it should look

16:20.940 --> 16:21.860
while it's moving.

16:22.700 --> 16:26.260
And that's a little bit of an art, I think.

16:26.260 --> 16:28.500
Or maybe it's just tapping into a knowledge

16:28.500 --> 16:30.420
that you have deep in your body

16:30.420 --> 16:33.140
and then trying to express that in the machine.

16:33.140 --> 16:34.860
But that's an intuition

16:34.860 --> 16:37.220
that's a little bit more on the art side.

16:37.220 --> 16:39.580
Maybe it predates your knowledge.

16:39.580 --> 16:41.660
Before you have the knowledge of how to control it,

16:41.660 --> 16:43.860
you try to work through the art channel.

16:43.860 --> 16:45.820
And humanoids sort of make that available to you.

16:45.820 --> 16:47.660
If it had been a different shape,

16:47.660 --> 16:50.780
maybe you wouldn't have had the same intuition about it.

16:50.780 --> 16:55.060
Yeah, so your knowledge about moving through the world

16:55.060 --> 16:56.860
is not made explicit to you.

16:57.700 --> 16:59.460
So you just, that's why it's art.

16:59.460 --> 17:02.540
Yeah, it might be hard to actually articulate exactly.

17:03.660 --> 17:07.180
There's something about, and being a competitive athlete,

17:07.180 --> 17:11.020
there's something about seeing movement.

17:11.020 --> 17:14.380
A coach, one of the greatest strengths a coach has

17:14.380 --> 17:17.220
is being able to see some little change

17:17.220 --> 17:18.860
in what the athlete is doing

17:18.860 --> 17:21.260
and then being able to articulate that to the athlete.

17:21.260 --> 17:22.740
And then maybe even trying to say,

17:22.740 --> 17:24.620
and you should try to feel this.

17:25.980 --> 17:28.220
So there's something just in seeing.

17:28.220 --> 17:31.580
And again, sometimes it's hard to articulate

17:31.580 --> 17:33.020
what it is you're seeing.

17:33.020 --> 17:35.820
But there's just perceiving the motion

17:35.860 --> 17:40.860
at a rate that is, again, sometimes hard to put into words.

17:41.740 --> 17:46.740
Yeah, I wonder how it is possible

17:46.740 --> 17:49.620
to achieve sort of truly elegant movement.

17:49.620 --> 17:51.780
You have a movie like Ex Machina,

17:51.780 --> 17:53.180
not sure if you've seen it.

17:53.180 --> 17:57.260
But the main actress in that, who plays the AI robot,

17:57.260 --> 17:59.020
I think is a ballerina.

17:59.020 --> 18:02.420
I mean, just the natural elegance

18:02.420 --> 18:05.460
and the, I don't know, eloquence of movement.

18:07.980 --> 18:12.980
It looks efficient and easy and just, it looks right.

18:13.260 --> 18:14.100
It looks beautiful.

18:14.100 --> 18:15.660
It looks right is sort of the key, yeah.

18:15.660 --> 18:19.020
And then you look at, especially early robots,

18:19.020 --> 18:22.180
I mean, they're so cautious in the way they move

18:23.340 --> 18:27.140
that it's not the caution that looks wrong.

18:27.140 --> 18:30.220
It's something about the movement that looks wrong

18:30.220 --> 18:32.940
because it feels like it's very inefficient,

18:32.940 --> 18:34.060
unnecessarily so.

18:34.060 --> 18:37.980
And it's hard to put that into words exactly.

18:37.980 --> 18:41.580
We think, and part of the reason why people are attracted

18:41.580 --> 18:45.820
to the machines we build is because the inherent dynamics

18:45.820 --> 18:48.620
of movement are closer to right.

18:49.860 --> 18:53.220
Because we try to use walking gates

18:53.220 --> 18:55.660
where we build a machine around this gate,

18:55.660 --> 18:57.900
where you're trying to work with the dynamics

18:57.940 --> 19:01.380
of the machine instead of to stop them.

19:01.380 --> 19:03.940
Some of the early walking machines,

19:03.940 --> 19:06.540
you're essentially, you're really trying hard

19:06.540 --> 19:08.060
to not let them fall over.

19:08.060 --> 19:10.900
And so you're always stopping the tipping motion.

19:11.980 --> 19:16.500
And sort of the insight of dynamic stability

19:16.500 --> 19:19.260
in a luggage machine is to go with it.

19:19.260 --> 19:22.460
Let the tipping happen, let yourself fall,

19:22.460 --> 19:24.860
but then catch yourself with that next foot.

19:24.860 --> 19:27.380
And there's something about getting those physics

19:27.380 --> 19:29.780
to be expressed in the machine

19:29.780 --> 19:34.780
that people interpret as lifelike or elegant

19:36.540 --> 19:38.340
or just natural looking.

19:38.340 --> 19:41.140
And so I think if you get the physics right,

19:41.140 --> 19:44.540
it also ends up being more efficient, likely.

19:44.540 --> 19:47.580
There's a benefit that it probably ends up being

19:47.580 --> 19:49.900
more stable in the long run.

19:49.900 --> 19:53.940
It could walk stably over a wide range of conditions.

19:55.500 --> 19:57.260
And it's more beautiful.

19:58.140 --> 19:58.980
And attractive at the same time.

19:58.980 --> 20:03.700
So how hard is it to get the humanoid robot Atlas

20:03.700 --> 20:06.100
to do some of the things it's recently been doing?

20:06.100 --> 20:08.180
Let's forget the flips and all of that.

20:08.180 --> 20:10.380
Let's just look at the running.

20:10.380 --> 20:11.380
Maybe you can correct me,

20:11.380 --> 20:12.980
but there's something about running,

20:12.980 --> 20:14.460
I mean, that's not careful at all.

20:14.460 --> 20:16.620
That's you're falling forward.

20:16.620 --> 20:18.260
You're jumping forward and are falling.

20:18.260 --> 20:20.900
So how hard is it to get that right?

20:20.900 --> 20:22.580
Our first humanoid,

20:22.580 --> 20:25.780
we needed to deliver natural looking walking.

20:25.820 --> 20:27.780
We took a contract from the army.

20:27.780 --> 20:31.180
They wanted a robot that could walk naturally.

20:31.180 --> 20:33.900
They wanted to put a suit on the robot

20:33.900 --> 20:36.700
and be able to test it in a gas environment.

20:36.700 --> 20:39.500
And so they wanted the motion to be natural.

20:41.020 --> 20:43.180
And so our goal was a natural looking gate.

20:43.180 --> 20:47.740
It was surprisingly hard to get that to work.

20:47.740 --> 20:50.420
And we, but we did build an early machine.

20:51.780 --> 20:53.420
We called it Petman prototype.

20:53.420 --> 20:56.140
It was the prototype before the Petman robot.

20:57.260 --> 21:01.540
And it had a really nice looking gate

21:01.540 --> 21:03.980
where it would stick the leg out.

21:03.980 --> 21:05.580
It would do heel strike first

21:05.580 --> 21:06.900
before it rolled onto the toe.

21:06.900 --> 21:08.460
So you didn't land with a flat foot.

21:08.460 --> 21:10.460
You extended your leg a little bit.

21:11.900 --> 21:14.500
But even then it was hard to get the robot to walk

21:14.500 --> 21:15.820
where when you were walking,

21:15.820 --> 21:17.780
that it fully extended its leg

21:17.780 --> 21:20.100
and essentially landed on an extended leg.

21:20.100 --> 21:22.340
And if you watch closely how you walk,

21:22.340 --> 21:23.980
you probably land on an extended leg,

21:23.980 --> 21:25.780
but then you immediately flex your knee

21:25.780 --> 21:28.140
as you start to make that contact.

21:28.140 --> 21:32.620
And getting that all to work well took such a long time.

21:32.620 --> 21:35.980
In fact, I probably didn't really see

21:35.980 --> 21:38.620
the nice natural walking that I expected

21:38.620 --> 21:42.540
out of our humanoids until maybe last year.

21:42.540 --> 21:44.380
And the team was developing

21:44.380 --> 21:46.620
on our newer generation of Atlas,

21:46.620 --> 21:50.460
some new techniques for developing

21:50.460 --> 21:52.180
a walking control algorithm.

21:53.020 --> 21:54.980
And they got that natural looking motion

21:54.980 --> 21:58.300
as sort of a byproduct of just a different process

21:58.300 --> 22:01.740
they were applying to developing the control.

22:01.740 --> 22:04.380
So that probably took 15 years,

22:04.380 --> 22:07.060
10 to 15 years to sort of get that from,

22:07.060 --> 22:10.860
you know, the Petman prototype was probably in 2008

22:10.860 --> 22:13.660
and what was it, 2022, last year

22:13.660 --> 22:15.980
that I think I saw good walking on Atlas.

22:15.980 --> 22:17.540
If you could just like linger on it,

22:17.540 --> 22:19.780
what are some challenges of getting good walking?

22:19.780 --> 22:24.780
So is this partially like a hardware,

22:25.500 --> 22:27.140
like actuator problem?

22:27.140 --> 22:29.060
Is it the control?

22:29.060 --> 22:31.220
Is it the artistic element of just observing

22:31.220 --> 22:32.420
the whole system operating

22:32.420 --> 22:34.260
in different conditions together?

22:34.260 --> 22:38.140
I mean, is there some kind of interesting quirks

22:38.140 --> 22:39.900
or challenges you can speak to,

22:39.900 --> 22:41.220
like the heel strike or all this kind of?

22:41.220 --> 22:43.060
Yeah, so one of the things that makes

22:43.060 --> 22:46.140
like this straight leg a challenge

22:46.140 --> 22:49.700
is you're sort of up against a singularity.

22:50.540 --> 22:51.900
A mathematical singularity,

22:51.900 --> 22:53.900
where, you know, when your leg is fully extended,

22:53.900 --> 22:56.180
it can't go further the other direction, right?

22:56.180 --> 22:58.780
There's only, you can only move in one direction.

22:58.780 --> 23:00.940
And that makes all of the calculations

23:00.940 --> 23:04.500
around how to produce torques at that joint

23:04.500 --> 23:07.500
or positions makes it more complicated.

23:07.500 --> 23:09.780
And so having all of the mathematics

23:09.780 --> 23:14.220
so it can deal with these singular configurations

23:14.220 --> 23:19.220
is one of many challenges that we face.

23:19.860 --> 23:23.900
And I'd say in those earlier days, again,

23:23.900 --> 23:27.180
we were working with these really simplified models.

23:27.180 --> 23:29.460
So we're trying to boil all the physics

23:29.460 --> 23:34.100
of the complex human body into a simpler subsystem

23:34.100 --> 23:36.780
that we can more easily describe in mathematics.

23:36.780 --> 23:38.980
And sometimes those simpler subsystems

23:38.980 --> 23:40.900
don't have all of that complexity

23:40.900 --> 23:43.900
of the straight leg built into them.

23:43.900 --> 23:46.260
And so what's happened more recently

23:46.260 --> 23:48.020
is we're able to apply techniques

23:48.180 --> 23:53.180
that let us take the full physics of the robot into account

23:53.940 --> 23:57.260
and deal with some of those strange situations

23:57.260 --> 23:59.100
like the straight leg.

23:59.100 --> 24:00.940
So is there a fundamental challenge here

24:00.940 --> 24:03.300
that it's, maybe you can correct me,

24:03.300 --> 24:05.180
but is it underactuated?

24:05.180 --> 24:06.500
Are you falling?

24:06.500 --> 24:08.300
Underactuated is the right word, right?

24:08.300 --> 24:12.700
You can't push the robot in any direction you want to, right?

24:12.700 --> 24:15.380
And so that is one of the hard problems

24:15.380 --> 24:16.980
of like a locomotion.

24:16.980 --> 24:20.300
And you have to do that for natural movement.

24:20.300 --> 24:22.260
It's not necessarily required for natural movement.

24:22.260 --> 24:27.260
It's just required, we don't have a gravity force

24:27.540 --> 24:28.820
that you can hook yourself onto

24:28.820 --> 24:31.340
to apply an external force

24:31.340 --> 24:33.340
in the direction you want at all times, right?

24:33.340 --> 24:36.060
The only external forces are being mediated

24:36.060 --> 24:38.260
through your feet and how they get mediated

24:38.260 --> 24:40.180
depend on how you place your feet.

24:40.180 --> 24:45.180
And you can't just, God's hand can't reach down

24:45.260 --> 24:47.740
and push in any direction you want.

24:49.100 --> 24:52.300
Is there some extra challenge to the fact

24:52.300 --> 24:54.380
that Atlas is such a big robot?

24:54.380 --> 24:55.220
There is.

24:55.220 --> 24:59.780
The humanoid form is attractive in many ways,

24:59.780 --> 25:01.780
but it's also a challenge in many ways.

25:03.860 --> 25:05.420
You have this big upper body

25:05.420 --> 25:07.460
that has a lot of mass and inertia.

25:08.660 --> 25:10.820
And throwing that inertia around

25:10.820 --> 25:13.940
increases the complexity of maintaining balance.

25:13.980 --> 25:16.260
And as soon as you pick up something heavy in your arms,

25:16.260 --> 25:19.100
you've made that problem even harder.

25:19.100 --> 25:23.100
And so in the early work, in the leg lab

25:23.100 --> 25:25.620
and in the early days at the company,

25:25.620 --> 25:28.060
we were pursuing these quadruped robots

25:28.060 --> 25:31.060
which had a kind of built-in simplification.

25:31.060 --> 25:34.580
You had this big rigid body and then really light legs.

25:34.580 --> 25:36.500
So when you swing the legs,

25:36.500 --> 25:41.460
the leg motion didn't impact the body motion very much.

25:41.460 --> 25:43.700
All the mass and inertia was in the body.

25:44.420 --> 25:45.940
But when you have the humanoid, that doesn't work.

25:45.940 --> 25:48.020
You have big heavy legs, you swing the legs,

25:48.020 --> 25:49.980
it affects everything else.

25:49.980 --> 25:54.340
And so dealing with all of that interaction

25:54.340 --> 25:58.100
does make the humanoid a much more complicated platform.

25:58.100 --> 26:00.980
And I also saw that, at least recently,

26:00.980 --> 26:02.940
you've been doing more explicit modeling

26:02.940 --> 26:04.700
of the stuff you pick up.

26:04.700 --> 26:05.540
Yeah, yeah.

26:05.540 --> 26:09.820
Which is very, really interesting.

26:09.820 --> 26:13.660
So you have to, what, model the shape,

26:14.660 --> 26:16.140
the weight distribution.

26:16.140 --> 26:19.220
I don't know, you have to include that

26:19.220 --> 26:21.860
as part of the modeling, as part of the planning.

26:21.860 --> 26:24.820
Because, okay, so for people who don't know,

26:24.820 --> 26:27.420
so Atlas, at least in a recent video,

26:27.420 --> 26:31.740
throws a heavy bag, throws a bunch of stuff.

26:31.740 --> 26:35.580
So what's involved in picking up a thing, a heavy thing,

26:37.340 --> 26:39.140
and when that thing is a bunch of different

26:39.140 --> 26:42.660
non-standard things, I think it also picked up a barbell.

26:43.540 --> 26:46.100
And to be able to throw, in some cases,

26:46.100 --> 26:48.620
what are some interesting challenges there?

26:48.620 --> 26:50.700
So we were definitely trying to show

26:50.700 --> 26:52.940
that the robot and the techniques we're applying

26:52.940 --> 26:57.940
to Atlas let us deal with heavy things in the world.

26:58.260 --> 26:59.780
Because if the robot's gonna be useful,

26:59.780 --> 27:02.020
it's actually gotta move stuff around.

27:02.020 --> 27:04.300
And that needs to be significant stuff.

27:04.300 --> 27:06.100
That's an appreciable portion

27:06.100 --> 27:07.940
of the body weight of the robot.

27:08.860 --> 27:11.020
And we also think this differentiates us

27:11.020 --> 27:13.180
from the other humanoid robot activities

27:13.180 --> 27:14.260
that you're seeing out there.

27:14.260 --> 27:16.740
Mostly they're not picking stuff up yet.

27:16.740 --> 27:18.100
And not heavy stuff anyway.

27:19.580 --> 27:22.860
But just like you or me, you need to anticipate that moment.

27:22.860 --> 27:24.260
You're reaching out to pick something up,

27:24.260 --> 27:25.300
and as soon as you pick it up,

27:25.300 --> 27:27.660
your center of mass is gonna shift.

27:27.660 --> 27:30.980
And if you're gonna turn in a circle,

27:30.980 --> 27:33.020
you have to take that inertia into account.

27:33.020 --> 27:35.140
And if you're gonna throw a thing,

27:35.140 --> 27:37.940
you've got, all of that has to be included

27:38.620 --> 27:41.180
in the model of what you're trying to do.

27:41.180 --> 27:44.140
So the robot needs to have some idea or expectation

27:44.140 --> 27:48.180
of what that weight is, and then sort of predict.

27:48.180 --> 27:49.620
Think a couple of seconds ahead,

27:49.620 --> 27:54.540
how do I manage now my body plus this big heavy thing

27:54.540 --> 27:58.660
together to get, and still maintain balance, right?

27:58.660 --> 28:03.660
And so that's a big change for us.

28:03.700 --> 28:05.460
And I think the tools we've built

28:05.500 --> 28:08.540
are really allowing that to happen quickly now.

28:08.540 --> 28:10.260
Some of those motions that you saw

28:10.260 --> 28:12.500
in that most recent video,

28:12.500 --> 28:14.940
we were able to create in a matter of days.

28:14.940 --> 28:16.540
It used to be that it took six months

28:16.540 --> 28:18.620
to do anything new on the robot.

28:18.620 --> 28:20.860
And now we're starting to develop the tools

28:20.860 --> 28:22.500
that let us do that in a matter of days.

28:22.500 --> 28:24.780
And so we think that's really exciting.

28:24.780 --> 28:27.480
That means that the ability to create new behaviors

28:27.480 --> 28:31.900
for the robot is gonna be a quicker process.

28:31.900 --> 28:35.060
So being able to explicitly model new things

28:35.060 --> 28:37.620
that it might need to pick up, new types of things.

28:37.620 --> 28:40.300
And to some degree, you don't wanna have

28:40.300 --> 28:45.220
to pay too much attention to each specific thing, right?

28:45.220 --> 28:47.060
There's sort of a generalization here.

28:48.980 --> 28:50.980
Obviously, when you grab a thing,

28:50.980 --> 28:53.860
you have to conform your hand, your end effector,

28:53.860 --> 28:55.660
to the surface of that shape.

28:55.660 --> 28:57.440
But once it's in your hands,

28:57.440 --> 29:00.020
it's probably just the mass and inertia that matter.

29:00.020 --> 29:03.460
And the shape may not be as important.

29:03.460 --> 29:07.100
And so in some ways, you wanna pay attention

29:07.100 --> 29:08.660
to that detailed shape.

29:08.660 --> 29:11.180
In others, you wanna generalize it and say,

29:11.180 --> 29:13.060
well, all I really care about

29:13.060 --> 29:14.540
is the center of mass of this thing,

29:14.540 --> 29:17.180
especially if I'm gonna throw it up on that scaffolding.

29:17.180 --> 29:19.020
And it's easier if the body is rigid.

29:19.020 --> 29:20.460
What if there's some,

29:20.460 --> 29:22.660
doesn't it throw like a sandbag type thing?

29:22.660 --> 29:26.260
That tool bag had loose stuff in it.

29:26.260 --> 29:28.280
So it managed that.

29:28.280 --> 29:30.620
There are harder things that we haven't done yet.

29:30.620 --> 29:32.460
We could have had a big jointed thing

29:32.460 --> 29:35.040
or I don't know, a bunch of loose wire or rope.

29:35.040 --> 29:36.460
What about carrying another robot?

29:36.460 --> 29:37.300
How about that?

29:37.300 --> 29:41.100
Yeah, we haven't done that yet.

29:41.100 --> 29:41.940
Carry spot.

29:41.940 --> 29:43.420
I guess we did a little bit of a,

29:43.420 --> 29:45.980
we did a little skit around Christmas

29:45.980 --> 29:48.820
where we had two spots holding up another spot

29:48.820 --> 29:51.140
that was trying to put a bow on a tree.

29:51.140 --> 29:53.380
So I guess we're doing that in a small way.

29:54.500 --> 29:56.180
Okay, that's pretty good.

29:56.180 --> 29:58.220
Let me ask the all important question.

29:58.220 --> 30:00.100
Do you know how much Atlas can curl?

30:02.660 --> 30:03.500
Have you?

30:04.660 --> 30:06.860
I mean, for us humans,

30:06.860 --> 30:09.820
that's really one of the most fundamental questions

30:09.820 --> 30:11.900
you can ask another human being.

30:11.900 --> 30:13.220
Curl?

30:13.220 --> 30:14.420
Bench?

30:14.420 --> 30:17.180
It probably can't curl as much as we can yet.

30:17.180 --> 30:20.020
But a metric that I think is interesting

30:20.020 --> 30:23.760
is another way of looking at that strength

30:23.760 --> 30:25.140
is the box jump.

30:25.140 --> 30:29.100
So how high of a box can you jump onto?

30:29.100 --> 30:30.140
Good question.

30:30.140 --> 30:32.980
And Atlas, I don't know the exact height.

30:32.980 --> 30:34.940
It was probably a meter high or something like that.

30:34.940 --> 30:38.340
It was a pretty tall jump that Atlas was able to manage

30:38.340 --> 30:40.100
when we last tried to do this.

30:40.100 --> 30:44.440
And I have video of my chief technical officer

30:44.440 --> 30:45.340
doing the same jump.

30:45.340 --> 30:47.020
And he really struggled.

30:47.020 --> 30:47.860
Oh, the human.

30:47.860 --> 30:50.220
The human, getting all the way on top of this box.

30:50.220 --> 30:52.280
But then Atlas was able to do it.

30:54.180 --> 30:56.800
We're now thinking about the next generation of Atlas.

30:56.800 --> 30:58.780
And we're probably gonna be in the realm

30:58.780 --> 31:02.780
of a person can't do it with the next generation.

31:02.780 --> 31:05.300
The robots, the actuators are gonna get stronger

31:05.300 --> 31:07.820
where it really is the case that at least some

31:07.820 --> 31:10.180
of these joints, some of these motions will be stronger.

31:10.180 --> 31:11.860
And to understand how high I can jump,

31:11.860 --> 31:14.260
you probably had to do quite a bit of testing.

31:14.260 --> 31:16.180
Oh yeah, and there's lots of videos of it trying

31:16.180 --> 31:19.140
and failing and that's all.

31:19.140 --> 31:20.960
We don't always release those videos,

31:20.960 --> 31:22.860
but they're a lot of fun to look at.

31:23.960 --> 31:26.540
So we'll talk a little bit about that.

31:27.420 --> 31:28.900
Can you talk to the jumping?

31:28.900 --> 31:30.140
Because you talked about the walking

31:30.140 --> 31:31.980
and it took a long time, many, many years

31:31.980 --> 31:34.020
to get the walking to be natural.

31:34.020 --> 31:37.400
But there's also really natural looking,

31:38.620 --> 31:40.940
robust, resilient jumping.

31:40.940 --> 31:43.220
How hard is it to do the jumping?

31:43.220 --> 31:45.560
Well again, this stuff has really evolved rapidly

31:45.560 --> 31:46.940
in the last few years.

31:46.940 --> 31:48.700
The first time we did a somersault,

31:50.100 --> 31:53.060
there was a lot of kind of manual iteration.

31:53.060 --> 31:54.540
What is the trajectory?

31:54.540 --> 31:55.580
How hard do you throw?

31:55.620 --> 31:58.780
In fact, in these early days,

31:58.780 --> 32:02.380
I actually would, when I'd see early experiments

32:02.380 --> 32:04.980
that the team was doing, I might make suggestions

32:04.980 --> 32:06.460
about how to change the technique.

32:06.460 --> 32:09.100
Again, kind of borrowing from my own intuition

32:09.100 --> 32:10.380
about how backflips work.

32:12.220 --> 32:13.780
But frankly, they don't need that anymore.

32:13.780 --> 32:17.500
So in the early days, you had to iterate kind of

32:17.500 --> 32:20.840
in almost a manual way, trying to change these trajectories

32:20.840 --> 32:23.740
of the arms or the legs to try to get

32:24.260 --> 32:27.260
a successful backflip to happen.

32:27.260 --> 32:29.540
But more recently, we're running

32:29.540 --> 32:34.300
these model predictive control techniques

32:34.300 --> 32:37.420
where we're able to, the robot essentially can think

32:37.420 --> 32:40.120
in advance for the next second or two

32:40.120 --> 32:43.100
about how its motion is going to transpire.

32:43.100 --> 32:45.980
And you can solve for optimal trajectories

32:45.980 --> 32:47.720
to get from A to B.

32:47.720 --> 32:50.020
So this is happening in a much more natural way,

32:50.020 --> 32:53.020
and we're really seeing an acceleration happen

32:53.020 --> 32:55.340
in the development of these behaviors.

32:55.340 --> 33:00.140
Again, partly due to these optimization techniques,

33:00.140 --> 33:01.900
sometimes learning techniques.

33:03.580 --> 33:07.860
So it's hard in that there's a lot of mathematics

33:07.860 --> 33:12.300
in behind it, but we're figuring that out.

33:12.300 --> 33:14.860
So you can do model predictive control for,

33:16.260 --> 33:18.220
I mean, I don't even understand what that looks like

33:18.220 --> 33:20.700
when the entire robot is in the air,

33:20.700 --> 33:22.780
flying and doing a backflip.

33:23.780 --> 33:26.260
But that's the cool part, right?

33:26.260 --> 33:30.060
So the physics, we can calculate physics pretty well

33:30.060 --> 33:33.620
using Newton's laws about how it's going to evolve

33:33.620 --> 33:36.860
over time, and the sick trick,

33:36.860 --> 33:39.820
which was a front somersault with a half twist

33:39.820 --> 33:41.200
is a good example, right?

33:42.620 --> 33:46.660
You saw the robot on various versions of that trick,

33:46.660 --> 33:49.420
I've seen it land in different configurations,

33:49.420 --> 33:51.980
and it still manages to stabilize itself.

33:51.980 --> 33:56.100
And so what this model predictive control means is,

33:56.100 --> 34:01.100
again, in real time, the robot is projecting ahead

34:01.260 --> 34:04.500
a second into the future and sort of exploring options.

34:04.500 --> 34:06.980
And if I move my arm a little bit more this way,

34:06.980 --> 34:08.620
how is that going to affect the outcome?

34:08.620 --> 34:11.360
And so it can do these calculations, many of them,

34:12.780 --> 34:16.560
and basically solve for, given where I am now,

34:16.560 --> 34:18.540
maybe I took off a little bit screwy

34:18.540 --> 34:21.180
from how I had planned, I can adjust.

34:21.220 --> 34:22.620
So you're adjusting in the air.

34:22.620 --> 34:24.100
Adjust on the fly.

34:24.100 --> 34:27.900
So the model predictive control lets you adjust on the fly.

34:27.900 --> 34:31.180
And of course, I think this is what people adapt as well.

34:31.180 --> 34:34.580
We, when we do it, even a gymnastics trick,

34:34.580 --> 34:38.220
we try to set it up so it's close to the same every time,

34:38.220 --> 34:40.460
but we figured out how to do some adjustment on the fly,

34:40.460 --> 34:41.980
and now we're starting to figure out

34:41.980 --> 34:44.700
that the robots can do this adjustment on the fly as well,

34:44.700 --> 34:46.260
using these techniques.

34:46.260 --> 34:47.160
In the air.

34:48.040 --> 34:50.520
It's so, I mean, it just feels,

34:50.520 --> 34:53.040
from a robotics perspective, just surreal.

34:53.040 --> 34:53.880
Well, that's sort of the,

34:53.880 --> 34:55.760
you talked about under-actuated, right?

34:55.760 --> 34:58.360
So when you're in the air,

34:58.360 --> 35:00.640
there's some things you can't change, right?

35:00.640 --> 35:03.160
You can't change the momentum while it's in the air,

35:03.160 --> 35:05.440
because you can't apply an external force, a torque,

35:05.440 --> 35:07.760
and so the momentum isn't going to change.

35:07.760 --> 35:09.500
So how do you work within the constraint

35:09.500 --> 35:13.120
of that fixed momentum to still get from A to B

35:13.120 --> 35:14.320
where you want to be?

35:14.320 --> 35:15.920
That's really under-actuated.

35:17.880 --> 35:18.840
You're in the air.

35:18.840 --> 35:21.760
I mean, you become a drone for a brief moment in time.

35:21.760 --> 35:23.920
No, you're not even a drone, because you can't-

35:23.920 --> 35:24.760
Can't hover.

35:24.760 --> 35:25.600
You can't hover.

35:25.600 --> 35:27.720
You're going to impact soon.

35:27.720 --> 35:28.560
Be ready.

35:28.560 --> 35:29.400
Yeah.

35:29.400 --> 35:31.360
Are you considered like a hover type thing, or no?

35:31.360 --> 35:32.200
No.

35:32.200 --> 35:33.020
It's too much weight.

35:33.020 --> 35:36.080
I mean, it's just, it's just incredible.

35:37.200 --> 35:40.000
And just even to have the guts to try backflip

35:40.000 --> 35:43.640
with such a large body, that's wild.

35:43.640 --> 35:44.720
But like-

35:44.720 --> 35:46.520
We definitely broke a few robots trying.

35:46.520 --> 35:49.320
But that's where the build it, break it, fix it,

35:50.520 --> 35:52.720
strategy comes in, gotta be willing to break.

35:52.720 --> 35:55.240
And what ends up happening is you end up,

35:55.240 --> 35:58.160
by breaking the robot repeatedly, you find the weak points,

35:58.160 --> 35:59.520
and then you end up redesigning it

35:59.520 --> 36:02.240
so it doesn't break so easily next time, you know?

36:02.240 --> 36:05.040
Through the breaking process, you learn a lot,

36:05.040 --> 36:07.640
like a lot of lessons, and you keep improving,

36:07.640 --> 36:09.560
not just how to make the backflip work,

36:09.560 --> 36:10.400
but everything just-

36:10.400 --> 36:11.720
And how to build the machine better.

36:11.720 --> 36:13.300
Yeah. Yeah.

36:13.300 --> 36:15.580
I mean, is there something about just the guts

36:15.580 --> 36:19.760
to come up with an idea of saying, you know what,

36:19.760 --> 36:21.780
let's try to make it do a backflip?

36:21.780 --> 36:24.020
Well, I think the courage to do a backflip

36:24.020 --> 36:26.740
in the first place, and to not worry too much

36:26.740 --> 36:28.740
about the ridicule of somebody saying,

36:28.740 --> 36:31.340
why the heck are you doing backflips with robots?

36:31.340 --> 36:33.420
Because a lot of people have asked that, you know?

36:33.420 --> 36:35.740
Why are you doing this?

36:35.740 --> 36:38.580
Why go to the moon in this decade

36:38.580 --> 36:40.220
and do the other things, JFK?

36:40.220 --> 36:43.500
It's not because it's easy, because it's hard.

36:43.500 --> 36:44.820
Yeah, exactly.

36:46.820 --> 36:47.980
Don't ask questions.

36:47.980 --> 36:49.700
Okay, so the jumping.

36:49.700 --> 36:51.340
I mean, there's a lot of incredible stuff.

36:51.340 --> 36:53.740
If we can just rewind a little bit

36:53.740 --> 36:57.940
to the DARPA Robotics Challenge in 2015, I think,

36:57.940 --> 37:00.300
which was, for people who are familiar

37:00.300 --> 37:02.360
with the DARPA challenges,

37:02.360 --> 37:05.740
it was first with autonomous vehicles,

37:05.740 --> 37:07.900
and there's a lot of interesting challenges around that.

37:07.900 --> 37:09.540
And the DARPA Robotics Challenge

37:09.540 --> 37:13.500
was when humanoid robots were tasked

37:13.500 --> 37:16.500
to do all kinds of manipulation,

37:19.620 --> 37:24.300
walking, driving a car, all these kinds of challenges,

37:24.300 --> 37:26.980
with, if I remember correctly,

37:26.980 --> 37:31.660
some slight capability to communicate with humans,

37:31.660 --> 37:34.140
but the communication was very poor.

37:34.140 --> 37:37.540
So it basically has to be almost entirely autonomous.

37:37.580 --> 37:39.460
It could have periods where the communication

37:39.460 --> 37:40.660
was entirely interrupted,

37:40.660 --> 37:42.660
and the robot had to be able to proceed.

37:42.660 --> 37:44.500
But you could provide some high-level guidance

37:44.500 --> 37:48.620
to the robot, basically low-bandwidth communications

37:48.620 --> 37:49.820
to steer it.

37:49.820 --> 37:53.020
I watched that challenge with kind of tears in my eyes,

37:53.020 --> 37:54.540
eating popcorn.

37:54.540 --> 37:55.380
Well, it was hard.

37:55.380 --> 37:56.220
Us too.

37:56.220 --> 38:00.460
But I wasn't personally losing

38:00.460 --> 38:02.540
hundreds of thousands, millions of dollars,

38:02.540 --> 38:05.620
and many years of incredible hard work

38:05.620 --> 38:08.460
by some of the most brilliant roboticists in the world.

38:08.460 --> 38:11.460
So that was why the tragic, that's why the tears came.

38:11.460 --> 38:15.220
So anyway, what have you, just looking back to that time,

38:15.220 --> 38:17.380
what have you learned from that experience?

38:18.340 --> 38:20.820
Maybe if you could describe what it was,

38:20.820 --> 38:23.140
sort of the setup for people who haven't seen it.

38:23.140 --> 38:24.820
Well, so there was a contest

38:24.820 --> 38:27.820
where a bunch of different robots

38:27.820 --> 38:30.260
were asked to do a series of tasks,

38:30.260 --> 38:31.900
some of those that you mentioned,

38:31.900 --> 38:34.740
drive a vehicle, get out, open a door,

38:34.740 --> 38:37.380
go identify a valve, shut a valve,

38:37.380 --> 38:42.380
use a tool to maybe cut a hole in a surface,

38:43.020 --> 38:47.820
and then crawl over some stairs and maybe some rough terrain.

38:47.820 --> 38:52.820
So it was, the idea was have a general purpose robot

38:53.020 --> 38:55.020
that could do lots of different things.

38:57.220 --> 39:00.540
Had to be mobility and manipulation on board perception.

39:01.540 --> 39:05.100
And there was a contest, which DARPA likes,

39:05.100 --> 39:06.940
at the time was running,

39:06.940 --> 39:10.140
sort of follow on to the grand challenge,

39:10.140 --> 39:14.140
which was let's try to push vehicle autonomy along, right?

39:14.140 --> 39:17.940
They encouraged people to build autonomous cars.

39:17.940 --> 39:21.460
So they're trying to basically push an industry forward.

39:21.460 --> 39:26.460
And we were asked, our role in this was to build a humanoid

39:26.980 --> 39:31.980
at the time it was our sort of first generation Atlas robot.

39:33.020 --> 39:37.020
And we built maybe 10 of them.

39:37.020 --> 39:38.820
I don't remember the exact number.

39:39.700 --> 39:43.460
And DARPA distributed those to various teams

39:44.500 --> 39:47.180
that sort of won a contest,

39:47.180 --> 39:50.900
showed that they could program these robots

39:50.900 --> 39:53.020
and then use them to compete against each other.

39:53.020 --> 39:55.140
And then other robots were introduced as well.

39:55.140 --> 39:56.620
Some teams built their own robots.

39:56.620 --> 40:00.500
Carnegie Mellon, for example, built their own robot.

40:00.500 --> 40:03.020
And all these robots competed

40:03.020 --> 40:07.700
to see who could sort of get through this maze the fastest.

40:07.700 --> 40:09.700
And again, I think the purpose

40:09.700 --> 40:12.060
was to kind of push the whole industry forward.

40:13.180 --> 40:16.180
We provided the robot and some baseline software,

40:16.180 --> 40:19.460
but we didn't actually compete as a participant

40:20.460 --> 40:25.460
where we were trying to drive the robot through this maze.

40:25.700 --> 40:28.540
We were just trying to support the other teams.

40:28.540 --> 40:32.140
It was humbling because it was really a hard task.

40:32.140 --> 40:34.340
And honestly, the tears were

40:34.340 --> 40:36.740
because mostly the robots didn't do it.

40:36.740 --> 40:41.380
They fell down repeatedly.

40:41.380 --> 40:44.020
It was hard to get through this contest.

40:44.020 --> 40:48.100
Some did, and they were rewarded and won.

40:48.180 --> 40:50.420
But it was humbling because of just how hard,

40:50.420 --> 40:51.740
these tasks weren't all that hard.

40:51.740 --> 40:54.140
A person could have done it very easily.

40:54.140 --> 40:56.660
But it was really hard to get the robots to do it.

40:57.660 --> 41:00.660
The general nature of it, the variety of it.

41:00.660 --> 41:01.500
The variety.

41:01.500 --> 41:04.500
And also that I don't know if the tasks were sort of,

41:07.020 --> 41:10.300
the task in themselves help us understand

41:10.300 --> 41:12.020
what is difficult and what is not.

41:12.020 --> 41:13.380
I don't know if that was obvious

41:13.380 --> 41:15.700
before the contest was designed.

41:15.700 --> 41:17.420
So you kind of tried to figure that out.

41:17.900 --> 41:22.660
I think Atlas is really a general robot platform.

41:22.660 --> 41:24.700
And it's perhaps not best suited

41:24.700 --> 41:27.660
for the specific tasks of that contest.

41:27.660 --> 41:31.380
For example, probably the hardest task

41:31.380 --> 41:33.300
is not the driving of the car,

41:33.300 --> 41:35.740
but getting in and out of the car.

41:35.740 --> 41:39.380
And Atlas probably, if you were to design a robot

41:39.380 --> 41:42.500
that can get into the car easily and get out easily,

41:42.500 --> 41:45.420
you probably would not make Atlas that particular car.

41:46.020 --> 41:47.500
The robot was a little bit big

41:47.500 --> 41:49.660
to get in and out of that car.

41:49.660 --> 41:50.500
It doesn't fit, yeah.

41:50.500 --> 41:53.060
But this is the curse of a general purpose robot.

41:53.060 --> 41:56.020
That they're not perfect at any one thing,

41:56.020 --> 41:58.740
but they might be able to do a wide variety of things.

41:58.740 --> 42:03.740
And that is the goal at the end of the day.

42:04.940 --> 42:08.140
I think we all wanna build general purpose robots

42:08.140 --> 42:11.140
that can be used for lots of different activities.

42:11.140 --> 42:12.020
But it's hard.

42:12.020 --> 42:17.020
And the wisdom in building successful robots

42:18.100 --> 42:19.940
up until this point have been,

42:19.940 --> 42:22.620
go build a robot for a specific task

42:22.620 --> 42:24.380
and it'll do it very well.

42:24.380 --> 42:26.660
And as long as you control that environment,

42:26.660 --> 42:27.940
it'll operate perfectly.

42:27.940 --> 42:31.260
But robots need to be able to deal with uncertainty.

42:31.260 --> 42:34.460
If they're gonna be useful to us in the future,

42:34.460 --> 42:38.700
they need to be able to deal with unexpected situations.

42:38.700 --> 42:40.780
And that's sort of the goal of a general purpose

42:40.780 --> 42:42.820
or multi-purpose robot.

42:42.820 --> 42:44.460
And that's just darn hard.

42:44.460 --> 42:45.300
And so some of the, yeah,

42:45.300 --> 42:46.740
there's these curious little failures.

42:46.740 --> 42:48.620
Like I remember one of the,

42:48.620 --> 42:53.460
a robot, the first time you start to try to push

42:53.460 --> 42:55.180
on the world with a robot,

42:55.180 --> 42:58.540
you forget that the world pushes back

42:58.540 --> 43:02.140
and will push you over if you're not ready for it.

43:02.140 --> 43:05.380
And the robot reached to grab the door handle.

43:05.380 --> 43:08.300
I think it missed the grasp of the door handle.

43:08.300 --> 43:10.860
Was expecting that its hand was on the door handle.

43:10.860 --> 43:12.860
And so when it tried to turn the knob,

43:12.860 --> 43:14.140
it just threw itself over.

43:14.140 --> 43:16.500
It didn't realize, oh, I had missed the door handle.

43:16.500 --> 43:18.580
I didn't have, I didn't,

43:18.580 --> 43:20.980
I was expecting a force back from the door.

43:20.980 --> 43:21.900
It wasn't there.

43:21.900 --> 43:23.620
And then I lost my balance.

43:23.620 --> 43:25.460
So these little simple things

43:25.460 --> 43:27.620
that you and I would take totally for granted

43:27.620 --> 43:31.420
and deal with the robots don't know how to deal with yet.

43:31.420 --> 43:32.660
And so you have to start to deal

43:32.660 --> 43:35.180
with all of those circumstances.

43:35.180 --> 43:38.340
Well, I think a lot of us experience this

43:38.340 --> 43:42.540
in even when sober, but drunk too.

43:42.540 --> 43:45.940
Sort of you pick up a thing and expect it to be,

43:45.940 --> 43:47.500
what is it, heavy?

43:47.500 --> 43:48.980
And it turns out to be light.

43:48.980 --> 43:49.860
Yeah, and then you, whoa.

43:49.860 --> 43:50.700
Oh yeah.

43:50.700 --> 43:52.140
And then, so the same,

43:52.140 --> 43:53.660
and I'm sure if your depth perception

43:53.660 --> 43:55.580
for whatever reason is screwed up,

43:55.580 --> 43:58.100
if you're drunk or some other reason,

43:58.100 --> 44:01.060
and then you think you're putting your hand on the table

44:01.060 --> 44:04.380
and you miss it, I mean, it's the same kind of situation.

44:04.380 --> 44:06.100
But there's a-

44:06.100 --> 44:06.940
Which is why you need to be able

44:06.940 --> 44:08.940
to predict forward just a little bit.

44:08.940 --> 44:10.060
And so that's where this model

44:10.060 --> 44:11.740
of predictive control stuff comes in.

44:11.740 --> 44:14.500
Predict forward what you think's gonna happen.

44:14.500 --> 44:16.580
And then if that does happen, you're in good shape.

44:16.580 --> 44:17.700
If something else happens,

44:17.700 --> 44:19.100
you better start predicting again.

44:19.100 --> 44:24.100
So like regenerate a plan when you don't.

44:24.620 --> 44:29.620
I mean, that also requires a very fast feedback loop

44:30.620 --> 44:33.700
of updating what your prediction,

44:33.700 --> 44:36.340
how it matches to the actual real world.

44:36.340 --> 44:38.500
Yeah, those things have to run pretty quickly.

44:38.500 --> 44:40.700
What's the challenge of running things pretty quickly?

44:40.700 --> 44:45.700
A thousand hertz of acting and sensing quickly.

44:47.020 --> 44:49.420
You know, there's a few different layers of that.

44:49.420 --> 44:51.380
You want, at the lowest level,

44:51.380 --> 44:54.580
you like to run things typically at around a thousand hertz,

44:54.580 --> 44:57.220
which means that at each joint of the robot,

44:57.340 --> 44:59.940
you're measuring position or force

44:59.940 --> 45:02.260
and then trying to control your actuator,

45:02.260 --> 45:04.900
whether it's a hydraulic or electric motor,

45:04.900 --> 45:07.420
trying to control the force coming out of that actuator.

45:07.420 --> 45:10.380
And you wanna do that really fast,

45:10.380 --> 45:11.660
something like a thousand hertz.

45:11.660 --> 45:14.180
And that means you can't have too much calculation

45:14.180 --> 45:15.820
going on at that joint.

45:16.940 --> 45:18.780
But that's pretty manageable these days

45:18.780 --> 45:20.780
and it's fairly common.

45:20.780 --> 45:22.060
And then there's another layer

45:22.060 --> 45:24.380
that you're probably calculating, you know,

45:24.420 --> 45:27.900
maybe at 100 hertz, maybe 10 times slower,

45:27.900 --> 45:30.980
which is now starting to look at the overall body motion

45:30.980 --> 45:35.980
and thinking about the larger physics of the robot.

45:37.500 --> 45:39.460
And then there's yet another loop

45:39.460 --> 45:41.420
that's probably happening a little bit slower,

45:41.420 --> 45:43.260
which is where you start to bring, you know,

45:43.260 --> 45:46.340
your perception and your vision and things like that.

45:46.340 --> 45:48.860
And so you need to run all of these loops

45:48.860 --> 45:50.540
sort of simultaneously.

45:50.540 --> 45:54.300
You do have to manage your computer time

45:54.300 --> 45:57.540
so that you can squeeze in all the calculations you need

45:57.540 --> 45:59.980
in real time in a very consistent way.

46:01.540 --> 46:05.180
And the amount of calculation we can do

46:05.180 --> 46:07.460
is increasing as computers get better,

46:07.460 --> 46:08.700
which means we can start to do

46:08.700 --> 46:10.580
more sophisticated calculations.

46:10.580 --> 46:15.580
I can have a more complex model doing my forward prediction

46:15.740 --> 46:19.380
and that might allow me to do even better predictions

46:19.380 --> 46:20.660
as I get better and better.

46:20.660 --> 46:24.220
And it used to be, again, we had, you know,

46:25.140 --> 46:29.380
10 years ago, we had to have pretty simple models

46:29.380 --> 46:32.300
that we were running, you know, at those fast rates

46:32.300 --> 46:34.620
because the computers weren't as capable

46:34.620 --> 46:38.460
about calculating forward with a sophisticated model.

46:38.460 --> 46:42.780
But as computation gets better, we can do more of that.

46:42.780 --> 46:46.620
What about the actual pipeline of software engineering?

46:46.620 --> 46:49.220
How easy it is to keep updating Atlas,

46:49.220 --> 46:51.540
like do continuous development on it?

46:51.540 --> 46:54.500
So how many computers are on there?

46:54.500 --> 46:56.260
Is there a nice pipeline?

46:56.260 --> 47:00.380
It's an important part of building a team around it,

47:00.380 --> 47:04.020
which means, you know, you need to also have

47:04.020 --> 47:06.180
software tools, simulation tools, you know,

47:06.180 --> 47:11.180
so we have always made strong use

47:11.220 --> 47:14.820
of physics-based simulation tools to do.

47:14.820 --> 47:19.300
Some of this calculation, basically test it in simulation

47:19.300 --> 47:21.060
before you put it on the robot,

47:21.100 --> 47:23.260
but you also want the same code that you're running

47:23.260 --> 47:25.060
in simulation to be the same code

47:25.060 --> 47:26.780
you're running on the hardware.

47:26.780 --> 47:30.300
And so even getting to the point where it was the same code

47:30.300 --> 47:32.060
going from one to the other,

47:32.060 --> 47:34.660
we probably didn't really get that working until,

47:34.660 --> 47:37.580
you know, a few years, several years ago.

47:37.580 --> 47:39.740
But that was a, you know, that was a bit of a milestone.

47:39.740 --> 47:42.660
And so you want to work, certainly work these pipelines

47:42.660 --> 47:44.620
so that you can make it as easy as possible

47:44.620 --> 47:47.100
and have a bunch of people working in parallel,

47:47.100 --> 47:49.140
especially when, you know, we only have, you know,

47:49.180 --> 47:51.020
four of the Atlas robots,

47:51.020 --> 47:54.020
the modern Atlas robots at the company.

47:54.020 --> 47:55.940
And, you know, we probably have, you know,

47:55.940 --> 47:59.660
40 developers there all trying to gain access to it.

47:59.660 --> 48:01.980
And so you need to share resources

48:01.980 --> 48:04.980
and use some of the software pipeline.

48:04.980 --> 48:06.940
Well, that's a really exciting step to be able to run

48:06.940 --> 48:10.420
the exact same code in simulation as on the actual robot.

48:10.420 --> 48:13.420
How hard is it to do realistic simulation,

48:14.020 --> 48:17.020
physics-based simulation of Atlas such that,

48:17.020 --> 48:20.340
I mean, the dream is like, if it works in simulation,

48:20.340 --> 48:21.900
it works perfectly in reality.

48:21.900 --> 48:25.580
How hard is it to sort of keep working on closing that gap?

48:25.580 --> 48:28.220
The root of some of our physics-based simulation tools

48:28.220 --> 48:29.980
really started at MIT,

48:29.980 --> 48:34.980
and we built some good physics-based modeling tools there.

48:35.980 --> 48:37.380
The early days of the company,

48:37.380 --> 48:39.100
we were trying to develop those tools

48:39.100 --> 48:40.620
as a commercial product.

48:40.700 --> 48:42.260
So we continued to develop them.

48:42.260 --> 48:44.860
It wasn't a particularly successful commercial product,

48:44.860 --> 48:46.100
but we ended up with some nice

48:46.100 --> 48:47.460
physics-based simulation tools

48:47.460 --> 48:49.660
so that when we started doing legged robotics again,

48:49.660 --> 48:51.900
we had a really nice tool to work with.

48:51.900 --> 48:53.860
And the things we paid attention to

48:53.860 --> 48:57.700
were things that weren't necessarily handled very well

48:57.700 --> 48:59.860
in the commercial tools you could buy off the shelf,

48:59.860 --> 49:04.100
like interaction with the world, like foot-ground contact.

49:04.100 --> 49:06.500
So trying to model those contact

49:06.500 --> 49:11.500
events well in a way that captured

49:11.820 --> 49:14.500
the important parts of the interaction

49:14.500 --> 49:17.980
was a really important element to get right,

49:17.980 --> 49:20.980
and to also do in a way that was computationally feasible

49:20.980 --> 49:23.580
and could run fast.

49:23.580 --> 49:26.420
Because if your simulation runs too slow,

49:26.420 --> 49:28.020
then your developers are sitting around

49:28.020 --> 49:29.900
waiting for stuff to run and compile.

49:29.900 --> 49:33.020
So it's always about efficiency.

49:33.100 --> 49:34.620
So that's been a big part of it.

49:34.620 --> 49:37.220
I think developing those tools in parallel

49:37.220 --> 49:39.900
to the development of the platform

49:39.900 --> 49:43.300
and trying to scale them has really been essential,

49:43.300 --> 49:46.620
I'd say, to us being able to assemble a team

49:46.620 --> 49:48.060
of people that could do this.

49:48.060 --> 49:50.620
Yeah, how to simulate contact periods,

49:50.620 --> 49:54.020
so foot-ground contact, but sort of for manipulation.

49:55.060 --> 49:57.460
Because don't you ever have to do that.

49:57.460 --> 49:58.300
You can't do that.

49:58.300 --> 49:59.140
You can't do that.

49:59.140 --> 49:59.980
You can't do that.

49:59.980 --> 50:00.820
You can't do that.

50:00.820 --> 50:01.660
You can't do that.

50:02.100 --> 50:06.420
Because don't you want to model all kinds of surfaces?

50:06.420 --> 50:09.980
Yeah, so it will be even more complex with manipulation

50:09.980 --> 50:12.660
because there's a lot more going on, you know?

50:12.660 --> 50:14.660
And you need to capture, I don't know,

50:14.660 --> 50:18.900
things slipping and moving in your hand.

50:20.700 --> 50:24.100
It's a level of complexity that I think goes above

50:24.100 --> 50:27.780
foot-ground contact when you really start

50:27.780 --> 50:29.460
doing dexterous manipulation.

50:29.460 --> 50:31.500
So there's challenges ahead still.

50:32.340 --> 50:34.260
So how far are we away from me being able to walk

50:34.260 --> 50:37.620
with Atlas in the sand along the beach

50:37.620 --> 50:40.540
and us both drinking a beer?

50:42.540 --> 50:43.900
Out of a can, out of a can.

50:43.900 --> 50:45.460
Maybe Atlas could spill his beer

50:45.460 --> 50:47.260
because he's got nowhere to put it.

50:48.860 --> 50:50.460
Atlas could walk on the sand.

50:50.460 --> 50:51.300
So can it?

50:51.300 --> 50:52.460
Yeah, yeah.

50:52.460 --> 50:55.700
I mean, have we really had him out on the beach?

50:55.700 --> 50:57.820
You know, we take them outside often,

50:57.820 --> 50:59.660
rocks, hills, that sort of thing,

50:59.660 --> 51:02.100
deep in or just around our lab in Waltham.

51:02.100 --> 51:04.980
We probably haven't been on the sand, but I'm...

51:04.980 --> 51:05.820
So soft surfaces.

51:05.820 --> 51:07.780
I don't doubt that we could deal with it.

51:07.780 --> 51:10.220
We might have to spend a little bit of time

51:10.220 --> 51:13.340
to sort of make that work, but we did take,

51:13.340 --> 51:18.340
we had to take Big Dog to Thailand years ago

51:20.020 --> 51:23.220
and we did this great video of the robot

51:24.060 --> 51:27.540
walking in the sand, walking into the ocean

51:27.580 --> 51:30.420
up to, I don't know, its belly or something like that

51:30.420 --> 51:32.180
and then turning around and walking out,

51:32.180 --> 51:35.020
all while playing some cool beach music.

51:35.020 --> 51:37.780
Great show, but then we didn't really clean the robot off

51:37.780 --> 51:39.540
and the salt water was really hard on it.

51:39.540 --> 51:42.340
So we put it in a box, shipped it back.

51:42.340 --> 51:45.740
By the time it came back, we had some problems with corrosion.

51:45.740 --> 51:48.020
So it's a salt water, it's not like...

51:48.020 --> 51:49.180
Salt stuff.

51:49.180 --> 51:51.100
It's not like sand getting into the components

51:51.100 --> 51:52.220
or something like this.

51:52.220 --> 51:54.580
But I'm sure if this is a big priority,

51:54.580 --> 51:56.620
you can make it waterproof or something.

51:57.060 --> 51:59.580
That just wasn't our goal at the time.

51:59.580 --> 52:03.580
Well, it's a personal goal of mine to walk along the beach.

52:03.580 --> 52:04.780
But it's a human problem too.

52:04.780 --> 52:07.340
You get sand everywhere, it's just a jam mess.

52:08.420 --> 52:10.340
So soft surfaces are okay.

52:10.340 --> 52:13.820
So, I mean, can we just linger on the robotics challenge?

52:13.820 --> 52:18.820
There was a pile of rubble they had to walk over.

52:21.940 --> 52:23.980
How difficult is that task?

52:23.980 --> 52:26.420
In the early days of developing Big Dog,

52:27.220 --> 52:30.180
the loose rock was the epitome of the hard walking surface.

52:30.180 --> 52:32.260
Because you step down and then the rock,

52:32.260 --> 52:35.420
and you had these little point feet on the robot,

52:35.420 --> 52:36.780
and the rock can roll.

52:38.340 --> 52:41.140
And you have to deal with that last minute

52:41.140 --> 52:43.460
change in your foot placement.

52:43.460 --> 52:45.420
Yeah, so you step on a thing

52:45.420 --> 52:47.340
and that thing responds to you stepping on it.

52:47.340 --> 52:50.700
Yeah, and it moves where your point of support is.

52:50.700 --> 52:54.420
And so it's really, that became kind of the essence

52:54.420 --> 52:55.260
of the test.

52:55.260 --> 52:57.620
And so that was the beginning of us starting

52:57.620 --> 53:01.580
to build rock piles in our parking lots.

53:01.580 --> 53:04.460
And we would actually build boxes full of rocks

53:04.460 --> 53:06.140
and bring them into the lab.

53:06.140 --> 53:07.860
And then we would have the robots walking

53:07.860 --> 53:09.260
across these boxes of rocks

53:09.260 --> 53:11.900
because that became the essential test.

53:12.900 --> 53:14.660
So you mentioned Big Dog,

53:14.660 --> 53:16.420
can we maybe take a stroll

53:16.420 --> 53:18.420
through the history of Boston Dynamics?

53:18.420 --> 53:21.420
So what and who is Big Dog?

53:21.420 --> 53:23.100
By the way, is who,

53:24.500 --> 53:27.860
do you try not to anthropomorphize the robots?

53:27.860 --> 53:31.620
Do you try not to, do you try to remember that they're,

53:31.620 --> 53:32.860
this is like the division I have

53:32.860 --> 53:35.020
because for me it's impossible.

53:35.020 --> 53:38.180
For me there's a magic to the being that is a robot.

53:38.180 --> 53:40.420
It is not human, but it is,

53:42.140 --> 53:46.180
the same magic that a living being has

53:46.180 --> 53:48.700
when it moves about the world is there in the robot.

53:48.700 --> 53:51.860
So I don't know what question I'm asking,

53:51.860 --> 53:54.420
but should I say what or who, I guess?

53:54.420 --> 53:57.180
Who is Big Dog, what is Big Dog?

53:57.180 --> 54:00.420
Well, I'll say to address the medic question,

54:00.420 --> 54:02.820
we don't try to draw hard lines around it

54:02.820 --> 54:05.300
being an it or a him or a her.

54:07.220 --> 54:08.780
It's okay, right?

54:08.780 --> 54:13.100
People, I think part of the magic of these kinds of machines

54:13.100 --> 54:18.100
is by nature of their organic movement of their dynamics.

54:18.940 --> 54:22.580
We tend to want to identify with them.

54:22.580 --> 54:25.980
We tend to look at them and sort of attribute

54:25.980 --> 54:29.460
maybe feeling to that because we've only seen

54:29.460 --> 54:31.740
things that move like this that were alive.

54:32.620 --> 54:35.620
And so this is an opportunity.

54:35.620 --> 54:40.620
It means that you could have feelings for a machine

54:41.740 --> 54:43.780
and people have feelings for their cars.

54:43.780 --> 54:46.340
They get attracted to them, attached to them.

54:46.340 --> 54:49.340
So that's inherently could be a good thing

54:49.340 --> 54:52.420
as long as we manage what that interaction is.

54:52.420 --> 54:56.340
So we don't put strong boundaries around this

54:56.340 --> 54:58.220
and ultimately think it's a benefit,

54:58.220 --> 55:01.220
but it's also can be a bit of a curse

55:01.220 --> 55:03.660
because I think people look at these machines

55:04.580 --> 55:06.780
and they attribute a level of intelligence

55:06.780 --> 55:08.180
that the machines don't have.

55:08.180 --> 55:09.020
Why?

55:09.020 --> 55:11.180
Because again, they've seen things move like this

55:11.180 --> 55:15.980
that were living beings, which are intelligent.

55:15.980 --> 55:18.820
And so they want to attribute intelligence to the robots

55:18.820 --> 55:19.980
that isn't appropriate yet,

55:19.980 --> 55:22.380
even though they move like an intelligent being.

55:22.380 --> 55:24.340
But you try to acknowledge

55:24.340 --> 55:27.060
that the anthropomorphization is there

55:27.060 --> 55:30.780
and try to, first of all, acknowledge that it's there.

55:31.700 --> 55:32.820
And have a little fun with it.

55:32.820 --> 55:35.460
You know, our most recent video,

55:35.460 --> 55:40.020
it's just kind of fun, you know, to look at the robot.

55:40.020 --> 55:43.140
We started off the video with Atlas

55:44.140 --> 55:47.980
kind of looking around for where the bag of tools was

55:47.980 --> 55:49.820
because the guy up on the scaffolding says,

55:49.820 --> 55:51.140
send me some tools.

55:51.140 --> 55:54.580
Atlas has to kind of look around and see where they are.

55:54.580 --> 55:56.620
And there's a little personality there.

55:56.620 --> 55:58.700
That is fun, it's entertaining,

55:58.700 --> 56:00.100
it makes our jobs interesting.

56:00.100 --> 56:03.780
And I think in the long run can enhance interaction

56:03.780 --> 56:07.380
between humans and robots in a way that isn't available

56:07.380 --> 56:09.380
to machines that don't move that way.

56:09.380 --> 56:11.460
This is something to me personally is very interesting.

56:11.460 --> 56:16.420
I happen to have a lot of legged robots.

56:18.340 --> 56:21.580
I hope to have a lot of spots in my possession.

56:22.900 --> 56:24.780
I'm interested in celebrating robotics

56:24.780 --> 56:25.820
and celebrating companies.

56:25.820 --> 56:27.260
And I also don't want to,

56:27.260 --> 56:29.860
companies that do incredible stuff like Boston Dynamics.

56:29.860 --> 56:34.620
And there's, you know, I'm a little crazy.

56:34.620 --> 56:38.020
And you say you don't want to, you want to align,

56:38.020 --> 56:39.780
you want to help the company.

56:40.020 --> 56:43.660
I ultimately want a company like Boston Dynamics to succeed.

56:43.660 --> 56:45.580
And part of that we'll talk about, you know,

56:45.580 --> 56:48.300
success kind of requires making money.

56:48.300 --> 56:52.540
And so the kind of stuff I'm particularly interested in

56:52.540 --> 56:54.660
may not be the thing that makes money in the short term.

56:54.660 --> 56:57.020
I can make an argument that it will in the long term.

56:57.020 --> 57:00.020
But the kind of stuff I've been playing with

57:00.020 --> 57:04.820
is a robust way of having the quadrupeds,

57:04.820 --> 57:07.140
the robot dogs communicate in motion

57:07.140 --> 57:08.500
with their body movement.

57:08.500 --> 57:10.900
The same kind of stuff you do with a dog.

57:10.900 --> 57:15.100
But not hard-coded, but in a robust way.

57:15.100 --> 57:18.500
And be able to communicate excitement or fear,

57:18.500 --> 57:20.900
boredom, all these kinds of stuff.

57:20.900 --> 57:25.900
And I think as a base layer of function of behavior

57:26.500 --> 57:27.900
to add on top of a robot,

57:27.900 --> 57:30.220
I think that's a really powerful way

57:30.220 --> 57:33.100
to make the robot more usable for humans

57:33.100 --> 57:33.940
for whatever application.

57:33.940 --> 57:35.460
I think it's gonna be really important.

57:35.460 --> 57:39.420
And it's a thing we're beginning to pay attention to.

57:40.820 --> 57:42.940
We really want to start,

57:42.940 --> 57:45.140
a differentiator for the company has always been,

57:45.140 --> 57:46.980
we really want the robot to work.

57:46.980 --> 57:48.460
We want it to be useful.

57:50.340 --> 57:52.700
Making it work at first meant

57:52.700 --> 57:54.660
the legged locomotion really works.

57:54.660 --> 57:57.060
It can really get around and it doesn't fall down.

57:58.820 --> 58:02.140
But beyond that, now it needs to be a useful tool.

58:02.140 --> 58:05.300
And our customers are, for example,

58:06.140 --> 58:07.340
factory owners, people who are running

58:07.340 --> 58:09.860
a process manufacturing facility.

58:09.860 --> 58:11.460
And the robot needs to be able to get through

58:11.460 --> 58:14.580
this complex facility in a reliable way,

58:14.580 --> 58:16.180
taking measurements.

58:17.700 --> 58:21.380
We need, for people who are operating those robots,

58:21.380 --> 58:23.620
to understand what the robots are doing.

58:23.620 --> 58:25.620
If the robot gets into, needs help,

58:25.620 --> 58:29.020
or is in trouble or something,

58:29.020 --> 58:31.060
it needs to be able to communicate.

58:31.060 --> 58:34.340
And a physical indication of some sort,

58:35.140 --> 58:36.660
so that a person looks at the robot and goes,

58:36.660 --> 58:38.460
oh, I know what that robot's doing.

58:38.460 --> 58:41.100
That robot's going to go take measurements

58:41.100 --> 58:43.900
of my vacuum pump with its thermal camera.

58:45.220 --> 58:47.900
You want to be able to indicate that.

58:47.900 --> 58:52.420
And where even just the robot's about to turn,

58:52.420 --> 58:55.460
in front of you and maybe indicate that it's going to turn.

58:55.460 --> 58:58.260
And so you sort of see and can anticipate its motion.

58:58.260 --> 59:00.140
So these, this kind of communication

59:00.140 --> 59:02.380
is going to become more and more important.

59:02.380 --> 59:04.340
It wasn't sort of our starting point.

59:05.980 --> 59:09.740
But now that the robots are really out in the world

59:09.740 --> 59:11.860
and we have about 1,000 of them out

59:11.860 --> 59:13.420
with customers right now,

59:14.460 --> 59:18.420
this layer of physical indication,

59:18.420 --> 59:21.060
I think is going to become more and more important.

59:21.060 --> 59:22.940
We'll talk about where it goes,

59:22.940 --> 59:24.580
because there's a lot of interesting possibilities.

59:24.580 --> 59:27.020
But if you can return back to the origins

59:27.020 --> 59:30.180
of Boston Dynamics with, so that the more research,

59:30.180 --> 59:33.580
the R&D side, before we talk about

59:33.580 --> 59:36.140
how to build robots at scale.

59:36.140 --> 59:39.180
So Big Dog, who's Big Dog?

59:39.180 --> 59:43.180
So the company started in 1992.

59:44.020 --> 59:47.020
And in probably 2003,

59:50.580 --> 59:55.300
I believe is when we took a contract from DARP,

59:55.300 --> 59:57.820
so basically 10 years, 11 years.

59:58.900 --> 01:00:00.020
We weren't doing robotics.

01:00:00.860 --> 01:00:02.540
We did a little bit of robotics with Sony.

01:00:02.540 --> 01:00:05.380
They had a Aibo, their Aibo robot.

01:00:05.380 --> 01:00:07.140
We were developing some software for that

01:00:07.140 --> 01:00:08.900
that kind of got us a little bit involved

01:00:08.900 --> 01:00:10.540
with robotics again.

01:00:10.540 --> 01:00:13.460
Then there's this opportunity to do a DARPA contract

01:00:13.460 --> 01:00:17.900
where they wanted to build a robot dog.

01:00:17.900 --> 01:00:21.420
And we won a contract to build that.

01:00:21.420 --> 01:00:24.660
And so that was the genesis of Big Dog.

01:00:24.660 --> 01:00:26.460
And it was a quadruped.

01:00:26.460 --> 01:00:28.180
And it was the first time we built a robot

01:00:28.180 --> 01:00:29.820
that had everything on board.

01:00:30.620 --> 01:00:32.260
You could actually take the robot out into the wild

01:00:32.260 --> 01:00:33.100
and operate it.

01:00:33.100 --> 01:00:34.420
So it had an onboard power plant.

01:00:34.420 --> 01:00:36.420
It had onboard computers.

01:00:36.420 --> 01:00:40.580
It had hydraulic actuators that needed to be cooled.

01:00:40.580 --> 01:00:43.060
So we had cooling systems built in.

01:00:43.060 --> 01:00:45.700
Everything integrated into the robot.

01:00:45.700 --> 01:00:48.740
And that was a pretty rough start, right?

01:00:48.740 --> 01:00:52.020
It was 10 years that we were not a robotics company.

01:00:52.020 --> 01:00:53.340
We were a simulation company.

01:00:53.340 --> 01:00:55.820
And then we had to build a robot in about a year.

01:00:55.820 --> 01:00:58.180
So that was a little bit of a rough transition.

01:01:00.820 --> 01:01:03.700
Can you just comment on the roughness of that transition?

01:01:03.700 --> 01:01:08.700
Because Big Dog, I mean, this is this big quadruped,

01:01:10.020 --> 01:01:11.500
four legs robot.

01:01:11.500 --> 01:01:13.740
We built a few different versions of them.

01:01:13.740 --> 01:01:15.940
But the first one, the very earliest ones,

01:01:15.940 --> 01:01:17.020
didn't work very well.

01:01:17.020 --> 01:01:18.500
And we would take them out.

01:01:18.500 --> 01:01:23.500
And it was hard to get a go-kart engine

01:01:23.860 --> 01:01:25.100
driving a hydraulic pump.

01:01:25.100 --> 01:01:27.020
Oh, is that what it was?

01:01:27.020 --> 01:01:31.740
And having that all work while trying to get

01:01:31.740 --> 01:01:34.540
the robot to stabilize itself.

01:01:34.540 --> 01:01:36.140
So what was the power plant?

01:01:36.140 --> 01:01:37.300
What was the engine?

01:01:37.300 --> 01:01:39.700
It seemed like my vague recollection.

01:01:41.860 --> 01:01:42.700
I don't know.

01:01:42.700 --> 01:01:45.260
It felt very loud and aggressive

01:01:45.260 --> 01:01:48.100
and kind of thrown together.

01:01:48.100 --> 01:01:49.540
Oh, it absolutely was, right?

01:01:49.540 --> 01:01:51.700
We weren't trying to design

01:01:51.700 --> 01:01:53.980
the best robot hardware at the time.

01:01:54.020 --> 01:01:57.380
And we wanted to buy an off-the-shelf engine.

01:01:57.380 --> 01:02:00.740
And so many of the early versions of Big Dog

01:02:00.740 --> 01:02:04.460
had literally go-kart engines or something like that.

01:02:04.460 --> 01:02:05.300
Are those gas-powered?

01:02:05.300 --> 01:02:07.980
Yeah, gas-powered two-stroke engines.

01:02:07.980 --> 01:02:09.460
And the reason why it was two-stroke

01:02:09.460 --> 01:02:12.180
is two-stroke engines are lighter weight.

01:02:12.180 --> 01:02:13.380
That they're also,

01:02:13.380 --> 01:02:15.900
and we generally didn't put mufflers on them

01:02:15.900 --> 01:02:17.260
because we're trying to save the weight.

01:02:17.260 --> 01:02:18.900
And we didn't care about the noise.

01:02:18.900 --> 01:02:21.700
And so these things were horribly loud.

01:02:21.700 --> 01:02:23.140
But we're trying to manage weight

01:02:23.140 --> 01:02:25.580
because managing weight in a legged robot

01:02:25.580 --> 01:02:28.740
is always important because it has to carry everything.

01:02:28.740 --> 01:02:30.660
That said, that thing was big.

01:02:30.660 --> 01:02:31.780
Well, I've seen the videos of it.

01:02:31.780 --> 01:02:35.180
Yeah, I mean, the early versions stood about,

01:02:35.180 --> 01:02:37.700
I don't know, belly high, chest high.

01:02:38.900 --> 01:02:42.100
They probably weighed maybe a couple of hundred pounds.

01:02:42.100 --> 01:02:46.540
But over the course of probably five years,

01:02:47.980 --> 01:02:50.020
we were able to get that robot

01:02:51.020 --> 01:02:55.500
to really manage a remarkable level of rough terrain.

01:02:55.500 --> 01:02:57.940
So we started out with just walking on the flat,

01:02:57.940 --> 01:02:59.380
and then we started walking on rocks,

01:02:59.380 --> 01:03:03.100
and then inclines, and then mud, and then slippery mud.

01:03:03.100 --> 01:03:05.780
And by the end of that program,

01:03:05.780 --> 01:03:09.900
we were convinced that legged locomotion in a robot

01:03:09.900 --> 01:03:11.420
could actually work.

01:03:11.420 --> 01:03:14.220
Because going into it, we didn't know that.

01:03:14.220 --> 01:03:17.780
We had built quadrupeds at MIT,

01:03:17.780 --> 01:03:21.660
but they used a giant hydraulic pump in the lab.

01:03:21.660 --> 01:03:23.740
They used a giant computer that was in the lab.

01:03:23.740 --> 01:03:26.300
They were always tethered to the lab.

01:03:26.300 --> 01:03:27.700
This was the first time something

01:03:27.700 --> 01:03:29.780
that was sort of self-contained

01:03:29.780 --> 01:03:33.980
walked around in the world and balanced.

01:03:33.980 --> 01:03:36.500
But the purpose was to prove to ourself

01:03:36.500 --> 01:03:38.540
that the legged locomotion could really work.

01:03:38.540 --> 01:03:41.820
And so Big Dog really cut that open for us.

01:03:41.820 --> 01:03:43.900
And it was the beginning of what became

01:03:43.900 --> 01:03:45.020
a whole series of robots.

01:03:45.020 --> 01:03:47.140
So once we showed to DARPA

01:03:47.180 --> 01:03:49.900
that you could make a legged robot that could work,

01:03:49.900 --> 01:03:53.300
there was a period at DARPA where robotics got really hot,

01:03:53.300 --> 01:03:55.820
and there was lots of different programs.

01:03:55.820 --> 01:03:58.500
And we were able to build other robots.

01:03:58.500 --> 01:04:00.820
We built other quadrupeds to hand,

01:04:00.820 --> 01:04:04.780
like LS3, designed to carry heavy loads.

01:04:04.780 --> 01:04:08.380
We built Cheetah, which was designed to explore

01:04:08.380 --> 01:04:11.340
what are the limits to how fast you can run.

01:04:11.340 --> 01:04:16.220
We began to build sort of a portfolio of machines

01:04:16.220 --> 01:04:20.220
and software that let us build not just one robot,

01:04:20.220 --> 01:04:21.420
but a whole family of robots.

01:04:21.420 --> 01:04:23.620
To push the limits in all kinds of directions.

01:04:23.620 --> 01:04:25.500
Yeah, and to discover those principles.

01:04:25.500 --> 01:04:27.540
You asked earlier about the art and science

01:04:27.540 --> 01:04:29.380
of legged locomotion.

01:04:29.380 --> 01:04:32.540
We were able to develop principles of legged locomotion

01:04:32.540 --> 01:04:35.380
so that we knew how to build a small legged robot

01:04:35.380 --> 01:04:36.220
or a big one.

01:04:36.220 --> 01:04:41.220
So leg length was now a parameter that we could play with.

01:04:41.380 --> 01:04:43.740
Payload was a parameter we could play with.

01:04:43.740 --> 01:04:46.700
So we built the LS3, which was an 800 pound robot

01:04:46.700 --> 01:04:49.580
designed to carry a 400 pound payload.

01:04:49.580 --> 01:04:51.540
And we learned the design rules,

01:04:51.540 --> 01:04:53.660
basically developed the design rules.

01:04:53.660 --> 01:04:57.820
How do you scale different robot systems to, you know,

01:04:57.820 --> 01:05:01.100
their terrain, to their walking speed, to their payload?

01:05:02.020 --> 01:05:05.020
So when was Spotborn?

01:05:06.220 --> 01:05:11.220
Around 2012 or so.

01:05:11.860 --> 01:05:15.380
So again, almost 10 years into sort of a run with DARPA

01:05:15.380 --> 01:05:17.980
where we built a bunch of different quadrupeds.

01:05:17.980 --> 01:05:19.620
We had sort of a different thread

01:05:19.620 --> 01:05:21.500
where we started building humanoids.

01:05:23.180 --> 01:05:27.220
We saw that probably an end was coming

01:05:27.220 --> 01:05:29.780
where the government was gonna kind of back off

01:05:29.780 --> 01:05:32.500
from a lot of robotics investment.

01:05:32.500 --> 01:05:37.500
And in order to maintain progress,

01:05:37.860 --> 01:05:39.660
we just deduced that, well,

01:05:39.660 --> 01:05:41.620
we probably need to sell ourselves to somebody

01:05:41.620 --> 01:05:43.980
who wants to continue to invest in this area.

01:05:43.980 --> 01:05:44.980
And that was Google.

01:05:45.900 --> 01:05:50.900
And so at Google, we would meet regularly with Larry Page

01:05:51.980 --> 01:05:53.900
and Larry just started asking us, you know,

01:05:53.900 --> 01:05:55.980
well, what's your product gonna be?

01:05:55.980 --> 01:05:59.020
And, you know, the logical thing,

01:05:59.020 --> 01:06:01.700
the thing that we had the most history with

01:06:01.700 --> 01:06:05.580
that we wanted to continue developing was our quadruped.

01:06:05.580 --> 01:06:07.020
But we knew it needed to be smaller.

01:06:07.020 --> 01:06:09.180
We knew it couldn't have a gas engine.

01:06:09.180 --> 01:06:12.660
We thought it probably couldn't be hydraulically actuated.

01:06:12.660 --> 01:06:16.460
So that began the process of exploring

01:06:16.460 --> 01:06:18.700
if we could migrate to a smaller,

01:06:18.700 --> 01:06:21.660
electrically actuated robot.

01:06:21.660 --> 01:06:23.660
And that was really the genesis of Spot.

01:06:24.860 --> 01:06:28.180
So not a gas engine and the actuators are electric.

01:06:28.180 --> 01:06:29.020
Yes.

01:06:29.020 --> 01:06:33.060
So can you maybe comment on what it's like at Google

01:06:33.060 --> 01:06:36.180
with working with Larry Page, having those meetings

01:06:36.180 --> 01:06:39.620
and thinking of what will a robot look like

01:06:39.620 --> 01:06:42.540
that could be built at scale?

01:06:42.540 --> 01:06:45.660
Like starting to think about a product.

01:06:45.660 --> 01:06:48.780
Larry always liked the toothbrush test.

01:06:48.780 --> 01:06:51.100
He wanted products that you used every day.

01:06:54.340 --> 01:06:57.180
What they really wanted was, you know,

01:06:57.180 --> 01:06:59.100
a consumer level product,

01:06:59.100 --> 01:07:01.100
something that would work in your house.

01:07:02.100 --> 01:07:06.300
We didn't think that was the right next thing to do

01:07:06.300 --> 01:07:08.780
because to be a consumer level product,

01:07:08.780 --> 01:07:11.260
cost is going to be very important.

01:07:11.260 --> 01:07:14.340
Probably needed to cost a few thousand dollars.

01:07:14.340 --> 01:07:16.260
And we were building these machines

01:07:16.260 --> 01:07:18.300
that cost hundreds of thousands of dollars,

01:07:18.300 --> 01:07:20.220
maybe a million dollars to build.

01:07:20.220 --> 01:07:22.300
Of course, we were only building two,

01:07:22.300 --> 01:07:25.660
but we didn't see how to get all the way

01:07:25.660 --> 01:07:27.100
to this consumer level product.

01:07:27.100 --> 01:07:27.940
In a short amount of time.

01:07:27.940 --> 01:07:30.020
In a short amount of time.

01:07:30.020 --> 01:07:34.980
And he suggested that we make the robots really inexpensive.

01:07:34.980 --> 01:07:37.340
And part of our philosophy has always been

01:07:38.300 --> 01:07:40.580
build the best hardware you can.

01:07:40.580 --> 01:07:44.300
Make the machine operate well

01:07:44.300 --> 01:07:48.740
so that you're trying to solve, you know,

01:07:48.740 --> 01:07:52.220
discover the hard problem that you don't know about.

01:07:52.220 --> 01:07:55.060
Don't make it harder by building a crappy machine, basically.

01:07:55.060 --> 01:07:56.900
Build the best machine you can.

01:07:56.900 --> 01:07:58.420
There's plenty of hard problems to solve

01:07:58.420 --> 01:08:00.060
that are going to have to do with, you know,

01:08:00.060 --> 01:08:02.140
under actuated systems and balance.

01:08:03.020 --> 01:08:06.540
And so we wanted to build these high quality machines still.

01:08:06.540 --> 01:08:09.420
And we thought that was important for us to continue learning

01:08:09.420 --> 01:08:13.300
about really what was the important parts of,

01:08:13.300 --> 01:08:14.500
that make robots work.

01:08:16.500 --> 01:08:17.580
And so there was a little bit

01:08:17.580 --> 01:08:20.540
of a philosophical difference there that we,

01:08:20.540 --> 01:08:23.300
and so ultimately that's why we're building robots

01:08:23.300 --> 01:08:24.900
for the industrial sector now.

01:08:24.900 --> 01:08:29.300
Because the industry can afford a more expensive machine

01:08:29.300 --> 01:08:32.140
because, you know, their productivity depends

01:08:32.140 --> 01:08:33.900
on keeping their factory going.

01:08:33.900 --> 01:08:38.860
And so if Spot costs, you know, $100,000 or more,

01:08:38.860 --> 01:08:41.980
that's not such a big expense to them.

01:08:41.980 --> 01:08:43.300
Whereas at the consumer level,

01:08:43.300 --> 01:08:45.540
no one's going to buy a robot like that.

01:08:45.540 --> 01:08:47.700
And I think we might eventually get

01:08:47.700 --> 01:08:50.780
to a consumer level product that will be that cheap.

01:08:50.780 --> 01:08:53.140
But I think the path to getting there needs to go

01:08:53.140 --> 01:08:54.940
through these really nice machines

01:08:54.940 --> 01:08:57.740
so that we can then learn how to simplify.

01:08:57.740 --> 01:09:01.940
So what can you say to the almost engineering challenge

01:09:01.940 --> 01:09:06.100
of bringing down cost of a robot?

01:09:06.100 --> 01:09:10.020
So that presumably when you try to build the robot at scale,

01:09:10.020 --> 01:09:11.820
that also comes into play when you're trying

01:09:11.820 --> 01:09:15.180
to make money on a robot, even in the industrial setting.

01:09:15.180 --> 01:09:20.180
But how interesting, how challenging of a thing is that?

01:09:21.100 --> 01:09:25.700
In particular, probably new to an R&D company.

01:09:25.700 --> 01:09:27.780
Yeah, I'm glad you brought that last part up.

01:09:27.780 --> 01:09:31.380
The transition from an R&D company to a commercial company,

01:09:31.380 --> 01:09:32.860
that's the thing you worry about.

01:09:32.860 --> 01:09:34.340
You know, because you've got these engineers

01:09:34.340 --> 01:09:36.500
who love hard problems, who want to figure out

01:09:36.500 --> 01:09:38.020
how to make robots work.

01:09:38.020 --> 01:09:41.060
And you don't know if you have engineers that want to work

01:09:41.060 --> 01:09:43.540
on the quality and reliability and cost

01:09:43.540 --> 01:09:45.100
that is ultimately required.

01:09:47.060 --> 01:09:49.620
And indeed, you know, we have brought on a lot of new people

01:09:49.620 --> 01:09:52.140
who are inspired by those problems.

01:09:52.140 --> 01:09:56.780
But the big takeaway lesson for me is we have good people.

01:09:56.780 --> 01:09:59.620
We have engineers who want to solve problems.

01:09:59.620 --> 01:10:03.100
And the quality and cost and manufacturability

01:10:03.100 --> 01:10:05.100
is just another kind of problem.

01:10:05.100 --> 01:10:09.020
And because they're so invested in what we're doing,

01:10:09.020 --> 01:10:10.820
they're interested in and will go work

01:10:10.820 --> 01:10:13.380
on those problems as well.

01:10:13.380 --> 01:10:16.900
And so I think we're managing that transition very well.

01:10:16.900 --> 01:10:21.140
In fact, I'm really pleased that, I mean,

01:10:21.140 --> 01:10:23.300
it's a huge undertaking, by the way, right?

01:10:23.300 --> 01:10:27.380
So even having to get reliability

01:10:27.380 --> 01:10:30.380
to where it needs to be, we have to have fleets of robots

01:10:30.380 --> 01:10:33.980
that we're just operating 24-7 in our offices

01:10:33.980 --> 01:10:37.420
to go find those rare failures and eliminate them.

01:10:37.420 --> 01:10:39.500
It's just a totally different kind of activity

01:10:39.500 --> 01:10:42.100
than the research activity where you get it to work,

01:10:42.100 --> 01:10:46.340
you know, the one robot you have to work in a repeatable way.

01:10:47.100 --> 01:10:48.860
At the high stakes demo.

01:10:48.860 --> 01:10:50.060
It's just very different.

01:10:51.220 --> 01:10:54.260
But I think we're making remarkable progress, I guess.

01:10:54.260 --> 01:10:56.380
So one of the cool things I got a chance

01:10:56.380 --> 01:10:59.100
to visit Boston Dynamics, and I mean,

01:11:01.100 --> 01:11:03.660
one of the things that's really cool

01:11:03.660 --> 01:11:06.820
is to see a large number of robots moving about.

01:11:07.700 --> 01:11:10.140
Because I think one of the things you notice

01:11:10.140 --> 01:11:14.380
in the research environment at MIT, for example,

01:11:14.420 --> 01:11:16.540
I don't think anyone ever has a working robot

01:11:16.540 --> 01:11:17.660
for a prolonged period of time.

01:11:17.660 --> 01:11:19.500
Exactly.

01:11:19.500 --> 01:11:21.740
So like most robots are just sitting there

01:11:21.740 --> 01:11:25.700
in a sad state of despair, waiting to be born,

01:11:25.700 --> 01:11:28.380
brought to life for a brief moment of time.

01:11:28.380 --> 01:11:32.420
Just to have, I just remember there's a spot robot

01:11:32.420 --> 01:11:34.860
just had like a cowboy hat on

01:11:34.860 --> 01:11:37.060
and was just walking randomly for whatever reason.

01:11:37.060 --> 01:11:40.700
I don't even know, but there's a kind of sense

01:11:40.700 --> 01:11:43.460
of sentience to it because it doesn't seem

01:11:43.460 --> 01:11:45.660
like anybody was supervising it.

01:11:45.660 --> 01:11:46.500
It was just doing its thing.

01:11:46.500 --> 01:11:48.940
I'm gonna stop way short of the sentience.

01:11:48.940 --> 01:11:51.820
It is the case that if you come to our office today

01:11:51.820 --> 01:11:53.700
and walk around the hallways,

01:11:54.580 --> 01:11:56.420
you're gonna see a dozen robots

01:11:56.420 --> 01:11:59.180
just kind of walking around all the time.

01:11:59.180 --> 01:12:03.100
And that's really a reliability test for us.

01:12:03.100 --> 01:12:07.620
So we have these robots programmed to do autonomous missions,

01:12:07.620 --> 01:12:09.940
get up off their charging dock, walk around the building,

01:12:09.940 --> 01:12:11.940
collect data at a few different places

01:12:11.980 --> 01:12:13.100
and go sit back down.

01:12:13.100 --> 01:12:16.100
And we want that to be a very reliable process

01:12:16.100 --> 01:12:20.220
because that's what somebody who's running a brewery,

01:12:20.220 --> 01:12:23.060
a factory, that's what they need the robot to do.

01:12:23.060 --> 01:12:26.100
And so we have to dog food our own robot.

01:12:26.100 --> 01:12:28.300
We have to test it in that way.

01:12:28.300 --> 01:12:32.700
And so on a weekly basis, we have robots

01:12:32.700 --> 01:12:36.380
that are accruing something like 1,500

01:12:36.380 --> 01:12:39.100
or maybe 2,000 kilometers of walking

01:12:39.140 --> 01:12:43.540
and over 1,000 hours of operation every week.

01:12:43.540 --> 01:12:45.580
And that's something that almost,

01:12:45.580 --> 01:12:47.260
I don't think anybody else in the world can do

01:12:47.260 --> 01:12:49.020
because, A, you have to have a fleet of robots

01:12:49.020 --> 01:12:50.940
to just accrue that much information.

01:12:51.900 --> 01:12:55.180
You have to be willing to dedicate it to that test.

01:12:55.180 --> 01:12:58.020
And so that's essential.

01:12:58.020 --> 01:12:59.420
That's how you get the reliability.

01:12:59.420 --> 01:13:00.260
That's how you get it.

01:13:00.260 --> 01:13:01.580
What about some of the cost cutting

01:13:01.580 --> 01:13:04.020
from the manufacturer side?

01:13:04.020 --> 01:13:06.620
What have you learned from the manufacturer side

01:13:06.620 --> 01:13:08.940
of the transition from R&D?

01:13:09.620 --> 01:13:11.860
We're still learning a lot there.

01:13:11.860 --> 01:13:13.500
We're learning how to cast parts

01:13:13.500 --> 01:13:17.300
instead of mill it all out of billet aluminum.

01:13:18.460 --> 01:13:21.100
We're learning how to get plastic molded parts.

01:13:22.060 --> 01:13:24.660
And we're learning about how to control that process

01:13:24.660 --> 01:13:27.500
so that you can build the same robot twice in a row.

01:13:27.500 --> 01:13:28.740
There's a lot to learn there.

01:13:28.740 --> 01:13:31.100
And we're only partway through that process.

01:13:32.300 --> 01:13:36.380
We've set up a manufacturing facility in Waltham.

01:13:36.380 --> 01:13:39.460
It's about a mile from our headquarters.

01:13:39.460 --> 01:13:41.340
And we're doing final assembly and test

01:13:41.340 --> 01:13:44.780
of both spots and stretches at that factory.

01:13:44.780 --> 01:13:49.140
And it's hard because, to be honest,

01:13:49.140 --> 01:13:51.100
we're still iterating on the design of the robot.

01:13:51.100 --> 01:13:53.980
As we find failures from these reliability tests,

01:13:53.980 --> 01:13:56.020
we need to go engineer changes.

01:13:56.020 --> 01:13:58.420
And those changes need to now be propagated

01:13:58.420 --> 01:13:59.860
to the manufacturing line.

01:13:59.860 --> 01:14:01.220
And that's a hard process,

01:14:01.220 --> 01:14:03.980
especially when you wanna move as fast as we do.

01:14:04.020 --> 01:14:07.340
And that's been challenging.

01:14:07.340 --> 01:14:08.980
And it makes it, you know,

01:14:08.980 --> 01:14:11.100
the folks who are working supply chain,

01:14:11.100 --> 01:14:14.340
who are trying to get the cheapest parts for us,

01:14:14.340 --> 01:14:16.260
kind of requires that you buy a lot of them

01:14:16.260 --> 01:14:17.100
to make them cheap.

01:14:17.100 --> 01:14:19.300
And then we go change the design from underneath them.

01:14:19.300 --> 01:14:20.300
And they're like, what are you doing?

01:14:20.300 --> 01:14:23.580
And so, you know, getting everybody on the same page here,

01:14:23.580 --> 01:14:25.620
that, yep, we still need to move fast,

01:14:25.620 --> 01:14:28.620
but we also need to try to figure out how to reduce costs.

01:14:28.620 --> 01:14:30.060
That's one of the challenges

01:14:30.060 --> 01:14:32.340
of this migration we're going through.

01:14:32.340 --> 01:14:33.820
And over the past few years,

01:14:33.820 --> 01:14:35.700
challenges to the supply chain.

01:14:35.700 --> 01:14:37.340
I mean, I imagine you've been a part

01:14:37.340 --> 01:14:38.780
of a bunch of stressful meetings.

01:14:38.780 --> 01:14:42.260
Yeah, things got more expensive and harder to get.

01:14:42.260 --> 01:14:44.860
And yeah, so it's all been a challenge.

01:14:44.860 --> 01:14:47.020
Is there still room for simplification?

01:14:47.020 --> 01:14:48.620
Oh yeah, much more.

01:14:48.620 --> 01:14:51.220
And, you know, these are really just the first generation

01:14:51.220 --> 01:14:52.660
of these machines.

01:14:52.660 --> 01:14:54.820
We're already thinking about what the next generation

01:14:54.820 --> 01:14:56.900
of Spot's gonna look like.

01:14:56.900 --> 01:14:58.740
Spot was built as a platform.

01:14:58.740 --> 01:15:01.060
So you could put almost any sensor on it.

01:15:01.140 --> 01:15:03.500
We provided data communications,

01:15:03.500 --> 01:15:06.980
mechanical connections, power connections.

01:15:08.660 --> 01:15:11.140
But for example, in the applications

01:15:11.140 --> 01:15:12.380
that we're excited about,

01:15:12.380 --> 01:15:15.980
where you're monitoring these factories for their health,

01:15:17.140 --> 01:15:19.700
there's probably a simpler machine that we could build

01:15:19.700 --> 01:15:23.100
that's really focused on that use case.

01:15:23.100 --> 01:15:26.540
And that's the difference between the general purpose

01:15:26.540 --> 01:15:29.820
machine or the platform versus the purpose built machine.

01:15:29.820 --> 01:15:32.020
And so even though, even in the factory,

01:15:32.020 --> 01:15:35.260
we'd still like the robot to do lots of different tasks.

01:15:35.260 --> 01:15:38.180
If we really knew on day one that we're gonna be operating

01:15:38.180 --> 01:15:40.820
in a factory with these three sensors in it,

01:15:40.820 --> 01:15:42.700
we would have it all integrated in a package

01:15:42.700 --> 01:15:45.780
that would be easier, more, less expensive,

01:15:45.780 --> 01:15:47.140
and more reliable.

01:15:47.140 --> 01:15:49.020
So we're contemplating building, you know,

01:15:49.020 --> 01:15:50.620
a next generation of that machine.

01:15:50.620 --> 01:15:53.980
So we should mention that, so Spot,

01:15:53.980 --> 01:15:56.340
for people who somehow are not familiar,

01:15:56.900 --> 01:16:00.460
is a yellow robotic dog,

01:16:00.460 --> 01:16:04.940
and has been featured in many dance videos.

01:16:04.940 --> 01:16:07.060
It also has gained an arm.

01:16:08.140 --> 01:16:11.260
So what can you say about the arm that Spot has,

01:16:11.260 --> 01:16:13.940
about the challenges of this design

01:16:13.940 --> 01:16:15.580
and the manufacture of it?

01:16:15.580 --> 01:16:20.580
We think the future of mobile robots is mobile manipulation.

01:16:20.940 --> 01:16:24.860
That's where, you know, in the past 10 years,

01:16:24.860 --> 01:16:26.220
it was getting mobility to work,

01:16:26.220 --> 01:16:27.940
getting the leg of locomotion to work.

01:16:27.940 --> 01:16:31.180
If you ask what's the hard problem in the next 10 years,

01:16:31.180 --> 01:16:33.020
it's getting a mobile robot

01:16:33.020 --> 01:16:35.220
to do useful manipulation for you.

01:16:35.220 --> 01:16:37.860
And so we wanted Spot to have an arm

01:16:37.860 --> 01:16:40.580
to experiment with those problems.

01:16:42.460 --> 01:16:47.460
And the arm is almost as complex as the robot itself,

01:16:48.460 --> 01:16:52.020
you know, and it's an attachable payload.

01:16:52.380 --> 01:16:57.140
It has, you know, several motors and actuators and sensors.

01:16:57.140 --> 01:16:59.380
It has a camera in the end of its hand,

01:16:59.380 --> 01:17:02.460
so, you know, you can sort of see something,

01:17:03.780 --> 01:17:06.540
and the robot will control the motion of its hand

01:17:06.540 --> 01:17:08.020
to go pick it up autonomously.

01:17:08.020 --> 01:17:11.300
So in the same way the robot walks and balances,

01:17:11.300 --> 01:17:13.740
managing its own foot placement to stay balanced,

01:17:13.740 --> 01:17:17.260
we want manipulation to be mostly autonomous,

01:17:17.260 --> 01:17:19.940
where the robot, you indicate, okay, go grab that bottle,

01:17:19.940 --> 01:17:21.340
and then the robot will just go do it

01:17:21.340 --> 01:17:23.220
using the camera in its hand,

01:17:23.220 --> 01:17:26.660
and then sort of closing in on that, the grasp.

01:17:27.620 --> 01:17:29.660
But it's a whole nother complex robot

01:17:29.660 --> 01:17:32.260
on top of a complex legged robot.

01:17:32.260 --> 01:17:35.780
And so, and of course we made the hand

01:17:35.780 --> 01:17:38.740
look a little like a head, you know,

01:17:38.740 --> 01:17:42.420
because, again, we want it to be sort of identifiable.

01:17:42.420 --> 01:17:45.860
In the last year, a lot of our sales

01:17:45.860 --> 01:17:47.980
have been people who already have a robot

01:17:47.980 --> 01:17:50.660
now buying an arm to add to that robot.

01:17:50.660 --> 01:17:54.500
Oh, interesting, and so the arm is for sale.

01:17:54.500 --> 01:17:56.700
Oh yeah, oh yeah, it's an option.

01:17:56.700 --> 01:18:00.220
What's the interface like to work with the arm?

01:18:00.220 --> 01:18:04.340
Like is it pretty, so are they designed primarily,

01:18:04.340 --> 01:18:06.420
I guess just ask that question in general

01:18:06.420 --> 01:18:09.020
about robots from Boss of Dynamics.

01:18:09.020 --> 01:18:13.260
Is it designed to be easily and efficiently

01:18:13.260 --> 01:18:15.660
operated remotely by a human being,

01:18:15.660 --> 01:18:20.160
or is there also the capability to push towards autonomy?

01:18:20.820 --> 01:18:21.940
We want both.

01:18:23.460 --> 01:18:26.780
In the next version of the software that we release,

01:18:26.780 --> 01:18:29.100
which will be version 3.3,

01:18:29.100 --> 01:18:31.460
we're gonna offer the ability of,

01:18:31.460 --> 01:18:34.340
if you have an autonomous mission for the robot,

01:18:34.340 --> 01:18:35.980
we're gonna include the option

01:18:35.980 --> 01:18:37.140
that it can go through a door,

01:18:37.140 --> 01:18:38.740
which means it's gonna have to have an arm,

01:18:38.740 --> 01:18:41.420
and it's gonna have to use that arm to open the door.

01:18:41.420 --> 01:18:44.300
And so that'll be an autonomous manipulation task

01:18:44.300 --> 01:18:48.500
that just, you can program easily with the robot.

01:18:48.820 --> 01:18:52.060
Strictly through, we have a tablet interface,

01:18:52.060 --> 01:18:55.020
and so on the tablet, you sort of see the view

01:18:55.020 --> 01:18:58.780
that Spot sees, you say, there's the door handle,

01:18:58.780 --> 01:19:00.820
the hinges are on the left and it opens in,

01:19:00.820 --> 01:19:03.340
the rest is up to you, take care of it.

01:19:03.340 --> 01:19:04.980
So it just takes care of everything.

01:19:04.980 --> 01:19:09.940
Yeah, so we want, and for a task like opening doors,

01:19:09.940 --> 01:19:11.300
you can automate most of that,

01:19:11.300 --> 01:19:13.680
and we've automated a few other tasks.

01:19:13.720 --> 01:19:18.720
We had a customer who had a high-powered breaker switch,

01:19:19.560 --> 01:19:22.040
essentially, it's an electric utility,

01:19:22.040 --> 01:19:23.920
Ontario Power Generation.

01:19:24.800 --> 01:19:28.200
And they have to, when they're gonna disconnect

01:19:28.200 --> 01:19:30.800
their power supply, that could be a gas generator,

01:19:30.800 --> 01:19:33.240
could be a nuclear power plant, from the grid,

01:19:33.240 --> 01:19:35.520
you have to disconnect this breaker switch.

01:19:35.520 --> 01:19:38.920
Well, as you can imagine, there's hundreds or thousands

01:19:38.920 --> 01:19:42.400
of amps and volts involved in this breaker switch,

01:19:42.400 --> 01:19:43.600
and it's a dangerous event,

01:19:43.600 --> 01:19:45.960
because occasionally, you'll get what's called an arc flash,

01:19:45.960 --> 01:19:48.040
as you just do this disconnect,

01:19:48.040 --> 01:19:50.400
the power, the sparks jump across,

01:19:50.400 --> 01:19:52.300
and people die doing this.

01:19:53.280 --> 01:19:58.280
And so, Ontario Power Generation used our Spot and the arm

01:19:58.440 --> 01:20:02.920
through the interface to operate this disconnect

01:20:04.240 --> 01:20:06.280
in an interactive way.

01:20:06.280 --> 01:20:10.120
And they showed it to us, and we were so excited about it,

01:20:10.120 --> 01:20:12.360
and said, you know, I bet we can automate that task.

01:20:12.360 --> 01:20:16.400
And so, we got some examples of that breaker switch,

01:20:16.400 --> 01:20:18.640
and I believe in the next generation of software,

01:20:18.640 --> 01:20:21.680
now we're gonna deliver back to Ontario Power Generation,

01:20:21.680 --> 01:20:24.160
they're gonna be able to just point the robot

01:20:24.160 --> 01:20:28.520
at that breaker, they'll indicate that's the switch,

01:20:28.520 --> 01:20:30.200
there's sort of two actions you have to do,

01:20:30.200 --> 01:20:33.640
you have to flip up this little cover, press a button,

01:20:33.640 --> 01:20:37.560
then get a ratchet, stick it into a socket,

01:20:37.560 --> 01:20:41.200
and literally unscrew this giant breaker switch.

01:20:41.200 --> 01:20:43.120
So, there's a bunch of different tasks,

01:20:43.120 --> 01:20:44.680
and we basically automated them,

01:20:44.680 --> 01:20:47.560
so that the human says, okay, there's the switch,

01:20:47.560 --> 01:20:49.160
go do that part.

01:20:49.160 --> 01:20:51.280
That right there is the socket

01:20:51.280 --> 01:20:52.400
where you're gonna put your tool,

01:20:52.400 --> 01:20:54.160
and you're gonna open it up.

01:20:54.160 --> 01:20:57.800
And so, you can remotely sort of indicate this on the tablet,

01:20:57.800 --> 01:21:00.460
and then the robot just does everything in between.

01:21:00.460 --> 01:21:02.560
And it does everything, all the coordinated movement

01:21:02.560 --> 01:21:04.840
of all the different actuators that includes the body.

01:21:04.840 --> 01:21:06.320
Yeah, it maintains its balance,

01:21:06.320 --> 01:21:10.760
it walks itself into position, so it's within reach,

01:21:10.760 --> 01:21:14.600
and the arm is in a position where it can do the whole task.

01:21:14.600 --> 01:21:17.400
So, it manages the whole body.

01:21:17.400 --> 01:21:20.320
So, how does one become a big enough customer

01:21:20.320 --> 01:21:21.640
to request features?

01:21:21.640 --> 01:21:25.340
Because I personally want a robot that gets me a beer.

01:21:25.340 --> 01:21:29.040
I mean, that has to be one of the most requests,

01:21:29.040 --> 01:21:30.620
I suppose, in the industrial setting,

01:21:30.620 --> 01:21:33.440
that's a non-alcoholic beverage

01:21:34.080 --> 01:21:38.080
of picking up objects and bringing the objects to you.

01:21:38.080 --> 01:21:39.720
We love working with customers

01:21:39.720 --> 01:21:41.600
who have challenging problems like this,

01:21:41.600 --> 01:21:43.160
and this one in particular,

01:21:43.160 --> 01:21:46.120
because we felt like what they were doing,

01:21:46.120 --> 01:21:47.760
A, it was a safety feature,

01:21:47.760 --> 01:21:51.600
B, we saw that the robot could do it,

01:21:51.600 --> 01:21:53.560
because they teleoperated it the first time,

01:21:53.560 --> 01:21:55.840
probably took them an hour to do it the first time, right?

01:21:55.840 --> 01:21:58.200
But the robot was clearly capable.

01:21:58.200 --> 01:22:00.060
And we thought, oh, this is a great problem

01:22:00.060 --> 01:22:02.040
for us to work on to figure out

01:22:02.040 --> 01:22:03.880
how to automate a manipulation task.

01:22:03.880 --> 01:22:05.480
And so, we took it on,

01:22:05.480 --> 01:22:07.820
not because we were gonna make a bunch of money from it

01:22:07.820 --> 01:22:09.720
in selling the robot back to them,

01:22:09.720 --> 01:22:12.600
but because it motivated us to go solve

01:22:12.600 --> 01:22:15.500
what we saw as the next logical step.

01:22:15.500 --> 01:22:17.400
But many of our customers, in fact,

01:22:18.280 --> 01:22:21.480
we try to, our bigger customers,

01:22:21.480 --> 01:22:23.240
typically ones who are gonna run a utility

01:22:23.240 --> 01:22:25.720
or a factory or something like that,

01:22:25.720 --> 01:22:27.560
we take that kind of direction from them.

01:22:27.560 --> 01:22:29.120
And if they're, especially if they're gonna buy

01:22:29.120 --> 01:22:31.140
10 or 20 or 30 robots,

01:22:31.180 --> 01:22:33.160
and they say, I really need it to do this,

01:22:33.160 --> 01:22:35.020
well, that's exactly the right kind of problem

01:22:35.020 --> 01:22:37.020
that we wanna be working on.

01:22:37.020 --> 01:22:37.860
And so.

01:22:37.860 --> 01:22:39.540
Note to self, buy 10 spots

01:22:39.540 --> 01:22:43.580
and aggressively push for beer manipulation.

01:22:45.100 --> 01:22:47.140
I think it's fair to say it's notoriously difficult

01:22:47.140 --> 01:22:49.580
to make a lot of money as a robotics company.

01:22:50.580 --> 01:22:54.580
How can you make money as a robotics company?

01:22:54.580 --> 01:22:55.940
Can you speak to that?

01:22:55.940 --> 01:22:58.680
It seems that a lot of robotics companies fail.

01:22:59.680 --> 01:23:02.280
It's difficult to build robots.

01:23:02.280 --> 01:23:06.160
It's difficult to build robots at a low enough cost

01:23:06.160 --> 01:23:07.960
where customers, even the industrial setting,

01:23:07.960 --> 01:23:09.320
want to purchase them.

01:23:09.320 --> 01:23:11.600
And it's difficult to build robots that are useful,

01:23:11.600 --> 01:23:13.180
sufficiently useful.

01:23:13.180 --> 01:23:14.600
So what can you speak to?

01:23:14.600 --> 01:23:18.160
And Boston Dynamics has been successful

01:23:18.160 --> 01:23:21.240
for many years of finding a way to make money.

01:23:21.240 --> 01:23:23.080
Well, in the early days, of course,

01:23:23.080 --> 01:23:26.480
the money we made was from doing contract R&D work.

01:23:26.480 --> 01:23:29.840
And we made money, but we weren't growing

01:23:29.840 --> 01:23:31.840
and we weren't selling a product.

01:23:31.840 --> 01:23:34.320
And then we went through several owners

01:23:34.320 --> 01:23:39.320
who had a vision of not only developing advanced technology

01:23:40.680 --> 01:23:42.680
but eventually developing products.

01:23:42.680 --> 01:23:46.840
And so both Google and SoftBank and now Hyundai

01:23:46.840 --> 01:23:51.840
had that vision and were willing to provide that investment.

01:23:52.360 --> 01:23:56.360
Now, our discipline is that we need to go find applications

01:23:56.360 --> 01:23:59.360
that are broad enough that you could imagine

01:23:59.360 --> 01:24:00.960
selling thousands of robots.

01:24:00.960 --> 01:24:03.160
Because it doesn't work if you don't sell thousands

01:24:03.160 --> 01:24:04.560
or tens of thousands of robots.

01:24:04.560 --> 01:24:08.160
If you only sell hundreds, you will commercially fail.

01:24:08.160 --> 01:24:10.360
And that's where most of the small robot companies

01:24:10.360 --> 01:24:11.200
have died.

01:24:14.960 --> 01:24:18.960
And that's a challenge because, A, you need to field

01:24:19.960 --> 01:24:24.360
the robots, they need to start to become reliable.

01:24:24.360 --> 01:24:27.920
And as we said, that takes time and investment to get there.

01:24:29.240 --> 01:24:31.960
And so it really does take visionary investment

01:24:31.960 --> 01:24:32.880
to get there.

01:24:32.880 --> 01:24:36.360
But we believe that we are going to make money

01:24:36.360 --> 01:24:40.680
in this industrial monitoring space.

01:24:40.680 --> 01:24:45.680
Because if a chip fab, if the line goes down

01:24:46.680 --> 01:24:49.360
because a vacuum pump failed someplace,

01:24:49.360 --> 01:24:51.240
that can be a very expensive process.

01:24:51.240 --> 01:24:54.360
It can be a million dollars a day in lost production.

01:24:54.360 --> 01:24:56.440
Maybe you have to throw away some of the product

01:24:56.440 --> 01:24:57.920
along the way.

01:24:57.920 --> 01:25:00.800
And so the robot, if you can prevent that

01:25:00.800 --> 01:25:04.360
by inspecting the factory every single day,

01:25:04.360 --> 01:25:06.080
maybe every hour if you have to,

01:25:07.000 --> 01:25:09.640
there's a real return on investment there.

01:25:09.640 --> 01:25:12.840
But there needs to be a critical mass of this task.

01:25:13.040 --> 01:25:18.040
And we're focusing on a few that we believe are ubiquitous

01:25:19.400 --> 01:25:22.440
in the industrial production environment.

01:25:22.440 --> 01:25:25.680
And that's using a thermal camera to keep things

01:25:25.680 --> 01:25:28.760
from overheating, using an acoustic imager

01:25:28.760 --> 01:25:30.880
to find compressed air leaks,

01:25:30.880 --> 01:25:35.800
using visual cameras to read gauges, measuring vibration.

01:25:35.800 --> 01:25:38.400
These are standard things that you do

01:25:38.400 --> 01:25:41.800
to prevent unintended shutdown of a factory.

01:25:41.800 --> 01:25:45.600
And this takes place in a beer factory.

01:25:45.600 --> 01:25:47.360
We're working with AB InBev.

01:25:47.360 --> 01:25:49.240
It takes place in chip fabs.

01:25:49.240 --> 01:25:51.600
We're working with global foundries.

01:25:51.600 --> 01:25:54.080
It takes place in electric utilities

01:25:54.080 --> 01:25:55.640
and nuclear power plants.

01:25:55.640 --> 01:25:58.480
And so the same robot can be applied

01:25:58.480 --> 01:25:59.880
in all of these industries.

01:26:00.800 --> 01:26:04.040
And as I said, we have about,

01:26:04.040 --> 01:26:06.520
actually it's 1,100 spots out now,

01:26:06.520 --> 01:26:08.640
to really get profitability.

01:26:08.640 --> 01:26:10.320
We need to be at 1,000 a year,

01:26:10.360 --> 01:26:15.240
maybe 1,500 a year for that sort of part of the business.

01:26:15.240 --> 01:26:19.480
So it still needs to grow, but we're on a good path.

01:26:19.480 --> 01:26:21.480
So I think that's totally achievable.

01:26:21.480 --> 01:26:23.560
So the application should require

01:26:23.560 --> 01:26:25.760
crossing that 1,000 robot barrier.

01:26:25.760 --> 01:26:27.520
It really should, yeah.

01:26:27.520 --> 01:26:30.560
I wanna mention our second robot, Stretch.

01:26:30.560 --> 01:26:32.000
Yeah, tell me about Stretch.

01:26:32.000 --> 01:26:32.840
What's Stretch?

01:26:32.840 --> 01:26:33.840
Who's Stretch?

01:26:33.840 --> 01:26:36.200
Stretch started differently than Spot.

01:26:36.200 --> 01:26:39.560
Spot we built because we had decades of experience

01:26:39.560 --> 01:26:40.440
building quadrupeds.

01:26:40.440 --> 01:26:42.200
We just, we had it in our blood.

01:26:42.200 --> 01:26:44.240
We had to build a quadruped product,

01:26:44.240 --> 01:26:47.120
but we had to go figure out what the application was.

01:26:47.120 --> 01:26:52.120
And we actually discovered this factory patrol application,

01:26:52.480 --> 01:26:54.600
basically preventative maintenance,

01:26:54.600 --> 01:26:57.400
by seeing what our customers did with it.

01:26:57.400 --> 01:26:58.480
Stretch is very different.

01:26:58.480 --> 01:27:02.000
We started knowing that there was warehouses

01:27:02.000 --> 01:27:02.920
all over the world.

01:27:02.920 --> 01:27:06.680
There's shipping containers moving all around the world,

01:27:06.680 --> 01:27:09.280
full of boxes that are mostly being moved by hand.

01:27:10.800 --> 01:27:13.520
By some estimates, we think there's a trillion boxes,

01:27:13.520 --> 01:27:16.080
cardboard boxes, shipped around the world each year.

01:27:16.080 --> 01:27:18.240
And a lot of it's done manually.

01:27:18.240 --> 01:27:22.040
It became clear early on that there was an opportunity

01:27:22.040 --> 01:27:24.960
for a mobile robot in here to move boxes around.

01:27:24.960 --> 01:27:27.680
And the commercial experience has been very different

01:27:27.680 --> 01:27:30.440
between Stretch and with Spot.

01:27:30.440 --> 01:27:33.800
As soon as we started talking to people,

01:27:33.800 --> 01:27:35.880
potential customers, about what Stretch

01:27:35.920 --> 01:27:38.120
is gonna be used for, they immediately started saying,

01:27:38.120 --> 01:27:40.480
oh, I'll buy, I'll buy that robot.

01:27:40.480 --> 01:27:43.680
In fact, I'm gonna put in an order for 20 right now.

01:27:43.680 --> 01:27:46.880
We just started shipping the robot in January,

01:27:46.880 --> 01:27:49.000
after several years of development.

01:27:49.000 --> 01:27:49.840
This year.

01:27:49.840 --> 01:27:50.660
This year.

01:27:50.660 --> 01:27:52.840
So our first deliveries of Stretch to customers

01:27:52.840 --> 01:27:56.240
were DHL and Maersk in January.

01:27:56.240 --> 01:27:58.320
We're delivering the GAP right now.

01:27:58.320 --> 01:28:00.960
And we have about seven or eight other customers,

01:28:00.960 --> 01:28:03.480
all who've already agreed in advance

01:28:03.480 --> 01:28:05.440
to buy between 10 and 20 robots.

01:28:05.960 --> 01:28:07.920
And so we've already got commitments for a couple hundred

01:28:07.920 --> 01:28:08.840
of these robots.

01:28:10.120 --> 01:28:11.400
This one's gonna go, right?

01:28:11.400 --> 01:28:14.000
It's so obvious that there's a need.

01:28:14.000 --> 01:28:15.560
And we're not just gonna unload trucks.

01:28:15.560 --> 01:28:18.000
We're gonna do any box moving task in the warehouse.

01:28:18.000 --> 01:28:21.240
And so it too will be a multi-purpose robot.

01:28:21.240 --> 01:28:23.800
And we'll eventually have it doing palletizing

01:28:23.800 --> 01:28:27.560
or depalletizing or loading trucks or unloading trucks.

01:28:28.420 --> 01:28:30.080
There's definitely thousands of robots.

01:28:30.080 --> 01:28:32.640
There's probably tens of thousands of robots of this

01:28:32.640 --> 01:28:33.480
in the future.

01:28:33.480 --> 01:28:35.160
So it's gonna be profitable.

01:28:35.160 --> 01:28:37.560
Can you describe what Stretch looks like?

01:28:37.560 --> 01:28:42.060
It looks like a big, strong robot arm on a mobile base.

01:28:42.060 --> 01:28:44.520
The base is about the size of a pallet.

01:28:44.520 --> 01:28:46.360
And we wanted it to be the size of a pallet

01:28:46.360 --> 01:28:48.400
because that's what lives in warehouses, right?

01:28:48.400 --> 01:28:50.360
Pallets of goods sitting everywhere.

01:28:50.360 --> 01:28:52.640
So it needed to be able to fit in that space.

01:28:52.640 --> 01:28:53.880
It's not a legged robot.

01:28:53.880 --> 01:28:54.720
It's not a legged robot.

01:28:54.720 --> 01:28:56.120
And so it was our first,

01:28:57.120 --> 01:29:02.120
it was actually a bit of a commitment from us,

01:29:03.120 --> 01:29:06.320
a challenge for us to build a non-balancing robot.

01:29:07.720 --> 01:29:11.080
To do the much easier problem and to put to do a well.

01:29:11.080 --> 01:29:14.600
Because it wasn't gonna have this balance problem.

01:29:14.600 --> 01:29:16.780
And in fact, the very first version

01:29:16.780 --> 01:29:20.520
of the logistics robot we built was a balancing robot.

01:29:20.520 --> 01:29:21.880
And that's called Handle.

01:29:23.040 --> 01:29:24.160
That thing was epic.

01:29:24.160 --> 01:29:25.920
Oh, it's a beautiful machine.

01:29:25.920 --> 01:29:27.440
It's an incredible machine.

01:29:27.440 --> 01:29:28.280
So it was,

01:29:30.520 --> 01:29:31.800
I mean, it looks epic.

01:29:31.800 --> 01:29:36.800
It looks like out of the sci-fi movie of some sort.

01:29:37.720 --> 01:29:40.600
Can you actually just linger on the design of that thing?

01:29:40.600 --> 01:29:42.320
Because that's another leap into something

01:29:42.320 --> 01:29:43.160
you probably haven't done.

01:29:43.160 --> 01:29:44.480
It's a different kind of balancing.

01:29:44.480 --> 01:29:47.400
Yeah, so I love talking about the history

01:29:47.400 --> 01:29:49.440
of how Handle came about.

01:29:49.440 --> 01:29:52.320
Because it connects all of our robots, actually.

01:29:52.320 --> 01:29:55.880
So I'm gonna start with Atlas.

01:29:55.880 --> 01:29:59.720
When we had Atlas getting fairly far along,

01:29:59.720 --> 01:30:01.640
we wanted to understand, I was telling you earlier,

01:30:01.640 --> 01:30:03.080
the challenge of the human form

01:30:03.080 --> 01:30:05.160
is that you have this mass up high.

01:30:06.120 --> 01:30:10.960
And balancing that inertia, that mass up high,

01:30:10.960 --> 01:30:12.680
is its own unique challenge.

01:30:12.680 --> 01:30:15.520
And so we started trying to get Atlas to balance

01:30:15.520 --> 01:30:18.280
standing on one foot, like on a balance beam,

01:30:18.280 --> 01:30:19.960
using its arms like this.

01:30:19.960 --> 01:30:21.280
And yeah, you can do this, I'm sure.

01:30:21.280 --> 01:30:22.280
I can do this, right?

01:30:22.280 --> 01:30:24.600
Like if you're walking a tightrope,

01:30:24.600 --> 01:30:26.600
how do you do that balance?

01:30:26.600 --> 01:30:29.660
So that's sort of controlling the inertia,

01:30:29.660 --> 01:30:31.980
controlling the momentum of the robot.

01:30:31.980 --> 01:30:34.180
We were starting to figure that out on Atlas.

01:30:35.500 --> 01:30:37.500
And so our first concept of Handle,

01:30:37.500 --> 01:30:40.220
which was a robot that was gonna be on two wheels,

01:30:40.220 --> 01:30:41.860
so it had to balance,

01:30:41.860 --> 01:30:43.500
but it was gonna have a big long arm

01:30:43.500 --> 01:30:47.100
so it could reach a box at the top of a truck.

01:30:47.100 --> 01:30:52.100
And it needed yet another counterbalance, a big tail,

01:30:52.860 --> 01:30:56.860
to help it balance while it was using its arm.

01:30:56.860 --> 01:31:01.140
So the reason why this robot sort of looks epic,

01:31:01.140 --> 01:31:04.180
some people said it looked like an ostrich,

01:31:04.180 --> 01:31:07.220
or maybe an ostrich moving around,

01:31:07.220 --> 01:31:12.220
was the wheels, it has legs, so it can extend its legs.

01:31:12.540 --> 01:31:13.920
So it's wheels on legs.

01:31:13.920 --> 01:31:15.740
We always wanted to build wheels on legs.

01:31:15.740 --> 01:31:17.340
It had a tail and it had this arm.

01:31:17.340 --> 01:31:19.260
And they're all moving simultaneously

01:31:19.260 --> 01:31:21.700
and in coordination to maintain balance.

01:31:21.700 --> 01:31:23.620
Because we had figured out the mathematics

01:31:23.620 --> 01:31:25.380
of doing this momentum control,

01:31:25.420 --> 01:31:27.860
how to maintain that balance.

01:31:27.860 --> 01:31:29.180
And so part of the reason

01:31:29.180 --> 01:31:31.500
why we built this two-legged robot

01:31:31.500 --> 01:31:33.700
was we had figured this thing out,

01:31:33.700 --> 01:31:36.260
we wanted to see it in this kind of machine,

01:31:36.260 --> 01:31:37.820
and we thought maybe this kind of machine

01:31:37.820 --> 01:31:39.860
would be good in a warehouse, and so we built it.

01:31:39.860 --> 01:31:41.300
And it's a beautiful machine.

01:31:41.300 --> 01:31:45.140
It moves in a graceful way, like nothing else we've built,

01:31:45.140 --> 01:31:48.740
but it wasn't the right machine for a logistics application.

01:31:48.740 --> 01:31:50.660
We decided it was too slow

01:31:50.660 --> 01:31:53.820
and couldn't pick boxes fast enough, basically.

01:31:54.300 --> 01:31:55.860
It was doing beautifully with elegance.

01:31:55.860 --> 01:31:58.860
It did beautifully, but it just wasn't efficient enough.

01:31:58.860 --> 01:32:00.500
So we let it go.

01:32:00.500 --> 01:32:04.420
But I think we'll come back to that machine eventually.

01:32:04.420 --> 01:32:05.740
The fact that it's possible,

01:32:05.740 --> 01:32:08.580
the fact that you showed that you could do so many things

01:32:08.580 --> 01:32:10.780
at the same time in coordination,

01:32:10.780 --> 01:32:13.020
that's so beautifully, there's something there.

01:32:13.020 --> 01:32:15.780
That was a demonstration of what is possible.

01:32:15.780 --> 01:32:17.260
Basically, we made a hard decision,

01:32:17.260 --> 01:32:20.220
and this was really kind of a hard-nosed business decision.

01:32:21.100 --> 01:32:25.580
It indicated us not doing it just for the beauty

01:32:25.580 --> 01:32:27.780
of the mathematics or the curiosity,

01:32:27.780 --> 01:32:30.140
but no, we actually need to build a business

01:32:30.140 --> 01:32:32.220
that can make money in the long run.

01:32:32.220 --> 01:32:34.340
And so we ended up building Stretch,

01:32:34.340 --> 01:32:35.660
which has a big, heavy base

01:32:35.660 --> 01:32:38.140
with a giant battery in the base of it

01:32:38.140 --> 01:32:41.540
that allows it to run for two shifts,

01:32:41.540 --> 01:32:43.860
16 hours worth of operation.

01:32:43.860 --> 01:32:47.380
And that big battery sort of helps it stay balanced, right?

01:32:47.380 --> 01:32:50.020
So it can move a 50-pound box around with its arm

01:32:50.820 --> 01:32:51.660
and not tip over.

01:32:52.660 --> 01:32:53.900
It's omnidirectional.

01:32:53.900 --> 01:32:55.180
It can move in any direction,

01:32:55.180 --> 01:32:57.940
so it has a nice suspension built into it

01:32:57.940 --> 01:33:01.580
so it can deal with gaps or things on the floor

01:33:01.580 --> 01:33:02.980
and roll over it.

01:33:02.980 --> 01:33:05.260
But it's not a balancing robot.

01:33:05.260 --> 01:33:08.460
It's a mobile robot arm that can work

01:33:08.460 --> 01:33:11.020
to carry or pick or place a box

01:33:11.020 --> 01:33:13.940
up to 50 pounds anywhere in the warehouse.

01:33:13.940 --> 01:33:16.540
Take a box from point A to point B anywhere.

01:33:16.540 --> 01:33:19.140
Yeah, palletize, depalletize.

01:33:19.140 --> 01:33:21.060
We're starting with unloading trucks

01:33:21.060 --> 01:33:23.340
because there's so many trucks and containers

01:33:23.340 --> 01:33:24.780
that where goods are shipped.

01:33:24.780 --> 01:33:26.300
And it's a brutal job.

01:33:26.300 --> 01:33:29.940
In the summer, it can be 120 degrees inside that container.

01:33:29.940 --> 01:33:31.500
People don't wanna do that job.

01:33:33.180 --> 01:33:34.780
And it's backbreaking labor, right?

01:33:34.780 --> 01:33:37.020
Again, these can be up to 50-pound boxes.

01:33:38.140 --> 01:33:43.140
And so we feel like this is a productivity enhancer.

01:33:43.140 --> 01:33:46.900
And for the people who used to do that job unloading trucks,

01:33:46.900 --> 01:33:49.180
they're actually operating the robot now.

01:33:49.180 --> 01:33:53.180
And so by building robots that are easy to control

01:33:53.180 --> 01:33:56.180
and it doesn't take an advanced degree to manage,

01:33:56.180 --> 01:33:57.900
you can become a robot operator.

01:33:57.900 --> 01:34:00.060
And so as we've introduced these robots

01:34:00.060 --> 01:34:02.500
to both DHL and Mariskin Gap,

01:34:02.500 --> 01:34:05.220
the warehouse workers who were doing that manual labor

01:34:05.220 --> 01:34:06.540
are now the robot operators.

01:34:06.540 --> 01:34:09.980
And so we see this as ultimately a benefit to them as well.

01:34:11.740 --> 01:34:14.140
Can you say how much stretch costs?

01:34:15.100 --> 01:34:20.100
Not yet, but I will say that when we engage

01:34:21.260 --> 01:34:23.740
with our customers, they'll be able to see

01:34:23.740 --> 01:34:26.660
a return on investment in typically two years.

01:34:26.660 --> 01:34:28.580
Okay, so that's something that you're constantly

01:34:28.580 --> 01:34:30.420
thinking about how.

01:34:30.420 --> 01:34:31.900
And I suppose you have to do the same kind

01:34:31.900 --> 01:34:32.740
of thinking with Spot.

01:34:32.740 --> 01:34:34.500
So it seems like with Stretch,

01:34:34.500 --> 01:34:38.580
the application is like directly obvious.

01:34:38.580 --> 01:34:39.460
Yeah, it's a slam dunk.

01:34:39.460 --> 01:34:42.620
Yeah, and so you have a little more flexibility.

01:34:42.660 --> 01:34:44.340
Well, I think we know the target.

01:34:44.340 --> 01:34:46.300
We know what we're going after.

01:34:46.300 --> 01:34:47.460
And with Spot, it took us a while

01:34:47.460 --> 01:34:49.340
to figure out what we were going after.

01:34:49.340 --> 01:34:50.860
Well, let me return to that question

01:34:50.860 --> 01:34:55.140
about maybe the conversation you were having

01:34:56.140 --> 01:34:58.140
a while ago with Larry Page,

01:34:58.140 --> 01:35:02.940
maybe looking to the longer future of social robotics,

01:35:02.940 --> 01:35:05.580
of using Spot to connect with human beings,

01:35:05.580 --> 01:35:06.740
perhaps in the home.

01:35:06.740 --> 01:35:08.180
Do you see a future there?

01:35:08.180 --> 01:35:11.900
If we were to sort of hypothesize or dream

01:35:11.940 --> 01:35:14.020
about a future where Spot-like robots

01:35:14.020 --> 01:35:16.060
are in the home as pets, as social robots.

01:35:16.060 --> 01:35:17.460
We definitely think about it.

01:35:17.460 --> 01:35:20.340
And we would like to get there.

01:35:20.340 --> 01:35:22.180
We think the pathway to getting there

01:35:22.180 --> 01:35:26.620
is likely through these industrial applications

01:35:26.620 --> 01:35:28.300
and then mass manufacturing.

01:35:28.300 --> 01:35:31.860
Let's figure out how to build the robots,

01:35:31.860 --> 01:35:33.660
how to make the software so that they can really

01:35:33.660 --> 01:35:35.460
do a broad set of skills.

01:35:35.460 --> 01:35:39.820
That's gonna take real investment to get there.

01:35:39.820 --> 01:35:41.260
Performance first, right?

01:35:41.300 --> 01:35:43.220
The principle of the company has always been

01:35:43.220 --> 01:35:45.740
really make the robots do useful stuff.

01:35:45.740 --> 01:35:50.020
And so the social robot companies

01:35:50.020 --> 01:35:52.140
that tried to start someplace else

01:35:52.140 --> 01:35:54.460
by just making acute interaction,

01:35:54.460 --> 01:35:55.860
mostly they haven't survived.

01:35:56.780 --> 01:36:01.780
And so we think the utility really needs to come first.

01:36:01.980 --> 01:36:03.980
And that means you have to solve

01:36:03.980 --> 01:36:05.900
some of these hard problems.

01:36:05.900 --> 01:36:10.780
And so to get there, we're gonna go through the design

01:36:10.780 --> 01:36:13.460
and software development in industrial.

01:36:13.460 --> 01:36:15.820
And then that's eventually gonna let you reach a scale

01:36:15.820 --> 01:36:16.940
that could then be addressed

01:36:16.940 --> 01:36:20.540
to a commercial consumer level market.

01:36:20.540 --> 01:36:22.540
And so, yeah, maybe we'll be able to build

01:36:22.540 --> 01:36:24.660
a smaller spot with an arm

01:36:24.660 --> 01:36:27.460
that could really go get your beer for you.

01:36:27.460 --> 01:36:30.140
But there's things we need to figure out still.

01:36:30.140 --> 01:36:32.380
How to safely, really safely,

01:36:32.380 --> 01:36:35.580
and if you're gonna be interacting with children,

01:36:35.580 --> 01:36:37.020
you better be safe.

01:36:37.020 --> 01:36:41.260
And right now we count on a little bit of standoff distance

01:36:41.260 --> 01:36:42.500
between the robot and people

01:36:42.500 --> 01:36:45.340
so that you don't pinch a finger in the robot.

01:36:45.340 --> 01:36:47.580
So you've got a lot of things you need to go solve

01:36:47.580 --> 01:36:50.820
before you jump to that consumer level product.

01:36:50.820 --> 01:36:52.860
Well, there's a kind of trade-off in safety

01:36:52.860 --> 01:36:57.620
because it feels like in the home you can fall.

01:36:58.660 --> 01:37:02.220
Like you don't have to be as good at,

01:37:02.220 --> 01:37:05.420
like you're allowed to fail in different ways,

01:37:05.420 --> 01:37:09.700
in more ways, as long as it's safe for the humans.

01:37:09.700 --> 01:37:12.420
So it just feels like an easier problem to solve

01:37:12.420 --> 01:37:13.580
because it feels like in the factory

01:37:13.580 --> 01:37:14.980
you're not allowed to fail.

01:37:16.020 --> 01:37:20.580
That may be true, but I also think the variety of things

01:37:20.580 --> 01:37:23.860
a consumer level robot would be expected to do

01:37:23.860 --> 01:37:25.820
will also be quite broad.

01:37:25.820 --> 01:37:27.300
They're gonna want to get the beer

01:37:27.300 --> 01:37:30.380
and know the difference between the beer and a Coca-Cola

01:37:30.380 --> 01:37:32.220
or my snack.

01:37:33.220 --> 01:37:36.460
Or they're all gonna want you to clean up the dishes

01:37:37.740 --> 01:37:39.700
from the table without breaking them.

01:37:39.700 --> 01:37:42.820
Those are pretty complex tasks.

01:37:42.820 --> 01:37:45.380
And so there's still work to be done there.

01:37:45.380 --> 01:37:47.540
So to push back on that, here's my application.

01:37:47.540 --> 01:37:49.300
I think they'll be very interesting.

01:37:49.300 --> 01:37:52.500
I think the application of being a pet, a friend.

01:37:53.340 --> 01:37:57.780
So like no tasks, just be cute.

01:37:57.780 --> 01:37:59.820
Because not cute, not cute.

01:38:00.180 --> 01:38:02.780
A dog is more than just cute.

01:38:02.780 --> 01:38:04.900
A dog is a friend, is a companion.

01:38:04.900 --> 01:38:07.660
There's something about just having interacted with them

01:38:07.660 --> 01:38:09.900
and maybe because I'm hanging out alone

01:38:09.900 --> 01:38:12.140
with the robot dogs a little too much.

01:38:12.140 --> 01:38:15.500
But like there's a connection there.

01:38:15.500 --> 01:38:17.100
And it feels like that connection

01:38:17.100 --> 01:38:19.660
is not, should not be disregarded.

01:38:20.500 --> 01:38:23.340
No, it should not be disregarded.

01:38:23.340 --> 01:38:25.300
Robots that can somehow communicate

01:38:25.300 --> 01:38:26.540
through their physical gestures

01:38:26.540 --> 01:38:30.260
are you're gonna be more attached to in the long run.

01:38:30.260 --> 01:38:33.740
Do you remember Ibo, the Sony Ibo?

01:38:33.740 --> 01:38:37.180
They sold over 100,000 of those, maybe 150,000.

01:38:38.420 --> 01:38:42.500
Probably wasn't considered a successful product for them.

01:38:42.500 --> 01:38:44.020
They suspended that eventually

01:38:44.020 --> 01:38:46.620
and then they brought it back, Sony brought it back.

01:38:46.620 --> 01:38:50.420
And people definitely treated this as a pet,

01:38:50.420 --> 01:38:52.020
as a companion.

01:38:53.620 --> 01:38:55.620
And I think that will come around again.

01:38:57.540 --> 01:39:01.540
Will you get away without having any other utility?

01:39:01.540 --> 01:39:03.580
Maybe in a world where we can really talk

01:39:03.580 --> 01:39:07.460
to our simple little pet because chat GPT

01:39:07.460 --> 01:39:10.220
or some other generative AI has made it possible

01:39:10.220 --> 01:39:13.940
for you to really talk in what seems like a meaningful way.

01:39:13.940 --> 01:39:18.580
Maybe that'll open the social robot up again.

01:39:20.860 --> 01:39:23.220
That's probably not a path we're gonna go down.

01:39:23.500 --> 01:39:28.500
Because again, we're so focused on performance and utility,

01:39:28.740 --> 01:39:30.940
we can add those other things also,

01:39:30.940 --> 01:39:32.860
but we really wanna start from that foundation

01:39:32.860 --> 01:39:34.180
of utility, I think.

01:39:34.180 --> 01:39:39.180
Yeah, but I also wanna predict that you're wrong on that.

01:39:39.700 --> 01:39:42.060
Which is that the very path you're taking,

01:39:42.060 --> 01:39:44.940
which is creating a great robot platform,

01:39:44.940 --> 01:39:48.020
will very easily take a leap to adding

01:39:49.980 --> 01:39:51.540
a chat GPT-like capability,

01:39:51.540 --> 01:39:54.500
maybe GPT-5, and there's just so many

01:39:54.500 --> 01:39:56.180
open source alternatives that you could just

01:39:56.180 --> 01:39:58.300
plop that on top of spot.

01:39:58.300 --> 01:40:01.260
And because you have this robust platform,

01:40:01.260 --> 01:40:03.340
and you're figuring out how to mass manufacture it

01:40:03.340 --> 01:40:05.300
and how to drive the cost down,

01:40:05.300 --> 01:40:07.700
and how to make it reliable, all those kinds of things,

01:40:07.700 --> 01:40:10.020
it'll be a natural transition to where

01:40:10.020 --> 01:40:11.980
just adding chat GPT on top of it will create a-

01:40:11.980 --> 01:40:16.980
Oh, I do think that being able to verbally converse

01:40:17.060 --> 01:40:20.220
or even converse through gestures,

01:40:20.260 --> 01:40:24.060
part of these learning models is that

01:40:24.060 --> 01:40:26.420
you can now look at video and imagery

01:40:26.420 --> 01:40:30.060
and associate intent with that.

01:40:30.060 --> 01:40:33.220
Those will all help in the communication

01:40:33.220 --> 01:40:35.860
between robots and people, for sure.

01:40:35.860 --> 01:40:37.340
And that's gonna happen, obviously,

01:40:37.340 --> 01:40:39.700
more quickly than any of us were expecting.

01:40:39.700 --> 01:40:42.620
I mean, what else do you want from life?

01:40:42.620 --> 01:40:43.740
Friends, get your beer,

01:40:43.740 --> 01:40:48.180
and then just talk shit about the state of the world.

01:40:50.260 --> 01:40:52.980
I mean, where there's a deep loneliness within all of us,

01:40:52.980 --> 01:40:57.260
and I think a beer and a good chat solves so much of it,

01:40:57.260 --> 01:41:00.820
or takes us a long way to solving a lot of it.

01:41:00.820 --> 01:41:02.220
It'll be interesting to see

01:41:06.340 --> 01:41:11.100
when a generative AI can give you that warm feeling

01:41:11.100 --> 01:41:15.220
that you connected, and that, oh yeah, you remember me,

01:41:15.220 --> 01:41:17.300
you're my friend, we have a history.

01:41:18.180 --> 01:41:20.420
You know, that history matters, right?

01:41:20.420 --> 01:41:23.380
Memory of joy, memory of, yeah.

01:41:23.380 --> 01:41:25.780
Having witnessed, that's what friendship,

01:41:25.780 --> 01:41:29.500
that's what connection, that's what love is in many cases.

01:41:29.500 --> 01:41:31.260
Some of the deepest friendships you have

01:41:31.260 --> 01:41:34.140
is having gone through a difficult time together,

01:41:34.140 --> 01:41:36.740
and having a shared memory of an amazing time

01:41:36.740 --> 01:41:41.580
or a difficult time, and kind of that memory

01:41:41.580 --> 01:41:44.140
creating this foundation based on which

01:41:44.140 --> 01:41:46.380
you can then experience the world together,

01:41:46.380 --> 01:41:48.700
the silly, the mundane stuff of day to day

01:41:48.700 --> 01:41:50.300
is somehow built on a foundation

01:41:50.300 --> 01:41:52.380
of having gone through some shit in the past.

01:41:52.380 --> 01:41:56.260
And the current systems are not personalized in that way,

01:41:56.260 --> 01:41:58.220
but I think that's a technical problem,

01:41:58.220 --> 01:42:00.980
not some kind of fundamental limitation.

01:42:00.980 --> 01:42:04.380
So combine that with an embodied robot like Spot,

01:42:04.380 --> 01:42:08.540
which already has magic in its movement.

01:42:08.540 --> 01:42:11.660
I think it's a very interesting possibility

01:42:11.660 --> 01:42:13.180
of where that takes us.

01:42:13.180 --> 01:42:15.980
But of course, you have to build that on top of a company

01:42:16.020 --> 01:42:19.260
that's making money with real application,

01:42:19.260 --> 01:42:22.460
with real customers, and with robots that are safe

01:42:22.460 --> 01:42:27.380
and work and reliable and manufactured scale.

01:42:27.380 --> 01:42:29.660
And I think we're in a unique position

01:42:29.660 --> 01:42:34.660
in that because of our investors, primarily Hyundai,

01:42:34.660 --> 01:42:37.020
but also SoftBank still owns 20% of us,

01:42:38.900 --> 01:42:41.500
they don't, they're not totally fixated

01:42:41.500 --> 01:42:45.340
on driving us to profitability as soon as possible.

01:42:45.380 --> 01:42:46.940
That's not the goal.

01:42:46.940 --> 01:42:51.380
The goal really is a longer term vision of creating,

01:42:51.380 --> 01:42:53.460
you know, what does mobility mean in the future?

01:42:53.460 --> 01:42:56.380
What, how is this mobile robot technology

01:42:56.380 --> 01:42:59.300
going to influence us?

01:42:59.300 --> 01:43:01.020
Can we, and can we shape that?

01:43:01.020 --> 01:43:02.100
And they want both.

01:43:02.100 --> 01:43:04.380
And so we are, as a company,

01:43:04.380 --> 01:43:06.540
we're trying to strike that balance between

01:43:06.540 --> 01:43:09.180
let's build a business that makes money.

01:43:09.180 --> 01:43:13.540
I've been describing that to my own team as self-destination.

01:43:13.540 --> 01:43:15.820
If I wanna drive my own ship,

01:43:15.820 --> 01:43:18.340
we need to have a business that's profitable in the end,

01:43:18.340 --> 01:43:21.220
otherwise somebody else is gonna drive the ship for us.

01:43:21.220 --> 01:43:23.580
So that's really important.

01:43:23.580 --> 01:43:27.900
But we're gonna retain the aspiration

01:43:27.900 --> 01:43:29.380
that we're gonna build the next generation

01:43:29.380 --> 01:43:30.940
of technology at the same time.

01:43:30.940 --> 01:43:33.260
And the real trick will be if we can do both.

01:43:35.060 --> 01:43:38.660
Speaking of ships, let me ask you about a competitor

01:43:39.820 --> 01:43:41.860
and somebody who's become a friend.

01:43:41.860 --> 01:43:44.980
So Elon Musk and Tesla have announced,

01:43:44.980 --> 01:43:48.620
have been in the early days of building a humanoid robot.

01:43:48.620 --> 01:43:53.620
How does that change the landscape of your work?

01:43:53.660 --> 01:43:57.420
So there's sort of from the outside perspective,

01:43:57.420 --> 01:44:01.860
it seems like, well, as a fan of robotics,

01:44:01.860 --> 01:44:03.580
it just seems exciting.

01:44:03.580 --> 01:44:04.740
Very exciting, right?

01:44:04.740 --> 01:44:08.580
When Elon speaks, people listen.

01:44:08.620 --> 01:44:12.220
And so it suddenly brought a bright light

01:44:12.220 --> 01:44:15.260
onto the work that we'd been doing for over a decade.

01:44:17.900 --> 01:44:19.460
And I think that's only gonna help.

01:44:19.460 --> 01:44:22.100
And in fact, what we've seen is that,

01:44:22.100 --> 01:44:26.180
in addition to Tesla, we're seeing a proliferation

01:44:26.180 --> 01:44:30.020
of robotic companies arise now.

01:44:30.020 --> 01:44:30.980
Including humanoid?

01:44:30.980 --> 01:44:31.820
Yes.

01:44:31.820 --> 01:44:32.660
Oh, wow.

01:44:32.660 --> 01:44:36.500
Yeah, and interestingly, many of them,

01:44:36.540 --> 01:44:39.460
as they're raising money, for example,

01:44:39.460 --> 01:44:41.500
will claim whether or not they have

01:44:41.500 --> 01:44:43.980
a former Boston Dynamics employee on their staff

01:44:43.980 --> 01:44:45.020
as a criteria.

01:44:46.180 --> 01:44:47.380
Yeah, that's true.

01:44:47.380 --> 01:44:51.460
That's, I would do that as a company, yeah, for sure.

01:44:51.460 --> 01:44:52.300
Yeah, so.

01:44:52.300 --> 01:44:53.380
And shows you're legit, yeah.

01:44:53.380 --> 01:44:54.740
Yeah, so you know what?

01:44:54.740 --> 01:44:58.340
It's bring, it has brung a tremendous validation

01:44:58.340 --> 01:44:59.820
to what we're doing.

01:44:59.820 --> 01:45:03.780
And excitement, competitive juices are flowing,

01:45:03.780 --> 01:45:04.820
you know, the whole thing.

01:45:04.820 --> 01:45:06.660
So it's all good.

01:45:07.580 --> 01:45:12.100
Ilana's also kind of stated

01:45:13.540 --> 01:45:18.540
that, you know, maybe he implied

01:45:19.860 --> 01:45:23.660
that the problem is solvable in the near term,

01:45:23.660 --> 01:45:26.980
which is a low-cost humanoid robot

01:45:26.980 --> 01:45:29.260
that's able to do, that's a relatively

01:45:29.260 --> 01:45:32.500
general use case robot.

01:45:32.500 --> 01:45:36.700
So I think Ilana's known for sort of setting

01:45:36.700 --> 01:45:39.060
these kinds of incredibly ambitious goals,

01:45:40.300 --> 01:45:44.180
maybe missing deadlines, but actually pushing

01:45:44.180 --> 01:45:45.780
not just the particular team he leads,

01:45:45.780 --> 01:45:50.180
but the entire world to like accomplishing those.

01:45:50.180 --> 01:45:54.180
Do you see Boston Dynamics in the near future

01:45:54.180 --> 01:45:56.100
being pushed in that kind of way?

01:45:56.100 --> 01:45:57.980
Like this excitement of competition

01:45:57.980 --> 01:46:02.980
kind of pushing Atlas maybe to do more cool stuff,

01:46:03.820 --> 01:46:06.660
trying to drive the cost of Atlas down perhaps?

01:46:06.660 --> 01:46:11.300
Or, I mean, I guess I wanna ask if there's

01:46:11.300 --> 01:46:16.300
some kind of exciting energy in Boston Dynamics

01:46:17.860 --> 01:46:19.620
due to this a little bit of competition.

01:46:19.620 --> 01:46:21.020
Oh yeah, definitely.

01:46:22.420 --> 01:46:25.580
When we released our most recent video of Atlas,

01:46:26.420 --> 01:46:28.260
I think you'd seen it, the scaffolding

01:46:28.260 --> 01:46:30.340
and throwing the box of tools around

01:46:30.340 --> 01:46:32.500
and then doing the flip at the end.

01:46:32.500 --> 01:46:34.380
We were trying to show the world

01:46:34.380 --> 01:46:38.660
that not only can we do this parkour mobility thing,

01:46:38.660 --> 01:46:41.060
but we can pick up and move heavy things.

01:46:41.060 --> 01:46:45.300
Because if you're gonna work in a manufacturing environment,

01:46:45.300 --> 01:46:47.900
that's what you gotta be able to do.

01:46:47.900 --> 01:46:51.140
And for the reasons I explained to you earlier,

01:46:51.140 --> 01:46:54.620
it's not trivial to do so, changing the center of mass

01:46:56.140 --> 01:46:58.940
by picking up a 50 pound block

01:46:58.940 --> 01:47:02.340
for a robot that weighs 150 pounds.

01:47:02.340 --> 01:47:04.780
That's a lot to accommodate.

01:47:04.780 --> 01:47:07.380
So we're trying to show that we can do that.

01:47:07.380 --> 01:47:11.980
And so it's totally been energizing.

01:47:11.980 --> 01:47:16.980
We see the next phase of Atlas being more dexterous hands

01:47:17.540 --> 01:47:19.860
that can manipulate and grab more things

01:47:19.860 --> 01:47:23.140
that we're gonna start by moving big things around

01:47:23.140 --> 01:47:25.660
that are heavy and that affect balance.

01:47:25.660 --> 01:47:26.500
And why is that?

01:47:26.500 --> 01:47:29.420
Well, really tiny dexterous things

01:47:29.420 --> 01:47:32.100
probably are gonna be hard for a while yet.

01:47:32.100 --> 01:47:36.940
Maybe you could go build a special purpose robot arm

01:47:36.940 --> 01:47:41.420
for stuffing chips into electronics boards.

01:47:41.420 --> 01:47:44.980
But we don't really wanna do really fine work like that.

01:47:44.980 --> 01:47:48.580
I think more coursework where you're using two hands

01:47:48.580 --> 01:47:50.860
to pick up and balance an unwieldy thing,

01:47:50.860 --> 01:47:52.700
maybe in a manufacturing environment,

01:47:52.700 --> 01:47:54.900
maybe in a construction environment.

01:47:54.900 --> 01:47:57.220
Those are the things that we think robots

01:47:57.220 --> 01:48:00.020
are gonna be able to do with the level of dexterity

01:48:00.020 --> 01:48:01.660
that they're gonna have in the next few years.

01:48:01.660 --> 01:48:03.900
And that's where we're headed.

01:48:03.900 --> 01:48:07.460
And I think, and Elon has seen the same thing, right?

01:48:07.460 --> 01:48:08.940
He's talking about using the robots

01:48:08.940 --> 01:48:11.180
in a manufacturing environment.

01:48:11.180 --> 01:48:12.940
We think there's something very interesting there

01:48:12.940 --> 01:48:16.340
about having this two armed robot.

01:48:16.340 --> 01:48:17.580
Because when you have two arms,

01:48:17.580 --> 01:48:20.260
you can transfer a thing from one hand to the other,

01:48:20.260 --> 01:48:21.900
you can turn it around,

01:48:22.460 --> 01:48:24.660
you can reorient it in a way that you can't do it

01:48:24.660 --> 01:48:26.580
if you just have one hand on it.

01:48:26.580 --> 01:48:29.940
And so there's a lot that extra arm brings to the table.

01:48:29.940 --> 01:48:32.780
So I think in terms of mission,

01:48:32.780 --> 01:48:35.340
you mentioned Boston Dynamics really wants to see

01:48:35.340 --> 01:48:38.100
what's the limits of what's possible.

01:48:38.100 --> 01:48:40.780
And so the cost comes second.

01:48:40.780 --> 01:48:42.180
Or it's a component,

01:48:42.180 --> 01:48:43.980
but first figure out what are the limitations.

01:48:43.980 --> 01:48:47.100
I think Elon, he's really driving the cost down.

01:48:47.100 --> 01:48:50.660
Is there some inspiration, some lessons you see there?

01:48:52.300 --> 01:48:55.020
Of the challenge of driving the cost down,

01:48:55.020 --> 01:48:57.100
especially with Atlas, with the humanoid robot.

01:48:57.100 --> 01:48:59.740
Well, I think the thing that he's certainly been learning

01:48:59.740 --> 01:49:04.060
by building car factories is what that looks like,

01:49:04.060 --> 01:49:05.220
and scaling.

01:49:06.180 --> 01:49:09.300
By scaling, you can get efficiencies

01:49:09.300 --> 01:49:11.860
that drive costs down very well.

01:49:11.860 --> 01:49:16.780
And the smart thing that they have in their favor

01:49:16.780 --> 01:49:18.980
is they know how to manufacture,

01:49:18.980 --> 01:49:20.540
they know how to build electric motors,

01:49:20.540 --> 01:49:23.860
they know how to build computers and vision systems.

01:49:23.860 --> 01:49:25.660
So there's a lot of overlap

01:49:25.660 --> 01:49:30.420
between modern automotive companies and robots.

01:49:31.660 --> 01:49:35.580
But hey, we have a modern robotic,

01:49:35.580 --> 01:49:38.140
I mean the automotive company behind us as well.

01:49:40.140 --> 01:49:41.420
So bring it on.

01:49:41.420 --> 01:49:43.100
Who's doing pretty well, right?

01:49:43.100 --> 01:49:46.660
The electric vehicles from Hyundai are doing pretty well.

01:49:46.660 --> 01:49:47.500
I love it.

01:49:47.540 --> 01:49:50.460
So how much, so we've talked about

01:49:50.460 --> 01:49:52.460
some of the low-level control,

01:49:52.460 --> 01:49:55.060
some of the incredible stuff that's going on,

01:49:55.060 --> 01:49:56.740
and basic perception.

01:49:57.860 --> 01:49:59.820
But how much do you see currently

01:49:59.820 --> 01:50:02.700
and in the future of Boston Dynamics,

01:50:02.700 --> 01:50:06.220
sort of more high-level machine learning applications?

01:50:06.220 --> 01:50:09.460
Do you see customers adding on those capabilities,

01:50:09.460 --> 01:50:12.300
or do you see Boston Dynamics doing that in-house?

01:50:12.300 --> 01:50:14.700
Some kinds of things we really believe

01:50:14.740 --> 01:50:18.900
are probably gonna be more broadly available,

01:50:18.900 --> 01:50:21.300
maybe even commoditized.

01:50:21.300 --> 01:50:24.340
You know, using a machine learning, like a vision algorithm.

01:50:24.340 --> 01:50:27.140
So a robot can recognize something in the environment.

01:50:27.140 --> 01:50:29.060
That ought to be something you can just download.

01:50:29.060 --> 01:50:31.300
Like I'm going to a new environment,

01:50:31.300 --> 01:50:34.060
I have a new kind of door handle or piece of equipment

01:50:34.060 --> 01:50:34.900
I want to inspect,

01:50:34.900 --> 01:50:36.140
you ought to be able to just download that.

01:50:36.140 --> 01:50:38.340
And I think people, besides Boston Dynamics,

01:50:38.340 --> 01:50:39.180
will provide that.

01:50:39.180 --> 01:50:41.660
And we've actually built an API

01:50:41.660 --> 01:50:46.660
that lets people add these vision algorithms to Spot.

01:50:48.300 --> 01:50:49.740
And we're currently working with some partners

01:50:49.740 --> 01:50:51.380
who are providing that.

01:50:51.380 --> 01:50:54.020
Levitas is an example of a small provider

01:50:54.020 --> 01:50:57.220
who's giving us software for reading gauges.

01:50:58.100 --> 01:51:00.060
And actually another partner in Europe,

01:51:00.060 --> 01:51:02.620
Reply, is doing the same thing.

01:51:02.620 --> 01:51:05.740
So we see that, we see it ultimately

01:51:05.740 --> 01:51:09.460
an ecosystem of providers doing stuff like that.

01:51:09.460 --> 01:51:13.380
And I think ultimately you might even be able

01:51:13.380 --> 01:51:15.260
to do the same thing with behaviors.

01:51:15.260 --> 01:51:19.260
So this technology will also be brought to bear

01:51:19.260 --> 01:51:24.060
on controlling the robot, the motions of the robot.

01:51:24.060 --> 01:51:27.300
And we're using learning, reinforcement learning

01:51:27.300 --> 01:51:32.300
to develop algorithms for both locomotion and manipulation.

01:51:33.220 --> 01:51:34.780
And ultimately this is gonna mean

01:51:34.780 --> 01:51:39.100
you can add new behaviors to a robot quickly.

01:51:39.100 --> 01:51:42.140
And that could potentially be done

01:51:42.140 --> 01:51:43.380
outside of Boston Dynamics.

01:51:43.380 --> 01:51:45.660
Right now, that's all internal to us.

01:51:45.660 --> 01:51:49.660
I think you need to understand at a deep level

01:51:51.140 --> 01:51:52.940
the robot control to do that.

01:51:52.940 --> 01:51:55.020
But eventually that could be outside.

01:51:55.020 --> 01:51:57.980
But it's certainly a place where these approaches

01:51:57.980 --> 01:52:00.340
are gonna be brought to bear in robotics.

01:52:00.340 --> 01:52:03.380
So reinforcement learning is part of the process.

01:52:03.380 --> 01:52:05.580
You do use reinforcement learning.

01:52:05.580 --> 01:52:06.420
Yes.

01:52:06.940 --> 01:52:11.740
So there's increasing levels of learning with these robots?

01:52:11.740 --> 01:52:12.980
Yes.

01:52:12.980 --> 01:52:15.060
And that's for both for locomotion,

01:52:15.060 --> 01:52:17.900
for manipulation and for perception?

01:52:17.900 --> 01:52:19.300
Yes.

01:52:19.300 --> 01:52:21.540
Well, what do you think in general

01:52:21.540 --> 01:52:23.580
about all the exciting advancements

01:52:23.580 --> 01:52:27.980
of transformer neural networks

01:52:28.940 --> 01:52:32.340
most beautifully illustrated

01:52:32.340 --> 01:52:35.220
through the large language models like GPT-4?

01:52:37.420 --> 01:52:41.260
Like everybody else, I'm surprised

01:52:41.260 --> 01:52:45.460
at how far they've come.

01:52:47.420 --> 01:52:49.780
I'm a little bit nervous about the,

01:52:51.300 --> 01:52:54.020
there's anxiety around them obviously

01:52:54.020 --> 01:52:56.100
for I think good reasons, right?

01:52:58.020 --> 01:53:00.980
Disinformation is a curse

01:53:00.980 --> 01:53:04.140
that's an unintended consequence of social media

01:53:04.180 --> 01:53:08.260
that could be exacerbated with these tools.

01:53:08.260 --> 01:53:11.660
So if you use them to deploy disinformation,

01:53:11.660 --> 01:53:12.940
it could be a real risk.

01:53:15.340 --> 01:53:17.620
But I also think that the risks associated

01:53:17.620 --> 01:53:21.140
with these kinds of models don't have a whole lot to do

01:53:21.140 --> 01:53:23.940
with the way we're gonna use them in our robots.

01:53:23.940 --> 01:53:25.860
If I'm using a robot,

01:53:25.860 --> 01:53:29.860
I'm building a robot to do a manual task of some sort.

01:53:31.260 --> 01:53:33.380
I can judge very easily.

01:53:33.380 --> 01:53:35.700
Is it doing the task I asked it to?

01:53:35.700 --> 01:53:37.060
Is it doing it correctly?

01:53:37.060 --> 01:53:40.700
There's sort of a built-in mechanism for judging.

01:53:40.700 --> 01:53:43.060
Is it doing the right thing?

01:53:43.060 --> 01:53:45.620
Did it successfully do the task?

01:53:45.620 --> 01:53:47.740
Yeah, physical reality is a good verifier.

01:53:47.740 --> 01:53:48.940
It's a good verifier.

01:53:48.940 --> 01:53:50.060
That's exactly it.

01:53:50.060 --> 01:53:52.620
Whereas if you're asking for, yeah, I don't know,

01:53:53.700 --> 01:53:57.620
you're trying to ask a theoretical question in chat GPT,

01:53:58.460 --> 01:54:00.460
it could be true or it may not be true.

01:54:00.460 --> 01:54:03.300
And it's hard to have that verifier.

01:54:04.220 --> 01:54:05.580
What is that truth that you're comparing against?

01:54:05.580 --> 01:54:08.540
Whereas in physical reality, you know the truth.

01:54:08.540 --> 01:54:10.540
And this is an important difference.

01:54:10.540 --> 01:54:13.260
And so I'm not,

01:54:13.260 --> 01:54:15.700
I think there is reason to be a little bit concerned

01:54:15.700 --> 01:54:19.860
about how these tools,

01:54:19.860 --> 01:54:21.740
large language models could be used,

01:54:21.740 --> 01:54:25.300
but I'm not very worried about how they're gonna be used.

01:54:25.300 --> 01:54:28.420
Well, how learning algorithms in general

01:54:28.420 --> 01:54:30.220
are gonna be used on robotics.

01:54:30.220 --> 01:54:33.060
It's really a different application

01:54:33.060 --> 01:54:36.500
that has different ways of verifying what's going on.

01:54:36.500 --> 01:54:39.460
Well, the nice thing about language models is that

01:54:39.460 --> 01:54:41.460
I ultimately see,

01:54:41.460 --> 01:54:43.140
I'm really excited about the possibility

01:54:43.140 --> 01:54:45.500
of having conversations with Spot.

01:54:45.500 --> 01:54:48.380
There's no, I would say negative consequences to that,

01:54:48.380 --> 01:54:50.900
but just increasing the bandwidth

01:54:50.900 --> 01:54:52.740
and the variety of ways you can communicate

01:54:52.740 --> 01:54:55.420
with this particular robot.

01:54:55.420 --> 01:54:56.860
So you can communicate visually,

01:54:56.860 --> 01:54:59.460
you can communicate through some interface,

01:54:59.460 --> 01:55:01.380
and to be able to communicate verbally,

01:55:01.380 --> 01:55:02.980
again, with the beer and so on.

01:55:03.900 --> 01:55:05.380
I think that's really exciting

01:55:05.380 --> 01:55:07.620
to make that much, much easier.

01:55:07.620 --> 01:55:09.380
We have this partner, Levitas,

01:55:09.380 --> 01:55:13.340
that's adding the vision algorithms for daydreaming for us.

01:55:13.340 --> 01:55:15.780
They just, just this week I saw a demo

01:55:15.780 --> 01:55:19.780
where they hooked up a language tool to Spot

01:55:19.780 --> 01:55:22.380
and they're talking to Spot to give a glance.

01:55:22.380 --> 01:55:25.620
Can you tell me about the Boston Dynamics AI Institute?

01:55:25.620 --> 01:55:28.500
What is it and what is its mission?

01:55:28.500 --> 01:55:30.340
So it's a separate organization.

01:55:31.180 --> 01:55:34.780
The Boston Dynamics Artificial Intelligence Institute.

01:55:34.780 --> 01:55:36.180
It's led by Mark Rayburn,

01:55:36.180 --> 01:55:39.460
the founder of Boston Dynamics and the former CEO

01:55:39.460 --> 01:55:40.980
and my old advisor at MIT.

01:55:41.860 --> 01:55:46.780
Mark has always loved the research, the pure research,

01:55:46.780 --> 01:55:50.900
without the confinement or demands of commercialization.

01:55:51.860 --> 01:55:56.860
And he wanted to continue to pursue

01:55:57.100 --> 01:56:00.420
that unadulterated research.

01:56:00.420 --> 01:56:05.420
And so suggested to Hyundai that he set up this institute

01:56:07.620 --> 01:56:10.580
and they agreed that it's worth additional investment

01:56:10.580 --> 01:56:14.340
to kind of continue pushing this forefront.

01:56:14.340 --> 01:56:17.620
And we expect to be working together where,

01:56:17.620 --> 01:56:19.380
Boston Dynamics is again,

01:56:19.380 --> 01:56:21.900
both commercialize and do research,

01:56:21.900 --> 01:56:24.740
but the sort of time horizon of the research

01:56:24.780 --> 01:56:28.220
we're gonna do is in the next, let's say five years.

01:56:28.220 --> 01:56:29.660
What can we do in the next five years?

01:56:29.660 --> 01:56:31.780
Let's work on those problems.

01:56:31.780 --> 01:56:33.860
And I think the goal of the AI Institute

01:56:33.860 --> 01:56:35.740
is to work even further out.

01:56:36.740 --> 01:56:40.500
Certainly, the analogy of legged locomotion again,

01:56:40.500 --> 01:56:43.140
when we started that, that was a multi-decade problem.

01:56:43.140 --> 01:56:45.580
And so I think Mark wants to have the freedom

01:56:46.660 --> 01:56:50.500
to pursue really hard over the horizon problems.

01:56:50.500 --> 01:56:52.740
And that'll be the goal of the Institute.

01:56:53.620 --> 01:56:56.380
So we mentioned some of the dangers

01:56:56.380 --> 01:57:00.180
of some of the concerns about large language models.

01:57:00.180 --> 01:57:04.820
That said, there's been a long running fear

01:57:04.820 --> 01:57:07.620
of these embodied robots.

01:57:07.620 --> 01:57:11.500
Why do you think people are afraid of legged robots?

01:57:11.500 --> 01:57:13.980
Yeah, I wanted to show you this.

01:57:13.980 --> 01:57:16.660
So this is in the Wall Street Journal.

01:57:16.660 --> 01:57:19.300
And this is all about chat GPT, right?

01:57:19.300 --> 01:57:20.820
But look at the picture.

01:57:20.820 --> 01:57:25.340
It's a humanoid robot that's saying it looks scary

01:57:25.340 --> 01:57:27.300
and it says, I'm gonna replace you.

01:57:27.300 --> 01:57:31.620
And so the humanoid robot is the embodiment

01:57:31.620 --> 01:57:36.620
of this chat GPT tool that there's reason

01:57:36.900 --> 01:57:40.140
to be a little bit nervous about how it gets deployed.

01:57:40.140 --> 01:57:42.260
So I'm nervous about that connection.

01:57:44.340 --> 01:57:46.580
It's unfortunate that they chose to use a robot

01:57:46.580 --> 01:57:49.860
as that embodiment for, as you and I just said,

01:57:49.860 --> 01:57:53.140
there's big differences in this.

01:57:53.140 --> 01:57:58.100
But people are afraid because we've been taught

01:57:58.100 --> 01:58:00.980
to be afraid for over a hundred years.

01:58:00.980 --> 01:58:03.220
So, you know, the word robot was developed

01:58:03.220 --> 01:58:06.620
by a playwright named Carol Chapek in 1921

01:58:06.620 --> 01:58:10.100
to check a playwright for Rossum's Universal Robots.

01:58:10.100 --> 01:58:13.140
And in that first depiction of a robot,

01:58:13.140 --> 01:58:16.580
the robots took over at the end of the story.

01:58:17.460 --> 01:58:19.340
And, you know, people love to be afraid.

01:58:19.340 --> 01:58:22.100
And so we've been entertained by these stories

01:58:22.100 --> 01:58:23.260
for a hundred years.

01:58:25.140 --> 01:58:28.060
And I think that's as much why people are afraid

01:58:28.060 --> 01:58:31.220
as anything else, is we've been sort of taught

01:58:31.220 --> 01:58:34.940
that this is the logical progression through fiction.

01:58:37.300 --> 01:58:38.900
I think it's fiction.

01:58:38.900 --> 01:58:42.620
I think what people more and more will realize,

01:58:42.620 --> 01:58:46.380
just like you said, that the threat,

01:58:46.420 --> 01:58:49.660
like say you have a super intelligent AI embodied

01:58:49.660 --> 01:58:52.220
in a robot, that's much less threatening

01:58:52.220 --> 01:58:55.380
because it's visible, it's verifiable,

01:58:55.380 --> 01:58:57.180
it's right there in physical reality.

01:58:57.180 --> 01:59:00.180
And we humans know how to deal with physical reality.

01:59:00.180 --> 01:59:04.140
I think it's much scarier when you have arbitrary scaling

01:59:04.140 --> 01:59:08.860
of intelligent AI systems in the digital space,

01:59:08.860 --> 01:59:12.060
that they could pretend to be human.

01:59:12.060 --> 01:59:14.340
So a robot spot is not gonna be pretend,

01:59:14.340 --> 01:59:17.140
it could pretend it's human all at once.

01:59:17.140 --> 01:59:19.940
It could tell you, you could put your LGBT on top of it,

01:59:19.940 --> 01:59:21.460
but you're gonna know it's not human

01:59:21.460 --> 01:59:23.700
because you have a contact with physical reality.

01:59:23.700 --> 01:59:24.700
And you're gonna know whether or not

01:59:24.700 --> 01:59:25.820
it's doing what you asked it to do.

01:59:25.820 --> 01:59:29.420
Yeah, like it's not gonna, like if it,

01:59:29.420 --> 01:59:32.900
I mean, I'm sure you can start just like a dog lies to you,

01:59:32.900 --> 01:59:35.380
like I wasn't part of tearing up that couch.

01:59:35.380 --> 01:59:39.140
So spot can try to lie that like, you know,

01:59:39.140 --> 01:59:40.700
it wasn't me that spilled that thing,

01:59:40.700 --> 01:59:44.020
but you're going to kind of figure it out eventually.

01:59:44.420 --> 01:59:46.260
If it happens multiple times, you know.

01:59:47.500 --> 01:59:49.300
But I think that...

01:59:49.300 --> 01:59:52.340
Humanity has figured out how to make machines safe.

01:59:52.340 --> 01:59:56.020
And there's, you know, the regulatory environments

01:59:56.020 --> 02:00:00.500
and certification protocols that we've developed

02:00:00.500 --> 02:00:03.780
in order to figure out how to make machines safe.

02:00:03.780 --> 02:00:06.860
We don't know and don't have that experience

02:00:06.860 --> 02:00:10.380
with software that can be propagated worldwide

02:00:10.380 --> 02:00:11.220
in an instant.

02:00:12.220 --> 02:00:14.580
And so I think we needed to develop those protocols

02:00:14.580 --> 02:00:15.700
and those tools.

02:00:15.700 --> 02:00:19.940
And so that's work to be done,

02:00:19.940 --> 02:00:22.500
but I don't think the fear of that and that work

02:00:22.500 --> 02:00:25.980
should necessarily impede our ability to now get robots out.

02:00:25.980 --> 02:00:28.060
Because again, I think we can judge

02:00:28.060 --> 02:00:29.740
when a robot's being safe.

02:00:29.740 --> 02:00:32.860
So, and again, just like in that image,

02:00:32.860 --> 02:00:35.900
there's a fear that robots will take our jobs.

02:00:35.900 --> 02:00:38.580
I just, I took a ride, I was in San Francisco,

02:00:38.620 --> 02:00:41.620
I took a ride in the Waymo vehicles, an autonomous vehicle.

02:00:41.620 --> 02:00:43.700
And I've done it several times.

02:00:43.700 --> 02:00:46.260
They're doing incredible work over there.

02:00:47.140 --> 02:00:50.780
But people flicked it off.

02:00:50.780 --> 02:00:51.620
Oh, really?

02:00:51.620 --> 02:00:52.460
The car.

02:00:52.460 --> 02:00:55.620
So, I mean, that's a long story

02:00:55.620 --> 02:00:57.180
of what the psychology of that is.

02:00:57.180 --> 02:00:59.740
It could be maybe big tech or what.

02:00:59.740 --> 02:01:02.740
I don't know exactly what they're flicking off.

02:01:02.740 --> 02:01:05.100
But there is an element of like these robots

02:01:05.140 --> 02:01:06.660
that are taking our jobs

02:01:06.660 --> 02:01:09.940
or irreversibly transforming society

02:01:09.940 --> 02:01:11.900
such that it will have economic impact

02:01:11.900 --> 02:01:15.540
and the little guy would lose a lot,

02:01:15.540 --> 02:01:16.820
would lose their well-being.

02:01:16.820 --> 02:01:21.140
Is there something to be said about the fear

02:01:21.140 --> 02:01:23.620
that robots will take our jobs?

02:01:23.620 --> 02:01:28.620
You know, at every significant technological transformation,

02:01:30.420 --> 02:01:34.140
there's been fear of an automation anxiety

02:01:34.140 --> 02:01:38.580
that it's gonna have a broader impact than we expected.

02:01:40.060 --> 02:01:45.060
And there will be, you know, jobs will change.

02:01:46.780 --> 02:01:49.100
Sometime in the future, we're gonna look back

02:01:49.100 --> 02:01:52.020
at people who manually unloaded these boxes from trailers

02:01:52.020 --> 02:01:54.700
and we're gonna say, why did we ever do that manually?

02:01:54.700 --> 02:01:57.580
But there's a lot of people who are doing that job today

02:01:57.580 --> 02:01:59.100
that it could be impacted.

02:02:01.220 --> 02:02:03.580
But I think the reality is, as I said before,

02:02:03.860 --> 02:02:05.380
we're gonna build the technologies

02:02:05.380 --> 02:02:07.580
so that those very same people can operate it.

02:02:07.580 --> 02:02:09.780
And so I think there's a pathway to upskilling

02:02:09.780 --> 02:02:13.900
and operating just like, look, we used to farm with hand tools

02:02:13.900 --> 02:02:15.940
and now we farm with machines

02:02:15.940 --> 02:02:20.300
and nobody has really regretted that transformation.

02:02:20.300 --> 02:02:21.620
And I think the same can be said

02:02:21.620 --> 02:02:24.860
for a lot of manual labor that we're doing today.

02:02:24.860 --> 02:02:27.340
And on top of that, you know, look,

02:02:27.340 --> 02:02:31.740
we're entering a new world where demographics

02:02:31.740 --> 02:02:35.380
are gonna have strong impact on economic growth.

02:02:35.380 --> 02:02:38.460
And the, you know, the advanced,

02:02:38.460 --> 02:02:42.340
the first world is losing population quickly.

02:02:43.500 --> 02:02:47.060
In Europe, they're worried about hiring enough people

02:02:47.060 --> 02:02:50.380
just to keep the logistics supply chain going.

02:02:51.300 --> 02:02:55.220
And, you know, part of this is the response to COVID

02:02:55.220 --> 02:02:58.140
and everybody's sort of thinking back

02:02:58.140 --> 02:03:00.020
what they really wanna do with their life.

02:03:00.020 --> 02:03:03.180
But these jobs are getting harder and harder to fill.

02:03:03.180 --> 02:03:06.300
And I just, I'm hearing that over and over again.

02:03:06.300 --> 02:03:08.860
So I think, frankly, this is the right technology

02:03:08.860 --> 02:03:13.460
at the right time where we're gonna need

02:03:13.460 --> 02:03:15.020
some of this work to be done

02:03:15.020 --> 02:03:18.500
and we're gonna want tools to enhance that productivity.

02:03:18.500 --> 02:03:21.500
And the scary impact, I think, again,

02:03:22.380 --> 02:03:23.780
GPT comes to the rescue

02:03:23.780 --> 02:03:25.780
in terms of being much more terrifying.

02:03:26.460 --> 02:03:30.540
The scary impact of basically,

02:03:30.540 --> 02:03:32.860
so I'm a, I guess, a software person,

02:03:32.860 --> 02:03:33.860
so I program a lot.

02:03:33.860 --> 02:03:35.780
And the fact that people like me

02:03:35.780 --> 02:03:40.540
can be easily replaced by GPT,

02:03:40.540 --> 02:03:42.020
that's going to have...

02:03:43.380 --> 02:03:46.100
Well, and a lot, you know, anyone who deals with techs

02:03:46.100 --> 02:03:49.220
and writing a draft proposal

02:03:49.220 --> 02:03:52.940
might be easily done with a chat GPT now.

02:03:52.940 --> 02:03:53.780
Consultants.

02:03:53.780 --> 02:03:54.660
Where it wasn't before.

02:03:54.700 --> 02:03:56.140
Journalists.

02:03:57.780 --> 02:03:58.820
Everybody is sweating.

02:03:58.820 --> 02:04:01.820
But on the other hand, you also want it to be right.

02:04:01.820 --> 02:04:05.100
And they don't know how to make it right yet.

02:04:05.100 --> 02:04:06.660
But it might make a good starting point

02:04:06.660 --> 02:04:07.900
for you to iterate.

02:04:07.900 --> 02:04:10.460
Boy, do I have to talk to you about modern journalism.

02:04:10.460 --> 02:04:13.420
That's another conversation altogether.

02:04:14.460 --> 02:04:18.260
But yes, more right than the average,

02:04:21.100 --> 02:04:22.500
the mean journalist, yes.

02:04:25.100 --> 02:04:28.300
You spearheaded the NT weaponization letter

02:04:29.220 --> 02:04:30.700
Boston Dynamics has.

02:04:30.700 --> 02:04:34.660
Can you describe what that letter states

02:04:34.660 --> 02:04:39.660
and the general topic of the use of robots in war?

02:04:41.500 --> 02:04:44.260
We authored a letter

02:04:44.260 --> 02:04:48.100
and then got several leading robotics companies

02:04:48.100 --> 02:04:50.460
around the world, including, you know,

02:04:50.460 --> 02:04:55.460
Unitree in China and Agility here in the United States

02:04:57.100 --> 02:05:02.100
and Animal in Europe and some others

02:05:03.740 --> 02:05:05.740
to co-sign a letter that said

02:05:05.740 --> 02:05:08.980
we won't put weapons on our robots.

02:05:08.980 --> 02:05:11.860
And part of the motivation there is,

02:05:11.860 --> 02:05:16.380
as these robots start to become commercially available,

02:05:16.380 --> 02:05:19.780
you can see videos online of people who've gotten a robot

02:05:19.780 --> 02:05:22.780
and strapped a gun on it and shown that they can,

02:05:22.780 --> 02:05:24.780
you know, operate the gun remotely

02:05:24.780 --> 02:05:26.820
while driving the robot around.

02:05:26.820 --> 02:05:29.580
And so having a robot that has this level of mobility

02:05:30.340 --> 02:05:33.420
and that can easily be configured in a way

02:05:33.420 --> 02:05:35.820
that could harm somebody from a remote operator

02:05:35.820 --> 02:05:38.700
is justifiably a scary thing.

02:05:39.620 --> 02:05:41.580
And so we felt like it was important

02:05:41.580 --> 02:05:44.140
to draw a bright line there and say,

02:05:44.140 --> 02:05:45.660
we're not going to allow this.

02:05:46.500 --> 02:05:51.140
For reasons that we think ultimately

02:05:51.140 --> 02:05:53.220
it's better for the whole industry

02:05:53.220 --> 02:05:57.940
if it grows in a way where robots

02:05:57.940 --> 02:05:59.780
are ultimately going to help us all

02:05:59.780 --> 02:06:03.540
and make our lives more fulfilled and productive,

02:06:03.540 --> 02:06:05.860
but by goodness, you're going to have to trust

02:06:05.860 --> 02:06:08.220
the technology to let it in.

02:06:08.220 --> 02:06:11.660
And if you think the robot's going to harm you,

02:06:11.660 --> 02:06:15.620
that's going to impede the growth of that industry.

02:06:16.460 --> 02:06:19.340
So we thought it was important to draw a bright line

02:06:22.260 --> 02:06:24.700
and then publicize that.

02:06:24.700 --> 02:06:28.100
And our plan is to begin to engage

02:06:28.100 --> 02:06:31.300
with lawmakers and regulators.

02:06:31.860 --> 02:06:34.980
Let's figure out what the rules are going to be

02:06:34.980 --> 02:06:36.940
around the use of this technology

02:06:37.860 --> 02:06:42.180
and use our position as leaders in this industry

02:06:42.180 --> 02:06:45.700
and technology to help force that issue.

02:06:47.020 --> 02:06:51.540
And so we are, in fact, I have a policy director

02:06:51.540 --> 02:06:55.660
at my company whose job it is to engage with the public,

02:06:55.660 --> 02:07:00.260
to engage with interested parties and including regulators

02:07:00.260 --> 02:07:02.100
to sort of begin these discussions.

02:07:03.380 --> 02:07:04.860
Yes, and a really important topic,

02:07:05.020 --> 02:07:06.340
and it's an important topic for people

02:07:06.340 --> 02:07:09.300
that worry about the impact of robots on our society

02:07:09.300 --> 02:07:11.940
with autonomous weapons systems.

02:07:11.940 --> 02:07:14.420
So I'm glad you're sort of leading the way in this.

02:07:16.660 --> 02:07:19.220
You are the CEO of Boston Dynamics.

02:07:19.220 --> 02:07:21.860
What's it take to be a CEO of a robotics company?

02:07:21.860 --> 02:07:24.260
So you started as a humble engineer, PhD.

02:07:29.700 --> 02:07:31.420
Just looking at your journey,

02:07:32.380 --> 02:07:35.140
what does it take to go from being,

02:07:35.140 --> 02:07:40.100
from building the thing to leading a company?

02:07:40.100 --> 02:07:42.380
What are some of the big challenges for you?

02:07:44.100 --> 02:07:48.980
Courage, I would put front and center for multiple reasons.

02:07:49.980 --> 02:07:53.100
I talked earlier about the courage to tackle hard problems.

02:07:53.980 --> 02:07:56.180
So I think there's courage required not just of me,

02:07:56.180 --> 02:07:59.980
but of all of the people who work at Boston Dynamics.

02:08:00.860 --> 02:08:03.620
I also think we have a lot of really smart people.

02:08:03.620 --> 02:08:06.540
We have people who are way smarter than I am.

02:08:06.540 --> 02:08:08.620
And I think it takes a kind of courage

02:08:08.620 --> 02:08:12.140
to be willing to lead them and to trust

02:08:12.140 --> 02:08:15.820
that you have something to offer to somebody

02:08:15.820 --> 02:08:20.820
who probably is maybe a better engineer than I am.

02:08:23.660 --> 02:08:26.380
Adaptability, you know, part of it,

02:08:26.380 --> 02:08:27.860
it's been a great career for me.

02:08:27.860 --> 02:08:29.380
I never would have guessed I'd stayed

02:08:29.380 --> 02:08:31.060
in one place for 30 years.

02:08:32.700 --> 02:08:34.620
And the job has always changed.

02:08:36.020 --> 02:08:40.460
I didn't really aspire to be CEO from the very beginning,

02:08:40.460 --> 02:08:43.100
but it was the natural progression of things.

02:08:43.100 --> 02:08:45.420
There was always, there always needed to be

02:08:45.420 --> 02:08:48.260
some level of management that was needed.

02:08:48.260 --> 02:08:52.460
And so, you know, when I saw something that needed

02:08:52.460 --> 02:08:54.340
to be done that wasn't being done,

02:08:54.340 --> 02:08:55.860
I just stepped in to go do it.

02:08:55.860 --> 02:08:58.500
And oftentimes, because we were full

02:08:58.500 --> 02:09:01.340
of such strong engineers,

02:09:01.340 --> 02:09:04.540
oftentimes that was in the management direction

02:09:04.540 --> 02:09:06.900
or it was in the business development direction

02:09:06.900 --> 02:09:10.140
or organizational hiring.

02:09:10.140 --> 02:09:12.620
Geez, I was the main person hiring

02:09:12.620 --> 02:09:14.460
at Boston Dynamics for probably 20 years.

02:09:14.460 --> 02:09:16.620
So I was the head of HR basically.

02:09:17.540 --> 02:09:21.060
So I, you know, just willingness to sort of tackle

02:09:21.060 --> 02:09:24.820
any piece of the business that needs it

02:09:24.860 --> 02:09:26.700
and then be willing to shift.

02:09:26.700 --> 02:09:27.660
Is there something you could say

02:09:27.660 --> 02:09:30.100
to what it takes to hire a great team?

02:09:30.100 --> 02:09:33.940
What's a good interview process?

02:09:33.940 --> 02:09:36.900
How do you know the guy or gal

02:09:36.900 --> 02:09:41.580
are gonna make a great member of a engineering team

02:09:41.580 --> 02:09:44.140
that's doing some of the hardest work in the world?

02:09:45.340 --> 02:09:47.540
You know, we developed an interview process

02:09:47.540 --> 02:09:50.260
that I was quite fond of.

02:09:50.260 --> 02:09:52.620
It's a little bit of a hard interview process

02:09:52.620 --> 02:09:55.340
because the best interviews,

02:09:55.340 --> 02:09:57.940
you ask somebody about what they're interested in

02:09:57.940 --> 02:09:59.180
and what they're good at.

02:10:00.260 --> 02:10:02.940
And if they can describe to you

02:10:02.940 --> 02:10:04.220
something that they worked on

02:10:04.220 --> 02:10:06.260
and you saw they really did the work,

02:10:06.260 --> 02:10:08.420
they solved the problems,

02:10:08.420 --> 02:10:10.220
and you saw their passion for it.

02:10:12.660 --> 02:10:15.180
And you can ask, but what makes that hard

02:10:15.180 --> 02:10:16.900
is you have to ask a probing question about it.

02:10:16.900 --> 02:10:18.620
You have to be smart enough

02:10:18.620 --> 02:10:22.140
about what they're telling you, their expert at,

02:10:22.140 --> 02:10:23.740
to ask a good question.

02:10:23.740 --> 02:10:26.940
And so it takes a pretty talented team to do that.

02:10:28.020 --> 02:10:30.860
But if you can do that, that's how you tap in to,

02:10:30.860 --> 02:10:33.020
ah, this person cares about their work,

02:10:33.020 --> 02:10:35.540
they really did the work, they're excited about it,

02:10:35.540 --> 02:10:38.220
that's the kind of person I want at my company.

02:10:39.340 --> 02:10:40.740
You know, at Google,

02:10:40.740 --> 02:10:43.780
they taught us about their interview process

02:10:43.780 --> 02:10:45.580
and it was a little bit different.

02:10:46.980 --> 02:10:51.540
You know, we evolved the process at Boston Dynamics

02:10:51.540 --> 02:10:54.100
where it didn't matter if you were an engineer

02:10:54.100 --> 02:10:57.140
or you were an administrative assistant

02:10:57.140 --> 02:11:00.060
or a financial person or a technician.

02:11:00.060 --> 02:11:01.660
You gave us a presentation.

02:11:01.660 --> 02:11:03.820
You came in and you gave us a presentation.

02:11:03.820 --> 02:11:06.620
You had to stand up and talk in front of us.

02:11:06.620 --> 02:11:08.060
And I just thought that was great

02:11:08.060 --> 02:11:10.380
to tap into those things I just described to you.

02:11:10.380 --> 02:11:12.140
At Google, they taught us,

02:11:12.140 --> 02:11:14.420
and I think I understand why, right?

02:11:14.420 --> 02:11:17.180
They're hiring tens of thousands of people.

02:11:17.180 --> 02:11:19.380
They need a more standardized process.

02:11:19.380 --> 02:11:21.500
So they would sort of err on the other side,

02:11:22.460 --> 02:11:23.620
where they would ask you a standard question.

02:11:23.620 --> 02:11:25.380
I'm gonna ask you a programming question

02:11:25.380 --> 02:11:28.860
and I'm just gonna ask you to write code in front of me.

02:11:28.860 --> 02:11:32.580
That's a terrifying, you know, application process.

02:11:33.660 --> 02:11:37.100
It does let you compare candidates really well,

02:11:37.100 --> 02:11:41.100
but it doesn't necessarily let you tap in to who they are,

02:11:41.100 --> 02:11:43.660
right, because you're asking them to answer your question

02:11:43.660 --> 02:11:47.420
instead of you asking them about what they're interested in.

02:11:47.420 --> 02:11:50.260
But frankly, that process is hard to scale

02:11:50.300 --> 02:11:52.700
and even at Boston Dynamics,

02:11:52.700 --> 02:11:55.100
we're not doing that with everybody anymore.

02:11:55.100 --> 02:11:59.380
But we are still doing that with the technical people,

02:11:59.380 --> 02:12:02.700
but because we too now need to sort of increase

02:12:02.700 --> 02:12:04.620
our rate of hiring,

02:12:04.620 --> 02:12:06.980
not everybody's giving a presentation anymore.

02:12:06.980 --> 02:12:08.700
But you're still ultimately trying to find

02:12:08.700 --> 02:12:11.100
that basic seed of passion for the world.

02:12:11.100 --> 02:12:14.420
Yeah, in terms, you know, did they really do it?

02:12:14.420 --> 02:12:19.100
Did they find something interesting or curious, you know?

02:12:19.300 --> 02:12:20.860
And do they care about it?

02:12:20.860 --> 02:12:25.780
I think somebody admires Jim Keller

02:12:25.780 --> 02:12:30.380
and he likes details.

02:12:30.380 --> 02:12:34.340
So one of the ways, if you get a person to talk about

02:12:34.340 --> 02:12:37.180
what they're interested in, how many details,

02:12:37.180 --> 02:12:39.940
like how much of the whiteboard can you fill out?

02:12:39.940 --> 02:12:41.020
Well, I think you figure out,

02:12:41.020 --> 02:12:42.020
did they really do the work

02:12:42.020 --> 02:12:43.660
if they know some of the details?

02:12:43.660 --> 02:12:45.340
And if they have to wash over the details,

02:12:45.340 --> 02:12:47.460
well, then they didn't do it.

02:12:47.500 --> 02:12:50.980
Especially with engineering, the work is in the details.

02:12:52.500 --> 02:12:54.700
I have to go there briefly

02:12:56.180 --> 02:12:58.140
just to get your kind of thoughts

02:12:58.140 --> 02:13:00.500
in the long-term future of robotics.

02:13:02.300 --> 02:13:04.740
There's been discussions on the GPT side

02:13:04.740 --> 02:13:06.860
on the large language model side

02:13:06.860 --> 02:13:08.860
of whether there's consciousness

02:13:08.860 --> 02:13:10.900
inside these language models.

02:13:12.340 --> 02:13:15.220
And I think there's fear,

02:13:15.300 --> 02:13:17.620
but I think there's also excitement,

02:13:17.620 --> 02:13:21.260
or at least a wide world of opportunity and possibility

02:13:21.260 --> 02:13:25.140
in embodied robots having something like,

02:13:25.140 --> 02:13:26.860
let's start with emotion,

02:13:28.580 --> 02:13:31.860
love towards other human beings,

02:13:31.860 --> 02:13:36.860
and perhaps the display, real or fake, of consciousness.

02:13:37.780 --> 02:13:39.820
Is this something you think about

02:13:39.820 --> 02:13:42.180
in terms of long-term future?

02:13:42.180 --> 02:13:45.580
Because as we've talked about,

02:13:45.580 --> 02:13:48.460
people do anthropomorphize these robots.

02:13:49.740 --> 02:13:53.340
It's difficult not to project some level of,

02:13:53.340 --> 02:13:55.340
I use the word sentience,

02:13:55.340 --> 02:13:59.420
some level of sovereignty, identity,

02:13:59.420 --> 02:14:00.780
all the things we think is human.

02:14:00.780 --> 02:14:02.740
That's what anthropomorphization is,

02:14:02.740 --> 02:14:07.060
is we project humanness onto mobile,

02:14:07.060 --> 02:14:08.620
especially legged robots.

02:14:09.900 --> 02:14:12.060
Is that something, almost from a science fiction perspective,

02:14:12.940 --> 02:14:15.140
or do you try to avoid ever,

02:14:17.100 --> 02:14:19.900
try to avoid the topic of consciousness altogether?

02:14:21.140 --> 02:14:22.580
I'm certainly not an expert in it,

02:14:22.580 --> 02:14:24.340
and I don't spend a lot of time

02:14:24.340 --> 02:14:26.380
thinking about this, right?

02:14:26.380 --> 02:14:28.740
And I do think it's fairly remote

02:14:28.740 --> 02:14:31.500
for the machines that we're dealing with.

02:14:33.860 --> 02:14:36.420
Our robots, you're right, the people anthropomorphize,

02:14:36.420 --> 02:14:40.420
they read into the robot's intelligence and emotion

02:14:40.420 --> 02:14:45.220
that isn't there because they see physical gestures

02:14:45.220 --> 02:14:47.260
that are similar to things they might even see

02:14:47.260 --> 02:14:48.380
in people or animals.

02:14:50.820 --> 02:14:51.820
I don't know much about

02:14:51.820 --> 02:14:54.540
how these large language models really work.

02:14:54.540 --> 02:14:58.340
I believe it's a kind of statistical averaging

02:14:58.340 --> 02:15:01.820
of the most common responses to a series of words, right?

02:15:01.820 --> 02:15:06.820
It's sort of a very elaborate word completion.

02:15:07.660 --> 02:15:11.660
And I'm dubious that that has anything

02:15:11.660 --> 02:15:13.260
to do with consciousness.

02:15:15.060 --> 02:15:18.260
And I even wonder if that model of sort of

02:15:18.260 --> 02:15:21.420
simulating consciousness by stringing words together

02:15:21.420 --> 02:15:23.980
that are statistically associated with one another,

02:15:25.500 --> 02:15:27.580
whether or not that kind of knowledge,

02:15:27.580 --> 02:15:29.460
if you want to call that knowledge,

02:15:30.900 --> 02:15:34.460
would be the kind of knowledge that allowed

02:15:35.340 --> 02:15:38.740
a sentient being to grow or evolve.

02:15:38.740 --> 02:15:43.740
It feels to me like there's something about truth

02:15:43.740 --> 02:15:47.740
or emotions that's just a very different kind of knowledge

02:15:47.740 --> 02:15:49.540
that is absolute.

02:15:49.540 --> 02:15:52.500
Like the interesting thing about truth is it's absolute.

02:15:52.500 --> 02:15:54.940
And it doesn't matter how frequently it's represented

02:15:54.940 --> 02:15:56.340
in the World Wide Web.

02:15:56.340 --> 02:16:00.660
If you know it to be true, it may only be there once,

02:16:00.660 --> 02:16:02.060
but by God, it's true.

02:16:02.420 --> 02:16:04.660
And I think emotions are a little bit like that too.

02:16:04.660 --> 02:16:07.460
You know something, you know,

02:16:07.460 --> 02:16:11.460
and I just think that's a different kind of knowledge

02:16:11.460 --> 02:16:14.220
than the way these large language models

02:16:14.220 --> 02:16:18.220
derive sort of simulated intelligence.

02:16:18.220 --> 02:16:20.220
It does seem that things that are true

02:16:21.980 --> 02:16:25.420
very well might be statistically well represented

02:16:25.420 --> 02:16:29.420
on the internet because the internet is made up of humans.

02:16:29.580 --> 02:16:32.740
So I tend to suspect that large language models

02:16:32.740 --> 02:16:34.940
are going to be able to simulate consciousness

02:16:34.940 --> 02:16:36.140
very effectively.

02:16:36.140 --> 02:16:39.020
And I actually believe that current GPT-4,

02:16:39.020 --> 02:16:43.020
when fine-tuned correctly, would be able to do just that.

02:16:43.020 --> 02:16:44.860
And that's going to be a lot of very complicated

02:16:44.860 --> 02:16:47.940
ethical questions that have to be dealt with.

02:16:47.940 --> 02:16:50.260
They have nothing to do with robotics.

02:16:50.260 --> 02:16:52.500
They have everything to do with...

02:16:52.500 --> 02:16:56.580
There needs to be some process of labeling

02:16:56.980 --> 02:17:01.980
what is true, because there is also disinformation

02:17:02.300 --> 02:17:06.300
available on the web, and these models are going to consider

02:17:06.300 --> 02:17:08.740
that kind of information as well.

02:17:08.740 --> 02:17:11.940
And again, you can't average something that's true

02:17:11.940 --> 02:17:13.740
and something that's untrue

02:17:13.740 --> 02:17:16.180
and get something that's moderately true.

02:17:16.180 --> 02:17:18.380
It's either right or it's wrong.

02:17:18.380 --> 02:17:20.980
And so how is that process...

02:17:20.980 --> 02:17:23.940
And this is obviously something that I've been doing

02:17:24.380 --> 02:17:27.780
and this is obviously something that the purveyors

02:17:27.780 --> 02:17:30.180
of these, BARD and CHAT GPT,

02:17:30.180 --> 02:17:31.740
I'm sure this is what they're working on.

02:17:31.740 --> 02:17:34.500
Well, if you interact on some controversial topics

02:17:34.500 --> 02:17:39.140
with these models, they're actually refreshingly nuanced.

02:17:39.140 --> 02:17:44.140
They present, because you realize there's no one truth.

02:17:46.900 --> 02:17:49.940
What caused the war in Ukraine?

02:17:51.700 --> 02:17:53.100
Any geopolitical conflict.

02:17:53.100 --> 02:17:54.580
You can ask any kind of question,

02:17:54.580 --> 02:17:59.140
especially the ones that are politically tense,

02:17:59.140 --> 02:18:00.940
divisive and so on.

02:18:00.940 --> 02:18:02.500
GPT is very good at presenting.

02:18:02.500 --> 02:18:06.820
Here's the, it presents the different hypotheses.

02:18:06.820 --> 02:18:11.820
It presents calmly the amount of evidence for each one.

02:18:12.380 --> 02:18:14.820
It's very, it's really refreshing.

02:18:14.820 --> 02:18:17.820
It makes you realize that truth is nuanced

02:18:17.820 --> 02:18:18.940
and it does that well.

02:18:18.940 --> 02:18:21.340
And I think with consciousness,

02:18:21.340 --> 02:18:25.420
it would very accurately say,

02:18:25.420 --> 02:18:30.220
well, it sure as hell feels like I'm one of you humans,

02:18:30.220 --> 02:18:32.100
but where's my body?

02:18:32.100 --> 02:18:33.820
I don't understand.

02:18:33.820 --> 02:18:35.220
You're going to be confused.

02:18:35.220 --> 02:18:40.020
The cool thing about GPT is it seems to be easily confused

02:18:40.020 --> 02:18:41.700
in the way we are.

02:18:41.700 --> 02:18:45.580
You wake up in a new room and you ask, where am I?

02:18:45.580 --> 02:18:49.140
It seems to be able to do that extremely well.

02:18:49.140 --> 02:18:51.300
It'll tell you one thing like a fact

02:18:51.300 --> 02:18:52.620
about when a war started.

02:18:52.620 --> 02:18:54.540
And when you correct it, say, well, this isn't,

02:18:54.540 --> 02:18:55.500
that's not consistent.

02:18:55.500 --> 02:18:56.420
It'll be confused.

02:18:56.420 --> 02:18:58.500
It'd be, yeah, you're right.

02:18:58.500 --> 02:19:02.980
It'll have that same element, childlike element

02:19:02.980 --> 02:19:07.100
with humility of trying to figure out its way in the world.

02:19:07.100 --> 02:19:10.180
And I think that's a really tricky area

02:19:10.180 --> 02:19:13.180
to sort of figure out with us humans

02:19:13.340 --> 02:19:18.340
what we want to allow AI systems to say to us.

02:19:18.460 --> 02:19:21.900
Because then if there's elements of sentience

02:19:21.900 --> 02:19:24.100
that are being on display,

02:19:24.100 --> 02:19:26.180
you can then start to manipulate human emotion

02:19:26.180 --> 02:19:27.020
and all that kind of stuff.

02:19:27.020 --> 02:19:29.820
But I think that's something,

02:19:29.820 --> 02:19:31.860
that's a really serious and aggressive discussion

02:19:31.860 --> 02:19:35.500
that needs to be had on the software side.

02:19:35.500 --> 02:19:40.500
I think, again, embodiment robotics are actually saving us

02:19:41.500 --> 02:19:45.220
from the arbitrary scaling of software systems

02:19:45.220 --> 02:19:47.980
versus creating more problems.

02:19:47.980 --> 02:19:51.620
But that said, I really believe in that connection

02:19:51.620 --> 02:19:52.660
between human and robot.

02:19:52.660 --> 02:19:53.780
There's magic there.

02:19:54.620 --> 02:19:57.780
And I think there's also, I think,

02:19:57.780 --> 02:19:59.500
a lot of money to be made there.

02:19:59.500 --> 02:20:01.780
And Boston Dynamics is leading the world

02:20:01.780 --> 02:20:06.780
in the most elegant movement done by robots.

02:20:07.620 --> 02:20:12.620
So I can't wait to what maybe other people

02:20:12.620 --> 02:20:15.900
that built on top of Boston Dynamics robots

02:20:15.900 --> 02:20:18.740
or Boston Dynamics by itself.

02:20:18.740 --> 02:20:22.780
So you had one wild career, one place,

02:20:22.780 --> 02:20:27.300
and one set of problems, but incredibly successful.

02:20:27.300 --> 02:20:31.260
Can you give advice to young folks today in high school,

02:20:31.260 --> 02:20:34.260
maybe in college, looking out to this future,

02:20:35.260 --> 02:20:40.260
where so much robotics and AI seems to be defining

02:20:43.020 --> 02:20:44.700
the trajectory of human civilization?

02:20:44.700 --> 02:20:48.260
Can you give them advice on how to have a career

02:20:48.260 --> 02:20:50.020
they can be proud of,

02:20:50.020 --> 02:20:52.220
or how to have a life they can be proud of?

02:20:53.740 --> 02:20:58.180
Well, I would say, follow your heart and your interest.

02:20:59.500 --> 02:21:01.620
Again, this was an organizing principle, I think,

02:21:01.620 --> 02:21:04.780
behind the leg lab at MIT

02:21:04.780 --> 02:21:09.260
that turned into a value at Boston Dynamics,

02:21:09.260 --> 02:21:14.260
which was follow your curiosity, love what you're doing.

02:21:16.820 --> 02:21:17.980
You'll have a lot more fun

02:21:17.980 --> 02:21:20.740
and you'll be a lot better at it as a result.

02:21:24.620 --> 02:21:26.740
I think it's hard to plan, you know?

02:21:26.740 --> 02:21:30.460
Don't get too hung up on planning too far ahead.

02:21:30.500 --> 02:21:32.060
Find things that you like doing

02:21:32.060 --> 02:21:33.660
and then see where it takes you.

02:21:33.660 --> 02:21:35.020
You can always change direction.

02:21:35.020 --> 02:21:36.940
You will find things that, you know,

02:21:36.940 --> 02:21:38.140
ah, that wasn't a good move.

02:21:38.140 --> 02:21:40.860
I'm gonna back up and go do something else.

02:21:40.860 --> 02:21:43.380
So when people are trying to plan a career,

02:21:43.380 --> 02:21:46.260
I always feel like, ah, there's a few happy mistakes

02:21:46.260 --> 02:21:49.380
that happen along the way, and just live with that,

02:21:49.380 --> 02:21:52.260
you know, but just, but make choices then.

02:21:52.260 --> 02:21:55.500
So avail yourselves to these interesting opportunities,

02:21:55.500 --> 02:21:57.940
like when I happened to run into Mark down in the lab,

02:21:57.940 --> 02:21:59.940
the basement of the AI lab,

02:21:59.940 --> 02:22:02.980
but be willing to make a decision and then pivot

02:22:02.980 --> 02:22:05.980
if you see something exciting to go at, you know?

02:22:05.980 --> 02:22:08.220
Because if you're out and about enough,

02:22:08.220 --> 02:22:12.060
you'll find things like that that get you excited.

02:22:12.060 --> 02:22:14.220
So there was a feeling when you first met Mark

02:22:14.220 --> 02:22:16.940
and saw the robots that there's something interesting.

02:22:16.940 --> 02:22:19.100
Oh boy, I gotta go do this.

02:22:19.100 --> 02:22:20.140
There is no doubt.

02:22:21.660 --> 02:22:24.140
What do you think in a hundred years,

02:22:25.860 --> 02:22:28.420
what do you think Boston Dynamics is doing?

02:22:28.420 --> 02:22:30.380
What do you think is the role, even bigger,

02:22:30.380 --> 02:22:32.780
what do you think is the role of robots in society?

02:22:32.780 --> 02:22:34.220
Do you think we'll be seeing

02:22:35.380 --> 02:22:38.180
billions of robots everywhere?

02:22:39.060 --> 02:22:41.060
Do you think about that long-term vision?

02:22:42.180 --> 02:22:43.340
Well, I do think that,

02:22:47.020 --> 02:22:49.700
I think that robots will be ubiquitous,

02:22:49.700 --> 02:22:52.260
and they will be out amongst us.

02:22:52.740 --> 02:22:56.740
And they'll be certainly doing,

02:22:56.740 --> 02:22:59.140
you know, some of the hard labor that we do today.

02:23:00.700 --> 02:23:03.020
I don't think people don't wanna work.

02:23:03.020 --> 02:23:03.860
People wanna work.

02:23:03.860 --> 02:23:07.540
People need to work to, I think, feel productive.

02:23:07.540 --> 02:23:10.780
We don't wanna offload all of the work to the robots

02:23:10.780 --> 02:23:12.380
because I'm not sure if people would know

02:23:12.380 --> 02:23:13.700
what to do with themselves.

02:23:13.700 --> 02:23:16.180
And I think just self-satisfaction

02:23:16.180 --> 02:23:19.420
and feeling productive is such an ingrained

02:23:19.580 --> 02:23:22.340
part of being human that we need to keep doing this work.

02:23:22.340 --> 02:23:24.380
So we're definitely gonna have to

02:23:24.380 --> 02:23:26.060
work in a complementary fashion.

02:23:26.060 --> 02:23:28.340
And I hope that the robots and the computers

02:23:28.340 --> 02:23:31.580
don't end up being able to do all the creative work, right?

02:23:31.580 --> 02:23:34.580
Because that's the part that's, you know,

02:23:34.580 --> 02:23:35.420
that's the rewarding.

02:23:35.420 --> 02:23:38.180
The creative part of solving a problem

02:23:38.180 --> 02:23:42.620
is the thing that gives you that serotonin rush

02:23:42.620 --> 02:23:45.500
that you never forget, you know?

02:23:45.500 --> 02:23:48.020
Or that adrenaline rush that you never forget.

02:23:48.580 --> 02:23:51.460
And so, you know, people need to be able to do

02:23:51.460 --> 02:23:54.340
that creative work and just feel productive.

02:23:54.340 --> 02:23:56.780
And sometimes you can feel productive

02:23:56.780 --> 02:23:59.460
over fairly simple work, but it's just well done,

02:23:59.460 --> 02:24:01.660
you know, and you can see the result of.

02:24:01.660 --> 02:24:06.660
So I, you know, there was a, I don't know,

02:24:06.660 --> 02:24:10.660
there was a cartoon, was it WALL-E?

02:24:10.660 --> 02:24:14.100
Where they had this big ship and all the people

02:24:14.100 --> 02:24:16.620
were just, you know, they were like,

02:24:16.700 --> 02:24:21.580
people were just overweight, lying on their beach chairs,

02:24:21.580 --> 02:24:25.140
kind of sliding around on the deck of the movie

02:24:25.140 --> 02:24:27.100
because they didn't do anything anymore.

02:24:27.100 --> 02:24:30.740
Well, we definitely don't want to be there, you know?

02:24:30.740 --> 02:24:32.740
We need to work in some complementary fashion

02:24:32.740 --> 02:24:35.260
where we keep all of our faculties and our physical health

02:24:35.260 --> 02:24:37.140
and we're doing some labor, right,

02:24:37.140 --> 02:24:39.220
but in a complementary fashion somehow.

02:24:39.220 --> 02:24:42.580
And I think a lot of that has to do with the interaction,

02:24:42.580 --> 02:24:45.380
the collaboration with robots and with AI systems.

02:24:45.420 --> 02:24:47.860
I'm hoping there's a lot of interesting possibilities there.

02:24:47.860 --> 02:24:49.340
I think that could be really cool, right?

02:24:49.340 --> 02:24:54.340
If you can work in an interaction and really be helpful.

02:24:54.780 --> 02:24:58.780
Robots, you know, you can ask a robot to do a job

02:24:58.780 --> 02:25:00.300
you wouldn't ask a person to do,

02:25:00.300 --> 02:25:01.900
and that would be a real asset.

02:25:01.900 --> 02:25:04.380
You wouldn't feel guilty about it, you know?

02:25:04.380 --> 02:25:07.100
You'd say, just do it, it's a machine.

02:25:07.100 --> 02:25:09.620
And I don't have to have qualms about that, you know?

02:25:09.620 --> 02:25:10.700
The ones that are machines.

02:25:10.700 --> 02:25:15.340
I also hope to see a future, and it is hope.

02:25:15.380 --> 02:25:17.020
I do have optimism about the future

02:25:17.020 --> 02:25:19.700
where some of the robots are pets,

02:25:19.700 --> 02:25:22.020
have an emotional connection to us humans.

02:25:22.020 --> 02:25:24.780
And because one of the problems that humans have to solve

02:25:24.780 --> 02:25:28.440
is this kind of, a general loneliness.

02:25:29.540 --> 02:25:30.940
The more love you have in your life,

02:25:30.940 --> 02:25:33.020
the more friends you have in your life.

02:25:33.020 --> 02:25:35.860
I think that makes a more enriching life, helps you grow.

02:25:35.860 --> 02:25:38.660
And I don't fundamentally see why some of those friends

02:25:38.660 --> 02:25:40.020
can't be robots.

02:25:40.020 --> 02:25:42.860
There's an interesting long-running study,

02:25:42.860 --> 02:25:43.940
maybe it's in Harvard.

02:25:44.420 --> 02:25:47.580
Nice report, article written about it recently.

02:25:47.580 --> 02:25:51.420
They've been studying this group of a few thousand people

02:25:51.420 --> 02:25:54.420
now for 70 or 80 years.

02:25:54.420 --> 02:25:59.420
And the conclusion is that companionship and friendship

02:25:59.620 --> 02:26:03.060
are the things that make for a better and happier life.

02:26:03.060 --> 02:26:06.640
And so I agree with you.

02:26:06.640 --> 02:26:10.940
And I think that could happen with a machine

02:26:10.940 --> 02:26:15.060
that is probably simulating intelligence.

02:26:15.060 --> 02:26:18.460
I'm not convinced there will ever be true intelligence

02:26:18.460 --> 02:26:23.220
in these machines, sentience, but they could simulate it

02:26:23.220 --> 02:26:25.980
and they could collect your history and they could,

02:26:25.980 --> 02:26:27.540
I guess it remains to be seen

02:26:27.540 --> 02:26:30.060
whether they can establish that real deep.

02:26:30.060 --> 02:26:30.980
When you sit with a friend

02:26:30.980 --> 02:26:33.620
and they remember something about you and bring that up

02:26:33.620 --> 02:26:36.860
and you feel that connection, it remains to be seen

02:26:36.860 --> 02:26:39.420
if a machine's gonna be able to do that for you.

02:26:39.420 --> 02:26:41.700
Well, I have to say, inklings of that

02:26:41.700 --> 02:26:43.340
are already starting to happen for me,

02:26:43.340 --> 02:26:45.260
some of my best friends are robots.

02:26:46.460 --> 02:26:48.860
And I have you to thank for leading the way

02:26:48.860 --> 02:26:53.340
in the accessibility and the ease of use of such robots

02:26:53.340 --> 02:26:55.320
and the elegance of their movement.

02:26:55.320 --> 02:26:56.880
Robert, you're an incredible person.

02:26:56.880 --> 02:26:58.780
Boston Dynamics is an incredible company.

02:26:58.780 --> 02:27:00.980
I've just been a fan for many, many years

02:27:00.980 --> 02:27:01.940
for everything you stand for,

02:27:01.940 --> 02:27:03.380
for everything you do in the world.

02:27:03.380 --> 02:27:05.380
If you're interested in great engineering robotics,

02:27:05.380 --> 02:27:07.140
go join them, build cool stuff.

02:27:07.180 --> 02:27:09.420
I'll forever celebrate the work you're doing.

02:27:09.420 --> 02:27:12.900
And it's just a big honor that you sit with me today

02:27:12.900 --> 02:27:14.100
and talk, it means a lot.

02:27:14.100 --> 02:27:15.500
So thank you so much.

02:27:15.500 --> 02:27:16.420
You're doing great work.

02:27:16.420 --> 02:27:17.260
Thank you, Lex.

02:27:17.260 --> 02:27:20.240
I'm honored to be here and I appreciate it, it was fun.

02:27:21.260 --> 02:27:22.700
Thanks for listening to this conversation

02:27:22.700 --> 02:27:23.940
with Robert Plater.

02:27:23.940 --> 02:27:25.060
To support this podcast,

02:27:25.060 --> 02:27:28.020
please check out our sponsors in the description.

02:27:28.020 --> 02:27:29.920
And now, let me leave you with some words

02:27:29.920 --> 02:27:32.780
from Alan Turing in 1950,

02:27:32.780 --> 02:27:36.300
defining what is now termed the Turing Test.

02:27:37.340 --> 02:27:40.620
A computer would deserve to be called intelligent

02:27:40.620 --> 02:27:42.560
if it could deceive a human

02:27:42.560 --> 02:27:45.100
into believing that it was human.

02:27:45.940 --> 02:27:49.080
Thank you for listening and hope to see you next time.

