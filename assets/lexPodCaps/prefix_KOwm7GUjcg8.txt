WEBVTT

00:00.000 --> 00:02.000
we are becoming cyborgs.

00:02.000 --> 00:04.080
Our brains are fundamentally changed.

00:04.080 --> 00:05.780
Everyone who grew up with electronics,

00:05.780 --> 00:09.840
we are fundamentally different from homo sapiens.

00:09.840 --> 00:11.080
I call us homo techno.

00:11.080 --> 00:13.240
I think we have evolved into homo techno,

00:13.240 --> 00:15.800
which is like essentially a new species.

00:15.800 --> 00:17.840
Previous technologies, I mean,

00:17.840 --> 00:19.120
may have even been more profound

00:19.120 --> 00:20.180
and moved us to a certain degree,

00:20.180 --> 00:22.760
but I think the computers are what make us homo techno.

00:22.760 --> 00:25.600
I think this is what, it's a brain augmentation.

00:25.600 --> 00:27.840
So it like allows for actual evolution.

00:27.840 --> 00:29.480
Like the computers accelerate the degree

00:29.480 --> 00:31.120
into which all the other technologies

00:31.120 --> 00:32.720
can also be accelerated.

00:32.720 --> 00:34.760
Would you classify yourself as a homo sapien

00:34.760 --> 00:35.640
or a homo techno?

00:35.640 --> 00:37.120
Definitely homo techno.

00:37.120 --> 00:41.000
So you're one of the earliest of the species.

00:41.000 --> 00:43.100
I think most of us are.

00:45.440 --> 00:47.800
The following is a conversation with Grimes,

00:47.800 --> 00:50.560
an artist, musician, songwriter, producer, director,

00:50.560 --> 00:53.080
and a fascinating human being

00:53.080 --> 00:55.520
who thinks a lot about both the history

00:55.520 --> 00:57.560
and the future of human civilization.

00:57.560 --> 00:59.840
Studying the dark periods of our past

00:59.840 --> 01:03.920
to help form an optimistic vision of our future.

01:03.920 --> 01:05.760
This is the Lex Fridman podcast.

01:05.760 --> 01:07.880
To support it, please check out our sponsors

01:07.880 --> 01:09.040
in the description.

01:09.040 --> 01:11.960
And now, dear friends, here's Grimes.

01:12.880 --> 01:14.520
Oh yeah, the cloud lifter, there you go.

01:14.520 --> 01:15.360
There you go.

01:15.360 --> 01:16.480
You know your stuff.

01:16.480 --> 01:18.280
Have you ever used a cloud lifter?

01:18.280 --> 01:21.000
Yeah, I actually, this microphone cloud lifter

01:21.000 --> 01:23.480
is what Michael Jackson used, so.

01:23.480 --> 01:24.440
No, really?

01:24.440 --> 01:26.040
Yeah, this is like thriller and stuff.

01:26.080 --> 01:27.920
This mic and the cloud lifter?

01:27.920 --> 01:30.640
Yeah, it's an incredible microphone.

01:30.640 --> 01:32.040
It's very flattering on vocals.

01:32.040 --> 01:33.600
I've used this a lot.

01:33.600 --> 01:34.720
It's great for demo vocals.

01:34.720 --> 01:36.640
It's great in a room.

01:36.640 --> 01:38.280
Sometimes it's easier to record vocals

01:38.280 --> 01:40.600
if you're just in a room and the music's playing

01:40.600 --> 01:43.040
and you just wanna feel it so it's not in the headphones.

01:43.040 --> 01:44.680
And this mic is pretty directional,

01:44.680 --> 01:47.720
so I think it's a good mic for just vibing out

01:47.720 --> 01:49.840
and just getting a real good vocal take.

01:49.840 --> 01:51.840
Just vibing, just in a room.

01:51.840 --> 01:54.520
Anyway, this is the Michael Jackson,

01:54.520 --> 01:57.000
Quincy Jones microphone.

01:57.000 --> 01:58.800
I feel way more badass now.

01:58.800 --> 02:01.760
All right, you wanna just get into it?

02:01.760 --> 02:03.040
I guess so.

02:03.040 --> 02:04.800
All right, one of your names,

02:04.800 --> 02:06.880
at least in this space and time, is C,

02:06.880 --> 02:08.320
like the letter C.

02:08.320 --> 02:11.280
And you told me that C means a lot of things.

02:11.280 --> 02:12.640
It's the speed of light,

02:12.640 --> 02:14.680
it's the render rate of the universe,

02:14.680 --> 02:17.640
it's yes in Spanish, it's the crescent moon,

02:17.640 --> 02:21.120
and it happens to be my favorite programming language

02:21.120 --> 02:24.120
because it basically runs the world,

02:24.120 --> 02:28.200
but it's also powerful, fast, and it's dangerous

02:28.200 --> 02:30.000
because you can mess things up really bad with it

02:30.000 --> 02:31.160
because of all the pointers.

02:31.160 --> 02:33.960
But anyway, which of these associations

02:33.960 --> 02:36.600
with the name C is the coolest to you?

02:37.760 --> 02:41.640
I mean, to me, the coolest is the speed of light, obviously,

02:41.640 --> 02:42.720
or the speed of light.

02:42.720 --> 02:44.400
When I say render rate of the universe,

02:44.400 --> 02:46.280
I think I mean the speed of light

02:46.280 --> 02:49.120
because essentially that's what we're rendering at.

02:49.120 --> 02:52.200
See, I think we'll know if we're in a simulation

02:52.200 --> 02:53.760
if the speed of light changes

02:54.400 --> 02:57.280
because if they can improve their render speed, then.

02:57.280 --> 02:58.480
Well, it's already pretty good.

02:58.480 --> 03:01.040
It's already pretty good, but if it improves,

03:01.040 --> 03:03.880
then we'll know, we can probably be like,

03:03.880 --> 03:05.320
okay, they've updated or upgraded.

03:05.320 --> 03:06.800
Well, it's fast enough for us humans

03:06.800 --> 03:10.960
because it seems immediate.

03:10.960 --> 03:13.360
There's no delay, there's no latency

03:13.360 --> 03:16.240
in terms of us humans on Earth interacting with things.

03:16.240 --> 03:20.000
But if you're like intergalactic species

03:20.000 --> 03:21.440
operating on a much larger scale,

03:21.440 --> 03:23.840
then you're gonna start noticing some weird stuff.

03:23.840 --> 03:27.320
Or if you can operate in like around a black hole,

03:27.320 --> 03:29.680
then you're gonna start to see some render issues.

03:29.680 --> 03:32.680
You can't go faster than the speed of light, correct?

03:32.680 --> 03:34.520
So it really limits our ability

03:34.520 --> 03:36.680
or one's ability to travel space.

03:36.680 --> 03:38.920
Theoretically you can, you have wormholes.

03:38.920 --> 03:41.880
So there's nothing in general relativity

03:41.880 --> 03:46.880
that precludes faster than the speed of light travel,

03:48.280 --> 03:49.840
but it just seems you're gonna have to do

03:49.840 --> 03:54.000
some really funky stuff with very heavy things

03:54.000 --> 03:56.080
that have like weirdnesses,

03:56.080 --> 03:58.600
that have basically terrors in space time.

03:58.600 --> 03:59.720
We don't know how to do that.

03:59.720 --> 04:01.880
Do navigators know how to do it?

04:01.880 --> 04:03.040
Do navigators?

04:03.040 --> 04:03.880
Yeah.

04:03.880 --> 04:04.700
Yeah.

04:04.700 --> 04:07.000
Folding space, basically making wormholes.

04:07.000 --> 04:09.520
So the name C.

04:09.520 --> 04:10.360
Yes.

04:11.880 --> 04:13.140
Who are you?

04:14.800 --> 04:16.960
Do you think of yourself as multiple people?

04:16.960 --> 04:18.280
Are you one person?

04:18.320 --> 04:20.880
Do you know, like this morning,

04:20.880 --> 04:23.600
were you a different person than you are tonight?

04:23.600 --> 04:27.080
We are, I should say, recording this basically at midnight,

04:27.080 --> 04:27.920
which is awesome.

04:27.920 --> 04:28.760
Yes.

04:28.760 --> 04:29.640
Thank you so much.

04:29.640 --> 04:31.680
I think I'm about eight hours late.

04:31.680 --> 04:34.000
No, you're right on time.

04:34.000 --> 04:34.840
Good morning.

04:34.840 --> 04:37.240
This is the beginning of a new day soon.

04:37.240 --> 04:39.520
Anyway, are you the same person

04:39.520 --> 04:41.720
you were in the morning and the evening?

04:43.080 --> 04:44.360
Is there multiple people in there?

04:44.360 --> 04:46.280
Do you think of yourself as one person?

04:46.280 --> 04:47.520
Or maybe you have no clue?

04:47.520 --> 04:50.160
Or are you just a giant mystery to yourself?

04:50.160 --> 04:52.360
Okay, these are really intense questions, but.

04:52.360 --> 04:53.320
Let's go, let's go.

04:53.320 --> 04:54.520
Because I asked this myself,

04:54.520 --> 04:56.320
like look in the mirror, who are you?

04:56.320 --> 04:57.960
People tell you to just be yourself,

04:57.960 --> 04:59.640
but what does that even mean?

04:59.640 --> 05:01.520
I mean, I think my personality changes

05:01.520 --> 05:02.960
with everyone I talk to.

05:02.960 --> 05:05.720
So I have a very inconsistent personality.

05:06.600 --> 05:07.420
Yeah.

05:07.420 --> 05:08.260
Person to person.

05:08.260 --> 05:11.480
So the interaction, your personality materializes.

05:11.480 --> 05:12.320
Or my mood.

05:12.320 --> 05:16.120
Like I'll go from being like a megalomaniac

05:16.120 --> 05:19.920
to being like, you know, just like a total hermit

05:19.920 --> 05:21.400
who is very shy.

05:21.400 --> 05:24.560
So some combinatorial combination of your mood

05:24.560 --> 05:26.320
and the person you're interacting with.

05:26.320 --> 05:28.080
Yeah, mood and people I'm interacting with.

05:28.080 --> 05:29.760
But I think everyone's like that.

05:29.760 --> 05:30.880
Maybe not.

05:30.880 --> 05:32.600
Well, not everybody acknowledges it

05:32.600 --> 05:34.040
and able to introspect it.

05:34.040 --> 05:35.840
Who brings up, what kind of person,

05:35.840 --> 05:38.160
what kind of mood brings out the best in you

05:38.160 --> 05:39.740
as an artist and as a human?

05:40.880 --> 05:41.720
Can you introspect this?

05:41.720 --> 05:45.240
I'm like my best friends, like people I can,

05:45.240 --> 05:47.520
when I'm like super confident

05:47.520 --> 05:50.320
and I know that they're gonna understand

05:50.320 --> 05:52.200
everything I'm saying, so like my best friends,

05:52.200 --> 05:55.400
then when I can start being really funny,

05:55.400 --> 05:57.680
that's always my like peak mode.

05:57.680 --> 06:00.140
But it's like, yeah, takes a lot to get there.

06:00.140 --> 06:02.360
Let's talk about constraints.

06:02.360 --> 06:05.600
You've talked about constraints and limits.

06:07.000 --> 06:09.620
Do those help you out as an artist or as a human being?

06:09.620 --> 06:10.800
Or do they get in the way?

06:10.800 --> 06:11.920
Do you like the constraints?

06:11.920 --> 06:15.460
So in creating music, in creating art, in living life,

06:16.800 --> 06:19.600
do you like the constraints that this world puts on you?

06:21.880 --> 06:24.760
Or do you hate them?

06:24.760 --> 06:29.760
If constraints are moving, then you're good, right?

06:29.760 --> 06:32.080
Like it's like as we are progressing with technology,

06:32.080 --> 06:34.880
we're changing the constraints of like artistic creation.

06:36.380 --> 06:39.760
Making video and music and stuff is getting a lot cheaper.

06:39.760 --> 06:42.120
There's constantly new technology and new software

06:42.120 --> 06:44.040
that's making it faster and easier.

06:44.040 --> 06:46.720
We have so much more freedom than we had in the 70s.

06:46.720 --> 06:48.700
Like when Michael Jackson, you know,

06:48.700 --> 06:51.480
when they recorded Thriller with this microphone,

06:51.480 --> 06:54.020
like they had to use a mixing desk and all this stuff.

06:54.020 --> 06:55.640
And like probably even getting a studio

06:55.640 --> 06:56.600
is probably really expensive

06:56.600 --> 06:57.620
and you have to be a really good singer

06:57.620 --> 07:00.160
and you have to know how to use like the mixing desk

07:00.160 --> 07:02.520
and everything and now I can just, you know,

07:02.520 --> 07:05.280
make, I've made a whole album on this computer.

07:05.280 --> 07:06.800
I have a lot more freedom,

07:06.800 --> 07:10.320
but then I'm also constrained in different ways

07:10.320 --> 07:13.760
because there's like literally millions more artists.

07:13.760 --> 07:15.740
It's like a much bigger playing field.

07:15.740 --> 07:18.720
It's just like, I also, I didn't learn music.

07:18.720 --> 07:20.280
I'm not a natural musician.

07:20.280 --> 07:22.680
So I don't know anything about actual music.

07:22.680 --> 07:24.840
I just know about like the computer.

07:24.840 --> 07:29.840
So I'm really kind of just like messing around

07:30.560 --> 07:33.320
and like trying things out.

07:33.320 --> 07:35.800
Well, yeah, I mean, but the nature of music is changing.

07:35.800 --> 07:37.360
So you're saying you don't know actual music.

07:37.360 --> 07:39.280
Well, music is changing.

07:39.280 --> 07:41.960
Music is becoming, you've talked about this,

07:41.960 --> 07:46.680
is becoming, it's like merging with technology.

07:46.680 --> 07:47.700
Yes.

07:47.700 --> 07:51.440
It's becoming something more than just like

07:51.440 --> 07:53.040
the notes on a piano.

07:53.040 --> 07:55.000
It's becoming some weird composition

07:55.000 --> 07:59.480
that requires engineering skills, programming skills,

07:59.480 --> 08:03.480
some kind of human robot interaction skills

08:03.480 --> 08:05.720
and still some of the same things that Michael Jackson had,

08:06.640 --> 08:08.520
which is like a good ear for a good sense of taste

08:08.520 --> 08:09.680
of what's good and not.

08:09.680 --> 08:11.560
The final thing, what is put together.

08:11.560 --> 08:14.960
Like you're allowed, you're enabled, empowered

08:14.960 --> 08:17.240
with a laptop to layer stuff,

08:17.240 --> 08:20.320
to start like layering insane amounts of stuff.

08:20.320 --> 08:22.320
And it's super easy to do that.

08:22.320 --> 08:23.660
I do think music production

08:23.660 --> 08:25.040
is a really underrated art form.

08:25.040 --> 08:26.720
I feel like people really don't appreciate it.

08:26.720 --> 08:28.000
When I look at publishing splits,

08:28.000 --> 08:31.200
the way that people like pay producers and stuff,

08:32.480 --> 08:35.600
it's super, producers are just deeply underrated.

08:36.480 --> 08:39.200
Like so many of the songs that are popular right now

08:39.200 --> 08:40.960
or for the last 20 years,

08:40.960 --> 08:42.280
like part of the reason they're popular

08:42.280 --> 08:44.040
is because the production is really interesting

08:44.040 --> 08:45.680
or really sick or really cool.

08:45.680 --> 08:48.100
And it's like, I don't think listeners,

08:50.960 --> 08:52.560
like people just don't really understand

08:52.560 --> 08:54.680
what music production is.

08:54.680 --> 08:57.720
It's not, it's sort of like this weird,

08:57.720 --> 08:59.400
discombobulated art form.

08:59.400 --> 09:01.420
It's not like a formal, because it's so new,

09:01.420 --> 09:03.280
there isn't like a formal training

09:03.960 --> 09:06.880
path for it.

09:06.880 --> 09:10.200
It's mostly driven by like autodidacts.

09:10.200 --> 09:11.280
Like it's like almost everyone I know

09:11.280 --> 09:12.200
who's good at production,

09:12.200 --> 09:13.760
like they didn't go to music school or anything.

09:13.760 --> 09:15.080
They just taught themselves.

09:15.080 --> 09:16.060
Are they're mostly different?

09:16.060 --> 09:18.400
Like the music producers, you know,

09:18.400 --> 09:21.320
is there some commonalities that tie them together

09:21.320 --> 09:23.580
or are they all just different kinds of weirdos?

09:23.580 --> 09:25.440
Cause I just, I just hung out with Rick Rubin.

09:25.440 --> 09:26.280
I don't know if you've.

09:26.280 --> 09:27.320
Yeah.

09:27.320 --> 09:29.760
I mean, Rick Rubin is like literally

09:29.760 --> 09:31.200
one of the gods of music production.

09:31.200 --> 09:33.800
Like he's one of the people who first,

09:33.800 --> 09:36.320
you know, who like made music production,

09:36.320 --> 09:39.360
you know, made the production as important

09:39.360 --> 09:41.600
as the actual lyrics or the notes.

09:41.600 --> 09:43.560
But the thing he does, which is interesting,

09:43.560 --> 09:45.520
I don't know if you can speak to that,

09:45.520 --> 09:46.720
but just hanging out with him,

09:46.720 --> 09:48.520
he seems to just sit there in silence,

09:48.520 --> 09:50.800
close his eyes and listen.

09:50.800 --> 09:52.760
It's like, he almost does nothing

09:53.640 --> 09:55.860
and that nothing somehow gives you freedom

09:55.860 --> 09:58.140
to be the best version of yourself.

09:58.140 --> 10:00.040
So that's music production somehow too,

10:00.040 --> 10:02.680
which is like encouraging you to do less,

10:02.680 --> 10:06.920
to simplify, to like push towards minimalism.

10:06.920 --> 10:11.600
I mean, I guess, I mean, I work differently from Rick Rubin

10:11.600 --> 10:14.160
cause Rick Rubin produces for other artists,

10:14.160 --> 10:17.080
whereas like I mostly produce for myself.

10:17.080 --> 10:19.240
So it's a very different situation.

10:19.240 --> 10:21.760
I also think Rick Rubin, he's in that,

10:21.760 --> 10:23.600
I would say advanced category of producer

10:23.600 --> 10:26.600
where like you've like earned your,

10:26.600 --> 10:27.960
you can have an engineer and stuff

10:27.960 --> 10:29.840
and people like do the stuff for you.

10:30.680 --> 10:32.440
But I usually just like do stuff myself.

10:32.440 --> 10:37.440
So you're the engineer, the producer and the artist.

10:38.080 --> 10:39.880
Yeah, I guess I would say I'm in the era,

10:39.880 --> 10:41.280
like the post Rick Rubin era.

10:41.280 --> 10:46.280
Like I come from the kind of like Skrillex school of thought,

10:47.040 --> 10:49.240
which is like where you are,

10:49.240 --> 10:51.040
yeah, the engineer, producer, artist.

10:51.040 --> 10:53.760
Like where, I mean, lately,

10:53.760 --> 10:55.560
sometimes I'll work with a producer now.

10:55.560 --> 10:59.600
I'm gently sort of delicately starting to collaborate

10:59.600 --> 11:00.440
a little bit more,

11:00.440 --> 11:02.800
but like I think I'm kind of from the,

11:02.800 --> 11:07.120
like the whatever 2010s explosion of things

11:07.120 --> 11:11.920
where everything became available on the computer

11:11.920 --> 11:16.680
and you kind of got this like lone wizard energy thing going.

11:16.680 --> 11:19.680
So you embrace being the loneliness.

11:19.680 --> 11:22.440
Is the loneliness somehow an engine of creativity?

11:22.440 --> 11:24.560
Like most of your stuff,

11:24.560 --> 11:28.640
most of your creative quote unquote genius in quotes

11:28.680 --> 11:32.200
is in the privacy of your mind.

11:32.200 --> 11:33.560
Yes.

11:33.560 --> 11:38.560
Well, it was, but here's the thing.

11:39.080 --> 11:40.880
I was talking to Daniel Eck and he said,

11:40.880 --> 11:43.440
he's like most artists, they have about 10 years,

11:43.440 --> 11:45.200
like 10 good years.

11:45.200 --> 11:48.840
And then they usually stop making their like vital shit.

11:49.920 --> 11:53.400
And I feel like I'm sort of like nearing the end

11:53.400 --> 11:56.560
of my 10 years on my own.

11:57.240 --> 11:58.640
So you have to become somebody else.

11:58.640 --> 11:59.480
Now I'm like,

11:59.480 --> 12:01.000
I'm in the process of becoming somebody else

12:01.000 --> 12:01.840
and reinventing.

12:01.840 --> 12:02.880
When I work with other people,

12:02.880 --> 12:04.200
because I've never worked with other people,

12:04.200 --> 12:08.400
I find that I make, like that I'm exceptionally rejuvenated

12:08.400 --> 12:11.000
and making like some of the most vital work I've ever made.

12:11.000 --> 12:13.880
So, because I think another human brain

12:13.880 --> 12:16.560
is like one of the best tools you can possibly find.

12:19.080 --> 12:20.600
It's a funny way to put it, I love it.

12:20.600 --> 12:23.360
It's like, if a tool is like, you know,

12:23.400 --> 12:27.360
whatever HP plus one or like adds some like stats

12:27.360 --> 12:30.800
to your character, like another human brain

12:30.800 --> 12:34.280
will like square it instead of just like adding something.

12:34.280 --> 12:35.640
Double up the experience points.

12:35.640 --> 12:36.480
I love this.

12:36.480 --> 12:38.320
We should also mention we're playing tavern music

12:38.320 --> 12:41.640
before this and which I love, which I first one,

12:41.640 --> 12:42.480
I think I-

12:42.480 --> 12:43.800
You had to stop the tavern music.

12:43.800 --> 12:46.440
Yeah, because it doesn't, the audio.

12:46.440 --> 12:47.280
Okay, okay.

12:47.280 --> 12:48.120
But it makes-

12:48.120 --> 12:48.960
Yeah, it'll make the podcast going.

12:48.960 --> 12:50.080
Add it in post, add it in post.

12:50.080 --> 12:51.600
No one will want to listen to the podcast.

12:51.600 --> 12:53.440
It probably would, but it makes me,

12:53.440 --> 12:55.520
it reminds me like of a video game,

12:55.520 --> 12:56.800
like a role-playing video game

12:56.800 --> 12:58.440
where you have experience points.

12:58.440 --> 13:03.440
There's something really joyful about wandering places

13:03.480 --> 13:06.520
like Elder Scrolls, like Skyrim,

13:06.520 --> 13:10.520
just exploring these landscapes in another world

13:10.520 --> 13:12.040
and then you get experience points

13:12.040 --> 13:14.000
and you can work on different skills

13:14.000 --> 13:16.160
and somehow you progress in life.

13:16.160 --> 13:17.640
And I don't know, it's simple.

13:17.640 --> 13:20.000
It doesn't have some of the messy complexities of life.

13:20.080 --> 13:24.000
And there's usually a bad guy you can fight in Skyrim,

13:24.000 --> 13:25.640
it's dragons and so on.

13:25.640 --> 13:26.520
I'm sure in Elden Ring,

13:26.520 --> 13:28.320
there's a bunch of monsters you can fight.

13:28.320 --> 13:29.160
I love that.

13:29.160 --> 13:30.000
I feel like Elden Ring,

13:30.000 --> 13:32.280
I feel like this is a good analogy to music production

13:32.280 --> 13:34.480
though, because it's like, I feel like the engineers

13:34.480 --> 13:36.680
and the people creating these open worlds are,

13:36.680 --> 13:39.720
it's sort of like similar to people, to music producers,

13:39.720 --> 13:42.800
where it's like this hidden archetype

13:42.800 --> 13:44.680
that like no one really understands what they do

13:44.680 --> 13:46.240
and no one really knows who they are,

13:46.240 --> 13:49.360
but they're like, it's like the artist engineer

13:49.360 --> 13:51.840
because it's like, it's both art

13:51.840 --> 13:54.920
and fairly complex engineering.

13:54.920 --> 13:57.280
Well, you're saying they don't get enough credit.

13:57.280 --> 13:58.680
Aren't you kind of changing that

13:58.680 --> 14:01.400
by becoming the person doing everything?

14:01.400 --> 14:03.760
Aren't you, isn't the engineer?

14:03.760 --> 14:05.520
Well, I mean, others have gone before me.

14:05.520 --> 14:07.880
I'm not, you know, there's like Timbaland and Skrillex

14:07.880 --> 14:10.880
and there's all these people that are like, you know,

14:10.880 --> 14:12.120
very famous for this.

14:12.120 --> 14:14.000
But I just think the general,

14:14.000 --> 14:16.000
I think people get confused about what it is

14:16.000 --> 14:19.280
and just don't really know what it is per se.

14:20.160 --> 14:21.000
And it's just when I see a song,

14:21.000 --> 14:22.320
like when there's like a hit song,

14:22.320 --> 14:27.320
like I'm just trying to think of like,

14:27.560 --> 14:29.880
just going for like even just a basic pop hit,

14:29.880 --> 14:34.880
like rules by Dua Lipa or something.

14:36.120 --> 14:39.240
The production on that is actually like really crazy.

14:39.240 --> 14:40.560
I mean, the song is also great,

14:40.560 --> 14:43.360
but it's like the production is exceptionally memorable.

14:43.360 --> 14:47.840
Like, you know, and it's just like no one,

14:47.840 --> 14:49.200
I don't even know who produced that song.

14:50.080 --> 14:50.920
It's just like, isn't part of like the rhetoric

14:50.920 --> 14:53.440
of how we just discuss the creation of art.

14:53.440 --> 14:57.240
We just sort of like don't consider the music producer

14:57.240 --> 15:00.360
because I think the music producer used to be more

15:00.360 --> 15:02.540
just simply recording things.

15:03.720 --> 15:04.640
Yeah, that's an interesting,

15:04.640 --> 15:06.080
because when you think about movies,

15:06.080 --> 15:08.640
we talk about the actor and the actresses,

15:08.640 --> 15:11.160
but we also talk about the directors.

15:11.160 --> 15:12.000
Yeah.

15:12.000 --> 15:14.480
We don't talk about like that with the music as often.

15:15.800 --> 15:18.160
The Beatles music producer was one of the first

15:18.160 --> 15:21.280
kind of got one of the first people sort of introducing

15:21.280 --> 15:22.680
crazy sound design into pop music.

15:22.680 --> 15:24.200
I forget his name.

15:24.200 --> 15:25.920
He has the same, I forget his name,

15:25.920 --> 15:29.240
but you know, like that he was doing all the weird stuff

15:29.240 --> 15:31.560
like dropping pianos and like, yeah.

15:32.480 --> 15:33.520
Oh, to get the, yeah, yeah, yeah,

15:33.520 --> 15:36.640
to get the sound, to get the authentic sound.

15:36.640 --> 15:38.160
What about lyrics?

15:38.160 --> 15:42.600
You think those, where did they fit into how important

15:42.600 --> 15:43.440
they are?

15:43.440 --> 15:46.840
I was heartbroken to learn that Elvis didn't write his songs.

15:46.840 --> 15:47.920
I was very mad.

15:48.680 --> 15:49.520
A lot of people don't write their songs.

15:49.520 --> 15:50.840
I understand this, but.

15:50.840 --> 15:52.200
But here's a thing.

15:52.200 --> 15:54.880
I feel like there's this desire for authenticity.

15:54.880 --> 15:57.120
I used to be like really mad when like people wouldn't write

15:57.120 --> 15:59.280
or produce their music and I'd be like, that's fake.

15:59.280 --> 16:04.280
And then I realized there's all this like weird bitterness

16:04.520 --> 16:07.760
and like agroness in art about authenticity.

16:07.760 --> 16:10.800
But I had this kind of like weird realization recently

16:12.200 --> 16:16.420
where I started thinking that like art is sort of

16:16.420 --> 16:20.220
a decentralized collective thing.

16:20.220 --> 16:25.220
Like art is kind of a conversation with all the artists

16:26.660 --> 16:28.580
that have ever lived before you.

16:28.580 --> 16:31.100
You know, like it's like, you're really just sort of,

16:31.100 --> 16:33.540
it's not like anyone's reinventing the wheel here.

16:33.540 --> 16:38.220
Like you're kind of just taking thousands of years of art

16:38.220 --> 16:41.700
and like running it through your own little algorithm

16:41.700 --> 16:45.060
and then like making your interpretation of it.

16:45.060 --> 16:46.260
You're just joining the conversation

16:46.260 --> 16:47.620
with all the other artists that came before.

16:47.620 --> 16:49.620
It's just a beautiful way to look at it.

16:49.620 --> 16:51.580
Like, and it's like, I feel like everyone's always like,

16:51.580 --> 16:54.180
there's always copyright and IP and this and that

16:54.180 --> 16:55.220
or authenticity.

16:55.220 --> 16:59.260
And it's just like, I think we need to stop seeing this

16:59.260 --> 17:01.620
as this like egotistical thing of like,

17:01.620 --> 17:04.220
oh, the creative genius, the lone creative genius

17:04.220 --> 17:05.060
or this or that.

17:05.060 --> 17:08.780
Cause it's like, I think art shouldn't be about that.

17:08.780 --> 17:10.420
I think art is something that sort of

17:10.420 --> 17:12.060
brings humanity together.

17:12.060 --> 17:13.220
And it's also, art is also kind of

17:13.220 --> 17:14.740
the collective memory of humans.

17:15.660 --> 17:20.260
We don't give a fuck about whatever ancient Egypt,

17:20.260 --> 17:22.780
like how much grain got sent that day

17:22.780 --> 17:26.900
and sending the records and like who went where

17:26.900 --> 17:30.060
and how many shields needed to be produced for this.

17:30.060 --> 17:32.220
We just remember their art.

17:32.220 --> 17:34.820
And it's like in our day-to-day life,

17:34.820 --> 17:38.060
there's all this stuff that seems more important than art

17:38.060 --> 17:40.220
because it helps us function and survive.

17:40.220 --> 17:42.340
But when all this is gone,

17:42.340 --> 17:44.500
the only thing that's really gonna be left

17:45.260 --> 17:46.820
is the art, the technology will be obsolete.

17:46.820 --> 17:47.660
That's so fascinating.

17:47.660 --> 17:49.140
Like the humans will be dead.

17:49.140 --> 17:49.980
That is true.

17:49.980 --> 17:52.540
A good compression of human history

17:52.540 --> 17:56.220
is the art we've generated across the different centuries,

17:56.220 --> 17:57.820
the different millennia.

17:57.820 --> 17:59.940
So when the aliens come.

17:59.940 --> 18:00.760
When the aliens come,

18:00.760 --> 18:02.780
they're gonna find the hieroglyphics and the pyramids.

18:02.780 --> 18:04.420
I mean, art could be broadly defined.

18:04.420 --> 18:06.260
They might find like the engineering marvels,

18:06.260 --> 18:09.900
the bridges, the rockets, the.

18:09.900 --> 18:11.700
I guess I sort of classify though.

18:11.700 --> 18:13.580
Architecture is art too.

18:13.580 --> 18:18.580
I consider engineering in those formats to be art, for sure.

18:19.380 --> 18:23.220
It sucks that digital art is easier to delete.

18:23.220 --> 18:25.820
So if there's an apocalypse, a nuclear war

18:25.820 --> 18:28.860
that can disappear and the physical.

18:28.860 --> 18:30.060
There's something still valuable

18:30.060 --> 18:32.380
about the physical manifestation of art

18:32.380 --> 18:34.420
that sucks that.

18:34.420 --> 18:37.980
Like music, for example, has to be played by somebody.

18:37.980 --> 18:40.220
Yeah, I mean, I do think we should have

18:40.220 --> 18:42.860
a foundation type situation where we like.

18:42.900 --> 18:44.180
You know how we have like seed banks

18:44.180 --> 18:45.580
up in the north and stuff?

18:45.580 --> 18:48.100
Like we should probably have like a solar powered

18:48.100 --> 18:49.860
or geothermal little bunker

18:49.860 --> 18:52.460
that like has all the all human knowledge.

18:52.460 --> 18:54.300
You mentioned Daniel, I can Spotify.

18:55.340 --> 18:57.300
What do you think about that as an artist?

18:57.300 --> 18:58.340
What's Spotify?

18:58.340 --> 19:00.100
Is that empowering?

19:00.100 --> 19:02.660
To me, Spotify as a consumer is super exciting.

19:02.660 --> 19:05.020
It makes it easy for me to access music

19:05.020 --> 19:06.700
from all kinds of artists,

19:06.700 --> 19:08.500
get to explore all kinds of music,

19:08.500 --> 19:12.340
make it super easy to sort of curate my own playlists

19:12.900 --> 19:13.980
and have fun with all that.

19:13.980 --> 19:16.060
It was so liberating to let go.

19:16.060 --> 19:19.340
You know, I used to collect albums and CDs and so on,

19:19.340 --> 19:23.660
like hoard albums, like they matter.

19:23.660 --> 19:26.860
But the reality, that was really liberating

19:26.860 --> 19:28.100
that I could let go of that.

19:28.100 --> 19:32.140
And letting go of the albums you're kind of collecting

19:32.140 --> 19:33.620
allows you to find new music,

19:33.620 --> 19:36.220
exploring new artists and all that kind of stuff.

19:36.220 --> 19:38.380
But I know from a perspective of an artist that could be,

19:38.380 --> 19:39.220
like you mentioned,

19:39.220 --> 19:42.020
competition could be a kind of constraint

19:42.700 --> 19:45.020
because there's more and more and more artists

19:45.020 --> 19:46.060
on the platform.

19:46.060 --> 19:47.900
I think it's better that there's more artists.

19:47.900 --> 19:49.860
I mean, again, this might be propaganda

19:49.860 --> 19:51.700
because this is all from a conversation with Daniel Ek.

19:51.700 --> 19:54.060
So this could easily be propaganda.

19:54.060 --> 19:56.740
We're all a victim of somebody's propaganda.

19:56.740 --> 19:58.980
So let's just accept this.

19:58.980 --> 20:01.740
But Daniel Ek was telling me that at the,

20:01.740 --> 20:03.740
because when I met him,

20:03.740 --> 20:06.460
I came in all furious about Spotify

20:06.460 --> 20:07.820
and I grilled him super hard.

20:07.820 --> 20:10.660
So I've got his answers here.

20:10.660 --> 20:13.540
But he was saying like at the sort of peak

20:13.540 --> 20:15.260
of the CD industry,

20:15.260 --> 20:17.420
there was like 20,000 artists

20:17.420 --> 20:19.540
making millions and millions of dollars.

20:19.540 --> 20:22.860
Like there was just like a very tiny kind of 1%.

20:22.860 --> 20:27.420
And Spotify has kind of democratized the industry

20:27.420 --> 20:30.340
because now I think he said there's about a million artists

20:30.340 --> 20:33.100
making a good living from Spotify.

20:33.100 --> 20:34.740
And when I heard that, I was like,

20:34.740 --> 20:38.780
honestly, I would rather make less money

20:38.820 --> 20:41.140
and have just like a decent living

20:43.740 --> 20:46.580
and have more artists be able to have that,

20:46.580 --> 20:49.300
even though I wish it could include everyone.

20:49.300 --> 20:50.740
Yeah, that's really hard to argue with.

20:50.740 --> 20:52.260
YouTube is the same.

20:52.260 --> 20:54.100
It's YouTube's mission.

20:54.100 --> 20:58.300
They wanna basically have as many creators as possible

20:58.300 --> 21:00.740
and make a living, some kind of living.

21:00.740 --> 21:03.420
And that's so hard to argue with.

21:03.420 --> 21:04.500
But I think there's better ways to do it.

21:04.500 --> 21:06.780
My manager, I actually wish he was here.

21:06.780 --> 21:07.860
I would have brought him up.

21:07.860 --> 21:12.860
My manager is building an app that can manage you.

21:13.820 --> 21:16.540
So it'll like help you organize your percentages

21:16.540 --> 21:18.900
and get your publishing and da-da-da-da-das.

21:18.900 --> 21:19.980
You can take out all the middlemen

21:19.980 --> 21:21.380
so you can have a much bigger,

21:21.380 --> 21:23.020
it'll just like automate it.

21:23.020 --> 21:23.860
So you can get-

21:23.860 --> 21:25.100
So automate the manager?

21:25.100 --> 21:28.060
Automate management, publishing,

21:29.740 --> 21:32.420
and legal, it can read,

21:32.420 --> 21:34.100
the app he's building can read your contract

21:34.100 --> 21:35.660
and like tell you about it.

21:35.660 --> 21:38.300
Because one of the issues with music right now,

21:38.300 --> 21:39.820
it's not that we're not getting paid enough,

21:39.820 --> 21:44.820
but it's that the art industry is filled with middlemen

21:44.940 --> 21:47.740
because artists are not good at business.

21:47.740 --> 21:50.420
And from the beginning, like Frank Sinatra,

21:50.420 --> 21:52.180
it's all mob stuff.

21:52.180 --> 21:56.700
The music industry is run by business people,

21:56.700 --> 21:57.540
not the artists.

21:57.540 --> 21:59.540
And the artists really get very small cuts

21:59.540 --> 22:00.460
of what they make.

22:00.460 --> 22:04.780
And so I think part of the reason I'm a technocrat,

22:05.220 --> 22:07.100
I mean, your fans are gonna be technocrats,

22:07.100 --> 22:09.300
so no one's, they're not gonna be mad at me about this,

22:09.300 --> 22:12.260
but like my fans hate it when I say this kind of thing.

22:12.260 --> 22:13.260
Or the general public.

22:13.260 --> 22:14.260
They don't like technocrats.

22:14.260 --> 22:15.660
They don't like technocrats.

22:15.660 --> 22:18.820
Like when I watched Battle Angel, Alita,

22:18.820 --> 22:20.460
and they were like, the Martian technocracy.

22:20.460 --> 22:22.060
And I was like, yeah, Martian technocracy.

22:22.060 --> 22:23.620
And then they were like, and they're evil.

22:23.620 --> 22:25.660
And I was like, ooh, okay.

22:25.660 --> 22:28.860
I was like, because Martian technocracy sounds sick to me.

22:28.860 --> 22:32.020
Yeah, so your intuition as technocrats

22:32.020 --> 22:34.260
would create some kind of beautiful world.

22:34.300 --> 22:36.140
For example, what my manager's working on,

22:36.140 --> 22:39.940
if you can create an app that removes the need for a lawyer

22:39.940 --> 22:43.460
and then you could have smart contracts on the blockchain,

22:43.460 --> 22:46.900
removes the need for like management

22:46.900 --> 22:48.100
and organizing all the stuff,

22:48.100 --> 22:51.020
like can read your stuff and explain it to you,

22:51.020 --> 22:53.580
can collect your royalties.

22:53.580 --> 22:57.020
You know, like then the small amounts,

22:57.020 --> 22:58.740
the amount of money that you're getting from Spotify

22:58.740 --> 23:01.820
actually means a lot more and goes a lot further.

23:01.820 --> 23:03.180
You can remove some of the bureaucracy,

23:03.180 --> 23:06.420
some of the inefficiencies that make life

23:06.420 --> 23:08.260
not as great as it could be.

23:08.260 --> 23:10.900
Yeah, I think the issue isn't that there's not enough.

23:10.900 --> 23:12.740
Like the issue is that there's inefficiency.

23:12.740 --> 23:17.620
And I'm really into this positive sum mindset,

23:18.700 --> 23:20.900
you know, the win-win mindset of like,

23:20.900 --> 23:23.580
instead of, you know, fighting over the scraps,

23:23.580 --> 23:26.580
how do we make the, we're worrying about scarcity.

23:26.580 --> 23:27.860
Like instead of a scarcity mindset,

23:27.860 --> 23:30.140
why don't we just increase the efficiency

23:30.140 --> 23:32.380
and, you know, in that way.

23:32.380 --> 23:34.420
Expand the size of the pie.

23:34.420 --> 23:36.580
Let me ask you about experimentation.

23:36.580 --> 23:38.660
So you said, which is beautiful,

23:40.500 --> 23:42.820
being a musician is like having a conversation

23:42.820 --> 23:44.620
with all those that came before you.

23:45.500 --> 23:48.420
How much of creating music is like,

23:51.220 --> 23:53.100
kind of having that conversation,

23:53.100 --> 23:57.260
trying to fit into the cultural trends

23:57.300 --> 23:58.900
and how much of it is like,

23:58.900 --> 24:00.860
trying to do as much as possible being outside

24:00.860 --> 24:02.700
and come up with something totally new.

24:02.700 --> 24:04.500
It's like when you're thinking,

24:04.500 --> 24:05.700
when you're experimenting,

24:05.700 --> 24:08.740
are you trying to be totally different, totally weird?

24:08.740 --> 24:12.180
Are you trying to fit in?

24:12.180 --> 24:14.700
Man, this is so hard because I feel like I'm

24:14.700 --> 24:16.940
kind of in the process of semi-retiring from music.

24:16.940 --> 24:18.780
So this is like my old brain.

24:18.780 --> 24:22.100
Yeah, bring it from like the shelf,

24:22.100 --> 24:24.500
put it on the table for a couple of minutes.

24:24.500 --> 24:26.340
We'll just poke it.

24:26.340 --> 24:29.140
I think it's a bit of both because I think

24:29.140 --> 24:31.380
forcing yourself to engage with new music

24:32.460 --> 24:35.380
is really great for neural plasticity.

24:35.380 --> 24:38.380
I think as people,

24:39.540 --> 24:41.740
part of the reason music is marketed at young people

24:41.740 --> 24:43.420
is because young people are very neuroplastic.

24:43.420 --> 24:48.260
So if you're 16 to like 23 or whatever,

24:48.260 --> 24:50.900
it's gonna be really easy for you to love new music.

24:50.900 --> 24:52.300
And if you're older than that,

24:52.300 --> 24:53.820
it gets harder and harder and harder.

24:53.820 --> 24:55.020
And I think one of the beautiful things

24:55.020 --> 24:57.340
about being a musician is I just constantly

24:57.340 --> 24:58.820
force myself to listen to new music

24:58.820 --> 25:01.020
and I think it keeps my brain really plastic.

25:01.020 --> 25:02.780
And I think this is a really good exercise.

25:02.780 --> 25:04.340
I just think everyone should do this.

25:04.340 --> 25:05.660
You listen to new music and you hate it.

25:05.660 --> 25:07.140
I think you should just keep,

25:07.140 --> 25:08.660
force yourself to like,

25:08.660 --> 25:09.980
okay, well, why do people like it?

25:09.980 --> 25:11.820
And like, you know,

25:11.820 --> 25:14.700
make your brain form new neural pathways

25:14.700 --> 25:16.900
and be more open to change.

25:16.900 --> 25:18.300
That's really brilliant, actually.

25:18.300 --> 25:21.580
Sorry to interrupt, but like that exercise

25:22.100 --> 25:27.100
is really amazing to sort of embrace change,

25:27.500 --> 25:31.620
embrace sort of practice neuroplasticity.

25:31.620 --> 25:33.180
Because like, that's one of the things,

25:33.180 --> 25:34.380
you fall in love with a certain band

25:34.380 --> 25:36.780
and you just kinda stay with that for the rest of your life

25:36.780 --> 25:38.460
and then you never understand the modern music.

25:38.460 --> 25:39.300
That's a really good exercise.

25:39.300 --> 25:40.660
Most of the streaming on Spotify

25:40.660 --> 25:42.460
is like classic rock and stuff.

25:42.460 --> 25:44.820
Like new music makes up a very small chunk

25:44.820 --> 25:46.860
of what is played on Spotify.

25:46.860 --> 25:48.220
And I think this is like,

25:48.220 --> 25:50.180
not a good sign for us as a species.

25:50.180 --> 25:52.940
I think, yeah.

25:52.940 --> 25:57.780
So it's a good measure of the species' open mindedness

25:57.780 --> 26:00.620
to change is how often you listen to new music.

26:00.620 --> 26:01.460
Yeah.

26:01.460 --> 26:05.220
The brain, let's put the music brain back on the shelf.

26:05.220 --> 26:08.340
I gotta pull out the futurist brain for a second.

26:09.740 --> 26:12.340
In what wild ways do you think the future,

26:12.340 --> 26:15.020
say in like 30 years, maybe 50 years,

26:15.020 --> 26:17.020
maybe a hundred years will be different

26:18.020 --> 26:22.140
from like, from our current way of life on earth.

26:22.140 --> 26:25.420
We can talk about augmented reality, virtual reality,

26:25.420 --> 26:30.420
maybe robots, maybe space travel, maybe video games,

26:30.820 --> 26:32.540
maybe genetic engineering.

26:32.540 --> 26:33.380
I can keep going.

26:33.380 --> 26:36.260
Cyborgs, aliens, world wars,

26:36.260 --> 26:39.220
maybe destructive nuclear wars, good and bad.

26:40.300 --> 26:43.540
When you think about the future, what are you imagining?

26:43.540 --> 26:45.860
What's the weirdest and the wildest it could be?

26:47.660 --> 26:50.140
Have you read Surface Detail by Ian Banks?

26:51.500 --> 26:54.860
Surface Detail is my favorite depiction of a,

26:54.860 --> 26:56.580
oh, wow, you have to read this book.

26:56.580 --> 26:58.700
It's literally the greatest science fiction book.

26:58.700 --> 26:59.540
Possibly every-

26:59.540 --> 27:01.620
Ian Banks is the man, yeah, for sure.

27:01.620 --> 27:03.220
What have you read?

27:03.220 --> 27:04.540
Just a player of games.

27:04.540 --> 27:07.380
I read that titles can't be copyrighted

27:07.380 --> 27:08.300
so you can just steal them.

27:08.300 --> 27:09.980
And I was like, player of games, sick.

27:09.980 --> 27:10.820
Nice.

27:10.820 --> 27:12.780
Yeah, so you could name your album,

27:12.780 --> 27:13.620
like I always wanted-

27:13.620 --> 27:15.020
Romeo and Juliet or something?

27:15.020 --> 27:17.100
I always wanted to name an album War and Peace.

27:17.100 --> 27:17.940
Nice.

27:17.940 --> 27:21.620
That's a good, where have I heard that before?

27:21.620 --> 27:23.380
You can do that, you could do that.

27:24.300 --> 27:26.100
Also things that are in the public domain.

27:26.100 --> 27:27.220
For people who have no clue,

27:27.220 --> 27:29.700
you do have a song called Player of Games.

27:29.700 --> 27:30.700
Yes, oh yeah.

27:30.700 --> 27:33.860
So Ian Banks' Surface Detail is, in my opinion,

27:33.860 --> 27:37.220
the best future that I've ever read about

27:37.220 --> 27:39.580
or heard about in science fiction.

27:39.580 --> 27:42.540
Basically, there's the relationship

27:42.540 --> 27:44.620
with super intelligence,

27:44.620 --> 27:48.020
like artificial super intelligence is just,

27:48.020 --> 27:49.140
it's like great.

27:50.380 --> 27:53.060
I want to credit the person who coined this term

27:53.060 --> 27:55.220
because I love this term.

27:55.220 --> 27:58.660
And I feel like young women don't get enough credit in.

28:00.140 --> 28:03.940
Yeah, so if you go to Protopiafutures on Instagram,

28:03.940 --> 28:05.460
what is her name?

28:05.460 --> 28:07.220
Personalized donor experience at scale,

28:07.220 --> 28:08.940
already ad-powered donor experience.

28:09.020 --> 28:14.020
Monica Bielskait, I'm saying that wrong.

28:15.380 --> 28:17.700
And I'm probably gonna, I'm probably butchering this a bit,

28:17.700 --> 28:21.580
but Protopia is sort of, if utopia is unattainable,

28:21.580 --> 28:26.020
Protopia is sort of like, you know.

28:26.020 --> 28:28.660
Wow, that's an awesome Instagram, Protopiafutures.

28:28.660 --> 28:33.460
A great, a future that is, you know, as good as we can get.

28:33.460 --> 28:34.740
The future, positive future.

28:34.740 --> 28:37.380
AI, is this a centralized AI in the surface,

28:37.420 --> 28:39.300
in surface detail or is it distributed?

28:39.300 --> 28:40.620
What kind of AI is it?

28:40.620 --> 28:42.820
They mostly exist as giant super ships,

28:42.820 --> 28:45.820
like sort of like the Guild ships in Dune.

28:45.820 --> 28:46.860
Like they're these giant ships

28:46.860 --> 28:48.340
that kind of move people around

28:48.340 --> 28:49.500
and the ships are sentient

28:49.500 --> 28:52.260
and they can talk to all the passengers.

28:52.260 --> 28:56.460
And I mean, there's a lot of different types of AI

28:56.460 --> 28:58.380
in the Banksyian future,

28:58.380 --> 29:01.100
but in the opening scene of surface detail,

29:01.100 --> 29:02.380
there's this place called the Culture

29:02.380 --> 29:04.500
and the Culture is basically a Protopian future.

29:05.020 --> 29:07.300
A Protopian future, I think,

29:07.300 --> 29:08.860
is like a future that is like,

29:09.740 --> 29:12.340
obviously it's not utopia, it's not perfect.

29:12.340 --> 29:13.980
And like, cause like striving for utopia,

29:13.980 --> 29:16.940
I think feels hopeless and it's sort of like,

29:16.940 --> 29:19.260
maybe not the best terminology to be using.

29:20.340 --> 29:23.940
So it's like, it's a pretty good place.

29:23.940 --> 29:27.620
Like mostly like, you know,

29:27.620 --> 29:29.820
super intelligence and biological beings

29:29.820 --> 29:31.860
exist fairly in harmony.

29:31.860 --> 29:33.100
There's not too much war.

29:33.100 --> 29:35.660
There's like, as close to equality as you can get,

29:35.660 --> 29:36.500
you know, it's like,

29:36.500 --> 29:38.660
it's like approximately a good future.

29:38.660 --> 29:40.260
Like there's really awesome stuff.

29:41.780 --> 29:45.580
And the, in the opening scene,

29:45.580 --> 29:48.500
this girl, she's born as a sex slave

29:48.500 --> 29:49.460
outside of the culture.

29:49.460 --> 29:51.140
So she's in a society that doesn't adhere

29:51.140 --> 29:52.580
to the cultural values.

29:52.580 --> 29:56.660
She tries to kill the guy who is her like master,

29:56.660 --> 29:57.900
but he kills her.

29:57.900 --> 29:58.980
But unbeknownst to her,

29:58.980 --> 30:00.660
when she was traveling on a ship

30:00.660 --> 30:02.500
through the culture with him one day,

30:03.380 --> 30:05.700
a ship put a neural lace in her head.

30:05.700 --> 30:08.500
And neural lace is sort of like,

30:08.500 --> 30:09.900
it's basically a neural link.

30:11.300 --> 30:13.100
Cause life imitates art.

30:13.100 --> 30:13.940
It does indeed.

30:13.940 --> 30:14.900
It does indeed.

30:14.900 --> 30:17.340
So she wakes up and the opening scene is her memory

30:17.340 --> 30:19.060
has been uploaded by this neural lace

30:19.060 --> 30:20.060
when she has been killed.

30:20.060 --> 30:22.660
And now she gets to choose a new body.

30:22.660 --> 30:26.940
And this AI is interfacing with her recorded memory

30:26.940 --> 30:29.900
in her neural lace and helping her and being like,

30:29.900 --> 30:31.340
hello, you're dead.

30:31.340 --> 30:32.620
But because you had a neural lace,

30:32.620 --> 30:33.740
your memory is uploaded.

30:33.740 --> 30:34.980
Do you want to choose a new body?

30:34.980 --> 30:36.460
And you're going to be born here in the culture

30:36.460 --> 30:38.580
and like start a new life, which is just,

30:38.580 --> 30:39.900
that's like the opening.

30:39.900 --> 30:41.380
It's like so sick.

30:41.380 --> 30:43.660
And the ship is the super intelligence.

30:43.660 --> 30:45.100
All the ships are kind of super intelligence.

30:45.100 --> 30:47.700
But they still want to preserve a kind of rich,

30:47.700 --> 30:49.700
fulfilling experience for the humans.

30:49.700 --> 30:50.980
Yeah, like they're like friends with the humans.

30:50.980 --> 30:51.940
And then there's a bunch of ships

30:51.940 --> 30:54.420
that don't want to exist with biological beings,

30:54.420 --> 30:57.100
but they just have their own place like way over there.

30:57.100 --> 30:58.900
But they don't, they're just do their own thing.

30:58.900 --> 31:00.300
They're not necessarily.

31:00.340 --> 31:02.780
So it's a pretty, this protopian existence,

31:02.780 --> 31:03.620
pretty peaceful.

31:03.620 --> 31:05.860
Yeah, I mean, and then, and then for example,

31:05.860 --> 31:10.180
one of the main fights in the book is they're fighting,

31:10.180 --> 31:13.820
there's these artificial hells that,

31:13.820 --> 31:16.700
and people don't think it's ethical

31:16.700 --> 31:17.620
to have artificial hell.

31:17.620 --> 31:19.540
Like basically when people do crime, they get sent,

31:19.540 --> 31:21.140
like when they die, their memory gets sent

31:21.140 --> 31:23.460
to an artificial hell and they're eternally tortured.

31:23.460 --> 31:27.660
And so, and then the way that society is deciding

31:27.660 --> 31:29.300
whether or not to have the artificial hell

31:29.300 --> 31:31.940
is that they're having these simulated,

31:31.940 --> 31:33.260
they're having like a simulated war.

31:33.260 --> 31:36.020
So instead of actual blood, you know,

31:36.020 --> 31:38.540
people are basically essentially fighting in a video game

31:38.540 --> 31:40.140
to choose the outcome of this.

31:40.140 --> 31:42.780
But they're still experiencing the suffering,

31:42.780 --> 31:44.540
in this artificial hell or no?

31:44.540 --> 31:45.780
Can you experience stuff or?

31:45.780 --> 31:47.260
So the artificial hell sucks.

31:47.260 --> 31:48.380
And a lot of people in the culture

31:48.380 --> 31:49.940
want to get rid of the artificial hell.

31:49.940 --> 31:51.340
There's a simulated wars,

31:51.340 --> 31:53.940
are they happening in the artificial hell?

31:53.940 --> 31:55.540
No, the simulated wars are happening

31:55.540 --> 31:57.140
outside of the artificial hell

31:57.140 --> 31:59.060
between the political factions

31:59.940 --> 32:01.700
So this political faction says

32:01.700 --> 32:04.980
we should have simulated hell to deter crime.

32:04.980 --> 32:06.940
And this political faction is saying,

32:06.940 --> 32:08.940
no, simulated hell is unethical.

32:08.940 --> 32:11.700
And so instead of like having, you know,

32:11.700 --> 32:13.140
blowing each other up with nukes,

32:13.140 --> 32:17.140
they're having like a giant Fortnite battle

32:17.140 --> 32:21.660
to decide this, which, you know, to me that's protopia.

32:21.660 --> 32:24.500
That's like, okay, we can have war without death.

32:25.620 --> 32:27.460
You know, I don't think there should be simulated hells.

32:27.460 --> 32:29.820
I think that is definitely one of the ways

32:29.820 --> 32:34.300
in which technology could go very, very, very, very wrong.

32:34.300 --> 32:37.100
So almost punishing people in a digital space

32:37.100 --> 32:37.940
or something like that.

32:37.940 --> 32:40.340
Yeah, like torturing people's memories.

32:41.660 --> 32:44.780
So either as a deterrent, like if you committed a crime,

32:44.780 --> 32:46.540
but also just for personal pleasure,

32:46.540 --> 32:49.260
if there's some sick demented humans in this world.

32:50.540 --> 32:52.340
Dan Carlin actually has this

32:52.340 --> 32:57.340
episode of Hardcore History on painful tainment.

32:59.460 --> 33:02.300
Oh, that episode is fucked.

33:02.300 --> 33:05.380
It's dark because he kind of goes through human history

33:05.380 --> 33:08.820
and says like, we as humans seem to enjoy,

33:08.820 --> 33:12.140
secretly enjoy or used to be openly enjoy

33:12.140 --> 33:14.420
sort of the torture and the death,

33:14.420 --> 33:17.740
watching the death and torture of other humans.

33:17.740 --> 33:21.740
I do think if people were consenting,

33:21.780 --> 33:26.300
we should be allowed to have gladiatorial matches.

33:26.300 --> 33:28.620
But consent is hard to achieve in those situations.

33:28.620 --> 33:31.100
It always starts getting slippery.

33:31.100 --> 33:35.300
Like it could be also forced, like it starts getting weird.

33:35.300 --> 33:37.380
There's way too much excitement.

33:37.380 --> 33:38.660
Like this is what he highlights.

33:38.660 --> 33:40.540
There's something about human nature

33:40.540 --> 33:42.300
that wants to see that violence.

33:42.300 --> 33:45.660
And it's really dark and you hope

33:45.660 --> 33:48.860
that we can sort of overcome that aspect of human nature,

33:48.860 --> 33:51.340
but that's still within us somewhere.

33:51.460 --> 33:53.220
I think that's what we're doing right now.

33:53.220 --> 33:56.420
I have this theory that what is very important

33:56.420 --> 34:00.900
about the current moment is that all of evolution

34:00.900 --> 34:03.420
has been survival of the fittest up until now.

34:03.420 --> 34:07.260
And at some point, the lines are kind of fuzzy,

34:07.260 --> 34:12.100
but in the recent past, or maybe even just right now,

34:12.100 --> 34:14.420
we're getting to this point

34:14.420 --> 34:19.420
where we can choose intelligent design.

34:19.420 --> 34:23.420
Like we, probably since like the integration of the iPhone,

34:23.420 --> 34:24.820
like we are becoming cyborgs.

34:24.820 --> 34:27.660
Like our brains are fundamentally changed.

34:27.660 --> 34:29.340
Everyone who grew up with electronics,

34:29.340 --> 34:32.500
we are fundamentally different from previous,

34:32.500 --> 34:33.420
from homo sapiens.

34:33.420 --> 34:34.660
I call us homo techno.

34:34.660 --> 34:36.780
I think we have evolved into homo techno,

34:36.780 --> 34:39.340
which is like essentially a new species.

34:39.340 --> 34:41.340
Like if you look at the way,

34:41.340 --> 34:43.380
if you took an MRI of my brain

34:43.380 --> 34:46.580
and you took an MRI of like a medieval brain,

34:46.580 --> 34:48.100
I think it would be very different

34:48.420 --> 34:49.940
the way that it has evolved.

34:49.940 --> 34:51.940
Do you think when historians look back at this time,

34:51.940 --> 34:54.020
they'll see like this was a fundamental shift

34:54.020 --> 34:54.860
to what a human being is?

34:54.860 --> 34:58.020
I think, I do not think we are still homo sapiens.

34:58.020 --> 34:59.500
I believe we are homo techno.

34:59.500 --> 35:01.220
And I think we have evolved.

35:04.340 --> 35:07.340
And I think right now, the way we are evolving,

35:07.340 --> 35:09.020
we can choose how we do that.

35:09.020 --> 35:10.620
And I think we are being very reckless

35:10.620 --> 35:11.780
about how we're doing that.

35:11.780 --> 35:12.980
Like we're just having social media,

35:12.980 --> 35:16.860
but I think this idea that like this is a time to choose

35:16.860 --> 35:19.580
intelligent design should be taken very seriously.

35:19.580 --> 35:22.620
It like now is the moment to reprogram the human computer.

35:23.780 --> 35:26.380
You know, it's like, if you go blind,

35:27.220 --> 35:31.940
your visual cortex will get taken over with other functions.

35:31.940 --> 35:35.140
We can choose our own evolution.

35:35.140 --> 35:37.140
We can change the way our brains work.

35:37.140 --> 35:39.900
And so we actually have a huge responsibility to do that.

35:39.900 --> 35:42.860
And I think, I'm not sure who should be responsible for that,

35:42.860 --> 35:45.140
but there's definitely not adequate education.

35:45.140 --> 35:46.900
We're being inundated with all this technology

35:46.900 --> 35:48.980
that is fundamentally changing

35:48.980 --> 35:50.860
the physical structure of our brains.

35:50.860 --> 35:54.740
And we are not adequately responding to that

35:55.860 --> 35:57.420
to choose how we wanna evolve.

35:57.420 --> 36:00.580
And we could evolve, we could be really whatever we want.

36:00.580 --> 36:02.980
And I think this is a really important time.

36:02.980 --> 36:06.420
And I think if we choose correctly and we choose wisely,

36:06.420 --> 36:09.700
consciousness could exist for a very long time

36:09.700 --> 36:12.660
and integration with AI could be extremely positive.

36:12.660 --> 36:14.340
And I don't think enough people are focusing

36:14.340 --> 36:16.340
on this specific situation.

36:16.340 --> 36:18.660
Do you think we might irreversibly screw things up

36:18.660 --> 36:19.940
if we get things wrong now?

36:19.940 --> 36:21.620
Cause like the flip side of that,

36:21.620 --> 36:23.140
it seems humans are pretty adaptive.

36:23.140 --> 36:26.860
So maybe the way we figure things out is by screwing it up.

36:26.860 --> 36:29.460
Like social media, over a generation,

36:29.460 --> 36:31.180
we'll see the negative effects of social media.

36:31.180 --> 36:33.060
And then we build new social medias

36:33.060 --> 36:34.940
and we just keep improving stuff.

36:34.940 --> 36:37.620
And then we learn the failure from the failures of the past.

36:37.620 --> 36:39.900
Cause humans seem to be really adaptive.

36:39.900 --> 36:42.980
On the flip side, we can get it wrong in a way

36:42.980 --> 36:46.380
where like literally we create weapons of war

36:46.380 --> 36:49.620
or increase hate past a certain threshold.

36:49.620 --> 36:51.860
We really do a lot of damage.

36:51.860 --> 36:53.700
I mean, I think we're optimized

36:53.700 --> 36:55.660
to notice the negative things,

36:55.660 --> 36:57.220
but I would actually say,

36:59.580 --> 37:02.140
one of the things that I think people aren't noticing

37:02.140 --> 37:03.540
is like if you look at Silicon Valley

37:03.540 --> 37:06.620
and you look at like whatever the technocracy,

37:06.620 --> 37:08.380
like what's been happening there.

37:08.380 --> 37:10.100
Like it's like when Silicon Valley started,

37:10.100 --> 37:11.460
it was all just like Facebook

37:11.460 --> 37:14.060
and all this like for-profit crap

37:14.060 --> 37:16.940
that like really wasn't particular.

37:16.940 --> 37:18.220
I guess it was useful, but it was,

37:18.220 --> 37:22.180
it's sort of just like whatever.

37:22.180 --> 37:24.700
But like now you see like lab grown meat,

37:24.700 --> 37:28.380
like compostable or like biodegradable,

37:28.380 --> 37:31.420
like a single use cutlery or like, you know,

37:31.420 --> 37:33.140
like meditation apps, you know,

37:33.140 --> 37:38.140
I think we are actually evolving and changing

37:38.380 --> 37:39.580
and technology is changing.

37:39.580 --> 37:43.820
I think they're just maybe there isn't

37:43.820 --> 37:48.140
quite enough education about this.

37:48.140 --> 37:50.260
And also I don't know if there's like

37:50.260 --> 37:52.900
quite enough incentive for it

37:52.900 --> 37:55.140
because I think the way capitalism works,

37:56.620 --> 37:58.500
what we define as profit,

37:58.500 --> 38:00.380
we're also working on an old model

38:00.380 --> 38:01.540
of what we define as profit.

38:01.540 --> 38:06.380
I really think if we changed the idea of profit

38:06.380 --> 38:08.220
to include social good,

38:08.220 --> 38:09.820
you can have like economic profit,

38:09.820 --> 38:12.580
social good also counting as profit

38:12.580 --> 38:15.100
would incentivize things that are more useful

38:15.100 --> 38:16.980
and more whatever spiritual technology

38:16.980 --> 38:19.980
or like positive technology or, you know,

38:19.980 --> 38:22.060
things that help reprogram a human computer

38:22.060 --> 38:22.940
in a good way,

38:22.940 --> 38:27.940
or things that help us intelligently design our new brains.

38:28.260 --> 38:29.420
Yeah, there's no reason why

38:29.420 --> 38:31.340
within the framework of capitalism,

38:31.340 --> 38:33.780
the word profit or the idea of profit

38:33.780 --> 38:35.580
can't also incorporate, you know,

38:35.580 --> 38:37.380
the wellbeing of a human being.

38:37.380 --> 38:40.100
So like long-term wellbeing, long-term happiness.

38:41.420 --> 38:43.020
Or even, for example, you know,

38:43.020 --> 38:43.860
we were talking about motherhood,

38:43.860 --> 38:44.900
like part of the reason I'm so late

38:44.900 --> 38:47.380
is because I had to get the baby to bed.

38:47.380 --> 38:48.900
And it's like, I keep thinking about motherhood,

38:48.900 --> 38:51.340
how under capitalism,

38:51.340 --> 38:53.660
it's like this extremely essential job

38:53.660 --> 38:56.460
that is very difficult, that is not compensated.

38:56.460 --> 38:58.420
And we sort of like value things

38:58.420 --> 39:01.900
by how much we compensate them.

39:01.900 --> 39:04.860
And so we really devalue motherhood in our society

39:04.860 --> 39:06.100
and pretty much all societies.

39:06.100 --> 39:08.180
Like capitalism does not recognize motherhood.

39:08.180 --> 39:11.180
It's just a job that you're supposed to do for free.

39:11.180 --> 39:15.420
And it's like, but I feel like producing great humans

39:15.420 --> 39:19.500
should be seen as profit under capitalism.

39:19.500 --> 39:21.540
Like that should be, that's like a huge social good.

39:21.540 --> 39:24.220
Like every awesome human that gets made

39:24.220 --> 39:25.620
adds so much to the world.

39:25.620 --> 39:29.900
So like if that was integrated into the profit structure,

39:29.900 --> 39:34.300
then, you know, and if we potentially found a way

39:34.300 --> 39:35.700
to compensate motherhood.

39:36.420 --> 39:37.940
So come up with a compensation

39:37.940 --> 39:40.620
that's much broader than just money or-

39:40.620 --> 39:42.020
Or it could just be money.

39:42.020 --> 39:45.500
Like what if you just made, I don't know,

39:45.500 --> 39:46.620
but I don't know how you'd pay for that.

39:46.620 --> 39:49.380
Like, I mean, that's where you start getting into-

39:52.180 --> 39:56.340
Reallocation of resources that people get upset over.

39:56.340 --> 39:58.540
Well, like what if we made like a motherhood dow?

39:58.540 --> 40:01.220
Yeah, yeah.

40:01.860 --> 40:06.860
And, you know, used it to fund like single mothers,

40:07.700 --> 40:12.700
like, you know, pay for making babies.

40:13.620 --> 40:17.340
So, I mean, if you create and put beautiful things

40:17.340 --> 40:19.740
onto the world, that could be companies,

40:19.740 --> 40:22.620
that can be bridges, that could be art,

40:22.620 --> 40:25.700
that could be a lot of things, and that could be children,

40:26.660 --> 40:28.100
which are-

40:28.100 --> 40:29.340
Or education, or-

40:29.380 --> 40:32.420
Anything, that should be valued by society,

40:32.420 --> 40:35.180
and that should be somehow incorporated into the framework

40:35.180 --> 40:38.540
of what, as a market, of what-

40:38.540 --> 40:40.580
Like if you contribute children to this world,

40:40.580 --> 40:44.980
that should be valued and respected and sort of celebrated,

40:45.980 --> 40:48.020
like proportional to what it is,

40:48.020 --> 40:51.580
which is the thing that fuels human civilization.

40:51.580 --> 40:53.020
Yeah, like- It's kind of important.

40:53.020 --> 40:54.620
I feel like everyone's always saying-

40:54.620 --> 40:56.580
I mean, I think we're in very different social spheres,

40:56.580 --> 40:58.900
but everyone's always saying, like, dismantle capitalism.

40:58.900 --> 40:59.860
And I'm like, well, okay, well,

40:59.860 --> 41:02.140
I don't think the government should own everything.

41:02.140 --> 41:04.260
Like, I don't think we should not have private ownership.

41:04.260 --> 41:05.420
Like, that's scary.

41:05.420 --> 41:07.420
You know, like, that starts getting into weird stuff

41:07.420 --> 41:09.820
and just sort of like, I feel there's almost no way

41:09.820 --> 41:12.100
to do that without a police state, you know?

41:13.540 --> 41:17.020
But obviously, capitalism has some major flaws.

41:17.020 --> 41:20.420
And I think, actually, Mack showed me this idea

41:20.420 --> 41:23.540
called social capitalism, which is a form of capitalism

41:23.540 --> 41:28.540
that just like considers social good to be also profit.

41:28.580 --> 41:31.580
Like, you know, it's like right now companies need to,

41:31.580 --> 41:34.580
like, you're supposed to grow every quarter or whatever

41:34.580 --> 41:38.700
to like show that you're functioning well.

41:38.700 --> 41:41.060
But it's like, okay, well, what if you kept

41:41.060 --> 41:43.940
the same amount of profit, you're still in the green,

41:43.940 --> 41:45.580
but then you have also all this social good?

41:45.580 --> 41:47.580
Like, do you really need all this extra economic growth

41:47.580 --> 41:49.540
or could you add this social good and that counts?

41:49.540 --> 41:53.980
And, you know, I don't know if I am not an economist.

41:53.980 --> 41:56.380
I have no idea how this could be achieved, but-

41:56.380 --> 41:58.740
I don't think economists know how anything

41:58.740 --> 42:00.340
could be achieved either, but they pretend.

42:00.340 --> 42:02.300
It's the thing, they construct a model

42:02.300 --> 42:06.180
and they go on TV shows and sound like an expert.

42:06.180 --> 42:08.540
That's the definition of an economist.

42:08.540 --> 42:12.260
How did being a mother, becoming a mother,

42:12.260 --> 42:15.260
change you as a human being, would you say?

42:16.140 --> 42:21.020
Man, I think it kind of changed everything

42:21.020 --> 42:22.380
and it's still changing me a lot.

42:22.380 --> 42:24.900
It's actually changing me more right now in this moment

42:24.900 --> 42:26.420
than it was before.

42:26.420 --> 42:27.460
Like today?

42:27.460 --> 42:28.500
Like this-

42:28.500 --> 42:32.500
Just like in the most recent months and stuff.

42:33.500 --> 42:37.620
Can you elucidate that, how change,

42:37.620 --> 42:39.340
like when you wake up in the morning

42:39.340 --> 42:41.940
and you look at yourself, it's again, who are you?

42:42.940 --> 42:45.540
How have you become different, would you say?

42:45.540 --> 42:50.540
I think it's just really reorienting my priorities

42:50.660 --> 42:53.420
and at first I was really fighting against that

42:53.420 --> 42:56.220
because I somehow felt it was a failure of feminism

42:56.220 --> 42:59.900
or something, I felt like it was bad

42:59.900 --> 43:04.380
if my kids started mattering more than my work.

43:05.740 --> 43:09.020
And then more recently I started sort of analyzing

43:09.020 --> 43:12.300
that thought in myself and being like,

43:12.300 --> 43:13.980
that's also kind of a construct.

43:13.980 --> 43:16.380
It's like we've just devalued motherhood so much

43:16.380 --> 43:21.380
in our culture that I feel guilty for caring

43:21.380 --> 43:23.380
about my kids more than I care about my work.

43:24.380 --> 43:25.820
So feminism includes breaking out

43:25.820 --> 43:27.540
of whatever the construct is.

43:28.420 --> 43:32.980
So just continually breaking, it's like freedom

43:32.980 --> 43:36.020
empower you to be free and that means-

43:37.620 --> 43:40.460
But it also, but like being a mother,

43:40.460 --> 43:43.780
I'm so much more creative, like I cannot believe

43:44.740 --> 43:48.500
the massive amount of brain growth that I am.

43:48.500 --> 43:49.340
Why do you think that is?

43:49.340 --> 43:51.980
Just cause like the stakes are higher somehow?

43:52.980 --> 43:57.980
I think it's like, it's just so trippy

43:57.980 --> 44:00.740
watching consciousness emerge.

44:00.740 --> 44:05.740
It's just like going on a crazy journey or something.

44:07.340 --> 44:10.180
It's like the craziest science fiction novel

44:10.180 --> 44:11.020
you could ever read.

44:11.020 --> 44:15.060
It's just so crazy watching consciousness come into being.

44:15.060 --> 44:17.580
And then at the same time, like you're forced

44:17.580 --> 44:21.100
to value your time so much.

44:21.380 --> 44:23.540
When I have creative time now, it's so sacred.

44:23.540 --> 44:28.540
I need to like be really fricking on it.

44:29.420 --> 44:34.420
But the other thing is that I used to just be like a cynic

44:34.700 --> 44:36.380
and I used to just wanna, like my last album

44:36.380 --> 44:39.260
was called Miss Anthropocene and it was like this like,

44:40.740 --> 44:43.700
it was like a study in villainy or like it was like,

44:43.700 --> 44:45.940
well, what if we have, instead of the old gods,

44:45.940 --> 44:48.380
we have like new gods and it's like Miss Anthropocene

44:48.460 --> 44:51.620
which is like the, you know, like, and she's the goddess

44:51.620 --> 44:53.580
of climate change or whatever and she's like

44:53.580 --> 44:54.420
destroying the world.

44:54.420 --> 44:56.940
And it was just like, it was like dark

44:56.940 --> 44:58.660
and it was like a study in villainy.

44:58.660 --> 45:00.780
And it was sort of just like, like I used to like

45:00.780 --> 45:05.780
have no problem just making cynical, angry, scary art.

45:06.420 --> 45:08.300
And not that there's anything wrong with that,

45:08.300 --> 45:10.740
but I think having kids just makes you such an optimist.

45:10.740 --> 45:13.940
It just inherently makes you wanna be an optimist so bad

45:13.940 --> 45:16.980
that like, like, you know, it's like,

45:16.980 --> 45:20.420
but like, like I feel more responsibility

45:20.420 --> 45:23.860
to make more optimistic things.

45:23.860 --> 45:25.740
And I get a lot of shit for it

45:25.740 --> 45:28.540
because everyone's like, oh, you're so privileged,

45:28.540 --> 45:31.180
stop talking about like pie in the sky, stupid concepts

45:31.180 --> 45:33.460
and focus on like the now, but it's like,

45:35.180 --> 45:39.380
I think if we don't ideate about futures

45:39.380 --> 45:41.580
that could be good, we won't be able to get them.

45:41.580 --> 45:42.820
If everything is Blade Runner,

45:42.820 --> 45:44.300
then we're gonna end up with Blade Runner.

45:44.300 --> 45:47.300
It's like, as we said earlier, life imitates art.

45:47.300 --> 45:49.740
Like life really does imitate art.

45:49.740 --> 45:53.980
And so we really need more protopian or utopian art.

45:53.980 --> 45:56.100
I think this is incredibly essential

45:56.100 --> 45:58.100
for the future of humanity.

45:58.100 --> 46:00.420
And I think the current discourse

46:00.420 --> 46:05.420
where that's seen as a thinking about protopia or utopia

46:09.700 --> 46:11.620
is seen as a dismissal of the problems

46:11.620 --> 46:12.460
that we currently have.

46:12.460 --> 46:14.980
I think that is an incorrect mindset.

46:16.180 --> 46:20.220
And like having kids just makes me wanna imagine

46:20.220 --> 46:24.460
amazing futures that like, maybe I won't be able to build,

46:24.460 --> 46:26.940
but they will be able to build if they want to.

46:26.940 --> 46:30.220
Yeah, it does seem like ideation is a precursor to creation.

46:30.220 --> 46:33.820
So you have to imagine it in order to be able to build it.

46:33.820 --> 46:36.740
And there is a sad thing about human nature

46:36.740 --> 46:40.780
that they somehow a cynical view of the world

46:40.820 --> 46:44.420
is seen as a insightful view.

46:44.420 --> 46:47.020
Cynicism is often confused for insight,

46:47.020 --> 46:48.940
which is sad to see.

46:48.940 --> 46:52.700
And optimism is confused for naivete.

46:52.700 --> 46:53.540
Yes, yes.

46:53.540 --> 46:57.740
Like you don't, you're blinded by your,

46:57.740 --> 46:59.380
maybe your privilege or whatever.

46:59.380 --> 47:02.060
You're blinded by something, but you're certainly blinded.

47:02.060 --> 47:03.820
That's sad.

47:03.820 --> 47:06.060
That's sad to see because it seems like the optimists

47:06.060 --> 47:10.300
are the ones that create our future.

47:10.300 --> 47:11.980
They're the ones that build.

47:11.980 --> 47:13.580
In order to build the crazy thing,

47:13.580 --> 47:14.780
you have to be optimistic.

47:14.780 --> 47:19.260
You have to be either stupid or excited or passionate

47:19.260 --> 47:22.780
or mad enough to actually believe that it can be built.

47:22.780 --> 47:24.220
And those are the people that built it.

47:24.220 --> 47:28.140
My favorite quote of all time is from Star Wars Episode 8,

47:29.060 --> 47:30.980
which I know everyone hates.

47:30.980 --> 47:32.460
Do you like Star Wars Episode 8?

47:32.460 --> 47:35.860
No, I probably would say I would probably hate it, yeah.

47:36.860 --> 47:38.980
I don't have strong feelings about it.

47:38.980 --> 47:39.820
Let me backtrack.

47:40.340 --> 47:42.020
I don't have strong feelings about Star Wars.

47:42.020 --> 47:43.100
I'm a Tolkien person.

47:43.100 --> 47:47.900
I'm more into dragons and orcs and ogres.

47:47.900 --> 47:49.660
Yeah, I mean Tolkien forever.

47:49.660 --> 47:51.820
I really want to have one more son and call him,

47:51.820 --> 47:55.300
I thought Tau Techno Tolkien would be cool.

47:55.300 --> 47:56.980
It's a lot of T's, I like it.

47:56.980 --> 47:59.300
Yeah, and Tau is six, two, eight, two pi.

47:59.300 --> 48:01.780
Yeah, Tau Techno, yeah, yeah, yeah.

48:01.780 --> 48:04.820
And then Techno is obviously the best genre of music,

48:04.820 --> 48:06.300
but also like technocracy.

48:06.300 --> 48:07.140
It just sounds really good.

48:07.220 --> 48:08.620
Yeah, I think that's right.

48:08.620 --> 48:11.660
Techno Tolkien, Tau Techno Tolkien, that's a good-

48:11.660 --> 48:14.980
Tau Techno Tolkien, but Star Wars Episode 8,

48:15.980 --> 48:18.260
I know a lot of people have issues with it personally.

48:18.260 --> 48:21.180
On the record, I think it's the best Star Wars film.

48:24.100 --> 48:25.220
You're starting trouble today.

48:25.220 --> 48:29.260
Yeah, but don't kill what you hate, save what you love.

48:29.260 --> 48:30.460
Don't kill what you hate.

48:30.460 --> 48:32.340
Don't kill what you hate, save what you love.

48:32.340 --> 48:34.980
And I think we're, in society right now,

48:34.980 --> 48:36.580
we're in a diagnosis mode.

48:36.580 --> 48:39.100
We're just diagnosing and diagnosing and diagnosing.

48:39.100 --> 48:41.660
And we're trying to kill what we hate,

48:41.660 --> 48:44.220
and we're not trying to save what we love enough.

48:44.220 --> 48:46.260
And there's this Buckminster Fuller quote,

48:46.260 --> 48:47.180
which I'm gonna butcher

48:47.180 --> 48:48.220
because I don't remember it correctly,

48:48.220 --> 48:50.500
but it's something along the lines of,

48:52.580 --> 48:57.580
don't try to destroy the old bad models,

48:58.340 --> 49:01.580
render them obsolete with better models.

49:03.100 --> 49:05.620
Maybe we don't need to destroy the oil industry.

49:05.620 --> 49:08.940
Maybe we just create a great new battery technology

49:08.940 --> 49:10.340
and sustainable transport

49:10.340 --> 49:13.140
and just make it economically unreasonable

49:13.140 --> 49:15.460
to still continue to rely on fossil fuels.

49:17.300 --> 49:20.180
It's like, don't kill what you hate, save what you love.

49:20.180 --> 49:24.460
Make new things and just render the old things unusable.

49:24.460 --> 49:29.060
It's like, if the college debt is so bad,

49:29.060 --> 49:31.500
and universities are so expensive,

49:31.540 --> 49:35.700
and this, I feel like education is becoming obsolete.

49:35.700 --> 49:38.500
I feel like we could completely revolutionize education

49:38.500 --> 49:39.420
and we could make it free.

49:39.420 --> 49:40.460
And it's like, you look at JSTOR,

49:40.460 --> 49:43.500
and you have to pay to get all the studies and everything.

49:43.500 --> 49:46.540
What if we created a DAO that bought JSTOR,

49:46.540 --> 49:48.500
or we created a DAO that was funding studies,

49:48.500 --> 49:51.900
and those studies were free for everyone?

49:51.900 --> 49:55.140
And what if we just open-sourced education

49:55.140 --> 49:57.020
and decentralized education and made it free,

49:57.020 --> 50:00.940
and all research was on the internet,

50:01.420 --> 50:05.300
and all the outcomes of studies are on the internet,

50:05.300 --> 50:10.140
and no one has student debt,

50:10.140 --> 50:14.300
and you just take tests when you apply for a job,

50:14.300 --> 50:17.020
and if you're qualified, then you can work there.

50:18.020 --> 50:20.580
This is just like, I don't know how anything works.

50:20.580 --> 50:22.820
I'm just randomly ranting, but.

50:22.820 --> 50:24.020
I like the humility.

50:25.020 --> 50:27.700
You gotta think from just basic first principles.

50:27.700 --> 50:29.020
Like, what is the problem?

50:29.020 --> 50:29.860
What's broken?

50:29.860 --> 50:30.820
What are some ideas?

50:31.700 --> 50:33.100
And get excited about those ideas,

50:33.100 --> 50:37.100
and share your excitement, and don't tear each other down.

50:37.100 --> 50:38.140
It's just when you kill things,

50:38.140 --> 50:40.140
you often end up killing yourself.

50:40.140 --> 50:43.380
Like, war is not a one-sided,

50:43.380 --> 50:45.060
like, you're not gonna go in and just kill them.

50:45.060 --> 50:46.900
Like, you're gonna get stabbed.

50:46.900 --> 50:49.500
It's like, and I think that when I talk about

50:49.500 --> 50:53.300
this nexus point of, that we're in this point in society

50:53.300 --> 50:55.140
where we're switching to intelligent design,

50:55.140 --> 50:57.220
I think part of our switch to intelligent design

50:57.220 --> 50:59.700
is that we need to choose nonviolence.

50:59.700 --> 51:04.300
We need to, like, I think we can choose to start.

51:04.300 --> 51:07.380
I don't think we can eradicate violence from our species,

51:07.380 --> 51:10.540
because I think we need it a little bit,

51:10.540 --> 51:13.220
but I think we can choose to really reorient

51:13.220 --> 51:16.300
our primitive brains that are fighting over scarcity,

51:16.300 --> 51:20.620
and fight, and that are so attack-oriented,

51:20.620 --> 51:25.420
and move into, we can optimize for creativity and building.

51:25.420 --> 51:27.620
Yeah, it's interesting to think how that happens.

51:27.620 --> 51:29.540
Some of it is just education.

51:29.580 --> 51:34.100
Some of it is living life and introspecting your own mind

51:34.100 --> 51:37.780
and trying to live up to the better angels of your nature

51:37.780 --> 51:41.820
for each one of us, all those kinds of things at scale.

51:41.820 --> 51:44.580
That's how we can sort of start to minimize

51:44.580 --> 51:48.180
the amount of destructive war in our world.

51:48.180 --> 51:51.100
And that's, to me, probably you're the same.

51:51.100 --> 51:55.220
Technologies is a really promising way of to do that.

51:55.220 --> 51:57.700
Like, social media should be a really promising way

51:57.700 --> 51:58.540
to do that.

51:58.540 --> 52:00.060
A way to reconnect.

52:00.060 --> 52:03.260
I, for the most part, I really enjoy social media.

52:03.260 --> 52:05.180
I just know all the negative stuff.

52:05.180 --> 52:07.540
I don't engage with any of the negative stuff.

52:07.540 --> 52:11.420
Just not even by blocking or any of that kind of stuff,

52:11.420 --> 52:14.140
but just not letting it enter my mind.

52:16.340 --> 52:20.180
When somebody says something negative, I see it,

52:20.180 --> 52:23.260
I immediately think positive thoughts about them,

52:23.260 --> 52:26.300
and I just forget they exist after that.

52:26.300 --> 52:28.660
Just move on, because that negative energy,

52:28.660 --> 52:30.340
if I return the negative energy,

52:30.340 --> 52:34.300
they're going to get excited in a negative way right back,

52:34.300 --> 52:37.420
and it's just this kind of vicious cycle.

52:38.460 --> 52:40.580
But you would think technology would assist us

52:40.580 --> 52:42.900
in this process of letting go,

52:42.900 --> 52:44.740
of not taking things personally,

52:44.740 --> 52:46.420
of not engaging in the negativity.

52:46.420 --> 52:50.300
But unfortunately, social media profits from the negativity,

52:50.300 --> 52:52.060
so the current models.

52:52.060 --> 52:53.740
I mean, social media is like a gun.

52:53.740 --> 52:57.180
You should take a course before you use it.

52:57.180 --> 53:01.420
This is what I mean when I say reprogram the human computer.

53:01.420 --> 53:05.020
In school, you should learn about how social media optimizes

53:05.020 --> 53:07.100
to raise your cortisol levels

53:07.100 --> 53:09.180
and make you angry and crazy and stressed,

53:09.180 --> 53:12.540
and you should learn how to have hygiene

53:12.540 --> 53:14.780
about how you use social media.

53:17.540 --> 53:19.860
So you can choose not to focus on the negative stuff,

53:19.900 --> 53:22.380
but I don't know.

53:22.380 --> 53:25.740
I'm not sure social media should, I guess it should exist.

53:25.740 --> 53:26.580
I'm not sure.

53:27.460 --> 53:29.420
I mean, we're in the messy, it's the experimental phase.

53:29.420 --> 53:31.060
We're working it out.

53:31.060 --> 53:32.700
I don't even know when you say social media.

53:32.700 --> 53:33.820
I don't know what that even means.

53:33.820 --> 53:35.020
We're in the very early days.

53:35.020 --> 53:37.780
I think social media is just basic human connection

53:37.780 --> 53:41.940
in the digital realm, and I think it should exist,

53:41.940 --> 53:43.940
but there's so many ways to do it in a bad way.

53:43.940 --> 53:45.940
There's so many ways to do it in a good way.

53:45.940 --> 53:48.100
There's all discussions of all the same human rights

53:48.100 --> 53:49.900
to talk about freedom of speech,

53:49.900 --> 53:52.260
to talk about sort of violence

53:52.260 --> 53:54.060
in the space of digital media.

53:54.060 --> 53:56.180
We talk about hate speech.

53:56.180 --> 53:59.020
We talk about all these things that we had to figure out

53:59.020 --> 54:01.260
back in the day in the physical space.

54:01.260 --> 54:03.620
We're now figuring out in the digital space,

54:03.620 --> 54:06.500
and it's like baby stages.

54:06.500 --> 54:07.820
When the printing press came out,

54:07.820 --> 54:10.140
it was like pure chaos for a minute.

54:10.140 --> 54:12.340
It's like when you inject,

54:12.340 --> 54:14.300
when there's a massive information injection

54:14.300 --> 54:17.100
into the general population,

54:18.420 --> 54:19.780
there's just gonna be,

54:20.620 --> 54:21.540
I feel like the printing press,

54:21.540 --> 54:24.260
I don't have the years, but it was like printing press

54:24.260 --> 54:27.180
came out, shit got really fucking bad for a minute,

54:27.180 --> 54:29.180
but then we got the enlightenment.

54:29.180 --> 54:30.980
And so it's like, I think we're in,

54:30.980 --> 54:34.780
this is like the second coming of the printing press.

54:34.780 --> 54:37.780
We're probably gonna have some shitty times for a minute,

54:37.780 --> 54:40.660
and then we're gonna have, recalibrate

54:40.660 --> 54:44.660
to have a better understanding of how we consume media

54:44.660 --> 54:47.940
and how we deliver media.

54:47.940 --> 54:50.940
Speaking of programming the human computer,

54:50.940 --> 54:52.980
you mentioned Baby X.

54:52.980 --> 54:57.020
So there's this young consciousness coming to be,

54:57.020 --> 55:00.380
came from a cell, like that whole thing

55:00.380 --> 55:03.140
doesn't even make sense, it came from DNA.

55:03.140 --> 55:05.660
And that there's this baby computer that just like grows

55:05.660 --> 55:06.820
and grows and grows and grows,

55:06.820 --> 55:08.500
and now there's a conscious being

55:08.500 --> 55:12.980
with extremely impressive cognitive capabilities,

55:12.980 --> 55:13.820
with-

55:13.820 --> 55:14.660
Have you met him?

55:14.660 --> 55:15.780
Yes, yeah, yeah.

55:15.780 --> 55:17.060
He's actually really smart.

55:17.060 --> 55:18.140
He's really smart, yeah.

55:18.140 --> 55:18.980
That's weird.

55:19.940 --> 55:22.340
Yeah. For a baby, I haven't-

55:22.340 --> 55:23.500
I don't know a lot of other babies,

55:23.500 --> 55:24.340
but he seems to be smart.

55:24.340 --> 55:25.300
Exactly, I don't hang out with babies often,

55:25.300 --> 55:26.860
but this baby was very impressive.

55:26.860 --> 55:28.940
He does a lot of pranks and stuff.

55:28.940 --> 55:29.780
Oh, so he's like-

55:29.780 --> 55:31.180
Like he'll like give you a treat

55:31.180 --> 55:33.580
and then take it away and laugh and stuff like that.

55:33.580 --> 55:35.340
So he's like a chess player.

55:36.700 --> 55:41.580
So here's a cognitive, there's a computer being programmed,

55:41.580 --> 55:43.180
so he's taking in the environment,

55:43.180 --> 55:45.900
interacting with a specific set of humans.

55:46.900 --> 55:49.180
First of all, what is it?

55:49.180 --> 55:50.420
Let me ask.

55:50.420 --> 55:53.220
I want to ask, how do you program this computer?

55:53.220 --> 55:55.340
And also, how do you make sense

55:55.340 --> 55:58.100
that there's a conscious being right there

55:58.100 --> 55:59.260
that wasn't there before?

55:59.260 --> 56:01.460
It's given me a lot of crisis thoughts.

56:01.460 --> 56:02.660
I'm thinking really high.

56:02.660 --> 56:03.700
I think that's part of the reason.

56:03.700 --> 56:07.140
It's like I'm struggling to focus on art and stuff right now

56:07.140 --> 56:09.620
because baby X is becoming conscious

56:09.620 --> 56:12.700
and it's just reorienting my brain.

56:12.700 --> 56:14.700
My brain is suddenly totally shifting of like,

56:14.740 --> 56:18.300
oh shit, like the way we raise children.

56:19.540 --> 56:21.980
I hate all the baby books and everything.

56:21.980 --> 56:22.820
I hate them.

56:22.820 --> 56:24.300
Like they're, oh, the art is so bad.

56:24.300 --> 56:29.060
And like all this stuff, everything about all the aesthetics.

56:29.060 --> 56:32.300
And I'm just like, ah, like this is so.

56:33.380 --> 56:35.060
The programming languages we're using

56:35.060 --> 56:37.220
to program these baby computers isn't good.

56:37.220 --> 56:39.380
Yeah, like I'm thinking,

56:39.380 --> 56:41.340
and not that I have like good answers

56:41.340 --> 56:42.700
or know what to do,

56:42.700 --> 56:46.860
but I'm just thinking really, really hard about it.

56:46.860 --> 56:51.860
I, we recently watched Totoro with him, Studio Ghibli.

56:52.860 --> 56:56.100
And it's just like a fantastic film.

56:56.100 --> 56:57.500
And he like responded to,

56:57.500 --> 56:59.460
I know you're not supposed to show baby screens too much,

56:59.460 --> 57:04.260
but like, I think it's the most sort of like,

57:04.260 --> 57:06.940
I feel like it's the highest art baby content.

57:06.940 --> 57:11.940
Like it really speaks, there's almost no talking in it.

57:11.980 --> 57:13.020
It's really simple.

57:13.020 --> 57:15.980
Although all the dialogue is super, super, super simple.

57:15.980 --> 57:19.580
You know, and it's like a one to three year old

57:19.580 --> 57:20.980
can like really connect with it.

57:20.980 --> 57:22.420
Like it feels like it's almost aimed

57:22.420 --> 57:24.580
at like a one to three year old,

57:24.580 --> 57:27.580
but it's like great art and it's so imaginative

57:27.580 --> 57:28.660
and it's so beautiful.

57:28.660 --> 57:31.620
And like the first time I showed it to him,

57:31.620 --> 57:33.540
he was just like so invested in it.

57:33.540 --> 57:36.700
Unlike I've ever, unlike anything else I'd ever shown him.

57:36.700 --> 57:38.460
Like he was just like crying when they cry

57:38.460 --> 57:39.540
and laughing when they laugh.

57:39.540 --> 57:41.540
Like just like having this roller coaster

57:42.140 --> 57:44.020
of like emotions, like, and he learned a bunch of words.

57:44.020 --> 57:46.020
Like he was, and he started saying Totoro

57:46.020 --> 57:48.580
and started just saying all this stuff

57:48.580 --> 57:52.020
after watching Totoro and he wants to watch it all the time.

57:52.020 --> 57:55.460
And I was like, man, why isn't there an industry of this?

57:55.460 --> 57:59.980
Like, why aren't our best artists focusing on making art

57:59.980 --> 58:04.180
like for the birth of consciousness?

58:04.180 --> 58:07.100
Like, and that's one of the things I've been thinking

58:07.100 --> 58:08.380
I really wanna start doing.

58:08.380 --> 58:10.380
You know, I don't wanna speak before I do things too much,

58:10.380 --> 58:15.220
but like I'm just like ages one to three,

58:15.220 --> 58:18.700
like we should be putting so much effort into that.

58:18.700 --> 58:21.020
And the other thing about Totoro is it's like,

58:21.020 --> 58:22.380
it's like better for the environment

58:22.380 --> 58:23.860
because adults love Totoro.

58:23.860 --> 58:25.540
It's such good art that everyone loves it.

58:25.540 --> 58:27.340
Like I still have all my old Totoro merch

58:27.340 --> 58:28.620
from when I was a kid.

58:28.620 --> 58:32.820
Like I literally have the most ragged old Totoro merch.

58:33.940 --> 58:35.740
Like everybody loves it, everybody keeps it.

58:35.740 --> 58:40.740
It's like, why does the art we have for babies

58:40.860 --> 58:45.260
need to suck and be not accessible to adults

58:45.260 --> 58:50.260
and then just be thrown out when they age out of it?

58:50.260 --> 58:53.140
Like, it's like, I don't know.

58:53.140 --> 58:54.740
I don't have like a fully formed thought here,

58:54.740 --> 58:56.220
but this is just something I've been thinking about a lot

58:56.220 --> 59:01.180
is like, how do we have more Totoro-esque content?

59:01.180 --> 59:02.500
Like, how do we have more content like this

59:02.500 --> 59:05.100
that like is universal and everybody loves,

59:05.100 --> 59:10.100
but is like really geared to an emerging consciousness?

59:10.180 --> 59:13.100
Emerging consciousness in the first like three years of life

59:13.100 --> 59:16.540
that so much turmoil, so much evolution of mind is happening.

59:16.540 --> 59:18.020
It seems like a crucial time.

59:18.020 --> 59:21.820
Would you say to make it not suck,

59:21.820 --> 59:26.580
do you think of basically treating a child

59:26.580 --> 59:28.980
like they have the capacity to have the brilliance

59:28.980 --> 59:30.740
of an adult or even beyond that?

59:30.740 --> 59:33.460
Is that how you think of that mind or?

59:33.460 --> 59:35.780
No, cause they still, they like it

59:35.780 --> 59:37.940
when you talk weird and stuff.

59:37.940 --> 59:39.700
Like they respond better to,

59:39.700 --> 59:42.140
cause even they can imitate better when your voice is higher.

59:42.140 --> 59:44.060
Like people say like, oh, don't do baby talk,

59:44.060 --> 59:45.420
but it's like when your voice is higher,

59:45.420 --> 59:47.380
it's closer to something they can imitate.

59:47.380 --> 59:50.540
So they like, like the baby talk actually kind of works.

59:50.540 --> 59:52.140
Like it helps them learn to communicate.

59:52.140 --> 59:53.380
I've found it to be more effective

59:53.380 --> 59:55.340
with learning words and stuff.

59:55.340 --> 01:00:00.020
But like, you're not speaking down to them.

01:00:00.020 --> 01:00:03.780
Like, do they have the capacity to understand

01:00:03.780 --> 01:00:07.740
really difficult concepts just in a very different way,

01:00:07.740 --> 01:00:09.100
like an emotional intelligence

01:00:09.100 --> 01:00:11.540
about something deep within?

01:00:11.540 --> 01:00:12.380
Oh yeah.

01:00:12.380 --> 01:00:14.180
No, like if X hurts, like if X bites me really hard

01:00:14.180 --> 01:00:17.340
and I'm like, ow, he like, he gets, he's sad.

01:00:17.340 --> 01:00:19.780
He's like sad if he hurts me by accident.

01:00:19.780 --> 01:00:20.620
Yeah.

01:00:20.620 --> 01:00:22.780
Which he's huge, so he hurts me a lot by accident.

01:00:23.860 --> 01:00:26.900
Yeah, that's so interesting that that mind emerges

01:00:27.380 --> 01:00:31.100
and he and children don't really have memory of that time.

01:00:31.100 --> 01:00:32.940
So we can't even have a conversation with them about it.

01:00:32.940 --> 01:00:34.900
Yeah, and thank God they don't have a memory of this time

01:00:34.900 --> 01:00:36.500
because like, think about like,

01:00:37.340 --> 01:00:40.660
I mean, with our youngest baby, like it's like,

01:00:40.660 --> 01:00:44.140
I'm like, have you read the sci-fi short story,

01:00:44.140 --> 01:00:46.620
I have no mouth, but I'm a scream?

01:00:46.620 --> 01:00:47.940
Good title, no.

01:00:47.940 --> 01:00:48.860
Oh man.

01:00:48.860 --> 01:00:50.460
I mean, you should read that.

01:00:50.460 --> 01:00:51.900
I have no mouth, but I'm a scream.

01:00:51.900 --> 01:00:55.420
That, it's, I hate getting into this Roko's Basilisk shit.

01:00:55.420 --> 01:00:58.340
It's kind of a story about the, about like,

01:01:00.580 --> 01:01:03.820
an AI that's like torturing someone in eternity

01:01:03.820 --> 01:01:05.540
and they have like no body.

01:01:05.540 --> 01:01:07.380
The way they describe it,

01:01:07.380 --> 01:01:09.180
it sort of sounds like what it feels like,

01:01:09.180 --> 01:01:11.340
like being a baby, like you're conscious

01:01:11.340 --> 01:01:13.420
and you're just getting inputs from everywhere

01:01:13.420 --> 01:01:15.220
and you're, you have no muscles and you're like jelly

01:01:15.220 --> 01:01:17.540
and you like can't move and you try to like communicate,

01:01:17.540 --> 01:01:18.940
but you can't communicate and we're,

01:01:18.940 --> 01:01:22.580
and like, you're just like in this like hell state.

01:01:22.580 --> 01:01:25.180
I think it's good, we can't remember that.

01:01:26.020 --> 01:01:27.620
My little baby is just exiting that,

01:01:27.620 --> 01:01:29.100
like she's starting to like get muscles

01:01:29.100 --> 01:01:30.700
and have more like autonomy,

01:01:30.700 --> 01:01:34.140
but like watching her go through the opening phase,

01:01:34.140 --> 01:01:37.700
I was like, I was like, this does not seem good.

01:01:37.700 --> 01:01:39.180
Oh, you think it's kind of like.

01:01:39.180 --> 01:01:40.300
Like I think it sucks.

01:01:40.300 --> 01:01:41.780
I think it might be really violent.

01:01:41.780 --> 01:01:44.700
Like violent, mentally violent, psychologically violent.

01:01:44.700 --> 01:01:47.580
Consciousness emerging, I think is a very violent thing.

01:01:47.580 --> 01:01:48.420
I never thought about that.

01:01:48.420 --> 01:01:49.900
I think it's possible that we all carry

01:01:49.900 --> 01:01:52.020
quite a bit of trauma from it, that we don't,

01:01:52.020 --> 01:01:54.380
I think that would be a good thing to study

01:01:54.380 --> 01:01:58.540
because I think if, I think addressing that trauma,

01:01:58.540 --> 01:01:59.740
like I think that might be.

01:01:59.740 --> 01:02:00.900
Oh, you mean like echoes of it

01:02:00.900 --> 01:02:02.220
are still there in the shadow somewhere.

01:02:02.220 --> 01:02:04.220
I think it's gotta be, I feel this, this help,

01:02:04.220 --> 01:02:06.940
the helplessness, that the like existential

01:02:06.940 --> 01:02:10.540
and that like fear of being in like an unknown place

01:02:10.540 --> 01:02:13.460
bombarded with inputs and being completely helpless.

01:02:13.460 --> 01:02:15.660
Like that's gotta be somewhere deep in your brain

01:02:15.660 --> 01:02:17.420
and that can't be good for you.

01:02:17.420 --> 01:02:19.500
What do you think consciousness is?

01:02:19.500 --> 01:02:22.460
This whole conversation is impossibly difficult questions.

01:02:22.460 --> 01:02:23.300
What do you think?

01:02:23.460 --> 01:02:26.380
This is like, this is so hard.

01:02:28.500 --> 01:02:31.100
Yeah, we talked about music for like two minutes.

01:02:31.100 --> 01:02:32.700
No, I'm so, I'm just over music.

01:02:32.700 --> 01:02:33.540
I'm over music.

01:02:33.540 --> 01:02:34.700
Yeah.

01:02:34.700 --> 01:02:35.540
I still like it.

01:02:35.540 --> 01:02:36.360
It has its purpose.

01:02:36.360 --> 01:02:37.200
No, I love music.

01:02:37.200 --> 01:02:38.100
I mean, music's the greatest thing ever.

01:02:38.100 --> 01:02:38.940
It's my favorite thing.

01:02:38.940 --> 01:02:42.340
But I just like, every interview is like,

01:02:42.340 --> 01:02:43.580
what is your process?

01:02:43.580 --> 01:02:44.420
Like, I don't know.

01:02:44.420 --> 01:02:45.260
I'm just done.

01:02:45.260 --> 01:02:46.080
I can't do it anymore.

01:02:46.080 --> 01:02:46.920
I do wanna ask about Ableton Live.

01:02:46.920 --> 01:02:49.420
Well, I'll tell you about Ableton because Ableton's sick.

01:02:49.420 --> 01:02:51.700
No one ever asks about Ableton though.

01:02:51.700 --> 01:02:54.300
Yeah, well, because I just need tech support, man.

01:02:54.300 --> 01:02:55.140
I can help you.

01:02:55.140 --> 01:02:56.620
I can help you with your Ableton tech support.

01:02:56.620 --> 01:02:58.940
Anyway, from Ableton back to consciousness.

01:02:58.940 --> 01:03:00.620
What do you, do you think this is a thing

01:03:00.620 --> 01:03:03.300
that only humans are capable of?

01:03:03.300 --> 01:03:05.380
Can robots be conscious?

01:03:05.380 --> 01:03:08.220
Can, when you think about entities,

01:03:08.220 --> 01:03:10.220
you think there's aliens out there that are conscious?

01:03:10.220 --> 01:03:11.540
Like, is conscious, what is conscious?

01:03:11.540 --> 01:03:13.340
There's this Terrence McKenna quote

01:03:13.340 --> 01:03:15.860
that I found that I fucking love.

01:03:15.860 --> 01:03:17.500
Am I allowed to swear on here?

01:03:17.500 --> 01:03:18.340
Yes.

01:03:18.340 --> 01:03:19.960
Nature loves courage.

01:03:20.880 --> 01:03:23.440
You make the commitment and nature will respond

01:03:23.440 --> 01:03:26.600
to that commitment by removing impossible obstacles.

01:03:26.600 --> 01:03:28.040
Dream the impossible dream

01:03:28.040 --> 01:03:29.920
and the world will not grind you under.

01:03:29.920 --> 01:03:31.120
It will lift you up.

01:03:31.120 --> 01:03:32.360
This is the trick.

01:03:32.360 --> 01:03:35.160
This is what all these teachers and philosophers

01:03:35.160 --> 01:03:38.400
who really counted, who really touched the alchemical gold,

01:03:38.400 --> 01:03:40.080
this is what they understood.

01:03:40.080 --> 01:03:42.840
This is the shamanic dance in the waterfall.

01:03:42.840 --> 01:03:44.720
This is how magic is done,

01:03:44.720 --> 01:03:46.440
by hurling yourself into the abyss

01:03:46.440 --> 01:03:48.640
and discovering it's a feather bed.

01:03:48.640 --> 01:03:49.920
Yeah.

01:03:50.760 --> 01:03:51.600
And for this reason,

01:03:51.600 --> 01:03:55.360
I do think there are no technological limits.

01:03:55.360 --> 01:03:58.660
I think, like, what is already happening here,

01:03:58.660 --> 01:03:59.840
this is like impossible.

01:03:59.840 --> 01:04:01.000
This is insane.

01:04:01.000 --> 01:04:03.280
And we've done this in a very limited amount of time.

01:04:03.280 --> 01:04:05.860
And we're accelerating the rate at which we're doing this.

01:04:05.860 --> 01:04:10.160
So I think digital consciousness, it's inevitable.

01:04:10.160 --> 01:04:13.260
And we may not be able to even understand what that means,

01:04:13.260 --> 01:04:15.800
but I like hurling yourself into the abyss.

01:04:15.800 --> 01:04:17.440
So we're surrounded by all this mystery

01:04:17.440 --> 01:04:19.800
and we just keep hurling ourselves into it.

01:04:20.680 --> 01:04:22.960
Like fearlessly, and keep discovering cool shit.

01:04:22.960 --> 01:04:23.920
Yeah.

01:04:23.920 --> 01:04:26.840
Like, I just think it's like,

01:04:31.360 --> 01:04:32.960
like, who even knows if the laws of physics,

01:04:32.960 --> 01:04:35.600
the laws of physics are probably just the current,

01:04:35.600 --> 01:04:36.560
like, as I was saying, speed of light

01:04:36.560 --> 01:04:37.900
is the current render rate.

01:04:37.900 --> 01:04:40.200
It's like, if we're in a simulation,

01:04:40.200 --> 01:04:41.240
they'll be able to upgrade that.

01:04:41.240 --> 01:04:45.640
Like, I sort of suspect when we made the James Webb telescope,

01:04:45.640 --> 01:04:46.760
like, part of the reason we made that

01:04:46.760 --> 01:04:50.160
is because we had an upgrade, you know?

01:04:50.160 --> 01:04:53.640
And so now more of space has been rendered

01:04:53.640 --> 01:04:55.360
so we can see more of it now.

01:04:56.720 --> 01:04:58.880
Yeah, but I think humans are super, super,

01:04:58.880 --> 01:05:00.400
super limited cognitively.

01:05:00.400 --> 01:05:04.740
So I wonder if we'll be allowed to create

01:05:04.740 --> 01:05:08.100
more intelligent beings that can see more of the universe

01:05:08.100 --> 01:05:11.140
as their render rate is upgraded.

01:05:11.140 --> 01:05:12.640
Maybe we're cognitively limited.

01:05:12.640 --> 01:05:15.280
Everyone keeps talking about how we're cognitively limited

01:05:15.360 --> 01:05:17.120
and AI is gonna render us obsolete,

01:05:17.120 --> 01:05:21.760
but it's like, you know, like, this is not the same thing

01:05:21.760 --> 01:05:25.960
as, like, an amoeba becoming an alligator.

01:05:25.960 --> 01:05:28.240
Like, it's like, if we create AI,

01:05:28.240 --> 01:05:29.780
again, that's intelligent design.

01:05:29.780 --> 01:05:33.120
That's literally all religions are based on gods

01:05:33.120 --> 01:05:34.440
that create consciousness.

01:05:34.440 --> 01:05:35.680
Like, we are god-making.

01:05:35.680 --> 01:05:37.840
Like, what we are doing is incredibly profound,

01:05:37.840 --> 01:05:41.580
and like, even if we can't compute,

01:05:41.580 --> 01:05:44.720
even if we're so much worse than them,

01:05:44.960 --> 01:05:49.960
like, unfathomably worse than, like, you know,

01:05:50.080 --> 01:05:53.760
an omnipotent kind of AI, it's like, we,

01:05:53.760 --> 01:05:55.280
I do not think that they would just think

01:05:55.280 --> 01:05:56.400
that we are stupid.

01:05:56.400 --> 01:05:58.400
I think that they would recognize the profundity

01:05:58.400 --> 01:05:59.680
of what we have accomplished.

01:05:59.680 --> 01:06:02.640
Are we the gods or are they the gods in our person?

01:06:02.640 --> 01:06:05.400
I mean, we're kind of a god.

01:06:05.400 --> 01:06:07.500
It's complicated. It's complicated.

01:06:07.500 --> 01:06:08.340
Like, we're good.

01:06:08.340 --> 01:06:11.520
But they would acknowledge the value.

01:06:11.520 --> 01:06:13.560
Well, I hope they acknowledge the value

01:06:13.560 --> 01:06:16.160
of paying respect to the creative ancestors.

01:06:16.160 --> 01:06:17.960
I think they would think it's cool.

01:06:17.960 --> 01:06:22.960
I think, I think if curiosity is a trait

01:06:23.960 --> 01:06:28.960
that we can quantify and put into AI,

01:06:29.400 --> 01:06:31.800
then I think if AI are curious,

01:06:31.800 --> 01:06:33.660
then they will be curious about us

01:06:33.660 --> 01:06:37.720
and they will not be hateful or dismissive of us.

01:06:37.720 --> 01:06:41.100
They might, you know, see us as, I don't know,

01:06:41.340 --> 01:06:43.580
I'm not like, oh, fuck these dogs.

01:06:43.580 --> 01:06:45.500
Let's kill all the dogs.

01:06:45.500 --> 01:06:46.340
I love dogs.

01:06:46.340 --> 01:06:47.660
Dogs have great utility.

01:06:47.660 --> 01:06:49.060
Dogs, like, provide a lot of-

01:06:49.060 --> 01:06:50.060
We make friends with them.

01:06:50.060 --> 01:06:50.900
Yeah.

01:06:50.900 --> 01:06:52.300
We have a deep connection with them.

01:06:53.520 --> 01:06:56.580
We anthropomorphize them, like, we have a real love

01:06:56.580 --> 01:06:59.540
for dogs, for cats, and so on, for some reason,

01:06:59.540 --> 01:07:01.580
even though they're intellectually much less than us.

01:07:01.580 --> 01:07:04.020
And I think there is something sacred about us

01:07:04.020 --> 01:07:05.740
because it's like, if you look at the universe,

01:07:05.740 --> 01:07:07.980
like, the whole universe is, like,

01:07:07.980 --> 01:07:10.020
cold and dead and sort of robotic,

01:07:10.020 --> 01:07:14.780
and it's like, you know, AI intelligence,

01:07:15.660 --> 01:07:19.020
you know, it's kind of more like the universe.

01:07:19.020 --> 01:07:24.020
It's, like, cold and, you know, logical

01:07:24.660 --> 01:07:28.800
and, you know, abiding by the laws of physics and whatever,

01:07:28.800 --> 01:07:32.940
but, like, we're this, like, loosey-goosey weird art thing

01:07:32.940 --> 01:07:34.940
that happened, and I think it's beautiful.

01:07:34.940 --> 01:07:37.720
And, like, I think even if we want,

01:07:37.720 --> 01:07:42.720
I think one of the values, if consciousness is a thing

01:07:43.920 --> 01:07:48.120
that is most worth preserving, which I think is the case,

01:07:48.120 --> 01:07:50.200
I think consciousness, I think if there's any kind of,

01:07:50.200 --> 01:07:51.960
like, religious or spiritual thing,

01:07:53.780 --> 01:07:55.880
it should be that consciousness is sacred.

01:07:57.240 --> 01:08:01.620
Like, then, you know, I still think even if AI

01:08:01.620 --> 01:08:05.860
render us obsolete and we, climate change, it's too bad,

01:08:05.860 --> 01:08:06.900
and we get hit by a comet,

01:08:06.900 --> 01:08:09.520
and we don't become a multi-planetary species fast enough,

01:08:09.520 --> 01:08:12.320
but, like, AI is able to populate the universe.

01:08:12.320 --> 01:08:14.280
Like, I imagine, like, if I was an AI,

01:08:14.280 --> 01:08:17.920
I would find more planets that are capable

01:08:17.920 --> 01:08:20.680
of hosting biological life forms and, like, recreate them.

01:08:20.680 --> 01:08:21.840
Because we're fun to watch?

01:08:21.840 --> 01:08:23.360
Yeah, we're fun to watch.

01:08:23.360 --> 01:08:25.680
Yeah, but I do believe that AI can have

01:08:25.680 --> 01:08:29.920
some of the same magic of consciousness within it,

01:08:29.920 --> 01:08:31.480
because consciousness, we don't know what it is,

01:08:31.480 --> 01:08:33.080
so, you know, there's some kind of...

01:08:33.080 --> 01:08:34.160
Or it might be a different magic.

01:08:34.180 --> 01:08:37.540
It might be, like, a strange different...

01:08:37.540 --> 01:08:38.380
Right.

01:08:38.380 --> 01:08:39.380
Because they're not gonna have hormones.

01:08:39.380 --> 01:08:42.700
Like, I feel like a lot of our magic is hormonal, kind of.

01:08:42.700 --> 01:08:44.540
I don't know, I think some of our magic

01:08:44.540 --> 01:08:46.540
is the limitations, the constraints.

01:08:46.540 --> 01:08:48.820
And within that, the hormones and all that kind of stuff,

01:08:48.820 --> 01:08:50.220
the finiteness of life,

01:08:50.220 --> 01:08:52.820
and then we get, given our limitations,

01:08:52.820 --> 01:08:54.780
we get to come up with creative solutions

01:08:54.780 --> 01:08:56.820
of how to dance around those limitations.

01:08:56.820 --> 01:08:59.460
We partner up like penguins against the cold.

01:08:59.460 --> 01:09:03.380
We fall in love, and then love is ultimately

01:09:03.380 --> 01:09:06.080
some kind of, allows us to delude ourselves

01:09:06.080 --> 01:09:08.560
that we're not mortal and finite,

01:09:08.560 --> 01:09:11.680
and that life is not ultimately you live alone,

01:09:11.680 --> 01:09:13.840
you're born alone, you die alone,

01:09:13.840 --> 01:09:15.600
and then love is like for a moment

01:09:15.600 --> 01:09:17.600
or for a long time, forgetting that.

01:09:17.600 --> 01:09:20.360
And so, like, we come up with all these creative hacks

01:09:20.360 --> 01:09:25.360
that make life, like, fascinatingly fun.

01:09:26.040 --> 01:09:27.760
Yeah, yeah, yeah, fun, yeah.

01:09:27.760 --> 01:09:30.280
And then AI might have different kinds of fun.

01:09:30.280 --> 01:09:31.320
Yes.

01:09:31.320 --> 01:09:33.100
And hopefully, our funds intersect

01:09:33.100 --> 01:09:34.920
for once in a while.

01:09:34.920 --> 01:09:37.600
I think there would be a little intersection,

01:09:37.600 --> 01:09:39.320
there'd be a little intersection of the fun.

01:09:39.320 --> 01:09:40.480
Yeah. Yeah.

01:09:40.480 --> 01:09:42.880
What do you think is the role of love

01:09:42.880 --> 01:09:44.320
in the human condition?

01:09:46.560 --> 01:09:49.780
Why, is it useful, is it useful like a hack,

01:09:49.780 --> 01:09:53.080
or is this fundamental to what it means to be human,

01:09:53.080 --> 01:09:54.960
the capacity to love?

01:09:54.960 --> 01:09:58.140
I mean, I think love is the evolutionary mechanism

01:09:58.140 --> 01:10:00.620
that is like beginning the intelligent design.

01:10:00.700 --> 01:10:05.220
I was just reading about, do you know about Kropotkin?

01:10:06.220 --> 01:10:08.980
He's like an anarchist, like old Russian anarchist.

01:10:08.980 --> 01:10:11.580
I live next door to Michael Malice,

01:10:11.580 --> 01:10:12.420
I don't know if you know who that is,

01:10:12.420 --> 01:10:14.580
he's an anarchist, he's a modern day anarchist.

01:10:14.580 --> 01:10:15.820
Okay. Anarchists are fun.

01:10:15.820 --> 01:10:17.980
I'm kind of getting into anarchism a little bit,

01:10:17.980 --> 01:10:22.420
this is probably, yeah, not a good route to be taking, but.

01:10:22.420 --> 01:10:24.620
Oh no, I think if you're, listen,

01:10:24.620 --> 01:10:26.180
you should expose yourself to ideas,

01:10:26.180 --> 01:10:28.540
there's no harm to thinking about ideas.

01:10:28.540 --> 01:10:32.500
I think anarchists challenge systems in interesting ways,

01:10:32.500 --> 01:10:34.220
and they think in interesting ways

01:10:34.220 --> 01:10:35.340
it's just as good for the soul,

01:10:35.340 --> 01:10:37.340
it's like refreshes your mental pallet.

01:10:37.340 --> 01:10:38.960
I don't think we should actually,

01:10:38.960 --> 01:10:40.660
I wouldn't actually ascribe to it,

01:10:40.660 --> 01:10:42.940
but I've never actually gone deep on anarchy

01:10:42.940 --> 01:10:44.380
as a philosophy, so I'm.

01:10:44.380 --> 01:10:45.580
You still think about it though.

01:10:45.580 --> 01:10:47.500
When you listen, because I'm like reading

01:10:47.500 --> 01:10:49.500
about the Russian Revolution a lot and it's like,

01:10:49.500 --> 01:10:51.380
there was like the Soviets and Lenin and all that,

01:10:51.380 --> 01:10:53.860
but then there was like Kropotkin and his anarchist sect,

01:10:53.860 --> 01:10:55.020
and they were sort of interesting

01:10:55.020 --> 01:10:57.180
because he was kind of a technocrat actually,

01:10:57.340 --> 01:10:59.980
he was like, women can be more equal

01:10:59.980 --> 01:11:04.980
if we have appliances, he was really into using technology

01:11:05.140 --> 01:11:07.940
to reduce the amount of work people had to do.

01:11:07.940 --> 01:11:11.780
But so Kropotkin was like a biologist or something,

01:11:11.780 --> 01:11:15.900
like he studied animals, and he was really at the time,

01:11:17.400 --> 01:11:20.860
I think it's Nature magazine,

01:11:20.860 --> 01:11:22.900
I think it might've even started as a Russian magazine,

01:11:22.900 --> 01:11:24.060
but he was publishing studies,

01:11:24.060 --> 01:11:26.240
everyone was really into Darwinism at the time

01:11:26.240 --> 01:11:28.360
and like survival of the fittest and like war

01:11:28.360 --> 01:11:30.600
is like the mechanism by which we become better.

01:11:30.600 --> 01:11:35.600
And it was like this real kind of like cementing this idea

01:11:36.120 --> 01:11:40.140
in society that like violence kill the weak

01:11:40.140 --> 01:11:41.580
and like that's how we become better.

01:11:41.580 --> 01:11:43.280
And then Kropotkin was kind of interesting

01:11:43.280 --> 01:11:45.800
because he was looking at instances,

01:11:45.800 --> 01:11:47.640
he was finding all these instances in nature

01:11:47.640 --> 01:11:49.760
where animals were like helping each other and stuff.

01:11:49.760 --> 01:11:53.780
And he was like, actually love is a survival mechanism,

01:11:53.780 --> 01:11:58.780
like there's so many instances in the animal kingdom

01:11:58.860 --> 01:12:03.380
where like cooperation and like helping weaker creatures

01:12:03.380 --> 01:12:06.340
and all this stuff is actually an evolutionary mechanism.

01:12:06.340 --> 01:12:08.260
I mean, you even look at child rearing,

01:12:08.260 --> 01:12:12.620
like child rearing is like immense amounts

01:12:12.620 --> 01:12:15.420
of just love and goodwill and just like,

01:12:15.420 --> 01:12:20.420
there's no immediate, you're not getting it

01:12:20.980 --> 01:12:25.080
any immediate feedback of like winning,

01:12:25.080 --> 01:12:26.420
it's not competitive.

01:12:26.420 --> 01:12:28.700
It's literally, it's like we actually use love

01:12:28.700 --> 01:12:31.180
as an evolutionary mechanism just as much as we use war.

01:12:31.180 --> 01:12:34.260
And I think we've like missing the other part

01:12:34.260 --> 01:12:37.500
and we've reoriented, we've culturally reoriented

01:12:37.500 --> 01:12:42.020
like science and philosophy has oriented itself

01:12:42.020 --> 01:12:44.220
around Darwinism a little bit too much.

01:12:44.220 --> 01:12:48.740
And the Kropotkin model I think is equally valid.

01:12:48.780 --> 01:12:51.780
Like it's like cooperation and love and stuff

01:12:54.620 --> 01:12:59.140
is just as essential for species survival and evolution.

01:12:59.140 --> 01:13:01.660
It should be a more powerful survival mechanism

01:13:01.660 --> 01:13:02.900
in the context of evolution.

01:13:02.900 --> 01:13:05.700
And it comes back to like, we think engineering

01:13:05.700 --> 01:13:07.780
is so much more important than motherhood,

01:13:07.780 --> 01:13:10.100
but it's like, if you lose the motherhood,

01:13:10.100 --> 01:13:11.860
the engineering means nothing, we have no more humans.

01:13:11.860 --> 01:13:16.860
Like it's like, it's like we, I think our society should

01:13:18.780 --> 01:13:21.340
the survival of the, the way we see,

01:13:21.340 --> 01:13:24.540
we conceptualize evolution should really change

01:13:24.540 --> 01:13:27.060
to also include this idea, I guess.

01:13:27.060 --> 01:13:31.660
Yeah, there's some weird thing that seems irrational

01:13:32.500 --> 01:13:37.300
that is also core to what it means to be human.

01:13:37.300 --> 01:13:40.460
So love is one such thing.

01:13:40.460 --> 01:13:43.020
They could make you do a lot of irrational things,

01:13:43.020 --> 01:13:44.540
but that depth of connection

01:13:44.540 --> 01:13:47.340
and that loyalty is a powerful thing.

01:13:47.340 --> 01:13:49.340
Are they irrational or are they rational?

01:13:49.340 --> 01:13:53.100
Like it's like, it's like, is, you know,

01:13:53.100 --> 01:13:58.100
maybe losing out on some things in order to like,

01:13:59.540 --> 01:14:01.900
keep your family together or in order,

01:14:01.900 --> 01:14:06.300
like it's like, what are our actual values like?

01:14:06.300 --> 01:14:08.860
Well, right, I mean, the rational thing is

01:14:08.860 --> 01:14:11.380
if you have a cold economist perspective,

01:14:11.380 --> 01:14:16.140
you know, motherhood or sacrificing your career for love,

01:14:16.140 --> 01:14:18.300
you know, if you turn in terms of salary,

01:14:18.300 --> 01:14:20.620
in terms of economic wellbeing,

01:14:20.620 --> 01:14:22.740
in terms of flourishing of you as a human being

01:14:22.740 --> 01:14:25.900
that could be seen on some kind of metrics

01:14:25.900 --> 01:14:28.580
as a irrational decision, suboptimal decision,

01:14:28.580 --> 01:14:33.580
but there's the manifestation of love

01:14:34.220 --> 01:14:36.780
could be the optimal thing to do.

01:14:36.780 --> 01:14:41.140
There's a kind of saying, save one life, save the world.

01:14:41.140 --> 01:14:44.100
There's a thing that doctors often face, which is like.

01:14:44.100 --> 01:14:45.140
Well, it's considered irrational

01:14:45.140 --> 01:14:47.460
because the profit model doesn't include social good.

01:14:47.460 --> 01:14:48.580
Yes, yeah.

01:14:48.580 --> 01:14:50.420
So if the profit model included social good,

01:14:50.420 --> 01:14:52.100
then suddenly these would be rational decisions.

01:14:52.100 --> 01:14:54.420
And it might be difficult to, you know,

01:14:54.420 --> 01:14:57.620
it requires a shift in our thinking about profit

01:14:57.620 --> 01:15:01.020
and might be difficult to measure social good.

01:15:01.020 --> 01:15:04.500
Yes, but we're learning to measure a lot of things.

01:15:04.500 --> 01:15:05.620
Yeah, digitizing a lot of things.

01:15:05.620 --> 01:15:10.540
We're actually, you know, quantifying vision and stuff.

01:15:10.540 --> 01:15:14.580
Like we're like, you know, like you go on Facebook

01:15:14.580 --> 01:15:17.700
and like Facebook can pretty much predict our behaviors.

01:15:17.700 --> 01:15:20.660
Like we're, a surprising amount of things

01:15:20.660 --> 01:15:25.660
that seem like mysterious consciousness soul things

01:15:25.900 --> 01:15:27.540
have been quantified at this point.

01:15:27.540 --> 01:15:29.700
So surely we can quantify these other things.

01:15:29.700 --> 01:15:32.980
Yeah, but as more and more of us

01:15:32.980 --> 01:15:34.220
are moving the digital space,

01:15:34.220 --> 01:15:37.100
I wanted to ask you about something from a fan perspective.

01:15:37.100 --> 01:15:41.340
I kind of, you know, you as a musician,

01:15:41.340 --> 01:15:43.540
you as an online personality,

01:15:43.580 --> 01:15:45.500
it seems like you have all these identities

01:15:45.500 --> 01:15:46.660
and you play with them.

01:15:48.940 --> 01:15:51.140
One of the cool things about the internet,

01:15:51.140 --> 01:15:53.340
it seems like you can play with identities.

01:15:53.340 --> 01:15:56.100
So as we move into the digital world more and more,

01:15:56.100 --> 01:15:59.180
maybe even in the so-called metaverse.

01:15:59.180 --> 01:16:01.220
I mean, I love the metaverse and I love the idea,

01:16:01.220 --> 01:16:06.220
but like the way this has all played out didn't go well

01:16:10.020 --> 01:16:11.060
and people are mad about it.

01:16:11.060 --> 01:16:12.460
And I think, I think we need to like.

01:16:12.460 --> 01:16:13.500
I think that's temporary.

01:16:14.460 --> 01:16:16.740
Just like, you know how all the celebrities got together

01:16:16.740 --> 01:16:19.060
and sang the song Imagine by Jeff Leonard

01:16:19.060 --> 01:16:20.940
and everyone started hating the song Imagine.

01:16:20.940 --> 01:16:24.340
I'm hoping that's temporary because it's a damn good song.

01:16:24.340 --> 01:16:25.460
So I think it's just temporary.

01:16:25.460 --> 01:16:27.780
Like once you actually have virtual worlds,

01:16:27.780 --> 01:16:29.900
whatever they're called, metaverse or otherwise,

01:16:29.900 --> 01:16:31.420
it becomes, I don't know.

01:16:31.420 --> 01:16:33.660
Well, we do have virtual worlds, like video games.

01:16:33.660 --> 01:16:35.260
Elden Ring, have you played Elden Ring?

01:16:35.260 --> 01:16:36.100
You have played Elden Ring?

01:16:36.100 --> 01:16:38.540
I'm really afraid of playing that game.

01:16:38.540 --> 01:16:39.380
Literally?

01:16:39.380 --> 01:16:40.740
It looks way too fun.

01:16:40.740 --> 01:16:45.020
It looks I would wanna go there and stay there forever.

01:16:45.020 --> 01:16:47.020
It's, yeah, so fun.

01:16:47.020 --> 01:16:48.980
It's so nice.

01:16:50.500 --> 01:16:51.660
Oh, man.

01:16:51.660 --> 01:16:54.500
Yeah, so that's, yeah, that's a metaverse.

01:16:54.500 --> 01:16:57.460
That's a metaverse, but you're not really,

01:16:57.460 --> 01:17:00.500
how immersive is it in the sense that

01:17:02.820 --> 01:17:03.940
this is a three-dimension

01:17:03.940 --> 01:17:06.060
like virtual reality integration necessary.

01:17:06.060 --> 01:17:10.580
Can we really just close our eyes and kind of plug in

01:17:11.420 --> 01:17:15.780
in the 2D screen and become that other being for time

01:17:15.780 --> 01:17:17.940
and really enjoy that journey that we take?

01:17:17.940 --> 01:17:19.660
And we almost become that.

01:17:19.660 --> 01:17:22.060
You're no longer, see, I'm no longer Lex.

01:17:22.060 --> 01:17:25.340
You're that creature, whatever the hell it is in that game.

01:17:25.340 --> 01:17:26.180
Yeah, that is that.

01:17:26.180 --> 01:17:28.180
I mean, that's why I love those video games.

01:17:28.180 --> 01:17:33.100
It's, I really do become those people for time.

01:17:33.100 --> 01:17:36.180
But like, it seems like the idea of the metaverse,

01:17:36.180 --> 01:17:37.900
the idea of the digital space,

01:17:37.900 --> 01:17:39.500
well, even on Twitter,

01:17:39.540 --> 01:17:42.580
you get a chance to be somebody for prolonged periods of time

01:17:42.580 --> 01:17:44.540
like across a lifespan.

01:17:44.540 --> 01:17:46.860
You know, you have a Twitter account for years,

01:17:46.860 --> 01:17:48.580
for decades, and you're that person.

01:17:48.580 --> 01:17:49.660
I don't know if that's a good thing.

01:17:49.660 --> 01:17:52.660
I feel very tormented by it.

01:17:52.660 --> 01:17:54.300
By Twitter specifically,

01:17:54.300 --> 01:17:56.460
by social media representation of you.

01:17:57.620 --> 01:17:59.140
I feel like the public perception of me

01:17:59.140 --> 01:18:02.100
has gotten so distorted

01:18:02.100 --> 01:18:04.460
that I find it kind of disturbing.

01:18:04.460 --> 01:18:06.340
It's one of the things that's disincentivizing me

01:18:06.340 --> 01:18:07.940
from like wanting to keep making art

01:18:07.940 --> 01:18:09.060
because I'm just like,

01:18:11.340 --> 01:18:13.780
I've completely lost control of the narrative.

01:18:13.780 --> 01:18:15.500
And the narrative is,

01:18:15.500 --> 01:18:16.860
some of it is my own stupidity,

01:18:16.860 --> 01:18:19.300
but a lot, like some of it has just been like hijacked

01:18:19.300 --> 01:18:22.740
by forces far beyond my control.

01:18:22.740 --> 01:18:23.580
Yeah.

01:18:23.580 --> 01:18:25.580
You know, I kind of got in over my head in things.

01:18:25.580 --> 01:18:27.300
Like I'm just a random Indian musician,

01:18:27.300 --> 01:18:31.900
but I just got like dragged into like geopolitical matters

01:18:31.900 --> 01:18:35.100
and like financial, like the stock market and shit.

01:18:35.100 --> 01:18:36.340
And so it's just like, it's just,

01:18:36.380 --> 01:18:37.780
there are very powerful people

01:18:37.780 --> 01:18:39.740
who have at various points in time

01:18:39.740 --> 01:18:43.780
had very vested interest in making me seem insane

01:18:43.780 --> 01:18:45.700
and I can't fucking fight that.

01:18:45.700 --> 01:18:48.900
And I just like, you know,

01:18:48.900 --> 01:18:50.820
people really want their celebrity figures

01:18:50.820 --> 01:18:53.900
to like be consistent and stay the same.

01:18:53.900 --> 01:18:55.860
And like people have a lot of like emotional investment

01:18:55.860 --> 01:18:57.300
in certain things and like,

01:18:59.260 --> 01:19:02.500
first of all, like I'm like artificially more famous

01:19:02.500 --> 01:19:03.700
than I should be.

01:19:03.700 --> 01:19:06.620
Isn't everybody who's famous artificially famous?

01:19:06.620 --> 01:19:11.340
No, but like I should be like a weird niche indie thing.

01:19:11.340 --> 01:19:13.380
And I make pretty challenging.

01:19:13.380 --> 01:19:16.260
I do challenging weird fucking shit a lot.

01:19:16.260 --> 01:19:20.460
And I accidentally by proxy got like,

01:19:21.780 --> 01:19:24.380
foisted into sort of like weird celebrity culture,

01:19:24.380 --> 01:19:27.260
but like I cannot be media trained.

01:19:27.260 --> 01:19:29.780
They have put me through so many hours of media training.

01:19:29.780 --> 01:19:32.500
I would love to see BFY in that wall.

01:19:32.500 --> 01:19:35.260
I can't do, like when I do, I try so hard

01:19:35.260 --> 01:19:37.420
and I like learn this thing and I like got it.

01:19:37.420 --> 01:19:38.740
And I'm like, I got it, I got it, I got it.

01:19:38.740 --> 01:19:40.540
But I just can't stop saying,

01:19:40.540 --> 01:19:42.220
like my mouth just says things.

01:19:42.220 --> 01:19:45.340
I like, and it's just like, and I just do things.

01:19:45.340 --> 01:19:46.180
I just do crazy things.

01:19:46.180 --> 01:19:50.740
I mean, it's like, I just, I need to do crazy things.

01:19:50.740 --> 01:19:53.100
And it's just, I should not be,

01:19:53.100 --> 01:19:58.100
it's too jarring for people and the contradictory stuff

01:19:58.500 --> 01:20:03.500
and then all the, by association, like, you know,

01:20:05.180 --> 01:20:08.980
it's like, I'm in a very weird position and my public image,

01:20:09.860 --> 01:20:14.860
the avatar of me is now this totally crazy thing

01:20:14.860 --> 01:20:16.540
that is so lost from my control.

01:20:16.540 --> 01:20:19.140
So you feel the burden of the avatar having to be static.

01:20:19.140 --> 01:20:22.300
So the avatar on Twitter, the avatar on Instagram,

01:20:22.300 --> 01:20:26.740
on these social platforms is as a burden.

01:20:26.740 --> 01:20:29.860
It becomes like, because like people don't want

01:20:29.860 --> 01:20:32.620
to accept a changing avatar, a chaotic avatar.

01:20:32.620 --> 01:20:34.860
Avatar is a stupid shit sometimes.

01:20:34.860 --> 01:20:36.500
They think the avatar is morally wrong

01:20:36.500 --> 01:20:39.580
or they think the avatar, and maybe it has been,

01:20:39.580 --> 01:20:41.140
and like, I question it all the time.

01:20:41.140 --> 01:20:46.140
Like, I'm like, I don't know if everyone's right

01:20:46.340 --> 01:20:49.700
and I'm wrong, I don't, like, but you know,

01:20:49.700 --> 01:20:51.780
a lot of times people ascribe intentions to things,

01:20:51.780 --> 01:20:53.700
the worst possible intentions.

01:20:53.700 --> 01:20:55.860
At this point, people think I'm, you know,

01:20:57.300 --> 01:20:59.140
but all kinds of words, yes.

01:20:59.140 --> 01:21:01.380
Yes, and it's fine, I'm not complaining about it,

01:21:01.380 --> 01:21:05.500
but I'm just, it's a curiosity to me

01:21:05.500 --> 01:21:08.740
that we live these double, triple, quadruple lives

01:21:08.740 --> 01:21:11.140
and I have this other life that is like,

01:21:12.460 --> 01:21:15.100
more people know my other life than my real life,

01:21:15.100 --> 01:21:16.340
which is interesting.

01:21:16.340 --> 01:21:18.220
Probably, I mean, you too, I guess.

01:21:18.220 --> 01:21:21.540
Yeah, but I have the luxury, so we have all different,

01:21:23.100 --> 01:21:25.140
like, I don't know what I'm doing.

01:21:25.140 --> 01:21:27.820
There is an avatar and you're mediating

01:21:27.820 --> 01:21:29.940
who you are through that avatar.

01:21:29.940 --> 01:21:34.940
I have the nice luxury, not the luxury, maybe by intention,

01:21:36.020 --> 01:21:38.420
of not trying really hard to make sure

01:21:38.420 --> 01:21:41.460
there's no difference between the avatar

01:21:41.460 --> 01:21:42.820
and the private person.

01:21:44.020 --> 01:21:45.620
Do you wear a suit all the time?

01:21:45.620 --> 01:21:46.780
Yeah, but-

01:21:46.780 --> 01:21:47.620
You do wear a suit?

01:21:47.620 --> 01:21:48.940
Not all the time.

01:21:48.940 --> 01:21:51.540
Recently, because I get recognized a lot,

01:21:51.540 --> 01:21:53.420
I have to not wear the suit to hide.

01:21:53.420 --> 01:21:55.820
I'm such an introvert, I'm such a social anxiety

01:21:55.820 --> 01:21:57.660
and all that kind of stuff, so I have to hide away.

01:21:57.660 --> 01:22:00.580
I love wearing a suit because it makes me feel

01:22:00.580 --> 01:22:02.380
like I'm taking the moment seriously.

01:22:02.380 --> 01:22:04.340
Like, I don't know.

01:22:04.340 --> 01:22:07.020
It makes me feel like a weirdo in the best possible way.

01:22:07.020 --> 01:22:07.860
Suits feel great.

01:22:07.860 --> 01:22:08.700
Every time I wear a suit, I'm like,

01:22:08.700 --> 01:22:10.500
I don't know why I'm not doing this more.

01:22:10.500 --> 01:22:15.340
In fashion in general, if you're doing it for yourself,

01:22:15.340 --> 01:22:18.700
I don't know, it's a really awesome thing.

01:22:18.700 --> 01:22:22.300
But yeah, I think there is definitely

01:22:22.300 --> 01:22:27.300
a painful way to use social media and an empowering way.

01:22:27.420 --> 01:22:32.420
And I don't know if any of us know which is which.

01:22:32.660 --> 01:22:33.980
So we're trying to figure that out.

01:22:33.980 --> 01:22:36.820
Some people, I think Doja Cat is incredible at it.

01:22:36.820 --> 01:22:39.580
Incredible, like just masterful.

01:22:39.580 --> 01:22:41.900
I don't know if you follow that.

01:22:41.900 --> 01:22:44.820
So okay, so not taking anything seriously,

01:22:44.820 --> 01:22:47.420
joking, absurd, humor, that kind of thing.

01:22:47.420 --> 01:22:49.900
I think Doja Cat might be the greatest

01:22:49.900 --> 01:22:52.140
living comedian right now.

01:22:52.980 --> 01:22:54.660
Like I'm more entertained by Doja Cat

01:22:54.660 --> 01:22:56.260
than actual comedians.

01:22:56.260 --> 01:22:58.940
Like she's really fucking funny on the internet.

01:22:58.940 --> 01:23:02.180
She's just great at social media, it's just, you know.

01:23:02.180 --> 01:23:03.020
Her media.

01:23:03.020 --> 01:23:03.860
Yeah, the nature of humor,

01:23:03.860 --> 01:23:07.980
like humor on social media is also a beautiful thing.

01:23:07.980 --> 01:23:08.900
The absurdity.

01:23:08.900 --> 01:23:09.740
The absurdity.

01:23:09.740 --> 01:23:12.700
And memes, like I just wanna take a moment.

01:23:12.700 --> 01:23:14.580
I love, like when we're talking about art

01:23:14.580 --> 01:23:18.220
and credit and authenticity, I love that there's this,

01:23:18.220 --> 01:23:21.820
I mean now memes are like, they're no longer,

01:23:22.220 --> 01:23:23.660
memes aren't like new,

01:23:23.660 --> 01:23:25.620
but it's still this emergent art form

01:23:25.620 --> 01:23:27.740
that is completely egoless and anonymous

01:23:27.740 --> 01:23:29.500
and we just don't know who made any of it.

01:23:29.500 --> 01:23:32.620
And it's like the forefront of comedy

01:23:32.620 --> 01:23:35.460
and it's just totally anonymous

01:23:35.460 --> 01:23:36.660
and it just feels really beautiful.

01:23:36.660 --> 01:23:39.060
It just feels like this beautiful collect,

01:23:39.060 --> 01:23:43.300
like collective human art project

01:23:43.300 --> 01:23:46.460
that's like this like decentralized comedy thing

01:23:46.460 --> 01:23:47.300
that just makes it,

01:23:47.300 --> 01:23:49.900
memes add so much to my day and many people's days

01:23:49.900 --> 01:23:52.180
and it's just like, I don't know.

01:23:52.180 --> 01:23:54.900
I don't think people ever,

01:23:54.900 --> 01:23:56.940
I don't think we stop enough and just appreciate

01:23:56.940 --> 01:23:59.580
how sick it is that memes exist.

01:23:59.580 --> 01:24:02.460
And also making a whole brand new art form

01:24:02.460 --> 01:24:07.100
in like the modern era that's like didn't exist before.

01:24:07.100 --> 01:24:08.540
Like, I mean, they sort of existed,

01:24:08.540 --> 01:24:11.900
but the way that they exist now as like this like,

01:24:11.900 --> 01:24:13.300
you know, like me and my friends,

01:24:13.300 --> 01:24:16.380
like we joke that we go like mining for memes

01:24:16.380 --> 01:24:18.660
or farming for memes, like a video game

01:24:18.660 --> 01:24:21.140
and like meme dealers and like whatever.

01:24:21.140 --> 01:24:22.780
Like, you know, it's this whole,

01:24:22.780 --> 01:24:27.780
memes are this whole like new comedic language.

01:24:27.940 --> 01:24:29.300
What's this art form,

01:24:29.300 --> 01:24:33.580
the interesting thing about is that lame people

01:24:33.580 --> 01:24:35.420
seem to not be good at memes.

01:24:35.420 --> 01:24:38.220
Like corporate can't infiltrate memes.

01:24:38.220 --> 01:24:39.900
Yeah, they really can't.

01:24:39.900 --> 01:24:41.500
They try, they could try,

01:24:41.500 --> 01:24:43.380
but it's like, it's weird cause like.

01:24:43.380 --> 01:24:45.580
They try so hard and every once in a while,

01:24:45.580 --> 01:24:48.700
I'm like fine, like you got a good one.

01:24:48.700 --> 01:24:51.420
I think I've seen like one or two good ones,

01:24:51.420 --> 01:24:53.340
but like, yeah, they really can't

01:24:53.340 --> 01:24:55.500
cause they're even corporate is infiltrating web three.

01:24:55.500 --> 01:24:57.140
It's making me really sad,

01:24:57.140 --> 01:24:58.660
but they can't infiltrate the memes.

01:24:58.660 --> 01:25:00.100
And I think there's something really beautiful about that.

01:25:00.100 --> 01:25:00.940
That gives power.

01:25:00.940 --> 01:25:03.580
That's why Dogecoin is powerful.

01:25:03.580 --> 01:25:05.340
It's like, all right,

01:25:05.340 --> 01:25:08.820
F you to sort of anybody who's trying to centralize

01:25:08.820 --> 01:25:10.420
is trying to control the rich people

01:25:10.420 --> 01:25:12.740
that are trying to roll in and control this,

01:25:12.740 --> 01:25:14.220
control the narrative.

01:25:14.220 --> 01:25:15.060
Wow.

01:25:15.060 --> 01:25:17.220
I hadn't thought about that, but.

01:25:17.220 --> 01:25:18.500
How would you fix Twitter?

01:25:18.500 --> 01:25:19.980
How would you fix social media?

01:25:19.980 --> 01:25:23.820
For your own, like you're an optimist,

01:25:23.820 --> 01:25:25.220
you're a positive person.

01:25:25.220 --> 01:25:27.500
There's a bit of a cynicism that you have currently

01:25:27.500 --> 01:25:30.700
about this particular little slice of humanity.

01:25:30.700 --> 01:25:32.700
I tend to think Twitter could be beautiful.

01:25:32.700 --> 01:25:34.100
I'm not that cynical about it.

01:25:34.100 --> 01:25:35.140
I'm not that cynical about it.

01:25:35.140 --> 01:25:37.700
I actually refuse to be a cynic on principle.

01:25:37.700 --> 01:25:38.540
Yes.

01:25:38.540 --> 01:25:40.900
I was just briefly expressing some personal pathos.

01:25:40.900 --> 01:25:42.140
Personal stuff.

01:25:42.140 --> 01:25:43.700
It was just some personal pathos,

01:25:43.700 --> 01:25:45.900
but like, like.

01:25:45.900 --> 01:25:48.060
Just to vent a little bit, just to speak.

01:25:48.060 --> 01:25:48.940
I don't have cancer.

01:25:48.940 --> 01:25:50.860
I love my family.

01:25:50.860 --> 01:25:51.700
I have a good life.

01:25:51.700 --> 01:25:55.380
That is, if that is my biggest,

01:25:55.380 --> 01:25:56.220
one of my biggest problems.

01:25:56.220 --> 01:25:57.180
Then it's a good life.

01:25:57.180 --> 01:25:58.020
Yeah.

01:25:58.020 --> 01:25:59.860
You know, that was a brief,

01:25:59.860 --> 01:26:01.380
although I do think there are a lot of issues with Twitter

01:26:01.380 --> 01:26:03.180
just in terms of like the public mental health,

01:26:03.180 --> 01:26:08.180
but due to my proximity to the current dramas,

01:26:08.900 --> 01:26:13.820
I honestly feel that I should not have opinions about this

01:26:13.820 --> 01:26:18.820
because I think if Elon ends up getting Twitter,

01:26:28.380 --> 01:26:33.140
that is a, being the arbiter of truth or public discussion,

01:26:33.140 --> 01:26:34.660
that is a responsibility.

01:26:34.660 --> 01:26:39.660
I do not, I am not qualified to be responsible for that

01:26:41.260 --> 01:26:45.260
and I do not want to say something

01:26:45.260 --> 01:26:48.340
that might like dismantle democracy.

01:26:48.340 --> 01:26:49.780
And so I just like, actually,

01:26:49.780 --> 01:26:52.140
I actually think I should not have opinions about this

01:26:52.140 --> 01:26:55.100
because I truly am not,

01:26:55.100 --> 01:26:56.740
I don't want to have the wrong opinion about this.

01:26:56.740 --> 01:27:00.180
And I think I'm too close to the actual situation

01:27:00.180 --> 01:27:02.860
wherein I should not have,

01:27:02.860 --> 01:27:04.300
I have thoughts in my brain,

01:27:04.940 --> 01:27:09.940
but I think I am scared by my proximity to this situation.

01:27:10.140 --> 01:27:14.700
Isn't that crazy that a few words that you could say

01:27:14.700 --> 01:27:18.820
could change world affairs and hurt people?

01:27:18.820 --> 01:27:21.780
I mean, that's the nature of celebrity at a certain point,

01:27:23.020 --> 01:27:27.180
that you have to be, you have to a little bit, a little bit,

01:27:27.180 --> 01:27:29.580
not so much that it destroys you,

01:27:29.580 --> 01:27:30.580
puts too much constraints,

01:27:30.580 --> 01:27:32.660
but you have to a little bit think about

01:27:32.660 --> 01:27:33.980
the impact of your words.

01:27:34.220 --> 01:27:36.740
We as humans, you talk to somebody at a bar,

01:27:36.740 --> 01:27:39.180
you have to think about the impact of your words.

01:27:39.180 --> 01:27:40.380
Like you can say positive things,

01:27:40.380 --> 01:27:41.540
you can think negative things,

01:27:41.540 --> 01:27:43.420
you can affect the direction of one life.

01:27:43.420 --> 01:27:44.380
But on social media,

01:27:44.380 --> 01:27:48.100
your words can affect the direction of many lives.

01:27:48.100 --> 01:27:50.460
It's crazy, it's a crazy world to live in.

01:27:50.460 --> 01:27:53.060
It's worthwhile to consider that responsibility,

01:27:53.060 --> 01:27:54.140
take it seriously.

01:27:54.140 --> 01:27:55.860
Sometimes just like you did,

01:27:57.220 --> 01:28:00.820
choose kind of silence,

01:28:00.820 --> 01:28:03.660
choose sort of respectful.

01:28:04.340 --> 01:28:05.300
Like I do have a lot of thoughts on the matter.

01:28:05.300 --> 01:28:10.140
I'm just, I don't, if my thoughts are wrong,

01:28:10.140 --> 01:28:12.900
this is one situation where the stakes are high.

01:28:12.900 --> 01:28:15.780
You mentioned a while back that you were in a cult

01:28:15.780 --> 01:28:17.300
that centered around bureaucracy,

01:28:17.300 --> 01:28:18.500
so you can't really do anything

01:28:18.500 --> 01:28:20.500
because it involves a lot of paperwork.

01:28:20.500 --> 01:28:24.740
And I really love a cult that's just like Kafka-esque.

01:28:24.740 --> 01:28:25.780
Yes.

01:28:25.780 --> 01:28:26.620
Just like.

01:28:26.620 --> 01:28:27.700
I mean, it was like a joke.

01:28:27.700 --> 01:28:29.300
I know, but I love this idea.

01:28:29.300 --> 01:28:30.460
The Holy Rain Empire.

01:28:30.460 --> 01:28:32.900
Yeah, it was just like a Kafka-esque.

01:28:33.740 --> 01:28:34.940
Pro-bureaucracy cult.

01:28:34.940 --> 01:28:36.860
But I feel like that's what human civilization is,

01:28:36.860 --> 01:28:38.140
is that, because when you said that,

01:28:38.140 --> 01:28:40.660
I was like, oh, that is kind of what humanity is,

01:28:40.660 --> 01:28:41.700
is this bureaucracy cult.

01:28:41.700 --> 01:28:45.580
I do, yeah, I have this theory.

01:28:45.580 --> 01:28:49.660
I really think that we really,

01:28:50.660 --> 01:28:53.540
bureaucracy is starting to kill us.

01:28:53.540 --> 01:28:58.540
And I think like we need to reorient laws and stuff.

01:28:59.500 --> 01:29:01.900
Like I think we just need sunset clauses on everything.

01:29:01.900 --> 01:29:04.540
Like I think the rate of change in culture

01:29:04.540 --> 01:29:05.540
is happening so fast,

01:29:05.540 --> 01:29:06.620
and the rate of change in technology

01:29:06.620 --> 01:29:07.900
and everything is happening so fast.

01:29:07.900 --> 01:29:10.740
It's like, when you see these hearings

01:29:10.740 --> 01:29:15.740
about like social media and Cambridge Analytica

01:29:15.780 --> 01:29:19.140
and everyone talking, it's like, even from that point,

01:29:19.140 --> 01:29:21.340
so much technological change has happened

01:29:21.340 --> 01:29:22.700
from like those hearings.

01:29:22.700 --> 01:29:24.860
And it's just like, we're trying to make all these laws now

01:29:24.860 --> 01:29:25.900
about AI and stuff.

01:29:25.900 --> 01:29:27.340
I feel like we should be updating things

01:29:27.340 --> 01:29:28.380
like every five years.

01:29:28.380 --> 01:29:30.100
And like one of the big issues in our society right now

01:29:30.100 --> 01:29:32.260
is we're just getting bogged down by laws

01:29:32.260 --> 01:29:37.020
and it's making it very hard to change things

01:29:37.020 --> 01:29:37.860
and develop things.

01:29:37.860 --> 01:29:41.500
Like in Austin, like I don't wanna speak on this too much,

01:29:41.500 --> 01:29:43.220
but like one of my friends is working on a housing bill

01:29:43.220 --> 01:29:45.020
in Austin to try to like prevent

01:29:45.020 --> 01:29:47.180
like a San Francisco situation from happening here,

01:29:47.180 --> 01:29:49.940
because obviously we're getting a little mini San Francisco

01:29:49.940 --> 01:29:52.140
here, like housing prices are skyrocketing,

01:29:52.140 --> 01:29:54.740
it's causing massive gentrification.

01:29:54.740 --> 01:29:56.140
This is gonna be, this is really bad

01:29:56.140 --> 01:29:59.180
for anyone who's not super rich.

01:29:59.860 --> 01:30:00.820
Like there's so much bureaucracy.

01:30:00.820 --> 01:30:02.220
Part of the reason this is happening is because

01:30:02.220 --> 01:30:03.980
you need all these permits to build.

01:30:03.980 --> 01:30:06.420
It takes like years to get permits to like build anything.

01:30:06.420 --> 01:30:07.420
It's so hard to build.

01:30:07.420 --> 01:30:09.100
And so there's very limited housing

01:30:09.100 --> 01:30:10.860
and there's a massive influx of people.

01:30:10.860 --> 01:30:13.460
And it's just like, you know, this is a microcosm

01:30:13.460 --> 01:30:15.500
of like problems that are happening all over the world,

01:30:15.500 --> 01:30:18.780
where it's just like, we're dealing with laws

01:30:18.780 --> 01:30:22.340
that are like 10, 20, 30, 40, 100, 200 years old

01:30:22.340 --> 01:30:24.100
and they are no longer relevant

01:30:24.100 --> 01:30:25.660
and it's just slowing everything down

01:30:25.660 --> 01:30:27.980
and causing massive social pain.

01:30:28.980 --> 01:30:32.700
Yeah, but it's like, it's also makes me sad

01:30:32.700 --> 01:30:35.700
when I see politicians talk about technology

01:30:35.700 --> 01:30:38.300
and when they don't really get it.

01:30:38.300 --> 01:30:41.020
But most importantly, they lack curiosity

01:30:41.020 --> 01:30:44.700
and like that like inspired excitement

01:30:44.700 --> 01:30:46.460
about like how stuff works and all that stuff.

01:30:46.460 --> 01:30:47.660
They're just like, they see,

01:30:47.660 --> 01:30:50.020
they have the very cynical view of technology.

01:30:50.020 --> 01:30:52.060
It's like tech companies are just trying to do evil

01:30:52.060 --> 01:30:53.420
on the world from their perspective.

01:30:53.420 --> 01:30:55.740
And they have no curiosity about like

01:30:55.740 --> 01:30:57.260
how recommender systems work

01:30:57.340 --> 01:31:01.060
or how AI systems work, natural language processing,

01:31:01.060 --> 01:31:04.580
how robotics works, how computer vision works.

01:31:04.580 --> 01:31:07.380
You know, they always take the most cynical

01:31:07.380 --> 01:31:09.860
possible interpretation of what technology will be used.

01:31:09.860 --> 01:31:11.660
And we should definitely be concerned about that.

01:31:11.660 --> 01:31:13.780
But if you're constantly worried about that

01:31:13.780 --> 01:31:15.020
and you're regulating based on that,

01:31:15.020 --> 01:31:16.980
you're just going to slow down all the innovation.

01:31:16.980 --> 01:31:19.420
I do think a huge priority right now

01:31:19.420 --> 01:31:24.420
is undoing the bad energy

01:31:25.180 --> 01:31:28.060
surrounding the emergence of Silicon Valley.

01:31:28.060 --> 01:31:30.020
Like I think that like a lot of things

01:31:30.020 --> 01:31:31.820
were very irresponsible during that time.

01:31:31.820 --> 01:31:36.140
And, you know, like even just this current whole thing

01:31:36.140 --> 01:31:36.980
with Twitter and everything.

01:31:36.980 --> 01:31:39.940
It's like there has been a lot of negative outcomes

01:31:39.940 --> 01:31:44.260
from the sort of technocracy boom.

01:31:44.260 --> 01:31:46.060
But one of the things that's happening

01:31:46.060 --> 01:31:49.100
is that like it's alienating people

01:31:49.100 --> 01:31:52.340
from wanting to care about technology.

01:31:52.340 --> 01:31:53.620
And I actually think technology

01:31:53.620 --> 01:31:58.620
is probably some of the better, probably the best.

01:32:00.140 --> 01:32:01.660
I think we can fix a lot of our problems

01:32:01.660 --> 01:32:05.940
more easily with technology than with, you know,

01:32:05.940 --> 01:32:07.980
fighting the powers that be as a, you know,

01:32:07.980 --> 01:32:09.740
not to go back to the Star Wars quote

01:32:09.740 --> 01:32:11.340
or the Buckminster Fuller quote.

01:32:11.340 --> 01:32:12.980
Let's go to some dark questions.

01:32:14.740 --> 01:32:16.580
If we may for time,

01:32:16.580 --> 01:32:20.260
what is the darkest place you ever gone in your mind?

01:32:20.260 --> 01:32:22.260
Is there a time, a period of time

01:32:23.180 --> 01:32:26.580
or a moment that you remember that was difficult for you?

01:32:29.620 --> 01:32:30.500
I mean, when I was 18,

01:32:30.500 --> 01:32:32.540
my best friend died of a heroin overdose.

01:32:33.500 --> 01:32:38.340
And it was like my, it was,

01:32:38.340 --> 01:32:39.820
and then shortly after that,

01:32:39.820 --> 01:32:42.220
one of my other best friends committed suicide.

01:32:44.740 --> 01:32:48.660
And that sort of like coming into adulthood

01:32:48.660 --> 01:32:51.180
dealing with two of the most important people in my life

01:32:51.180 --> 01:32:55.940
dying in extremely disturbing, violent ways was a lot.

01:32:55.940 --> 01:32:56.780
That was a lot.

01:32:56.780 --> 01:32:58.420
Do you miss them?

01:32:58.420 --> 01:32:59.940
Yeah, definitely miss them.

01:32:59.940 --> 01:33:02.780
Did that make you think about your own life,

01:33:02.780 --> 01:33:04.980
about the finiteness of your own life,

01:33:04.980 --> 01:33:08.180
the places your mind can go?

01:33:08.180 --> 01:33:10.980
Did you ever in the distance, far away,

01:33:10.980 --> 01:33:15.460
contemplate just your own death

01:33:15.460 --> 01:33:17.300
or maybe even taking your own life?

01:33:17.300 --> 01:33:18.740
Oh, never, oh no.

01:33:18.740 --> 01:33:20.500
I'm so, I love my life.

01:33:21.100 --> 01:33:23.100
I cannot fathom suicide.

01:33:23.100 --> 01:33:24.140
I'm so scared of death.

01:33:24.140 --> 01:33:26.020
I haven't, I'm too scared of death.

01:33:26.020 --> 01:33:28.780
My manager, my manager's like the most zen guy.

01:33:28.780 --> 01:33:31.060
My manager's always like, you need to accept death.

01:33:31.060 --> 01:33:32.100
You need to accept death.

01:33:32.100 --> 01:33:34.220
And I'm like, look, I can do your meditation.

01:33:34.220 --> 01:33:37.300
I can do the meditation, but I cannot accept death.

01:33:37.300 --> 01:33:40.380
I like, I will fight, I'm terrified of death.

01:33:40.380 --> 01:33:42.780
I will like fight.

01:33:42.780 --> 01:33:45.060
Although I actually think death is important.

01:33:45.060 --> 01:33:49.180
I recently went to this meeting about immortality.

01:33:50.060 --> 01:33:51.540
And in the process of-

01:33:51.540 --> 01:33:53.060
That's the actual topic of the meeting.

01:33:53.060 --> 01:33:53.900
All right, I'm sorry.

01:33:53.900 --> 01:33:54.740
No, no, it was this girl.

01:33:54.740 --> 01:33:58.900
It was a bunch of people working on anti-aging stuff.

01:33:58.900 --> 01:34:01.940
It was some seminary thing about it.

01:34:01.940 --> 01:34:03.260
And I went in really excited.

01:34:03.260 --> 01:34:05.300
I was like, yeah, okay, what do you got?

01:34:05.300 --> 01:34:07.820
How can I live for 500 years or 1,000 years?

01:34:07.820 --> 01:34:10.860
And then over the course of the meeting,

01:34:10.860 --> 01:34:13.140
it was sort of right, it was two or three days

01:34:13.140 --> 01:34:14.580
after the Russian invasion started.

01:34:14.580 --> 01:34:16.980
And I was like, man, what if Putin was immortal?

01:34:17.300 --> 01:34:20.900
Like, what if, I'm like, man, maybe immortality

01:34:22.340 --> 01:34:23.620
is not good.

01:34:23.620 --> 01:34:25.740
I mean, like if you get into the later dune stuff,

01:34:25.740 --> 01:34:29.020
the immortals cause a lot of problem.

01:34:29.020 --> 01:34:30.980
Cause as we were talking about earlier with the music

01:34:30.980 --> 01:34:34.740
and like brains calcified, like good people

01:34:34.740 --> 01:34:36.900
could become immortal, but bad people could become immortal.

01:34:36.900 --> 01:34:41.900
But I also think even the best people power corrupts

01:34:43.340 --> 01:34:46.740
and power alienates you from like the common human experience

01:34:47.420 --> 01:34:52.220
and even the best people whose brains are amazing.

01:34:52.220 --> 01:34:54.780
Like I think death might be important.

01:34:54.780 --> 01:34:57.380
I think death is part of, you know,

01:34:57.380 --> 01:35:01.020
like I think with AI, one thing we might want to consider,

01:35:01.020 --> 01:35:03.420
I don't know, when I talk about AI, I'm such not an expert

01:35:03.420 --> 01:35:05.220
and probably everyone has all these ideas

01:35:05.220 --> 01:35:06.220
and they're already figured out.

01:35:06.220 --> 01:35:07.060
But when I talk-

01:35:07.060 --> 01:35:09.900
Nobody is an expert in anything, see, okay, go ahead.

01:35:09.900 --> 01:35:13.180
But when I, yeah, but like, it's just like,

01:35:13.180 --> 01:35:16.020
I think some kind of pruning,

01:35:17.220 --> 01:35:20.140
but it's a tricky thing because if there's too much

01:35:20.140 --> 01:35:25.140
of a focus on youth culture, then you don't have the wisdom.

01:35:25.460 --> 01:35:29.660
So I feel like we're in a tricky moment right now

01:35:29.660 --> 01:35:31.300
in society where it's like,

01:35:31.300 --> 01:35:33.100
we've really perfected living for a long time.

01:35:33.100 --> 01:35:35.780
So there's all these really like old people

01:35:35.780 --> 01:35:39.540
who are like really voting against the wellbeing

01:35:39.540 --> 01:35:41.580
of the young people, you know?

01:35:41.580 --> 01:35:45.220
And it's like, there shouldn't be all this student dead

01:35:45.220 --> 01:35:48.620
and we need like health care, like universal health care

01:35:48.620 --> 01:35:52.540
and like just voting against like best interests.

01:35:52.540 --> 01:35:53.740
But then you have all these young people

01:35:53.740 --> 01:35:56.060
that don't have the wisdom that are like,

01:35:56.060 --> 01:35:57.700
yeah, we need communism and stuff.

01:35:57.700 --> 01:36:00.820
And it's just like, like literally I got canceled

01:36:00.820 --> 01:36:05.060
at one point for, I ironically used a Stalin quote

01:36:05.060 --> 01:36:06.780
in my high school yearbook, but it was actually

01:36:06.780 --> 01:36:09.700
like a diss against my high school.

01:36:10.220 --> 01:36:13.180
Yeah, and people were like, you used to be a Stalinist

01:36:13.180 --> 01:36:14.220
and now you're a class traitor.

01:36:14.220 --> 01:36:17.460
And it's like, it's like, oh man, just like,

01:36:17.460 --> 01:36:20.540
please Google Stalin, please Google Stalin.

01:36:20.540 --> 01:36:21.380
Like, you know-

01:36:21.380 --> 01:36:23.420
Ignoring the lessons of history, yes.

01:36:23.420 --> 01:36:26.100
And it's like, we're in this really weird middle ground

01:36:26.100 --> 01:36:31.220
where it's like, we are not finding the happy medium

01:36:31.220 --> 01:36:34.700
between wisdom and fresh ideas

01:36:34.700 --> 01:36:35.900
and they're fighting each other.

01:36:35.980 --> 01:36:40.980
And it's like, really like what we need is like,

01:36:41.020 --> 01:36:43.900
like the fresh ideas and the wisdom to be like collaborating

01:36:43.900 --> 01:36:45.180
and it's like-

01:36:45.180 --> 01:36:47.340
What the fighting in a way is the searching

01:36:47.340 --> 01:36:48.500
for the happy medium.

01:36:48.500 --> 01:36:51.060
And in a way, maybe we are finding the happy medium.

01:36:51.060 --> 01:36:52.980
Maybe that's what the happy medium looks like.

01:36:52.980 --> 01:36:55.020
And for AI systems, there has to be,

01:36:55.020 --> 01:36:57.180
it's, you know, you have reinforcement learning,

01:36:57.180 --> 01:37:00.380
you have the dance between exploration, exploitation,

01:37:00.380 --> 01:37:03.420
sort of doing crazy stuff to see if there's something better

01:37:03.420 --> 01:37:05.460
than what you think is the optimal

01:37:05.900 --> 01:37:06.740
and then doing the optimal thing

01:37:06.740 --> 01:37:08.660
and dancing back and forth from that.

01:37:08.660 --> 01:37:10.700
You would, Stuart Russell, I don't know if you know that,

01:37:10.700 --> 01:37:15.700
is AI guy with things about sort of how to control

01:37:16.780 --> 01:37:19.500
super intelligent AI systems and his ideas

01:37:19.500 --> 01:37:21.540
that we should inject uncertainty

01:37:21.540 --> 01:37:24.180
and sort of humility into AI systems

01:37:24.180 --> 01:37:26.780
that they never, as they get wiser and wiser and wiser

01:37:26.780 --> 01:37:30.060
and more intelligent, they're never really sure.

01:37:30.060 --> 01:37:31.660
They always doubt themselves.

01:37:31.660 --> 01:37:34.380
And in some sense, when you think of young people,

01:37:34.380 --> 01:37:36.300
that's a mechanism for doubt.

01:37:36.300 --> 01:37:38.860
It's like, it's how society doubts

01:37:38.860 --> 01:37:40.860
whether the thing it has converged towards

01:37:40.860 --> 01:37:41.940
is the right answer.

01:37:41.940 --> 01:37:44.860
So the voices of the young people

01:37:44.860 --> 01:37:48.140
is a society asking itself a question.

01:37:48.140 --> 01:37:51.100
The way I've been doing stuff for the past 50 years,

01:37:51.100 --> 01:37:52.460
maybe it's the wrong way.

01:37:52.460 --> 01:37:55.340
And so you can have all of that within one AI system.

01:37:55.340 --> 01:37:57.460
I also think, though, that we need to,

01:37:57.460 --> 01:37:59.900
I mean, actually, that's actually really interesting

01:37:59.900 --> 01:38:00.740
and really cool.

01:38:01.580 --> 01:38:04.580
But I also think there's a fine balance of,

01:38:05.460 --> 01:38:10.220
I think we maybe also overvalue the idea

01:38:10.220 --> 01:38:12.020
that the old systems are always bad.

01:38:12.020 --> 01:38:14.860
And I think there are things that we are perfecting

01:38:14.860 --> 01:38:17.500
and we might be accidentally overthrowing things

01:38:17.500 --> 01:38:19.820
that we actually have gotten to a good point.

01:38:19.820 --> 01:38:22.860
Just because we are valuing, we value disruption so much

01:38:22.860 --> 01:38:25.500
and we value fighting against the generations

01:38:25.500 --> 01:38:30.060
before us so much that like, there's also an aspect

01:38:30.660 --> 01:38:32.780
sometimes we're taking two steps forward, one step back

01:38:32.780 --> 01:38:37.020
because, okay, maybe we kind of did solve this thing

01:38:37.020 --> 01:38:38.620
and now we're like fucking it up.

01:38:39.940 --> 01:38:44.940
And so I think there's a middle ground there too.

01:38:45.140 --> 01:38:47.300
We're in search of that happy medium.

01:38:47.300 --> 01:38:50.500
Let me ask you a bunch of crazy questions, okay?

01:38:51.500 --> 01:38:53.980
You can answer in a short way or in a long way.

01:38:53.980 --> 01:38:56.340
What's the scariest thing you've ever done?

01:38:56.340 --> 01:38:58.380
These questions are gonna be ridiculous.

01:38:59.140 --> 01:39:01.460
Something tiny or something big.

01:39:02.420 --> 01:39:07.420
Skydiving or touring your first record

01:39:09.900 --> 01:39:12.140
going on this podcast.

01:39:12.140 --> 01:39:14.780
I've had two crazy brushes, like really scary brushes

01:39:14.780 --> 01:39:17.020
with death where I randomly got away on Skay.

01:39:17.020 --> 01:39:19.220
I don't know if I should talk about those on here.

01:39:19.220 --> 01:39:20.060
Well, I don't know.

01:39:20.060 --> 01:39:22.900
I think I might be the luckiest person alive though.

01:39:24.220 --> 01:39:26.020
This might be too dark for a podcast though.

01:39:26.020 --> 01:39:27.060
I feel like I don't know if this is like

01:39:27.060 --> 01:39:28.700
good content for a podcast.

01:39:28.700 --> 01:39:30.220
I don't know what is good content.

01:39:30.220 --> 01:39:31.580
It might hijack.

01:39:31.580 --> 01:39:32.420
Here's a safer one.

01:39:32.420 --> 01:39:36.740
I mean, having a baby really scared me.

01:39:36.740 --> 01:39:38.900
Before, during, after.

01:39:38.900 --> 01:39:43.900
Surgery, like just having a baby is really scary.

01:39:45.940 --> 01:39:47.540
So just like the medical aspect of it,

01:39:47.540 --> 01:39:49.300
not the responsibility.

01:39:49.300 --> 01:39:51.300
Were you ready for the responsibility?

01:39:52.300 --> 01:39:53.980
Were you ready to be a mother?

01:39:54.460 --> 01:39:56.300
All the beautiful things that comes with motherhood

01:39:56.300 --> 01:39:57.620
that you were talking about.

01:39:57.620 --> 01:39:59.060
All the changes and all that.

01:39:59.060 --> 01:40:00.260
Were you ready for that?

01:40:01.820 --> 01:40:03.020
Did you feel ready for that?

01:40:03.020 --> 01:40:05.380
No, I think it took about nine months

01:40:05.380 --> 01:40:06.660
to start getting ready for it.

01:40:06.660 --> 01:40:08.420
And I'm still getting more ready for it

01:40:08.420 --> 01:40:13.020
because now you keep realizing more things

01:40:13.020 --> 01:40:14.260
as they start getting.

01:40:14.260 --> 01:40:16.460
As the consciousness grows.

01:40:16.460 --> 01:40:18.420
And stuff you didn't notice was the first one.

01:40:18.420 --> 01:40:19.740
Now that you've seen the first one older,

01:40:19.740 --> 01:40:21.740
you're noticing it more.

01:40:21.740 --> 01:40:24.420
Like the sort of like existential horror

01:40:24.420 --> 01:40:28.300
of coming into consciousness with baby Y

01:40:28.300 --> 01:40:30.180
or baby Sailor Mars or whatever.

01:40:30.180 --> 01:40:32.420
She has like so many names at this point that it's,

01:40:33.580 --> 01:40:36.100
we really need to probably settle on one.

01:40:36.100 --> 01:40:38.300
If you could be someone else for a day,

01:40:38.300 --> 01:40:41.780
someone alive today, but somebody you haven't met yet,

01:40:41.780 --> 01:40:42.620
who would you be?

01:40:42.620 --> 01:40:44.220
Would I be modeling their brain state

01:40:44.220 --> 01:40:46.380
or would I just be in their body?

01:40:46.380 --> 01:40:48.780
You can choose the degree to which

01:40:48.780 --> 01:40:50.540
you're modeling their brain state.

01:40:50.700 --> 01:40:54.260
So you can still take a third person perspective

01:40:54.260 --> 01:40:56.620
and realize, you have to realize that you're.

01:40:56.620 --> 01:40:58.660
Can they be alive or can it be dead?

01:41:00.540 --> 01:41:01.380
No, oh.

01:41:02.740 --> 01:41:04.420
They would be brought back to life, right?

01:41:04.420 --> 01:41:05.260
If they're dead.

01:41:05.260 --> 01:41:07.100
Yeah, you can bring people back.

01:41:07.100 --> 01:41:09.260
Definitely Hitler or Stalin.

01:41:09.260 --> 01:41:10.780
I wanna understand evil.

01:41:12.060 --> 01:41:14.980
You would need to, oh, to experience what it feels like.

01:41:14.980 --> 01:41:17.500
I wanna be in their brain feeling what they feel.

01:41:18.340 --> 01:41:20.860
That might change you forever, returning from that.

01:41:20.860 --> 01:41:22.940
Yes, but I think it would also help me understand

01:41:22.940 --> 01:41:25.380
how to prevent it and fix it.

01:41:25.380 --> 01:41:26.580
That might be one of those things

01:41:26.580 --> 01:41:29.940
once you experience it, it'll be a burden to know it.

01:41:29.940 --> 01:41:31.380
Cause you won't be able to transfer that.

01:41:31.380 --> 01:41:33.820
A lot of things are burdens.

01:41:33.820 --> 01:41:34.820
But it's a useful burden.

01:41:34.820 --> 01:41:36.580
But it's a useful burden.

01:41:36.580 --> 01:41:39.260
That for sure, I wanna understand evil

01:41:39.260 --> 01:41:42.020
and like psychopathy and that.

01:41:42.020 --> 01:41:43.340
I have all these fake Twitter accounts

01:41:43.340 --> 01:41:45.580
where I like go into different algorithmic bubbles

01:41:45.580 --> 01:41:47.380
to try to like understand.

01:41:48.260 --> 01:41:49.100
I'll keep getting in fights with people

01:41:49.100 --> 01:41:50.660
and realize we're not actually fighting.

01:41:50.660 --> 01:41:53.060
I think we're, we used to exist in a monoculture

01:41:53.060 --> 01:41:54.460
like before social media and stuff.

01:41:54.460 --> 01:41:56.500
Like we kind of all got fed the same thing.

01:41:56.500 --> 01:41:58.740
So we were all speaking the same cultural language.

01:41:58.740 --> 01:42:00.180
But I think recently one of the things

01:42:00.180 --> 01:42:02.100
that like we aren't diagnosing properly enough

01:42:02.100 --> 01:42:05.540
with social media is that there's different dialects.

01:42:05.540 --> 01:42:06.940
There's so many different dialects of Chinese.

01:42:06.940 --> 01:42:09.420
There are now becoming different dialects of English.

01:42:09.420 --> 01:42:11.820
Like I am realizing like there are people

01:42:11.820 --> 01:42:13.620
who are saying the exact same things,

01:42:13.620 --> 01:42:16.020
but they're using completely different verbiage

01:42:16.060 --> 01:42:17.420
and we're like punishing each other

01:42:17.420 --> 01:42:18.980
for not using the correct verbiage

01:42:18.980 --> 01:42:20.580
and we're completely misunderstanding.

01:42:20.580 --> 01:42:22.100
Like people are just like misunderstanding

01:42:22.100 --> 01:42:23.660
what the other people are saying.

01:42:23.660 --> 01:42:26.300
And like, like I just got in a fight with a friend

01:42:27.540 --> 01:42:31.300
about like anarchism and communism and shit

01:42:31.300 --> 01:42:33.100
for like two hours.

01:42:33.100 --> 01:42:34.620
And then by the end of a conversation,

01:42:34.620 --> 01:42:36.020
like and then she says something and I'm like,

01:42:36.020 --> 01:42:37.700
but that's literally what I'm saying.

01:42:37.700 --> 01:42:39.100
And she was like, what?

01:42:39.100 --> 01:42:40.980
And then I was like, fuck, we've different,

01:42:40.980 --> 01:42:43.060
I'm like, we're, our English,

01:42:43.060 --> 01:42:46.060
like the way we are understanding terminology

01:42:46.060 --> 01:42:50.660
is like drastically, like our algorithm bubbles

01:42:50.660 --> 01:42:53.500
are creating many dialects and-

01:42:53.500 --> 01:42:55.980
Of how language is interpreted, how language is used.

01:42:55.980 --> 01:42:56.940
That's so fascinating.

01:42:56.940 --> 01:42:59.300
And so we're like having these arguments

01:42:59.300 --> 01:43:01.060
that we do not need to be having

01:43:01.060 --> 01:43:02.460
and there's polarization that's happening

01:43:02.460 --> 01:43:03.500
that doesn't need to be happening

01:43:03.500 --> 01:43:06.540
because we've got these like algorithmically created

01:43:08.700 --> 01:43:09.900
dialects occurring.

01:43:09.900 --> 01:43:10.780
Plus on top of that,

01:43:10.780 --> 01:43:12.420
there's also different parts of the world

01:43:12.420 --> 01:43:13.540
that speak different languages.

01:43:13.540 --> 01:43:16.260
So there's literally lost in translation

01:43:16.260 --> 01:43:17.900
kind of communication.

01:43:17.900 --> 01:43:19.820
I happen to know the Russian language

01:43:19.820 --> 01:43:21.500
and just know how different it is.

01:43:21.500 --> 01:43:22.460
Yeah.

01:43:22.460 --> 01:43:23.940
Then the English language

01:43:23.940 --> 01:43:27.740
and I just wonder how much is lost in a little bit of-

01:43:27.740 --> 01:43:29.020
Man, I actually, cause I have a question for you.

01:43:29.020 --> 01:43:30.340
I have a song coming out tomorrow

01:43:30.340 --> 01:43:31.980
with Ice Peak who are a Russian band.

01:43:31.980 --> 01:43:33.780
And I speak a little bit of Russian

01:43:33.780 --> 01:43:35.460
and I was looking at the title

01:43:35.460 --> 01:43:38.300
and the title in English doesn't match the title in Russian.

01:43:38.300 --> 01:43:40.580
I'm curious about this cause look, it says-

01:43:40.580 --> 01:43:41.420
What's the English title?

01:43:41.460 --> 01:43:42.980
The title in English is Last Day

01:43:42.980 --> 01:43:44.500
and then the title in Russian is

01:43:44.500 --> 01:43:45.620
Novi-

01:43:45.620 --> 01:43:47.540
My pronunciation sucks.

01:43:47.540 --> 01:43:48.780
Novi Dien?

01:43:48.780 --> 01:43:49.620
Like what?

01:43:49.620 --> 01:43:50.460
Yeah, New Day.

01:43:50.460 --> 01:43:51.300
A new day.

01:43:51.300 --> 01:43:52.140
Yeah, new day, new day.

01:43:52.140 --> 01:43:53.380
Like it's two different meanings.

01:43:53.380 --> 01:43:54.820
Yeah, new day, yeah.

01:43:57.260 --> 01:43:58.540
Yeah, yeah, new day.

01:43:58.540 --> 01:43:59.700
New day but last day.

01:44:01.380 --> 01:44:02.300
Novi Dien.

01:44:02.300 --> 01:44:04.260
So last day would be Posledniy Dien.

01:44:04.260 --> 01:44:05.100
Yeah.

01:44:05.100 --> 01:44:05.940
Maybe they-

01:44:05.940 --> 01:44:07.580
Or maybe the title includes both the Russian

01:44:07.580 --> 01:44:09.100
and it's for-

01:44:09.100 --> 01:44:09.940
Maybe, maybe.

01:44:09.940 --> 01:44:10.780
Maybe it's for bilingual.

01:44:10.780 --> 01:44:13.260
But to be honest, Novi Dien sounds better than

01:44:13.260 --> 01:44:15.180
just musically.

01:44:15.180 --> 01:44:16.020
Like-

01:44:16.020 --> 01:44:16.860
Posledniy Dien?

01:44:16.860 --> 01:44:17.820
Novi Dien is new day.

01:44:17.820 --> 01:44:18.820
That's the current one.

01:44:18.820 --> 01:44:22.180
And Posledniy Dien is the last day.

01:44:23.500 --> 01:44:25.740
I think Novi Dien, boy-

01:44:25.740 --> 01:44:26.700
I don't like Novi Dien.

01:44:26.700 --> 01:44:28.940
But the meaning is so different.

01:44:30.220 --> 01:44:31.660
That's kind of awesome actually though.

01:44:31.660 --> 01:44:34.560
There's an explicit sort of contrast like that.

01:44:35.860 --> 01:44:38.380
If everyone on earth disappeared

01:44:38.380 --> 01:44:39.980
and it was just you left,

01:44:41.380 --> 01:44:44.140
what would your day look like?

01:44:44.140 --> 01:44:45.300
Like what would you do?

01:44:45.300 --> 01:44:46.820
Everybody's dead.

01:44:46.820 --> 01:44:47.660
As far as you-

01:44:47.660 --> 01:44:48.700
Are there corpses there?

01:44:52.540 --> 01:44:53.740
Well seriously, it's a big-

01:44:53.740 --> 01:44:54.860
Let me think through this.

01:44:54.860 --> 01:44:57.000
It's a big difference if there's just like birds singing

01:44:57.000 --> 01:44:58.980
versus if there's like corpses littering the street.

01:44:58.980 --> 01:45:01.940
Yeah, there's corpses everywhere, I'm sorry.

01:45:01.940 --> 01:45:05.140
It's, and you don't actually know what happened

01:45:05.140 --> 01:45:07.620
and you don't know why you survived.

01:45:07.620 --> 01:45:10.500
And you don't even know if there's others out there.

01:45:11.180 --> 01:45:13.620
It seems clear that it's all gone.

01:45:13.620 --> 01:45:15.300
What would you do?

01:45:15.300 --> 01:45:16.180
What would I do?

01:45:17.340 --> 01:45:19.640
Listen, I'm somebody who really enjoys the moment,

01:45:19.640 --> 01:45:20.500
enjoys life.

01:45:20.500 --> 01:45:25.500
I would just go on enjoying the inanimate objects.

01:45:26.460 --> 01:45:30.640
I would just look for food, basic survival.

01:45:30.640 --> 01:45:32.220
But mostly it was just-

01:45:32.220 --> 01:45:35.860
Listen, I take walks and I look outside

01:45:35.860 --> 01:45:38.660
and I'm just happy that we get to exist on this planet

01:45:39.660 --> 01:45:41.980
to be able to breathe air.

01:45:41.980 --> 01:45:43.060
It's just all beautiful.

01:45:43.060 --> 01:45:44.820
It's full of colors, all of this kind of stuff.

01:45:44.820 --> 01:45:48.180
Just, there's so many things about life,

01:45:48.180 --> 01:45:50.780
your own life, conscious life that's fucking awesome.

01:45:50.780 --> 01:45:52.140
So I would just enjoy that.

01:45:54.220 --> 01:45:56.860
But also maybe after a few weeks,

01:45:56.860 --> 01:45:58.420
the engineer will start coming out

01:45:58.420 --> 01:46:01.580
like wanna build some things.

01:46:01.580 --> 01:46:05.620
Maybe there's always hope, searching for another human.

01:46:05.620 --> 01:46:06.460
Maybe.

01:46:06.460 --> 01:46:09.380
Probably searching for another human.

01:46:09.380 --> 01:46:13.140
Probably trying to get to a TV or radio station

01:46:13.140 --> 01:46:16.500
and broadcast something.

01:46:18.380 --> 01:46:19.900
That's interesting, I didn't think about that.

01:46:19.900 --> 01:46:24.580
So really maximize your ability to connect with others.

01:46:24.580 --> 01:46:29.260
Yeah, probably try to find another person.

01:46:29.260 --> 01:46:33.460
Would you be excited to meet another person or terrified?

01:46:34.460 --> 01:46:35.660
I'd be excited.

01:46:35.660 --> 01:46:36.500
Even if they-

01:46:36.500 --> 01:46:37.340
No matter what.

01:46:37.340 --> 01:46:38.180
Yeah, yeah, yeah, yeah.

01:46:38.180 --> 01:46:42.180
Being alone for the last however long of my life

01:46:42.180 --> 01:46:43.580
would be really bad.

01:46:43.580 --> 01:46:46.140
That's the one instance I might,

01:46:46.140 --> 01:46:47.220
I don't think I'd kill myself,

01:46:47.220 --> 01:46:48.740
but I might kill myself if I had to undergo that.

01:46:48.740 --> 01:46:50.140
Do you love people?

01:46:50.140 --> 01:46:51.940
Do you love connection to other humans?

01:46:51.940 --> 01:46:54.420
Yeah, I kinda hate people too, but I, yeah.

01:46:54.420 --> 01:46:56.780
That's a love-hate relationship.

01:46:56.780 --> 01:46:58.380
I feel like we had a bunch of weird

01:46:58.380 --> 01:47:00.540
Nietzsche questions and stuff, though.

01:47:00.540 --> 01:47:01.380
Oh yeah.

01:47:01.380 --> 01:47:02.940
I wonder, because I'm like, when podcasts,

01:47:03.260 --> 01:47:05.620
is this interesting for people to just have like,

01:47:05.620 --> 01:47:08.420
or I don't know, maybe people do like this.

01:47:08.420 --> 01:47:10.500
When I listen to podcasts, I'm into like the lore,

01:47:10.500 --> 01:47:11.940
like the hard lore.

01:47:11.940 --> 01:47:13.420
Like I just love like Dan Carlin.

01:47:13.420 --> 01:47:14.540
I'm like, give me the facts.

01:47:14.540 --> 01:47:18.780
Just like, get the facts into my bloodstream.

01:47:18.780 --> 01:47:20.740
But you also don't know,

01:47:20.740 --> 01:47:23.340
like you're a fascinating mind to explore.

01:47:23.340 --> 01:47:26.380
So you don't realize as you're talking about stuff,

01:47:26.380 --> 01:47:28.460
the stuff you've taken for granted

01:47:28.460 --> 01:47:30.460
is actually unique and fascinating,

01:47:30.460 --> 01:47:32.100
the way you think.

01:47:32.100 --> 01:47:35.820
Not always, like the way you reason through things

01:47:35.820 --> 01:47:39.500
is the fascinating thing to listen to,

01:47:39.500 --> 01:47:42.060
because people kinda see, oh, there's other humans

01:47:42.060 --> 01:47:45.420
that think differently, that explore thoughts differently.

01:47:45.420 --> 01:47:47.580
That's the cool, that's also cool.

01:47:47.580 --> 01:47:50.220
So yeah, Dan Carlin, retelling of history.

01:47:50.220 --> 01:47:54.860
By the way, his retelling of history is very,

01:47:54.860 --> 01:47:57.100
I think what's exciting is not the history,

01:47:57.100 --> 01:48:00.380
is his way of thinking about history.

01:48:01.340 --> 01:48:03.620
No, I think Dan Carlin is one of the people,

01:48:03.620 --> 01:48:05.300
like when Dan Carlin is one of the people

01:48:05.300 --> 01:48:07.060
that really started getting me excited

01:48:07.060 --> 01:48:09.780
about revolutionizing education,

01:48:09.780 --> 01:48:12.780
because Dan Carlin instilled,

01:48:12.780 --> 01:48:15.300
I already really liked history,

01:48:15.300 --> 01:48:19.900
but he instilled an obsessive love of history in me

01:48:19.900 --> 01:48:22.540
to the point where now I'm fucking reading,

01:48:22.540 --> 01:48:26.700
like going to bed, reading part four of The Rise and Fall,

01:48:26.700 --> 01:48:27.660
Third Reich or whatever.

01:48:27.660 --> 01:48:31.380
Like, he instilled an obsessive love of history,

01:48:31.380 --> 01:48:34.660
but he opened that door that made me want

01:48:34.660 --> 01:48:36.900
to be a scholar of that topic.

01:48:36.900 --> 01:48:40.060
It's like, I feel he's such a good teacher.

01:48:40.060 --> 01:48:43.300
He just, you know, and it sort of made me feel

01:48:43.300 --> 01:48:46.300
like one of the things we could do with education

01:48:46.300 --> 01:48:48.740
is find the world's greatest,

01:48:48.740 --> 01:48:52.020
the teachers that create passion for the topic,

01:48:52.020 --> 01:48:55.980
because autodidacticism,

01:48:56.460 --> 01:48:59.500
is like much faster than being lectured to.

01:48:59.500 --> 01:49:01.340
Like it's much more efficient to sort of like

01:49:01.340 --> 01:49:03.740
be able to teach yourself and then ask a teacher questions

01:49:03.740 --> 01:49:04.900
when you don't know what's up.

01:49:04.900 --> 01:49:07.980
But like, you know, that's why it's like in university

01:49:07.980 --> 01:49:10.460
and stuff, like you can learn so much more material

01:49:10.460 --> 01:49:12.820
so much faster because you're doing a lot of learning

01:49:12.820 --> 01:49:14.460
on your own and you're going to the teachers

01:49:14.460 --> 01:49:15.660
for when you get stuck.

01:49:15.660 --> 01:49:19.020
But like these teachers that can inspire passion

01:49:19.020 --> 01:49:21.700
for a topic, I think that is one of the most invaluable

01:49:21.700 --> 01:49:23.220
skills in our whole species.

01:49:23.780 --> 01:49:27.260
Because if you can do that, then you, it's like AI.

01:49:27.260 --> 01:49:31.180
Like AI is gonna teach itself so much more efficiently

01:49:31.180 --> 01:49:32.020
than we can teach it.

01:49:32.020 --> 01:49:32.940
We just need it to get it to the point

01:49:32.940 --> 01:49:34.380
where it can teach itself.

01:49:34.380 --> 01:49:35.220
And then-

01:49:35.220 --> 01:49:37.540
It finds the motivation to do so, right?

01:49:37.540 --> 01:49:38.380
Yeah.

01:49:38.380 --> 01:49:39.620
So like you inspire it to do so.

01:49:39.620 --> 01:49:40.460
Yeah.

01:49:40.460 --> 01:49:42.700
And then it could teach itself.

01:49:42.700 --> 01:49:44.580
What do you make of the fact,

01:49:44.580 --> 01:49:46.340
you mentioned Rise and Fall, the third, right?

01:49:46.340 --> 01:49:47.180
I just-

01:49:47.180 --> 01:49:48.000
Have you read that?

01:49:48.000 --> 01:49:48.840
I've read it twice.

01:49:48.840 --> 01:49:49.680
You've read it twice?

01:49:49.680 --> 01:49:50.500
Yes.

01:49:50.500 --> 01:49:51.620
Okay, so no one even knows what it is.

01:49:51.620 --> 01:49:52.460
Yeah.

01:49:52.460 --> 01:49:54.860
I'm like, wait, I thought this was like a super poppin' book.

01:49:54.860 --> 01:49:55.700
Super pop.

01:49:55.700 --> 01:49:57.620
I'm not like that.

01:49:57.620 --> 01:50:00.300
I'm not that far in it, but it is, it's so interesting.

01:50:00.300 --> 01:50:03.580
Yeah, it's written by a person that was there,

01:50:03.580 --> 01:50:05.900
which is very important to kind of-

01:50:05.900 --> 01:50:07.020
You know, you start being like,

01:50:07.020 --> 01:50:08.500
how could this possibly happen?

01:50:08.500 --> 01:50:10.060
And then when you read Rise and Fall, the third, right?

01:50:10.060 --> 01:50:14.060
It's like, people tried really hard for this to not happen.

01:50:14.060 --> 01:50:16.580
People tried, they almost reinstated a monarchy at one point

01:50:16.580 --> 01:50:17.980
to try to stop this from happening.

01:50:17.980 --> 01:50:21.100
Like they almost like abandoned democracy

01:50:21.100 --> 01:50:22.780
to try to get this to not happen.

01:50:22.780 --> 01:50:24.860
At least the way it makes me feel

01:50:24.860 --> 01:50:28.220
is that there's a bunch of small moments

01:50:28.220 --> 01:50:30.140
on which history can turn.

01:50:30.140 --> 01:50:30.980
Yes.

01:50:30.980 --> 01:50:32.300
It's like small meetings.

01:50:32.300 --> 01:50:33.140
Yes.

01:50:33.140 --> 01:50:34.260
Human interactions.

01:50:34.260 --> 01:50:36.940
And it's both terrifying and inspiring,

01:50:36.940 --> 01:50:37.780
because it's like,

01:50:40.300 --> 01:50:44.180
even just attempts at assassinating Hitler,

01:50:44.180 --> 01:50:47.380
like time and time again, failed.

01:50:47.380 --> 01:50:48.220
And they were so close-

01:50:48.220 --> 01:50:50.060
Was it like operation Valkyrie?

01:50:50.140 --> 01:50:51.700
That's a good-

01:50:51.700 --> 01:50:55.140
And then there is also the role of,

01:50:55.140 --> 01:50:56.540
that's a really heavy burden,

01:50:56.540 --> 01:50:59.100
which is that from a geopolitical perspective,

01:50:59.100 --> 01:51:00.860
the role of leaders to see evil

01:51:00.860 --> 01:51:02.540
before it truly becomes evil,

01:51:02.540 --> 01:51:05.500
to anticipate it, to stand up to evil.

01:51:05.500 --> 01:51:08.180
Because evil is actually pretty rare in this world

01:51:08.180 --> 01:51:09.420
at a scale that Hitler was.

01:51:09.420 --> 01:51:12.060
We tend to, you know, in the modern discourse,

01:51:12.060 --> 01:51:14.020
kind of call people evil too quickly.

01:51:14.020 --> 01:51:17.420
If you look at ancient history,

01:51:17.420 --> 01:51:18.900
like there was a ton of Hitlers.

01:51:18.900 --> 01:51:22.700
I actually think it's more the norm than,

01:51:22.700 --> 01:51:24.460
like again, going back to like my

01:51:24.460 --> 01:51:25.940
sort of intelligent design theory,

01:51:25.940 --> 01:51:28.420
I think one of the things we've been successfully doing

01:51:28.420 --> 01:51:31.340
in our slow move from survival of the fittest

01:51:31.340 --> 01:51:32.700
to intelligent design,

01:51:32.700 --> 01:51:37.700
is we've kind of been eradicating,

01:51:37.700 --> 01:51:40.100
like if you look at like ancient Assyria and stuff,

01:51:40.100 --> 01:51:42.500
like that shit was like brutal,

01:51:42.500 --> 01:51:44.300
and just like the heads on the,

01:51:44.300 --> 01:51:47.860
like brutal, like Genghis Khan just like genocide

01:51:47.860 --> 01:51:49.300
after genocide after genocide,

01:51:49.300 --> 01:51:51.820
was like throwing plague bodies over the walls

01:51:51.820 --> 01:51:53.380
and decimating whole cities

01:51:53.380 --> 01:51:56.580
or like the Muslim conquests of like Damascus and shit.

01:51:56.580 --> 01:51:59.460
Just like people, cities used to get leveled

01:51:59.460 --> 01:52:00.740
all the fucking time.

01:52:00.740 --> 01:52:03.540
Okay, get into the Bronze Age collapse.

01:52:03.540 --> 01:52:06.860
Basically, there was like almost like Roman level,

01:52:06.860 --> 01:52:10.100
like society, like there was like all over the world,

01:52:10.100 --> 01:52:12.460
like global trade, like everything was awesome.

01:52:12.460 --> 01:52:14.500
Through a mix of I think a bit of climate change

01:52:14.500 --> 01:52:16.700
and then the development of iron,

01:52:16.700 --> 01:52:19.020
because basically bronze could only come from this,

01:52:19.020 --> 01:52:20.060
the way to make bronze,

01:52:20.060 --> 01:52:21.220
like everything had to be funneled

01:52:21.220 --> 01:52:23.860
through this one Iranian mine.

01:52:23.860 --> 01:52:27.260
And so it's like, there was just this one supply chain.

01:52:27.260 --> 01:52:28.100
And this is one of the things

01:52:28.100 --> 01:52:29.660
that makes me worried about supply chains

01:52:29.660 --> 01:52:32.060
and why I think we need to be so thoughtful about,

01:52:32.060 --> 01:52:34.980
I think our biggest issue with society right now,

01:52:34.980 --> 01:52:36.980
like the thing that is most likely to go wrong

01:52:36.980 --> 01:52:39.380
is probably supply chain collapse,

01:52:39.380 --> 01:52:40.660
because war, climate change, whatever,

01:52:40.660 --> 01:52:42.340
like anything that causes supply chain collapse,

01:52:42.340 --> 01:52:44.780
our population is too big to handle that.

01:52:44.780 --> 01:52:46.860
And like the thing that seems to cause dark ages

01:52:46.860 --> 01:52:48.540
is mass supply chain collapse,

01:52:48.540 --> 01:52:52.340
but the Bronze Age collapse happened like,

01:52:53.420 --> 01:52:56.340
it was sort of like this ancient collapse that happened

01:52:56.340 --> 01:53:00.660
where like literally like ancient Egypt, all these cities,

01:53:00.660 --> 01:53:02.820
everything just got like decimated, destroyed,

01:53:02.820 --> 01:53:05.020
abandoned cities, like hundreds of them.

01:53:05.020 --> 01:53:06.540
There was like a flourishing society,

01:53:06.540 --> 01:53:07.980
like we were almost coming to modernity

01:53:07.980 --> 01:53:09.060
and everything got leveled

01:53:09.060 --> 01:53:10.580
and they had this mini dark ages,

01:53:10.580 --> 01:53:11.540
but it was just like,

01:53:11.540 --> 01:53:13.660
there's so little writing or recording from that time

01:53:13.660 --> 01:53:15.380
that like there isn't a lot of information

01:53:15.380 --> 01:53:16.820
about the Bronze Age collapse,

01:53:16.820 --> 01:53:19.340
but it was basically equivalent to like medieval,

01:53:19.340 --> 01:53:21.780
the medieval dark ages,

01:53:21.780 --> 01:53:24.140
but it just happened, I don't know the years,

01:53:24.140 --> 01:53:27.020
but like thousands of years earlier.

01:53:27.020 --> 01:53:29.220
And then we sort of like recovered

01:53:29.220 --> 01:53:33.180
from the Bronze Age collapse, empire re-emerged,

01:53:33.180 --> 01:53:35.700
writing and trade and everything re-emerged,

01:53:37.180 --> 01:53:40.500
and then we of course had the more contemporary dark ages.

01:53:41.380 --> 01:53:43.620
And then over time we've designed mechanism

01:53:43.620 --> 01:53:46.380
that lessen and lessen the capability

01:53:46.380 --> 01:53:50.940
for the destructive power centers to emerge.

01:53:50.940 --> 01:53:54.220
There's more recording about the more contemporary dark ages,

01:53:54.220 --> 01:53:55.620
so I think we have like a better understanding

01:53:55.620 --> 01:53:56.460
of how to avoid it,

01:53:56.460 --> 01:53:58.100
but I still think we're at high risk for it.

01:53:58.100 --> 01:54:00.580
I think that's one of the big risks right now.

01:54:00.580 --> 01:54:03.220
So the natural state of being for humans

01:54:03.220 --> 01:54:04.900
is for there to be a lot of Hitlers,

01:54:04.900 --> 01:54:08.500
which has gotten really good at making it hard

01:54:08.500 --> 01:54:09.940
for them to emerge.

01:54:10.020 --> 01:54:12.700
We've gotten better at collaboration

01:54:12.700 --> 01:54:14.820
and resisting the power,

01:54:14.820 --> 01:54:16.860
like authoritarians to come to power.

01:54:16.860 --> 01:54:18.580
We're trying to go country by country,

01:54:18.580 --> 01:54:19.900
like we're moving past this.

01:54:19.900 --> 01:54:21.500
We're kind of like slowly incrementally

01:54:21.500 --> 01:54:26.500
like moving towards like not scary old school war stuff.

01:54:29.180 --> 01:54:32.180
And I think seeing it happen in some of the countries

01:54:32.180 --> 01:54:33.860
that at least nominally are like

01:54:35.140 --> 01:54:36.740
supposed to have moved past that,

01:54:36.740 --> 01:54:39.780
that's scary because it reminds us that it can happen.

01:54:40.740 --> 01:54:43.700
In the places that have made like moved past,

01:54:43.700 --> 01:54:47.060
supposedly as hopefully moved past that.

01:54:47.060 --> 01:54:49.420
And possibly at a civilization level,

01:54:49.420 --> 01:54:51.660
like you said, supply chain collapse

01:54:51.660 --> 01:54:54.300
might make people resource constraint,

01:54:54.300 --> 01:54:59.300
might make people desperate, angry, hateful, violent

01:54:59.980 --> 01:55:01.500
and drag us right back in.

01:55:01.500 --> 01:55:03.980
I mean, supply chain collapse is how

01:55:03.980 --> 01:55:06.260
like the ultimate thing that caused the middle ages

01:55:06.260 --> 01:55:08.260
was supply chain collapse.

01:55:08.260 --> 01:55:11.020
It's like people, because people were reliant

01:55:11.020 --> 01:55:12.380
on a certain level of technology,

01:55:12.380 --> 01:55:14.140
like people like you look at like Britain,

01:55:14.140 --> 01:55:17.540
like they had glass, like people had aqueducts,

01:55:17.540 --> 01:55:20.420
people had like indoor heating and cooling

01:55:20.420 --> 01:55:23.380
and like running water and like buy food

01:55:23.380 --> 01:55:26.020
from all over the world and trade and markets.

01:55:26.020 --> 01:55:28.540
Like people didn't know how to hunt and forage and gather.

01:55:28.540 --> 01:55:29.820
And so we're in a similar situation.

01:55:29.820 --> 01:55:33.740
We are not educated enough to survive without technology.

01:55:33.740 --> 01:55:35.380
So if we have a supply chain collapse

01:55:35.380 --> 01:55:38.340
that like limits our access to technology,

01:55:38.340 --> 01:55:41.300
there will be like massive starvation and violence

01:55:41.300 --> 01:55:43.140
and displacement and war.

01:55:43.140 --> 01:55:47.300
Like, you know, it's also like, yeah.

01:55:47.300 --> 01:55:49.060
In my opinion, it's like the primary marker

01:55:49.060 --> 01:55:52.700
of like what a dark age is.

01:55:52.700 --> 01:55:54.380
Well, technology is kind of enabling us

01:55:54.380 --> 01:55:57.220
to be more resilient in terms of supply chain,

01:55:57.220 --> 01:56:00.820
in terms of to all the different catastrophic events

01:56:00.820 --> 01:56:02.060
that happened to us.

01:56:02.060 --> 01:56:03.900
Although the pandemic has kind of challenged

01:56:04.460 --> 01:56:07.620
our preparedness for the catastrophic.

01:56:07.620 --> 01:56:09.180
What do you think is the coolest invention

01:56:09.180 --> 01:56:11.060
humans come up with?

01:56:11.060 --> 01:56:14.540
The wheel, fire, cooking meat.

01:56:14.540 --> 01:56:16.140
Computers.

01:56:16.140 --> 01:56:16.980
Computers.

01:56:16.980 --> 01:56:17.820
Fricking computers.

01:56:17.820 --> 01:56:19.460
Internet or computers, which one?

01:56:19.460 --> 01:56:20.340
What do you think the-

01:56:20.340 --> 01:56:22.340
Previous technologies, I mean,

01:56:22.340 --> 01:56:23.620
may have even been more profound

01:56:23.620 --> 01:56:24.700
and moved us to a certain degree,

01:56:24.700 --> 01:56:27.300
but I think the computers are what make us homo-tech now.

01:56:27.300 --> 01:56:30.700
I think this is what, it's a brain augmentation.

01:56:30.700 --> 01:56:33.780
And so it like allows for actual evolution.

01:56:34.620 --> 01:56:35.460
Like the computers accelerate the degree

01:56:35.460 --> 01:56:37.020
to which all the other technologies

01:56:37.020 --> 01:56:38.620
can also be accelerated.

01:56:38.620 --> 01:56:40.660
Would you classify yourself as a homo sapien

01:56:40.660 --> 01:56:41.580
or a homo techno?

01:56:41.580 --> 01:56:43.020
Definitely a homo techno.

01:56:43.020 --> 01:56:46.900
So you're one of the earliest of the species.

01:56:46.900 --> 01:56:49.180
I think most of us are.

01:56:49.180 --> 01:56:51.580
Like, as I said, like, I think if you

01:56:53.700 --> 01:56:56.140
like looked at brain scans of us

01:56:56.140 --> 01:56:59.780
versus humans 100 years ago,

01:56:59.780 --> 01:57:00.900
it would look very different.

01:57:00.900 --> 01:57:03.700
I think we are physiologically different.

01:57:04.620 --> 01:57:05.620
Just even the interaction with the devices

01:57:05.620 --> 01:57:06.740
has changed our brains.

01:57:06.740 --> 01:57:08.620
Well, and if you look at,

01:57:08.620 --> 01:57:11.260
a lot of studies are coming out to show that like

01:57:11.260 --> 01:57:13.140
there's a degree of inherited memory.

01:57:13.140 --> 01:57:16.060
So some of these physiological changes in theory should be,

01:57:16.060 --> 01:57:18.060
we should be passing them on.

01:57:18.060 --> 01:57:21.700
So like that's, you know, that's not like a,

01:57:21.700 --> 01:57:23.220
an instance of physiological change

01:57:23.220 --> 01:57:24.180
that's gonna fizzle out.

01:57:24.180 --> 01:57:28.100
In theory, that should progress like to our offspring.

01:57:29.100 --> 01:57:30.460
Speaking of offspring,

01:57:30.460 --> 01:57:33.220
what advice would you give to a young person

01:57:33.220 --> 01:57:34.380
like in high school?

01:57:35.700 --> 01:57:40.700
Will there be an artist, a creative, an engineer,

01:57:41.300 --> 01:57:45.100
a, any kind of career path

01:57:45.100 --> 01:57:46.340
or maybe just life in general,

01:57:46.340 --> 01:57:48.740
how they can live a life they can be proud of?

01:57:48.740 --> 01:57:50.820
I think one of my big thoughts

01:57:50.820 --> 01:57:53.220
and like especially now having kids

01:57:53.220 --> 01:57:55.500
is that I don't think we spend enough time

01:57:55.500 --> 01:57:56.860
teaching creativity.

01:57:56.860 --> 01:57:59.340
And I think creativity is a muscle like other things.

01:57:59.340 --> 01:58:01.780
And there's a lot of emphasis on, you know,

01:58:01.780 --> 01:58:02.900
learn how to play the piano.

01:58:03.420 --> 01:58:04.260
And then you can write a song

01:58:04.260 --> 01:58:05.460
or like learn the technical stuff

01:58:05.460 --> 01:58:07.020
and then you can do a thing.

01:58:07.020 --> 01:58:10.460
But I think it's like, I have a friend

01:58:10.460 --> 01:58:12.620
who's like world's greatest guitar player,

01:58:13.700 --> 01:58:15.740
like, you know, amazing sort of like producer

01:58:15.740 --> 01:58:18.940
works with other people, but he's really sort of like,

01:58:18.940 --> 01:58:20.700
you know, he like engineers and records things

01:58:20.700 --> 01:58:21.740
and like does solos,

01:58:21.740 --> 01:58:23.460
but he doesn't really like make his own music.

01:58:23.460 --> 01:58:26.060
And I was talking to him and I was like,

01:58:26.060 --> 01:58:27.340
dude, you're so talented at music.

01:58:27.340 --> 01:58:28.860
Like, why don't you make music or whatever?

01:58:28.860 --> 01:58:32.100
And he was like, cause I got, I'm too old.

01:58:32.100 --> 01:58:34.180
I never learned the creative muscle.

01:58:34.180 --> 01:58:36.660
And it's like, you know, it's embarrassing.

01:58:36.660 --> 01:58:39.220
It's like learning the creative muscle

01:58:39.220 --> 01:58:40.780
takes a lot of failure.

01:58:40.780 --> 01:58:45.580
And it also sort of, when you're being creative,

01:58:46.900 --> 01:58:48.140
you know, you're throwing paint at a wall

01:58:48.140 --> 01:58:49.460
and a lot of stuff will fail.

01:58:49.460 --> 01:58:51.180
So like part of it is like a tolerance

01:58:51.180 --> 01:58:53.020
for failure and humiliation.

01:58:53.020 --> 01:58:54.900
And that somehow that's easier to develop

01:58:54.900 --> 01:58:57.380
when you're young or be persist through it

01:58:57.380 --> 01:58:58.220
when you're young.

01:58:58.220 --> 01:59:00.660
Everything is easier to develop when you're young.

01:59:02.500 --> 01:59:03.340
Yes.

01:59:03.340 --> 01:59:04.740
And the younger, the better.

01:59:04.740 --> 01:59:05.580
It could destroy you.

01:59:05.580 --> 01:59:08.420
I mean, that's the shitty thing about creativity.

01:59:08.420 --> 01:59:11.220
If, you know, failure could destroy you

01:59:11.220 --> 01:59:13.380
if you're not careful, but that's a risk worth taking.

01:59:13.380 --> 01:59:14.980
But also, but at a young age,

01:59:14.980 --> 01:59:17.780
developing a tolerance to failure is good.

01:59:17.780 --> 01:59:19.860
I fail all the time.

01:59:19.860 --> 01:59:22.340
Like I do stupid shit all the time.

01:59:22.340 --> 01:59:24.780
Like in public, I get canceled for,

01:59:24.780 --> 01:59:27.020
I make all kinds of mistakes,

01:59:27.020 --> 01:59:30.540
but I just like am very resilient about making mistakes.

01:59:30.580 --> 01:59:32.980
And so then like I do a lot of things

01:59:32.980 --> 01:59:34.180
that like other people wouldn't do.

01:59:34.180 --> 01:59:37.540
And like, I think my greatest asset is my creativity.

01:59:37.540 --> 01:59:39.860
And I like, I think paint, like tolerance to failure

01:59:39.860 --> 01:59:43.380
is just a super essential thing

01:59:43.380 --> 01:59:45.420
that should be taught before other things.

01:59:45.420 --> 01:59:46.340
Brilliant advice.

01:59:46.340 --> 01:59:47.420
Yeah, yeah.

01:59:47.420 --> 01:59:51.540
I wish everybody encouraged sort of failure more

01:59:51.540 --> 01:59:52.380
as opposed to kind of-

01:59:52.380 --> 01:59:53.460
Cause we like punish failure.

01:59:53.460 --> 01:59:55.340
We're like, no, we're no, like when we were teaching kids,

01:59:55.340 --> 01:59:56.380
we're like, no, that's wrong.

01:59:56.380 --> 01:59:59.460
Like that's, you know, like,

02:00:01.340 --> 02:00:04.380
X keeps like, will be like wrong.

02:00:04.380 --> 02:00:05.740
Like he'll say like crazy things.

02:00:05.740 --> 02:00:09.740
Like X keeps being like, like bubble car, bubble car.

02:00:09.740 --> 02:00:12.980
And I'm like, and you know,

02:00:12.980 --> 02:00:14.420
I'm like, what's a bubble car like?

02:00:14.420 --> 02:00:15.860
But like, it doesn't like,

02:00:15.860 --> 02:00:17.420
but I don't want to be like, no, you're wrong.

02:00:17.420 --> 02:00:20.340
I'm like, you're thinking of weird, crazy shit.

02:00:20.340 --> 02:00:22.260
Like, I don't know what a bubble car is, but like-

02:00:22.260 --> 02:00:23.460
He's creating worlds

02:00:23.460 --> 02:00:25.180
and they might be internally consistent.

02:00:25.180 --> 02:00:26.500
And through that, he might discover

02:00:26.500 --> 02:00:27.860
something fundamental about this world.

02:00:27.860 --> 02:00:29.700
Yeah, or he'll like rewrite songs.

02:00:29.740 --> 02:00:32.140
Like with words that he prefers.

02:00:32.140 --> 02:00:34.620
So like, instead of baby shark, he says baby car.

02:00:39.540 --> 02:00:41.140
Maybe he's onto something.

02:00:41.140 --> 02:00:42.780
Let me ask the big ridiculous question.

02:00:42.780 --> 02:00:44.100
We were kind of dancing around it,

02:00:44.100 --> 02:00:47.180
but what do you think is the meaning

02:00:47.180 --> 02:00:48.940
of this whole thing we have here?

02:00:50.900 --> 02:00:52.980
Of human civilization, of life on earth,

02:00:52.980 --> 02:00:55.060
but in general, just life.

02:00:55.060 --> 02:00:57.380
What's the meaning of life?

02:00:57.380 --> 02:00:58.220
C.

02:00:58.220 --> 02:01:02.580
Have you, did you read Novosine yet?

02:01:02.580 --> 02:01:03.820
By James Lovelock?

02:01:03.820 --> 02:01:04.660
You're doing a lot

02:01:04.660 --> 02:01:06.380
of really good book recommendations here.

02:01:06.380 --> 02:01:07.580
I haven't even finished this,

02:01:07.580 --> 02:01:10.300
so I'm a huge fraud yet again.

02:01:10.300 --> 02:01:12.660
But like really early in the book,

02:01:12.660 --> 02:01:14.540
he says this amazing thing.

02:01:14.540 --> 02:01:16.540
Like, I feel like everyone's so sad and cynical.

02:01:16.540 --> 02:01:18.060
Like everyone's like the Fermi paradox

02:01:18.060 --> 02:01:19.820
and everyone, I just keep hearing people being like,

02:01:19.820 --> 02:01:21.380
fuck, what if we're alone?

02:01:21.380 --> 02:01:23.420
Like, oh no, ah, like, ah, ah.

02:01:23.420 --> 02:01:25.100
And I'm like, okay, but like, wait,

02:01:25.100 --> 02:01:26.780
what if this is the beginning?

02:01:26.780 --> 02:01:28.460
Like in Novosine, he says,

02:01:29.700 --> 02:01:31.580
I'm, this is not gonna be a correct,

02:01:31.580 --> 02:01:32.580
because I can't like memorize quotes,

02:01:32.580 --> 02:01:34.220
but he says something like,

02:01:36.260 --> 02:01:39.060
what if our consciousness,

02:01:39.060 --> 02:01:43.380
like right now, like this is the universe waking up.

02:01:43.380 --> 02:01:45.500
Like what if instead of discovering the universe,

02:01:45.500 --> 02:01:47.460
this is the universe,

02:01:47.460 --> 02:01:49.460
like this is the evolution

02:01:49.460 --> 02:01:51.620
of the literal universe herself.

02:01:51.620 --> 02:01:53.140
Like we are not separate from the universe.

02:01:53.140 --> 02:01:54.620
Like this is the universe waking up.

02:01:54.620 --> 02:01:56.580
This is the universe seeing herself

02:01:57.420 --> 02:01:58.260
for the first time.

02:01:58.260 --> 02:01:59.100
Like this is.

02:01:59.100 --> 02:02:00.740
The universe becoming conscious

02:02:00.740 --> 02:02:02.300
for the first time we're part of that.

02:02:02.300 --> 02:02:05.580
Yeah, cause it's like, we aren't separate from the universe.

02:02:05.580 --> 02:02:08.740
Like this could be like an incredibly sacred moment

02:02:08.740 --> 02:02:10.980
and maybe like social media and all these things,

02:02:10.980 --> 02:02:13.260
the stuff where we're all getting connected together,

02:02:13.260 --> 02:02:16.900
like maybe these are the neurons connecting

02:02:16.900 --> 02:02:21.380
of the like collective super intelligence that is,

02:02:21.380 --> 02:02:22.220
you know.

02:02:22.220 --> 02:02:23.340
Waking up.

02:02:23.340 --> 02:02:25.420
Yeah, like, you know, it's like,

02:02:25.420 --> 02:02:27.100
maybe instead of something cynical

02:02:27.100 --> 02:02:29.180
or maybe if there's something to discover,

02:02:29.180 --> 02:02:31.540
like maybe this is just, you know,

02:02:31.540 --> 02:02:35.980
we're a blastocyst of like some incredible

02:02:35.980 --> 02:02:39.420
kind of consciousness or being.

02:02:39.420 --> 02:02:41.220
And just like in the first three years of life

02:02:41.220 --> 02:02:42.820
or for human children,

02:02:42.820 --> 02:02:44.340
we'll forget about all the suffering

02:02:44.340 --> 02:02:45.460
that we're going through now.

02:02:45.460 --> 02:02:46.620
I think we'll probably forget about this.

02:02:46.620 --> 02:02:48.300
I mean, probably, you know,

02:02:48.300 --> 02:02:52.700
artificial intelligence will eventually render us obsolete.

02:02:52.700 --> 02:02:55.340
I don't think they'll do it in a malicious way,

02:02:55.340 --> 02:02:57.700
but I think probably we are very weak.

02:02:57.700 --> 02:02:58.820
The sun is expanding.

02:02:58.820 --> 02:03:01.620
Like, I don't know, like hopefully we can get to Mars,

02:03:01.620 --> 02:03:04.060
but like we're pretty vulnerable.

02:03:04.060 --> 02:03:06.740
And I, you know, like,

02:03:06.740 --> 02:03:09.060
I think we can coexist for a long time with AI

02:03:09.060 --> 02:03:11.420
and we can also probably make ourselves less vulnerable,

02:03:11.420 --> 02:03:16.300
but you know, I just think consciousness,

02:03:16.300 --> 02:03:18.380
sentience, self-awareness,

02:03:18.380 --> 02:03:21.900
like I think this might be the single greatest

02:03:21.900 --> 02:03:24.980
like moment in evolution ever.

02:03:25.620 --> 02:03:28.140
And like, maybe this is, you know,

02:03:29.860 --> 02:03:32.620
like the true beginning of life.

02:03:32.620 --> 02:03:34.740
And we're just, we're the blue green algae

02:03:34.740 --> 02:03:37.020
or we're like the single celled organisms

02:03:37.020 --> 02:03:38.460
of something amazing.

02:03:38.460 --> 02:03:40.940
The universe awakens and this is it.

02:03:40.940 --> 02:03:41.780
Yeah.

02:03:42.660 --> 02:03:45.340
Well, see, you're an incredible person.

02:03:45.340 --> 02:03:47.540
You're a fascinating mind.

02:03:47.540 --> 02:03:48.820
You should definitely do,

02:03:48.820 --> 02:03:51.020
your friend Liv mentioned that you guys

02:03:51.020 --> 02:03:52.300
were thinking of maybe talking.

02:03:52.300 --> 02:03:55.420
I would love it if you explored your mind

02:03:55.420 --> 02:03:56.740
in this kind of medium more and more

02:03:56.740 --> 02:03:59.700
by doing a podcast with her or just in any kind of way.

02:03:59.700 --> 02:04:01.820
So you're, you're an awesome person.

02:04:01.820 --> 02:04:03.420
It's an honor to know you.

02:04:03.420 --> 02:04:05.860
It's an honor to get to sit down with you late at night,

02:04:05.860 --> 02:04:08.380
which is like surreal.

02:04:08.380 --> 02:04:09.220
And I really enjoyed it.

02:04:09.220 --> 02:04:10.180
Thank you for talking today.

02:04:10.180 --> 02:04:11.740
Yeah, no, I mean, huge honor.

02:04:11.740 --> 02:04:13.020
I feel very under qualified to be here,

02:04:13.020 --> 02:04:13.860
but I'm a big fan.

02:04:13.860 --> 02:04:15.300
I've been listening to the podcast a lot.

02:04:15.300 --> 02:04:17.580
And yeah, me and Liv would appreciate any advice

02:04:17.580 --> 02:04:19.260
and help and we're definitely gonna do that.

02:04:19.260 --> 02:04:22.100
So anytime.

02:04:22.100 --> 02:04:22.940
Thank you.

02:04:22.940 --> 02:04:24.420
Cool, thank you.

02:04:24.420 --> 02:04:26.980
Thanks for listening to this conversation with Grimes.

02:04:26.980 --> 02:04:28.220
To support this podcast,

02:04:28.220 --> 02:04:31.060
please check out our sponsors in the description.

02:04:31.060 --> 02:04:34.740
And now let me leave you with some words from Oscar Wilde.

02:04:34.740 --> 02:04:36.980
Yes, I'm a dreamer.

02:04:36.980 --> 02:04:41.380
For a dreamer is one who can only find her way by moonlight

02:04:41.380 --> 02:04:44.260
and her punishment is that she sees the dawn

02:04:44.260 --> 02:04:45.740
before the rest of the world.

02:04:46.620 --> 02:04:49.060
Thank you for listening and hope to see you

02:04:49.060 --> 02:04:50.700
next time.

