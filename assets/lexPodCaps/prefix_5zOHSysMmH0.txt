WEBVTT

00:00.000 --> 00:02.560
Let's talk about free speech and censorship.

00:02.560 --> 00:04.040
You don't build a company like this

00:04.040 --> 00:06.440
unless you believe that people expressing themselves

00:06.440 --> 00:07.280
is a good thing.

00:07.280 --> 00:08.640
Let me ask you as a father,

00:08.640 --> 00:09.760
there's a weight heavy on you

00:09.760 --> 00:13.000
that people get bullied on social networks.

00:13.000 --> 00:14.440
I care a lot about how people feel

00:14.440 --> 00:15.460
when they use our products

00:15.460 --> 00:19.320
and I don't want to build products that make people angry.

00:19.320 --> 00:22.000
Why do you think so many people dislike you?

00:23.440 --> 00:25.580
Some even hate you.

00:25.580 --> 00:27.940
And how do you regain their trust and support?

00:30.120 --> 00:32.720
The following is a conversation with Mark Zuckerberg,

00:32.720 --> 00:35.700
CEO of Facebook, now called Meta.

00:36.760 --> 00:38.680
Please allow me to say a few words

00:38.680 --> 00:41.300
about this conversation with Mark Zuckerberg,

00:41.300 --> 00:42.680
about social media

00:42.680 --> 00:45.440
and about what troubles me in the world today

00:45.440 --> 00:47.760
and what gives me hope.

00:47.760 --> 00:49.480
If this is not interesting to you,

00:49.480 --> 00:51.560
I understand, please skip.

00:52.700 --> 00:55.000
I believe that at its best,

00:55.000 --> 00:57.760
social media puts a mirror to humanity

00:57.760 --> 01:01.040
and reveals the full complexity of our world,

01:01.040 --> 01:04.040
shining a light on the dark aspects of human nature

01:04.040 --> 01:06.660
and giving us hope, a way out

01:06.660 --> 01:09.760
through compassionate but tense chaos of conversation

01:09.760 --> 01:12.760
that eventually can turn into understanding,

01:12.760 --> 01:14.620
friendship and even love.

01:15.560 --> 01:17.400
But this is not simple.

01:17.400 --> 01:19.540
Our world is not simple.

01:19.540 --> 01:21.440
It is full of human suffering.

01:22.320 --> 01:24.440
I think about the hundreds of millions of people

01:24.440 --> 01:28.460
who are starving and who live in extreme poverty,

01:28.460 --> 01:31.600
the 1 million people who take their own life every year,

01:31.600 --> 01:33.920
the 20 million people that attempt it

01:33.920 --> 01:37.400
and the many, many more millions who suffer quietly

01:37.400 --> 01:39.360
in ways that numbers can never know.

01:40.760 --> 01:44.640
I'm troubled by the cruelty and pain of war.

01:44.640 --> 01:48.560
Today, my heart goes out to the people of Ukraine.

01:48.560 --> 01:52.240
My grandfather spilled his blood on this land,

01:52.240 --> 01:54.000
held the line as a machine gunner

01:54.560 --> 01:59.200
against the Nazi invasion, surviving impossible odds.

01:59.200 --> 02:01.380
I am nothing without him.

02:01.380 --> 02:03.560
His blood runs in my blood.

02:04.960 --> 02:07.560
My words are useless here.

02:07.560 --> 02:10.180
I send my love, it's all I have.

02:11.160 --> 02:14.120
I hope to travel to Russia and Ukraine soon.

02:14.120 --> 02:16.780
I will speak to citizens and leaders,

02:16.780 --> 02:18.920
including Vladimir Putin.

02:20.000 --> 02:22.680
As I've said in the past, I don't care about access,

02:22.680 --> 02:26.760
fame, money or power, and I'm afraid of nothing.

02:27.640 --> 02:29.120
But I am who I am.

02:29.120 --> 02:31.120
And my goal in conversation

02:31.120 --> 02:33.460
is to understand the human being before me,

02:33.460 --> 02:36.560
no matter who they are, no matter their position.

02:36.560 --> 02:40.040
And I do believe the line between good and evil

02:40.040 --> 02:42.480
runs through the heart of every man.

02:43.520 --> 02:45.360
So this is it.

02:45.360 --> 02:47.420
This is our world.

02:47.420 --> 02:50.660
It is full of hate, violence and destruction.

02:51.660 --> 02:55.260
But it is also full of love, beauty

02:55.260 --> 02:57.500
and the insatiable desire to help each other.

02:59.060 --> 03:01.260
The people who run the social networks

03:01.260 --> 03:05.340
that show this world, that show us to ourselves

03:05.340 --> 03:08.460
have the greatest of responsibilities.

03:08.460 --> 03:11.700
In a time of war, pandemic, atrocity,

03:11.700 --> 03:13.020
we turn to social networks

03:13.020 --> 03:15.740
to share real human insights and experiences,

03:15.740 --> 03:18.580
to organize protests and celebrations,

03:18.580 --> 03:21.900
to learn and to challenge our understanding of the world,

03:21.900 --> 03:24.260
of our history and of our future,

03:24.260 --> 03:27.420
and above all, to be reminded of our common humanity.

03:28.480 --> 03:30.460
When the social networks fail,

03:30.460 --> 03:33.600
they have the power to cause immense suffering.

03:33.600 --> 03:34.980
And when they succeed,

03:34.980 --> 03:37.780
they have the power to lessen that suffering.

03:37.780 --> 03:39.300
This is hard.

03:39.300 --> 03:40.580
It's a responsibility,

03:40.580 --> 03:44.040
perhaps almost unlike any other in history.

03:44.040 --> 03:47.220
This podcast conversation attempts to understand the man

03:47.220 --> 03:50.640
and the company who take this responsibility on,

03:50.640 --> 03:53.220
where they fail and where they hope to succeed.

03:54.220 --> 03:57.900
Mark Zuckerberg's feet are often held to the fire,

03:57.900 --> 04:01.500
as they should be, and this actually gives me hope.

04:01.500 --> 04:03.860
The power of innovation and engineering,

04:03.860 --> 04:05.520
coupled with the freedom of speech

04:05.520 --> 04:07.660
in the form of its highest ideal,

04:07.660 --> 04:11.100
I believe can solve any problem in the world.

04:11.100 --> 04:12.640
But that's just it.

04:12.640 --> 04:14.760
Both are necessary.

04:14.760 --> 04:16.600
The engineer and the critic.

04:17.580 --> 04:20.520
I believe that criticism is essential,

04:20.520 --> 04:23.220
but cynicism is not.

04:23.220 --> 04:25.620
And I worry that in our public discourse,

04:25.620 --> 04:30.340
cynicism too easily masquerades as wisdom, as truth,

04:30.340 --> 04:32.180
becomes viral and takes over,

04:32.180 --> 04:35.420
and worse, suffocates the dreams of young minds

04:35.420 --> 04:39.220
who want to build solutions to the problems of the world.

04:39.220 --> 04:41.500
We need to inspire those young minds.

04:41.500 --> 04:43.700
At least for me, they give me hope.

04:44.540 --> 04:47.140
And one small way I'm trying to contribute

04:48.020 --> 04:49.500
is to have honest conversations like these

04:49.500 --> 04:53.220
that don't just ride the viral wave of cynicism,

04:53.220 --> 04:55.460
but seek to understand the failures and successes

04:55.460 --> 04:57.900
of the past, the problems before us,

04:57.900 --> 04:59.500
and the possible solutions

04:59.500 --> 05:02.540
in this very complicated world of ours.

05:02.540 --> 05:05.780
I'm sure I will fail often.

05:05.780 --> 05:10.180
And I count on the critic to point it out when I do.

05:10.180 --> 05:12.540
But I ask for one thing,

05:12.540 --> 05:15.180
and that is to fuel the fire of optimism,

05:15.220 --> 05:18.340
especially in those who dream to build solutions.

05:18.340 --> 05:21.780
Because without that, we don't have a chance

05:21.780 --> 05:24.600
on this too fragile, tiny planet of ours.

05:25.820 --> 05:28.020
This is the Lex Freedman podcast.

05:28.020 --> 05:30.260
To support it, please check out our sponsors

05:30.260 --> 05:31.620
in the description.

05:31.620 --> 05:35.620
And now, dear friends, here's Mark Zuckerberg.

05:40.980 --> 05:43.220
Can you circle all the traffic lights, please?

05:45.180 --> 05:46.020
Okay.

05:53.860 --> 05:54.820
You actually did it.

05:54.820 --> 05:56.780
That is very impressive performance.

05:56.780 --> 05:59.980
Okay, now we can initiate the interview procedure.

05:59.980 --> 06:02.940
Is it possible that this conversation is happening

06:02.940 --> 06:05.340
inside the metaverse created by you,

06:05.340 --> 06:07.140
by Meta many years from now,

06:07.140 --> 06:10.140
and we're doing a memory replay experience?

06:10.140 --> 06:11.580
I don't know the answer to that.

06:11.580 --> 06:15.220
Then I'd be some computer construct

06:15.220 --> 06:18.980
and not the person who created that Meta company.

06:18.980 --> 06:20.500
But that would truly be Meta.

06:21.380 --> 06:23.340
Right, so this could be somebody else

06:23.340 --> 06:26.420
using the Mark Zuckerberg avatar.

06:26.420 --> 06:29.200
You can do the Mark and the Lex conversation replay

06:29.200 --> 06:33.340
from four decades ago when Meta, it was first.

06:33.340 --> 06:34.800
I mean, it's not gonna be four decades

06:34.800 --> 06:38.020
before we have photorealistic avatars like this.

06:38.020 --> 06:40.100
So I think we're much closer to that.

06:40.100 --> 06:41.380
Well, that's something you talk about

06:41.380 --> 06:43.500
is how passionate you are about the idea

06:43.500 --> 06:46.580
of the avatar representing who you are in the metaverse.

06:46.580 --> 06:49.260
So I do these podcasts in person.

06:51.100 --> 06:52.260
You know, I'm a stickler for that

06:52.260 --> 06:55.780
because there's a magic to the in-person conversation.

06:55.780 --> 06:58.140
How long do you think it'll be before

06:58.140 --> 07:00.620
you can have the same kind of magic in the metaverse,

07:00.620 --> 07:02.620
the same kind of intimacy in the chemistry,

07:02.620 --> 07:05.620
whatever the heck is there when we're talking in person,

07:05.620 --> 07:07.100
how difficult is it,

07:07.100 --> 07:09.300
how long before we have it in the metaverse?

07:10.340 --> 07:12.940
Well, I think this is like the key question, right?

07:12.940 --> 07:17.500
Because the thing that's different about virtual

07:17.500 --> 07:19.140
and hopefully augmented reality

07:19.140 --> 07:22.380
compared to all other forms of digital platforms before

07:22.380 --> 07:24.420
is this feeling of presence, right?

07:24.420 --> 07:27.020
The feeling that you're right, that you're in an experience

07:27.020 --> 07:29.700
and that you're there with other people or in another place.

07:29.700 --> 07:32.300
And that's just different from all of the other screens

07:32.300 --> 07:33.900
that we have today, right?

07:33.900 --> 07:35.780
Phones, TVs, all this stuff.

07:35.780 --> 07:38.120
It's, you know, they're trying to, in some cases,

07:38.120 --> 07:43.040
deliver experiences that feel high fidelity,

07:43.040 --> 07:46.160
but at no point do you actually feel like you're in it,

07:46.160 --> 07:47.000
right?

07:47.000 --> 07:49.640
At some level, your content is trying to sort of convince you

07:49.640 --> 07:52.000
that this is a realistic thing that's happening,

07:52.000 --> 07:55.000
but all of the kind of subtle signals are telling you now,

07:55.000 --> 07:56.480
you're looking at a screen.

07:56.480 --> 08:00.680
So the question about how you develop these systems is like,

08:00.680 --> 08:03.880
what are all of the things that make the physical world,

08:03.880 --> 08:04.920
all the different cues?

08:04.920 --> 08:09.920
So I think on visual presence and spatial audio,

08:13.080 --> 08:15.440
we're making reasonable progress.

08:15.440 --> 08:16.960
Spatial audio makes a huge deal.

08:16.960 --> 08:19.600
I don't know if you've tried this experience,

08:19.600 --> 08:21.960
work rooms that we launched where you have meetings.

08:21.960 --> 08:24.800
And, you know, I basically made a rule for, you know,

08:24.800 --> 08:27.740
all of the top, you know, management folks at the company

08:27.740 --> 08:29.520
that they need to be doing standing meetings

08:29.520 --> 08:31.720
in work rooms already, right?

08:31.720 --> 08:33.600
I feel like we got to dog food this, you know,

08:33.600 --> 08:35.760
this is how people are gonna work in the future.

08:35.760 --> 08:37.840
So we have to adopt this now.

08:38.760 --> 08:41.080
And there are already a lot of things that I think

08:41.080 --> 08:44.760
feel significantly better than like typical Zoom meetings.

08:44.760 --> 08:47.440
Even though the avatars are a lot lower fidelity,

08:48.640 --> 08:50.760
you know, the idea that you have spatial audio,

08:50.760 --> 08:53.940
you're around a table in VR with people.

08:53.940 --> 08:55.240
If someone's talking from over there,

08:55.240 --> 08:56.860
it sounds like it's talking from over there.

08:56.860 --> 09:00.280
You can see, you know, the arm gestures and stuff

09:00.280 --> 09:01.760
feel more natural.

09:01.760 --> 09:03.080
You can have side conversations,

09:03.080 --> 09:04.880
which is something that you can't really do in Zoom.

09:04.880 --> 09:08.720
I mean, I guess you can text someone over like out of band,

09:08.720 --> 09:11.240
but, and if you're actually sitting around a table

09:11.240 --> 09:14.200
with people, you know, you can lean over

09:14.200 --> 09:15.560
and whisper to the person next to you

09:15.560 --> 09:18.000
and like have a conversation that you can't, you know,

09:18.000 --> 09:23.000
that you can't really do with in just video communication.

09:23.520 --> 09:27.500
So I think it's interesting in what ways

09:27.500 --> 09:29.840
some of these things already feel more real

09:29.840 --> 09:32.600
than a lot of the technology that we have.

09:32.600 --> 09:35.040
Even when the visual fidelity isn't quite there,

09:35.040 --> 09:37.180
but I think it'll get there over the next few years.

09:37.180 --> 09:38.760
Now, I mean, you were asking about comparing that

09:38.760 --> 09:40.480
to the true physical world,

09:40.480 --> 09:42.760
not Zoom or something like that.

09:42.760 --> 09:45.700
And there, I mean, I think you have feelings

09:45.700 --> 09:50.700
of like temperature, you know, olfactory,

09:50.720 --> 09:52.120
obviously touch, right?

09:52.120 --> 09:54.360
We're working on haptic gloves.

09:54.360 --> 09:56.460
You know, the sense that you wanna be able to, you know,

09:56.460 --> 09:59.720
put your hands down and feel some pressure from the table.

09:59.720 --> 10:01.000
You know, all these things I think are gonna be

10:01.000 --> 10:04.640
really critical to be able to keep up this illusion

10:04.640 --> 10:06.800
that you're in a world

10:06.800 --> 10:08.760
and that you're fully present in this world.

10:08.760 --> 10:10.360
But I don't know, I think we're gonna have

10:10.360 --> 10:12.640
a lot of these building blocks within, you know,

10:12.640 --> 10:14.200
the next 10 years or so.

10:14.200 --> 10:15.880
And even before that, I think it's amazing

10:15.880 --> 10:18.120
how much you're just gonna be able to build with software

10:18.120 --> 10:20.200
that sort of masks some of these things.

10:21.360 --> 10:22.800
I realize I'm going long,

10:22.800 --> 10:25.320
but I was told we have a few hours here.

10:25.320 --> 10:27.200
Yeah, we're here for five to six hours.

10:27.200 --> 10:28.960
Yeah, so I mean, look, I mean,

10:29.160 --> 10:30.440
that's on the shorter end

10:30.440 --> 10:32.520
of the congressional testimonies I've done.

10:32.520 --> 10:36.880
But it's, you know, one of the things that we found

10:36.880 --> 10:39.480
with hand presence, right?

10:39.480 --> 10:41.960
So the earliest VR, you just have the headset

10:41.960 --> 10:43.720
and then, and that was cool.

10:43.720 --> 10:45.360
You could look around, you feel like you're in a place,

10:45.360 --> 10:47.160
but you don't feel like you're really able to interact

10:47.160 --> 10:48.520
with it until you have hands.

10:48.520 --> 10:49.600
And then there was this big question

10:49.600 --> 10:51.280
where once you got hands,

10:51.280 --> 10:53.400
what's the right way to represent them?

10:53.400 --> 10:58.400
And initially, all of our assumptions was, okay,

10:58.560 --> 11:00.400
when I look down and see my hands in the physical world,

11:00.400 --> 11:02.760
I see an arm and it's gonna be super weird

11:02.760 --> 11:04.840
if you see, you know, just your hand.

11:06.480 --> 11:08.080
But it turned out to not be the case

11:08.080 --> 11:09.840
because there's this issue with your arms,

11:09.840 --> 11:11.560
which is like, what's your elbow angle?

11:11.560 --> 11:14.800
And if the elbow angle that we're kind of interpolating

11:14.800 --> 11:18.680
based on where your hand is and where your headset is,

11:18.680 --> 11:19.920
actually isn't accurate,

11:19.920 --> 11:21.920
it creates this very uncomfortable feeling

11:21.920 --> 11:24.440
where it's like, oh, like my arm is actually out like this,

11:24.440 --> 11:25.920
but it's like showing it in here.

11:25.920 --> 11:29.520
And that actually broke the feeling of presence a lot more,

11:29.520 --> 11:31.920
whereas it turns out that if you just show the hands

11:31.920 --> 11:36.200
and you don't show the arms, it actually is fine for people.

11:36.200 --> 11:38.400
So I think that there's a bunch

11:38.400 --> 11:41.080
of these interesting psychological cues

11:41.080 --> 11:44.960
where it'll be more about getting the right details right.

11:44.960 --> 11:46.920
And I think a lot of that will be possible

11:46.920 --> 11:49.800
even over a few year period or a five year period.

11:49.800 --> 11:52.080
And we won't need like every single thing to be solved

11:52.080 --> 11:54.640
to deliver this like full sense of presence.

11:54.640 --> 11:56.480
Yeah, it's a fascinating psychology question

11:56.480 --> 11:59.960
of what is the essence

11:59.960 --> 12:04.240
that makes in-person conversation special?

12:04.240 --> 12:08.040
It's like emojis are able to convey emotion really well,

12:08.040 --> 12:10.560
even though they're obviously not photorealistic.

12:10.560 --> 12:12.480
And so in that same way, just like you're saying,

12:12.480 --> 12:15.320
just showing the hands is able to create

12:15.320 --> 12:18.200
a comfortable expression with your hands.

12:18.200 --> 12:19.520
So I wonder what that is.

12:19.520 --> 12:21.920
People in the World Wars used to write letters

12:21.920 --> 12:24.360
and you can fall in love with just writing letters.

12:25.040 --> 12:26.640
You don't need to see each other in person.

12:26.640 --> 12:27.720
You can convey emotion.

12:27.720 --> 12:32.720
You can be depth of experience with just words.

12:32.720 --> 12:35.760
So that's a, I think a fascinating place

12:35.760 --> 12:37.480
to explore psychology of like,

12:37.480 --> 12:39.240
how do you find that intimacy?

12:39.240 --> 12:42.720
Yeah, and the way that I come to all of this stuff is,

12:42.720 --> 12:45.040
I basically studied psychology and computer science.

12:45.040 --> 12:47.920
So all of the work that I do

12:47.920 --> 12:49.880
is sort of at the intersection of those things.

12:49.880 --> 12:52.180
I think most of the other big tech companies

12:52.180 --> 12:55.060
are building technology for you to interact with.

12:55.060 --> 12:56.700
What I care about is building technology

12:56.700 --> 12:58.100
to help people interact with each other.

12:58.100 --> 12:59.900
So I think it's a somewhat different approach

12:59.900 --> 13:02.300
than most of the other tech entrepreneurs

13:02.300 --> 13:04.340
and big companies come at this from.

13:05.940 --> 13:08.940
And a lot of the lessons

13:08.940 --> 13:10.940
in terms of how I think about designing products

13:10.940 --> 13:15.940
come from some just basic elements of psychology, right?

13:15.940 --> 13:19.060
In terms of our brains,

13:19.060 --> 13:22.060
you can compare to the brains of other animals.

13:22.060 --> 13:25.540
We're very wired to specific things, facial expressions.

13:25.540 --> 13:28.220
Right, I mean, we're very visual, right?

13:28.220 --> 13:29.780
So compared to other animals, I mean,

13:29.780 --> 13:33.000
that's clearly the main sense that most people have.

13:34.100 --> 13:35.300
But there's whole part of your brain

13:35.300 --> 13:38.600
that's just kind of focused on reading facial cues.

13:38.600 --> 13:42.220
So when we're designing the next version of Quest

13:42.220 --> 13:45.840
or the VR headset, a big focus for us is face tracking

13:45.840 --> 13:48.900
and basically eye tracking so you can make eye contact,

13:48.900 --> 13:50.140
which again, isn't really something

13:50.140 --> 13:51.540
that you can do over a video conference.

13:51.540 --> 13:54.300
It's sort of amazing how much,

13:54.300 --> 13:56.160
how far video conferencing has gotten

13:56.160 --> 13:58.740
without the ability to make eye contact, right?

13:58.740 --> 14:00.540
It's sort of a bizarre thing if you think about it.

14:00.540 --> 14:03.140
You're like looking at someone's face,

14:03.140 --> 14:05.620
sometimes for an hour when you're in a meeting

14:05.620 --> 14:08.960
and like you looking at their eyes to them

14:08.960 --> 14:10.940
doesn't look like you're looking at their eyes.

14:10.940 --> 14:11.780
So it's a-

14:11.780 --> 14:13.060
Yeah, you're always looking, I mean,

14:13.060 --> 14:14.660
past each other, I guess.

14:14.660 --> 14:15.700
Yeah. I guess you're right.

14:15.700 --> 14:16.540
You're not sending that signal.

14:16.540 --> 14:17.360
Well, you're trying to.

14:17.360 --> 14:18.200
Right, you're trying to.

14:18.200 --> 14:19.740
Like a lot of times, I mean, or at least I find myself,

14:19.740 --> 14:21.420
I'm trying to look into the other person's eyes.

14:21.420 --> 14:23.060
They don't feel like you're looking to their eyes.

14:23.060 --> 14:23.900
Yeah, so then the question is,

14:23.900 --> 14:25.220
all right, am I supposed to look at the camera

14:25.220 --> 14:27.800
so that way you can have a sensation

14:27.800 --> 14:28.640
that I'm looking at you?

14:28.640 --> 14:30.100
I think that that's an interesting question.

14:30.100 --> 14:35.100
And then with VR today, even without eye tracking

14:35.660 --> 14:37.500
and knowing what your eyes are actually looking at,

14:37.500 --> 14:39.400
you can fake it reasonably well, right?

14:39.400 --> 14:42.240
So you can look at like where the head poses

14:42.240 --> 14:43.700
and if it looks like I'm kind of looking

14:43.700 --> 14:46.500
in your general direction, then you can sort of assume

14:46.500 --> 14:48.620
that maybe there's some eye contact intended

14:48.620 --> 14:50.740
and you can do it in a way where it's like,

14:50.740 --> 14:54.300
okay, maybe it's not a fixated stare,

14:54.300 --> 14:56.880
but it's somewhat natural.

14:56.880 --> 14:58.740
But once you have actual eye tracking,

14:58.740 --> 15:00.200
you can do it for real.

15:00.200 --> 15:02.140
And I think that that's really important stuff.

15:02.140 --> 15:05.300
So when I think about Meta's contribution to this field,

15:05.300 --> 15:06.660
I have to say, it's not clear to me

15:06.660 --> 15:09.500
that any of the other companies that are focused

15:09.500 --> 15:13.320
on the metaverse or on virtual and augmented reality

15:13.320 --> 15:15.840
are gonna prioritize putting these features in the hardware

15:15.840 --> 15:18.260
because like everything, they're trade-offs, right?

15:18.260 --> 15:21.500
I mean, it adds some weight to the device,

15:21.500 --> 15:22.740
maybe it adds some thickness.

15:22.740 --> 15:25.060
You could totally see another company taking the approach

15:25.060 --> 15:27.600
but just make the lightest and thinnest thing possible.

15:27.600 --> 15:31.380
But I want us to design the most human thing possible

15:31.380 --> 15:33.340
that creates the richest sense of presence

15:33.340 --> 15:37.900
and because so much of human emotion and expression

15:37.900 --> 15:39.500
comes from these like micro movements.

15:39.500 --> 15:42.660
If I like move my eyebrow millimeter, you will notice

15:42.660 --> 15:44.660
and that like means something.

15:44.660 --> 15:46.860
So the fact that we're losing these signals

15:47.180 --> 15:49.660
and a lot of communication I think is a loss.

15:49.660 --> 15:51.700
And so it's not like, okay, there's one feature

15:51.700 --> 15:53.300
and you add this, then it all of a sudden

15:53.300 --> 15:55.100
is gonna feel like we have real presence.

15:55.100 --> 15:57.820
You can sort of look at how the human brain works

15:57.820 --> 16:01.820
and how we express and kind of read emotions

16:01.820 --> 16:04.700
and you can just build a roadmap of that,

16:04.700 --> 16:06.460
of just what are the most important things

16:06.460 --> 16:08.520
to try to unlock over a five to 10 year period

16:08.520 --> 16:10.060
and just try to make the experience

16:10.060 --> 16:12.800
more and more human and social.

16:12.800 --> 16:16.640
When do you think would be a moment

16:16.640 --> 16:19.360
like a singularity moment for the metaverse

16:19.360 --> 16:22.280
where there's a lot of ways to ask this question

16:22.280 --> 16:26.560
but people will have many or most

16:26.560 --> 16:28.800
of their meaningful experiences

16:28.800 --> 16:31.320
in the metaverse versus the real world.

16:31.320 --> 16:33.400
And actually it's interesting to think about the fact

16:33.400 --> 16:36.640
that a lot of people are having the most important moments

16:36.640 --> 16:39.040
of their life happen in the digital sphere,

16:39.080 --> 16:40.520
especially now during COVID,

16:41.640 --> 16:45.000
like even falling in love or meeting friends

16:45.000 --> 16:47.280
or getting excited about stuff that is happening

16:47.280 --> 16:49.640
on the 2D digital plane.

16:49.640 --> 16:51.320
When do you think the metaverse will provide

16:51.320 --> 16:54.080
those experiences for a large number,

16:54.080 --> 16:54.920
like a majority of the population?

16:54.920 --> 16:57.240
Yeah, I think it's a really good question.

16:57.240 --> 17:01.480
There was someone, I read this piece that framed this as,

17:02.880 --> 17:06.040
a lot of people think that the metaverse is about a place

17:06.040 --> 17:10.400
but one definition of this is it's about a time

17:10.400 --> 17:12.880
when basically immersive digital worlds

17:12.880 --> 17:17.080
become the primary way that we live our lives

17:17.080 --> 17:18.720
and spend our time.

17:18.720 --> 17:20.160
I think that that's a reasonable construct

17:20.160 --> 17:21.880
and from that perspective,

17:21.880 --> 17:25.520
I think you also just wanna look at this as a continuation

17:25.520 --> 17:28.920
because it's not like, okay, we are building digital worlds

17:28.920 --> 17:29.800
but we don't have that today.

17:29.800 --> 17:32.280
I think you and I probably already live

17:32.280 --> 17:34.620
a very large part of our life in digital worlds.

17:34.620 --> 17:37.220
They're just not 3D immersive virtual reality

17:37.220 --> 17:39.780
but I do a lot of meetings over video

17:39.780 --> 17:42.260
or I spend a lot of time writing things over email

17:42.260 --> 17:44.500
or WhatsApp or whatever.

17:44.500 --> 17:46.020
So what is it gonna take to get there

17:46.020 --> 17:48.660
for kind of the immersive presence version of this,

17:48.660 --> 17:51.020
which I think is what you're asking.

17:51.020 --> 17:52.900
And for that, I think that there's just a bunch

17:52.900 --> 17:57.900
of different use cases and I think when you're building

17:57.900 --> 18:02.900
technology, I think a lot of it is just you're managing

18:04.900 --> 18:06.940
this duality where on the one hand,

18:06.940 --> 18:10.060
you wanna build these elegant things that can scale

18:10.060 --> 18:12.100
and have billions of people use them

18:12.100 --> 18:13.300
and get value from them.

18:13.300 --> 18:14.500
And then on the other hand,

18:14.500 --> 18:16.980
you're fighting this kind of ground game

18:16.980 --> 18:19.660
where there are just a lot of different use cases

18:19.660 --> 18:20.860
and people do different things

18:20.860 --> 18:22.220
and you wanna be able to unlock them.

18:22.220 --> 18:25.900
So the first ones that we basically went after

18:25.940 --> 18:30.340
were gaming with Quest and social experiences.

18:30.340 --> 18:32.340
And this is, it goes back to when we started

18:32.340 --> 18:33.380
working on virtual reality.

18:33.380 --> 18:36.140
My theory at the time was basically

18:37.380 --> 18:39.420
people thought about it as gaming

18:39.420 --> 18:44.160
but if you look at all computing platforms up to that point,

18:45.100 --> 18:47.460
gaming is a huge part, it was a huge part of PCs,

18:47.460 --> 18:49.500
it was a huge part of mobile

18:49.500 --> 18:51.980
but it was also very decentralized, right?

18:51.980 --> 18:54.260
There wasn't, for the most part,

18:54.260 --> 18:55.700
one or two gaming companies,

18:56.540 --> 18:57.460
there were a lot of gaming companies

18:57.460 --> 18:58.700
and gaming is somewhat hits based.

18:58.700 --> 19:00.340
I mean, we're getting some games

19:00.340 --> 19:03.900
that have more longevity but in general,

19:03.900 --> 19:06.580
there were a lot of different games out there.

19:06.580 --> 19:11.580
But on PC and on mobile,

19:11.580 --> 19:13.700
the companies that focused on communication

19:13.700 --> 19:15.100
and social interaction,

19:15.100 --> 19:17.260
there tended to be a smaller number of those

19:17.260 --> 19:19.140
and that ended up being just as important of a thing

19:19.140 --> 19:21.580
as all of the games that you did combined.

19:21.580 --> 19:23.140
I think productivity is another area.

19:23.140 --> 19:24.680
That's obviously something that we've historically

19:24.680 --> 19:26.000
been less focused on

19:26.000 --> 19:27.200
but I think it's gonna be really important for us.

19:27.200 --> 19:29.560
With workroom or do you mean productivity

19:29.560 --> 19:30.840
in the collaborative aspect?

19:30.840 --> 19:34.360
Yeah, I think that there's a workroom's aspect of this,

19:34.360 --> 19:36.120
like a meeting aspect and then I think that there's

19:36.120 --> 19:40.360
like a Word, Excel, productivity.

19:41.360 --> 19:44.600
You're working or coding or knowledge work, right?

19:44.600 --> 19:46.760
As opposed to just meetings.

19:46.760 --> 19:47.760
So you can kind of go through

19:47.760 --> 19:49.600
all these different use cases.

19:49.600 --> 19:51.280
Gaming, I think we're well on our way.

19:51.280 --> 19:56.080
Social, I think we're just the kind of preeminent company

19:56.080 --> 19:57.040
that focuses on this.

19:57.040 --> 20:00.440
And I think that that's already on Quest becoming the,

20:00.440 --> 20:03.480
if you look at the list of what are the top apps,

20:03.480 --> 20:06.460
social apps are already number one, two, three.

20:06.460 --> 20:09.220
So that's kind of becoming a critical thing.

20:10.480 --> 20:12.560
But I don't know, I would imagine for someone like you,

20:12.560 --> 20:17.560
it'll be until we get a lot of the work things dialed in,

20:17.720 --> 20:20.840
when this is just like much more adopted

20:21.640 --> 20:24.280
and clearly better than Zoom for VC,

20:24.280 --> 20:27.080
when if you're doing your coding or your writing

20:27.080 --> 20:29.440
or whatever it is in VR,

20:29.440 --> 20:31.240
which it's not that far off to imagine that

20:31.240 --> 20:32.640
because pretty soon you're just gonna be able

20:32.640 --> 20:34.200
to have a screen that's bigger than,

20:34.200 --> 20:36.160
it'll be your ideal setup and you can bring it with you

20:36.160 --> 20:38.640
and put it on anywhere and have your kind

20:38.640 --> 20:39.800
of ideal workstation.

20:39.800 --> 20:42.580
So I think that there are a few things to work out on that,

20:42.580 --> 20:46.960
but I don't think that that's more than five years off.

20:46.960 --> 20:48.120
And then you'll get a bunch of other things

20:48.120 --> 20:50.200
that like aren't even possible

20:50.200 --> 20:52.040
or you don't even think about using a phone

20:52.040 --> 20:54.440
or PC for today, like fitness, right?

20:54.440 --> 20:57.480
So I mean, I know we were talking before

20:57.480 --> 20:58.980
about how you're into running

20:58.980 --> 21:00.760
and like I'm really into a lot of things

21:00.760 --> 21:02.720
around fitness as well,

21:02.720 --> 21:04.120
different things in different places.

21:04.120 --> 21:06.280
I got really into hydrofoiling recently and-

21:06.280 --> 21:08.360
Nice, I saw a video.

21:08.360 --> 21:12.440
Yeah, and surfing and I used to fence competitively,

21:12.440 --> 21:13.680
I like run.

21:13.680 --> 21:14.840
And you were saying that you were thinking

21:14.840 --> 21:16.360
about trying different martial arts

21:16.360 --> 21:18.200
and I tried to trick you and convince you

21:18.200 --> 21:19.960
into doing Brazilian jiu-jitsu.

21:19.960 --> 21:21.520
Or you actually mentioned that that was one

21:21.520 --> 21:23.000
you're curious about and I-

21:23.000 --> 21:24.160
Is that a trick?

21:24.160 --> 21:26.080
Yeah, I don't know.

21:26.080 --> 21:27.440
We're in the metaverse now.

21:27.440 --> 21:29.600
Yeah, no, I mean, I took that seriously.

21:29.600 --> 21:34.360
I thought that that was a real suggestion.

21:34.360 --> 21:36.440
That would be an amazing chance

21:36.440 --> 21:37.800
if we ever step on the mat together

21:37.800 --> 21:39.080
and just like roll around.

21:39.080 --> 21:40.160
I'll show you some moves.

21:40.160 --> 21:43.080
Well, give me a year to train and then we can do it.

21:43.080 --> 21:44.800
This is like, you know, you've seen Rocky IV

21:44.800 --> 21:46.400
where the Russian faces off the American.

21:46.400 --> 21:48.040
I'm the Russian in this picture.

21:48.880 --> 21:50.720
And then you're the Rocky, the underdog

21:50.720 --> 21:52.160
that gets to win in the end.

21:52.160 --> 21:56.200
The idea of me as Rocky and like fighting is-

21:56.200 --> 21:58.160
If he dies, he dies.

21:58.160 --> 22:00.720
Sorry, just had to-

22:00.720 --> 22:01.560
I mean-

22:01.560 --> 22:02.640
Anyway, yeah.

22:02.640 --> 22:05.880
But I mean, a lot of aspects of fitness,

22:05.880 --> 22:08.760
you know, I don't know if you've tried supernatural

22:08.760 --> 22:10.160
on Quest or-

22:10.160 --> 22:12.080
So first of all, can I just comment on the fact

22:12.080 --> 22:15.000
every time I played around with Quest II,

22:15.800 --> 22:18.760
I get giddy every time I step into virtual reality.

22:18.760 --> 22:20.880
So you mentioned productivity and all those kinds of things.

22:20.880 --> 22:23.800
That's definitely something I'm excited about,

22:23.800 --> 22:26.760
but really I just love the possibilities

22:26.760 --> 22:28.840
of stepping into that world.

22:28.840 --> 22:30.440
Maybe it's the introvert in me,

22:30.440 --> 22:34.080
but it just feels like the most convenient way

22:34.080 --> 22:37.840
to travel into worlds,

22:37.840 --> 22:40.320
worlds that are similar to the real world

22:40.320 --> 22:41.640
or totally different.

22:41.640 --> 22:42.840
It's like Alice in Wonderland.

22:42.840 --> 22:44.680
Just try out crazy stuff.

22:44.680 --> 22:46.480
The possibilities are endless.

22:46.480 --> 22:50.920
I personally just love,

22:50.920 --> 22:54.000
get excited for stepping into those virtual worlds.

22:54.000 --> 22:55.040
So I'm a huge fan.

22:55.040 --> 22:58.360
In terms of the productivity as a programmer,

22:58.360 --> 23:00.080
I spend most of my day programming.

23:00.080 --> 23:02.040
That's really interesting also,

23:02.040 --> 23:04.360
but then you have to develop the right IDEs.

23:04.360 --> 23:05.320
You have to develop-

23:05.320 --> 23:06.160
Yeah.

23:06.160 --> 23:08.360
There has to be a threshold where a large amount

23:08.360 --> 23:10.560
of the programming community moves there,

23:10.560 --> 23:13.080
but the collaborative aspects that are possible

23:13.080 --> 23:14.280
in terms of meetings,

23:14.280 --> 23:18.400
in terms of when two coders are working together.

23:18.400 --> 23:21.800
I mean, the possibilities there are super, super exciting.

23:21.800 --> 23:24.240
I think that in building this,

23:24.240 --> 23:25.880
we sort of need to balance.

23:27.120 --> 23:28.200
There are gonna be some new things

23:28.200 --> 23:29.720
that you just couldn't do before,

23:29.720 --> 23:31.560
and those are gonna be the amazing experiences.

23:31.560 --> 23:33.440
So teleporting to any place,

23:33.440 --> 23:37.080
whether it's a real place or something that people made.

23:38.080 --> 23:40.560
And I mean, some of the experiences around

23:40.560 --> 23:42.080
how we can build stuff in new ways,

23:42.080 --> 23:45.680
where a lot of the stuff that when I'm coding stuff,

23:45.680 --> 23:46.520
it's like, all right, you code it,

23:46.520 --> 23:48.240
and then you build it, and then you see it afterwards.

23:48.240 --> 23:50.480
But increasingly, it's gonna be possible to,

23:50.480 --> 23:52.760
you're in a world and you're building the world

23:52.760 --> 23:55.760
as you are in it and kind of manipulating it.

23:55.760 --> 23:58.720
One of the things that we showed at our Inside the Lab

23:59.880 --> 24:02.520
for recent artificial intelligence progress

24:02.520 --> 24:03.920
is this BuilderBot program,

24:03.920 --> 24:06.880
where now you can just talk to it

24:06.880 --> 24:08.880
and say, hey, okay, I'm in this world.

24:08.880 --> 24:10.720
Put some trees over there, and it'll do that.

24:10.720 --> 24:13.200
And like, all right, put some bottles of water

24:13.200 --> 24:17.040
on our picnic blanket, and it'll do that,

24:17.040 --> 24:17.880
and you're in the world.

24:17.880 --> 24:19.920
And I think there are gonna be new paradigms for coding.

24:19.920 --> 24:22.080
So yeah, there are gonna be some things

24:22.080 --> 24:24.600
that I think are just pretty amazing,

24:24.600 --> 24:26.600
especially the first few times that you do them,

24:26.600 --> 24:28.560
that you're like, whoa,

24:28.560 --> 24:30.640
I've never had an experience like this.

24:30.640 --> 24:34.280
But most of your life, I would imagine,

24:34.280 --> 24:38.160
is not doing things that are amazing for the first time.

24:38.160 --> 24:39.600
A lot of this in terms of,

24:39.600 --> 24:42.000
I mean, just answering your question from before around,

24:42.000 --> 24:43.440
what is it gonna take before you're spending

24:43.440 --> 24:45.040
most of your time in this?

24:45.040 --> 24:48.200
Well, first of all, let me just say this as an aside,

24:48.200 --> 24:49.400
the goal isn't to have people

24:49.400 --> 24:50.960
spend a lot more time in computing.

24:50.960 --> 24:52.360
I'm asking for myself.

24:52.360 --> 24:54.960
When will I spend all my time in computing?

24:54.960 --> 24:57.040
Yeah, it's to make computing more natural.

24:57.040 --> 25:02.040
But I think you will spend most of your computing time

25:02.680 --> 25:04.840
in this when it does the things

25:04.840 --> 25:07.240
that you use computing for somewhat better.

25:07.240 --> 25:10.480
So maybe having your perfect workstation

25:10.480 --> 25:15.080
is a 5% improvement on your coding productivity.

25:15.080 --> 25:18.360
Maybe it's not like a completely new thing.

25:19.240 --> 25:21.560
But I mean, look, if I could increase the productivity

25:21.560 --> 25:23.960
of every engineer at Meta by 5%,

25:25.480 --> 25:27.600
we'd buy those devices for everyone.

25:27.600 --> 25:30.320
And I imagine a lot of other companies would too.

25:30.320 --> 25:31.800
And that's how you start getting to the scale

25:32.760 --> 25:34.480
that I think makes this rival

25:34.480 --> 25:37.040
some of the bigger computing platforms that exist today.

25:37.040 --> 25:38.280
Let me ask you about identity.

25:38.280 --> 25:40.440
We talked about the avatar.

25:40.440 --> 25:42.720
How do you see identity in the metaverse?

25:42.720 --> 25:46.400
Should the avatar be tied to your identity

25:46.400 --> 25:49.280
or can I be anything in the metaverse?

25:49.280 --> 25:52.160
Like can I be whatever the heck I want?

25:52.160 --> 25:53.640
Can I even be a troll?

25:53.640 --> 25:57.440
So there's exciting freeing possibilities

25:57.440 --> 25:59.400
and there's the darker possibilities too.

26:00.400 --> 26:02.840
Yeah, I mean, I think that there's gonna be a range, right?

26:02.840 --> 26:07.240
So we're working on for expression and avatars

26:09.880 --> 26:11.040
on one end of the spectrum

26:11.040 --> 26:14.560
are kind of expressive and cartoonish avatars.

26:14.560 --> 26:16.120
And then on the other end of the spectrum

26:16.120 --> 26:18.120
are photorealistic avatars.

26:18.120 --> 26:20.480
And I just think the reality is that

26:20.480 --> 26:23.280
there are gonna be different use cases for different things.

26:23.280 --> 26:24.800
And I guess there's another access.

26:24.800 --> 26:28.360
So if you're going from photorealistic to expressive,

26:28.720 --> 26:31.120
there's also like representing you directly

26:31.120 --> 26:33.680
versus like some fantasy identity.

26:33.680 --> 26:35.360
And I think that there are gonna be things

26:35.360 --> 26:37.880
on all ends of that spectrum too, right?

26:37.880 --> 26:41.040
So you'll want photo, like in some experience

26:41.040 --> 26:44.320
you might wanna be like a photorealistic dragon, right?

26:44.320 --> 26:47.000
Or, you know, if I'm playing onward

26:47.000 --> 26:50.040
or just this military simulator game, you know,

26:50.040 --> 26:52.840
it's, you know, I think getting to be more photorealistic

26:52.840 --> 26:56.800
as a soldier in that could enhance the experience.

26:57.760 --> 26:59.520
There are times when I'm hanging out with friends

26:59.520 --> 27:02.040
where I want them to, you know, know it's me.

27:02.040 --> 27:06.160
So a kind of cartoonish or expressive version of me is good.

27:06.160 --> 27:09.400
But there are also experiences like,

27:09.400 --> 27:11.560
you know, VR chat does this well today

27:11.560 --> 27:14.880
where a lot of the experience is kind of dressing up

27:14.880 --> 27:17.760
and wearing a fantastical avatar

27:17.760 --> 27:19.520
that's almost like a meme or is humorous.

27:19.520 --> 27:22.280
So you come into an experience and it's almost like

27:22.280 --> 27:24.520
you have like a built-in icebreaker

27:24.560 --> 27:27.320
because like you see people and you're just like,

27:27.320 --> 27:29.960
all right, like I'm cracking up at what you're wearing

27:29.960 --> 27:30.800
because that's funny.

27:30.800 --> 27:31.920
And it's just like, where'd you get that?

27:31.920 --> 27:32.760
Or, oh, you made that?

27:32.760 --> 27:34.360
That's, you know, it's awesome.

27:35.520 --> 27:38.920
Whereas, you know, okay, if you're going into a work meeting

27:38.920 --> 27:41.800
maybe a photorealistic version of your real self

27:41.800 --> 27:43.600
is gonna be the most appropriate thing for that.

27:43.600 --> 27:47.400
So I think the reality is there aren't going to be,

27:47.400 --> 27:49.000
it's not just gonna be one thing.

27:50.520 --> 27:54.400
You know, my own sense of kind of how you wanna

27:54.400 --> 27:56.880
express identity online has sort of evolved over time

27:56.880 --> 27:58.640
and that, you know, early days in Facebook,

27:58.640 --> 28:00.280
I thought, okay, people are gonna have one identity.

28:00.280 --> 28:02.080
And now I think that's clearly not gonna be the case.

28:02.080 --> 28:04.400
I think you're gonna have all these different things

28:04.400 --> 28:07.320
and there's utility in being able to do different things.

28:07.320 --> 28:10.120
So some of the technical challenges

28:10.120 --> 28:12.120
that I'm really interested in around it

28:12.120 --> 28:14.840
are how do you build the software to allow people

28:14.840 --> 28:17.080
to seamlessly go between them?

28:17.080 --> 28:22.080
So say, so you could view them as just completely

28:22.920 --> 28:25.120
discrete points on a spectrum,

28:25.120 --> 28:28.480
but let's talk about the metaverse economy for a second.

28:28.480 --> 28:31.200
Let's say I buy a digital shirt

28:31.200 --> 28:34.400
for my photorealistic avatar, which by the way,

28:34.400 --> 28:36.440
I think at the time where we're spending a lot of time

28:36.440 --> 28:38.720
in the metaverse doing a lot of our work meetings

28:38.720 --> 28:40.240
in the metaverse and et cetera,

28:40.240 --> 28:42.440
I would imagine that the economy around virtual clothing

28:42.440 --> 28:44.640
as an example is going to be quite as big.

28:44.640 --> 28:47.080
Why wouldn't I spend almost as much money

28:47.080 --> 28:49.760
in investing in my appearance or expression

28:49.800 --> 28:52.400
for my photorealistic avatar for meetings

28:52.400 --> 28:55.520
as I would for whatever I'm gonna wear in my video chat.

28:55.520 --> 28:57.600
But the question is, okay, so let's say you buy some shirt

28:57.600 --> 28:59.800
for your photorealistic avatar.

28:59.800 --> 29:02.600
Wouldn't it be cool if there was a way

29:02.600 --> 29:07.600
to basically translate that into a more expressive thing

29:07.920 --> 29:11.160
for your kind of cartoonish or expressive avatar?

29:11.160 --> 29:12.520
And there are multiple ways to do that.

29:12.520 --> 29:14.200
You can view them as two discrete points

29:14.200 --> 29:18.160
and okay, maybe if a designer sells one thing,

29:18.160 --> 29:19.880
then it actually comes in a pack and there's two

29:19.880 --> 29:22.280
and you can use either one on that.

29:22.280 --> 29:24.360
But I actually think this stuff might exist more

29:24.360 --> 29:26.040
as a spectrum in the future.

29:26.040 --> 29:29.400
And that's what I do think the direction

29:29.400 --> 29:33.280
on some of the AI advances that is happening

29:33.280 --> 29:35.880
to be able to, especially stuff around like style transfer,

29:35.880 --> 29:39.800
being able to take a piece of art or express something

29:39.800 --> 29:42.240
and say, okay, paint me this photo

29:43.360 --> 29:46.480
in the style of Gauguin or whoever it is

29:46.480 --> 29:48.000
that you're interested in.

29:49.000 --> 29:51.240
Take this shirt and put it in the style

29:51.240 --> 29:53.760
of what I've designed for my expressive avatar.

29:55.160 --> 29:56.880
I think that's gonna be pretty compelling.

29:56.880 --> 30:00.000
And so the fashion, you might be buying like a generator,

30:00.000 --> 30:03.240
like a closet that generates a style.

30:03.240 --> 30:05.480
And then like with the GANs,

30:05.480 --> 30:08.120
they'll be able to infinitely generate outfits

30:08.120 --> 30:10.720
thereby making it, so the reason I wear the same thing

30:10.720 --> 30:12.320
all the time is I don't like choice.

30:12.320 --> 30:15.080
You've talked about the same thing,

30:15.080 --> 30:16.640
but now you don't even have to choose.

30:16.640 --> 30:19.440
Your closet generates your outfit for you every time.

30:19.440 --> 30:23.400
And so you have to live with the outfit it generates.

30:23.400 --> 30:24.560
I mean, you could do that.

30:24.560 --> 30:27.440
Although, no, I think some people will,

30:27.440 --> 30:30.000
but I think like, I think that there's going to be

30:30.000 --> 30:35.000
a huge aspect of just people doing creative commerce here.

30:35.840 --> 30:37.800
So I think that there is going to be a big market

30:37.800 --> 30:41.000
around people designing digital clothing.

30:41.000 --> 30:42.960
But the question is, if you're designing digital clothing,

30:42.960 --> 30:44.800
do you need to design, if you're the designer,

30:44.800 --> 30:47.640
do you need to make it for each kind of specific,

30:47.640 --> 30:49.960
discrete point along a spectrum?

30:49.960 --> 30:52.760
Or are you just designing it for kind of a photorealistic

30:52.760 --> 30:54.120
case or an expressive case?

30:54.120 --> 30:56.200
Or can you design one and have it translate

30:56.200 --> 30:57.960
across these things?

30:57.960 --> 31:00.560
You know, if I buy a style from, you know,

31:00.560 --> 31:03.000
a designer who I care about and now I'm a dragon,

31:03.000 --> 31:04.240
you know, is there a way to morph that

31:04.240 --> 31:07.640
so it like goes on the dragon in a way that makes sense?

31:07.640 --> 31:09.480
And that I think is an interesting AI problem

31:09.480 --> 31:10.800
because you're probably not going to make it

31:10.800 --> 31:14.720
so that designers have to go design for all those things.

31:14.720 --> 31:17.920
But the more useful the digital content is that you buy

31:17.920 --> 31:21.240
in a lot of uses, in a lot of use cases,

31:21.240 --> 31:23.440
the more that economy will just explode.

31:23.440 --> 31:25.800
And that's a lot of what, you know, all of the,

31:26.800 --> 31:29.720
you know, we were joking about NFTs before,

31:29.720 --> 31:32.600
but I think a lot of the promise here is that

31:32.600 --> 31:35.040
if the digital goods that you buy are not just tied

31:35.040 --> 31:37.080
to one platform or one use case,

31:37.080 --> 31:38.280
they end up being more valuable,

31:38.280 --> 31:39.840
which means that people are more willing

31:39.840 --> 31:41.320
and more likely to invest in them.

31:41.320 --> 31:44.240
And that just spurs the whole economy.

31:44.280 --> 31:47.320
But the question is, so that's a fascinating positive aspect,

31:47.320 --> 31:50.840
but the potential negative aspect is that

31:50.840 --> 31:52.720
you can have people concealing their identity

31:52.720 --> 31:57.080
in order to troll or even not people, bots.

31:57.080 --> 31:58.760
So how do you know in the metaverse

31:58.760 --> 32:02.080
that you're talking to a real human or an AI

32:02.080 --> 32:03.920
or a well-intentioned human?

32:03.920 --> 32:05.000
Is that something you think about,

32:05.000 --> 32:06.960
something you're concerned about?

32:06.960 --> 32:10.280
Well, let's break that down into a few different cases.

32:10.280 --> 32:12.000
I mean, cause knowing that you're talking to someone

32:12.000 --> 32:13.880
who has good intentions is something that I think

32:13.880 --> 32:17.840
is not even solved in pretty much anywhere.

32:17.840 --> 32:20.360
But if you're talking to someone who's a dragon,

32:20.360 --> 32:21.480
I think it's pretty clear that they're not

32:21.480 --> 32:23.320
representing themselves as a person.

32:23.320 --> 32:25.320
I think probably the most pernicious thing

32:25.320 --> 32:28.560
that you want to solve for is,

32:30.120 --> 32:32.040
I think probably one of the scariest ones

32:32.040 --> 32:33.160
is how do you make sure that someone

32:33.160 --> 32:35.040
isn't impersonating you, right?

32:35.040 --> 32:37.520
So like, okay, you're in a future version

32:37.520 --> 32:41.720
of this conversation and we have photorealistic avatars

32:41.720 --> 32:43.320
and we're doing this in workrooms

32:43.320 --> 32:45.000
or whatever the future version of that is,

32:45.000 --> 32:48.880
and someone walks in who like looks like me.

32:48.880 --> 32:50.320
How do you know that that's me?

32:50.320 --> 32:54.840
And one of the things that we're thinking about is,

32:54.840 --> 32:57.560
it's still a pretty big AI project

32:57.560 --> 32:59.520
to be able to generate photorealistic avatars

32:59.520 --> 33:00.920
that basically can like,

33:00.920 --> 33:03.440
they work like these codecs of you, right?

33:03.440 --> 33:06.240
So you kind of have a map from your headset

33:06.240 --> 33:08.080
and whatever sensors of what your body's actually doing

33:08.080 --> 33:11.200
and it takes the model and it kind of displays it in VR.

33:11.200 --> 33:12.440
But there's a question,

33:12.440 --> 33:15.440
which is should there be some sort of biometric security

33:15.440 --> 33:18.240
so that like when I put on my VR headset

33:18.240 --> 33:20.960
or I'm going to go use that avatar,

33:20.960 --> 33:24.360
I need to first prove that I am that.

33:24.360 --> 33:26.800
And I think you probably are gonna want something like that.

33:26.800 --> 33:31.160
So as we're developing these technologies,

33:31.160 --> 33:34.680
we're also thinking about the security for things like that

33:34.680 --> 33:37.120
because people aren't gonna want to be impersonated.

33:37.120 --> 33:38.920
That's a huge security issue.

33:38.920 --> 33:40.640
Then you just get the question of people

33:40.640 --> 33:45.640
hiding behind fake accounts to do malicious things,

33:45.640 --> 33:48.320
which is not gonna be unique to the metaverse.

33:48.320 --> 33:53.320
Although, you know, certainly in a environment

33:53.320 --> 33:54.480
where it's more immersive

33:54.480 --> 33:55.880
and you have more of a sense of presence,

33:55.880 --> 33:58.640
it could be more painful.

33:58.640 --> 34:01.320
But this is obviously something that we've just dealt with

34:01.320 --> 34:05.880
for years in social media and the internet more broadly.

34:05.880 --> 34:08.560
And I think that's a really important thing

34:08.720 --> 34:13.120
and there I think there have been a bunch of tactics

34:13.120 --> 34:17.760
that I think we've just evolved to,

34:17.760 --> 34:20.480
you know, we've built up these different AI systems

34:20.480 --> 34:21.880
to basically get a sense of,

34:21.880 --> 34:26.360
is this account behaving in the way that a person would?

34:26.360 --> 34:28.360
And it turns out, you know,

34:28.360 --> 34:31.800
so in all of the work that we've done around,

34:31.800 --> 34:33.320
you know, we call it community integrity

34:33.320 --> 34:36.920
and it's basically like policing harmful content

34:36.920 --> 34:38.360
and trying to figure out where to draw the line.

34:38.360 --> 34:39.800
And there are all these like really hard

34:39.800 --> 34:41.280
and philosophical questions around like,

34:41.280 --> 34:42.880
where do you draw the line on some of this stuff?

34:42.880 --> 34:47.800
And the thing that I've kind of found the most effective

34:47.800 --> 34:51.200
is as much as possible trying to figure out

34:51.200 --> 34:53.360
who are the inauthentic accounts

34:53.360 --> 34:55.520
or where are the accounts that are behaving

34:55.520 --> 34:58.400
in an overall harmful way at the account level,

34:58.400 --> 35:00.400
rather than trying to get into like policing

35:00.400 --> 35:01.400
what they're saying, right?

35:01.400 --> 35:03.680
Which I think the metaverse is gonna be even harder

35:03.680 --> 35:07.280
because the metaverse I think will have more properties of,

35:07.320 --> 35:09.200
it's almost more like a phone call, right?

35:09.200 --> 35:12.360
Or like, you know, it's not like I post a piece of content

35:12.360 --> 35:14.720
and is that piece of content good or bad?

35:14.720 --> 35:16.240
So I think more of this stuff will have to be done

35:16.240 --> 35:19.440
at the level of the account.

35:19.440 --> 35:21.720
But this is the area where, you know,

35:21.720 --> 35:25.920
between the kind of, you know,

35:25.920 --> 35:27.680
counterintelligence teams that we've built up

35:27.680 --> 35:29.880
inside the company and like years of building

35:31.280 --> 35:34.320
just different AI systems to basically detect

35:34.320 --> 35:36.880
what is a real account and what isn't.

35:36.880 --> 35:38.640
I'm not saying we're perfect, but like,

35:38.640 --> 35:42.160
this is an area where I just think we are like years ahead

35:42.160 --> 35:44.920
of basically anyone else in the industry

35:44.920 --> 35:48.080
in terms of having built those capabilities.

35:48.080 --> 35:50.160
And I think that that just is gonna be incredibly important

35:50.160 --> 35:51.480
for this next wave of things.

35:51.480 --> 35:53.440
And like you said, on a technical level,

35:53.440 --> 35:54.920
on a philosophical level,

35:54.920 --> 35:57.640
it's an incredibly difficult problem to solve.

35:59.200 --> 36:03.200
By the way, I would probably like to open source my avatar

36:03.200 --> 36:05.880
so that could be like millions of Lexes walking around,

36:05.880 --> 36:07.000
just like an army.

36:07.000 --> 36:08.440
Like Agent Smith?

36:08.440 --> 36:10.680
Agent Smith, yeah, exactly.

36:10.680 --> 36:15.680
So the Unity ML folks built a copy of me

36:16.360 --> 36:18.400
and they sent it to me.

36:18.400 --> 36:20.200
So there's a person running around

36:20.200 --> 36:22.440
and I'd just been doing reinforcement learning on it.

36:22.440 --> 36:26.440
I was gonna release it because, you know,

36:26.440 --> 36:29.840
just to have sort of like thousands of Lexes

36:29.840 --> 36:32.440
doing reinforcement, so they fall over naturally.

36:32.440 --> 36:34.880
They have to learn how to like walk around and stuff.

36:34.880 --> 36:37.240
So I love that idea of this tension

36:37.240 --> 36:40.360
between biometric security, you want to have one identity,

36:40.360 --> 36:43.600
but then certain avatars, you might have to have many.

36:43.600 --> 36:45.400
I don't know which is better security,

36:45.400 --> 36:48.120
sort of flooding the world with Lexes

36:48.120 --> 36:49.440
and thereby achieving security

36:49.440 --> 36:51.800
or really being protected over your identity.

36:51.800 --> 36:53.840
I have to ask you a security question actually.

36:53.840 --> 36:56.840
Well, how does flooding the world with Lexes help me know

36:56.840 --> 36:59.640
in our conversation that I'm talking to the real Lex?

36:59.640 --> 37:01.560
I completely destroy the trust

37:01.560 --> 37:03.040
in all my relationships then, right?

37:03.040 --> 37:06.680
Like if I flood, because then it's, yeah, that.

37:07.800 --> 37:09.480
I think that one's not gonna work that well for you.

37:09.480 --> 37:11.880
It's not gonna work for the original copy.

37:11.880 --> 37:13.320
It probably fits some things.

37:13.320 --> 37:14.760
Like if you're a public figure

37:14.760 --> 37:18.440
and you're trying to have, you know, a bunch of,

37:18.440 --> 37:19.440
if you're trying to show up

37:19.440 --> 37:21.040
in a bunch of different places in the future,

37:21.040 --> 37:23.480
you'll be able to do that in the metaverse.

37:23.480 --> 37:26.120
So that kind of replication I think will be useful.

37:26.120 --> 37:29.240
But I do think that you're gonna want a notion of like,

37:29.240 --> 37:31.480
I am talking to the real one.

37:31.480 --> 37:32.680
Yeah.

37:32.680 --> 37:35.640
Yeah, especially if the fake ones start outperforming you

37:35.640 --> 37:37.400
in all your private relationships

37:37.400 --> 37:38.680
and then you're left behind.

37:38.680 --> 37:41.040
I mean, that's a serious concern I have with clones.

37:41.040 --> 37:43.320
Again, the things I think about.

37:43.320 --> 37:48.320
Okay, so I recently got, I use QNAP NAS storage.

37:48.360 --> 37:50.200
So just storage for video and stuff.

37:50.200 --> 37:51.440
And I recently got hacked.

37:51.440 --> 37:53.520
It was the first time for me with ransomware.

37:53.520 --> 37:56.560
It's not me personally, it's all QNAP devices.

37:58.680 --> 38:00.760
So the question that people have

38:00.760 --> 38:03.320
is about security in general,

38:03.320 --> 38:05.040
because I was doing a lot of the right things

38:05.040 --> 38:06.840
in terms of security and nevertheless,

38:06.840 --> 38:10.360
ransomware basically disabled my device.

38:10.360 --> 38:11.200
Yeah.

38:11.200 --> 38:12.040
Is that something you think about?

38:12.040 --> 38:13.800
What are the different steps you could take

38:13.800 --> 38:16.960
to protect people's data on the security front?

38:16.960 --> 38:20.440
I think that there's different solutions for,

38:21.360 --> 38:22.960
in strategies where it makes sense

38:22.960 --> 38:25.440
to have stuff kind of put behind a fortress, right?

38:25.440 --> 38:30.200
So the centralized model versus decentralizing.

38:30.200 --> 38:32.080
Then I think both have strengths and weaknesses.

38:32.080 --> 38:33.000
So I think anyone who says,

38:33.000 --> 38:34.960
okay, just decentralize everything,

38:34.960 --> 38:36.600
that'll make it more secure.

38:36.600 --> 38:38.920
I think that that's tough because,

38:38.920 --> 38:42.680
I mean, the advantage of something like encryption

38:42.680 --> 38:46.400
is that we run the largest encrypted service

38:46.400 --> 38:47.680
in the world with WhatsApp.

38:47.680 --> 38:49.560
And we're one of the first to roll out

38:49.560 --> 38:52.600
a multi-platform encryption service.

38:52.600 --> 38:55.960
And that's something that I think was a big advance

38:55.960 --> 38:57.120
for the industry.

38:57.120 --> 38:59.280
And one of the promises that we can basically make

38:59.280 --> 39:02.280
because of that, our company doesn't see

39:02.280 --> 39:04.480
when you're sending an encrypted message

39:04.480 --> 39:06.760
and an encrypted message what the content is

39:06.760 --> 39:07.880
of what you're sharing.

39:07.880 --> 39:10.600
So that way, if someone hacks Meta's servers,

39:11.520 --> 39:14.720
they're not gonna be able to access the WhatsApp message

39:14.720 --> 39:16.920
that you're sending to your friend.

39:16.920 --> 39:19.080
And that I think matters a lot to people

39:19.080 --> 39:21.880
because obviously if someone is able to compromise

39:21.880 --> 39:24.400
a company's servers and that company has hundreds of millions

39:24.400 --> 39:25.240
or billions of people,

39:25.240 --> 39:27.920
then that ends up being a very big deal.

39:27.920 --> 39:29.360
The flip side of that is, okay,

39:29.360 --> 39:31.080
all the content is on your phone.

39:32.920 --> 39:35.840
Are you following security best practices on your phone?

39:35.840 --> 39:38.080
If you lose your phone, all your content is gone.

39:38.080 --> 39:39.640
So that's an issue.

39:39.640 --> 39:42.320
Maybe you go back up your content from WhatsApp

39:42.320 --> 39:45.760
or some other service in an iCloud or something,

39:45.760 --> 39:47.960
but then you're just at Apple's whims about,

39:47.960 --> 39:51.920
are they gonna go turn over the data to some government

39:51.920 --> 39:53.400
or are they gonna get hacked?

39:53.400 --> 39:57.360
So a lot of the time it is useful to have data

39:57.360 --> 39:58.840
in a centralized place too,

39:58.840 --> 40:01.520
because then you can train systems

40:01.520 --> 40:04.760
that can just do much better personalization.

40:04.760 --> 40:06.680
I think that in a lot of cases,

40:07.560 --> 40:10.320
centralized systems can offer,

40:10.320 --> 40:13.440
especially if you're a serious company,

40:13.440 --> 40:16.040
you're running the state of the art stuff

40:16.040 --> 40:19.560
and you have red teams attacking your own stuff

40:19.560 --> 40:24.280
and you're putting out bounty programs

40:24.280 --> 40:25.880
and trying to attract some of the best hackers

40:25.880 --> 40:27.240
in the world to go break into your stuff

40:27.240 --> 40:28.080
all the time.

40:28.080 --> 40:30.480
So any system is gonna have security issues,

40:30.480 --> 40:34.320
but I think the best way forward is to basically try

40:34.320 --> 40:37.000
to be as aggressive and open about hardening the systems

40:37.000 --> 40:39.120
as possible, not trying to kind of hide

40:39.120 --> 40:40.680
and pretend that there aren't gonna be issues,

40:40.680 --> 40:43.760
which I think is over time why a lot of open source systems

40:43.760 --> 40:46.520
have gotten relatively more secure is because they're open

40:46.520 --> 40:48.400
and it's not, rather than pretending

40:48.400 --> 40:49.440
that there aren't gonna be issues,

40:49.440 --> 40:50.880
just people surface them quicker.

40:50.880 --> 40:53.720
So I think you wanna adopt that approach as a company

40:53.720 --> 40:56.600
and just constantly be hardening yourself.

40:56.600 --> 41:00.040
Trying to stay one step ahead of the attackers.

41:01.040 --> 41:03.240
It's an inherently adversarial space.

41:03.240 --> 41:04.080
Yeah.

41:04.080 --> 41:07.240
I think it's an interesting, security is interesting

41:07.240 --> 41:09.120
because of the different kind of threats

41:09.120 --> 41:11.800
that we've managed over the last five years,

41:11.800 --> 41:15.520
there are ones where basically the adversaries

41:15.520 --> 41:16.800
keep on getting better and better.

41:16.800 --> 41:19.880
So trying to kind of interfere with,

41:21.080 --> 41:23.040
security is certainly one area of this.

41:23.040 --> 41:25.880
If you have like nation states that are trying to interfere

41:25.880 --> 41:27.080
in elections or something,

41:27.080 --> 41:29.440
like they're kind of evolving their tactics.

41:29.440 --> 41:31.080
Whereas on the other hand,

41:31.080 --> 41:33.120
I don't wanna be too simplistic about it,

41:33.120 --> 41:36.640
but like if someone is saying something hateful,

41:36.640 --> 41:38.680
people usually aren't getting smarter and smarter

41:38.680 --> 41:40.440
about how they say hateful things, right?

41:40.440 --> 41:42.560
So maybe there's some element of that,

41:42.560 --> 41:46.080
but it's a very small dynamic compared to,

41:46.080 --> 41:47.360
how advanced attackers

41:47.360 --> 41:49.960
and some of these other places get over time.

41:49.960 --> 41:51.320
I believe most people are good.

41:51.320 --> 41:53.640
So they actually get better over time

41:53.640 --> 41:55.360
and not being less hateful

41:55.440 --> 41:59.120
because they realize it's not fun being hateful.

42:00.080 --> 42:02.000
That's at least the belief I have.

42:02.000 --> 42:05.000
But first, bathroom break.

42:05.000 --> 42:05.840
Sure, okay.

42:06.880 --> 42:08.200
So we'll come back to AI,

42:08.200 --> 42:11.040
but let me ask some difficult questions now.

42:11.040 --> 42:13.840
Social Dilemma is a popular documentary

42:13.840 --> 42:15.520
that raised concerns about the effects

42:15.520 --> 42:17.560
of social media in society.

42:17.560 --> 42:19.960
You responded with a point by point rebuttal

42:19.960 --> 42:23.160
titled What the Social Dilemma Gets Wrong.

42:23.160 --> 42:25.000
People should read that.

42:25.000 --> 42:26.720
I would say the key point they make

42:26.720 --> 42:29.600
is because social media is funded by ads,

42:29.600 --> 42:33.320
algorithms want to maximize attention and engagement

42:33.320 --> 42:36.280
and an effective way to do so

42:36.280 --> 42:38.920
is to get people angry at each other,

42:38.920 --> 42:40.960
increase division and so on.

42:40.960 --> 42:44.280
Can you steel man their criticisms and arguments

42:44.280 --> 42:46.280
that they make in the documentary

42:46.280 --> 42:48.600
as a way to understand the concern

42:48.600 --> 42:51.600
and as a way to respond to it?

42:52.600 --> 42:56.440
Well, yeah, I think that that's a good conversation to have.

42:56.440 --> 42:59.960
I don't happen to agree with the conclusions

42:59.960 --> 43:01.600
and I think that they make a few assumptions

43:01.600 --> 43:05.840
that are just very big jumps

43:05.840 --> 43:08.440
that I don't think are reasonable to make.

43:08.440 --> 43:13.440
But I understand overall why people would be concerned

43:13.520 --> 43:18.040
that our business model and ads in general,

43:19.000 --> 43:20.720
we do make more money

43:20.720 --> 43:23.360
as people use the service more in general, right?

43:23.360 --> 43:26.760
So as a kind of basic assumption, okay,

43:26.760 --> 43:28.360
do we have an incentive for people

43:28.360 --> 43:31.280
to build a service that people use more?

43:31.280 --> 43:32.920
Yes, on a lot of levels.

43:32.920 --> 43:34.560
I mean, we think what we're doing is good.

43:34.560 --> 43:37.240
So we think that if people are finding it useful,

43:37.240 --> 43:38.640
they'll use it more.

43:38.640 --> 43:41.400
Or if you just look at it as this sort of,

43:41.400 --> 43:43.400
if the only thing we cared about is money,

43:43.400 --> 43:46.320
which is not for anyone who knows me,

43:46.320 --> 43:47.920
but okay, we're a company.

43:47.920 --> 43:51.440
So let's say you just kind of simplified it down to that.

43:51.440 --> 43:53.920
Then would we want people to use the services more?

43:53.920 --> 43:57.320
Yes, and then you get to the second question,

43:57.320 --> 44:01.920
which is does kind of getting people agitated

44:03.000 --> 44:07.560
make them more likely to use the services more?

44:07.560 --> 44:12.560
And I think from looking at other media in the world,

44:12.720 --> 44:17.240
especially TV and there's the old news adage,

44:17.240 --> 44:18.640
if it bleeds, it leads.

44:18.640 --> 44:23.640
Like I think that there are a bunch of reasons

44:24.080 --> 44:29.080
why someone might think that kind of provocative content

44:30.480 --> 44:32.600
would be the most engaging.

44:32.600 --> 44:35.600
Now, what I've always found is two things.

44:35.600 --> 44:39.120
One is that we'll grab someone's attention in the near term

44:39.120 --> 44:40.800
is not necessarily something

44:40.800 --> 44:43.600
that they're going to appreciate having seen

44:43.600 --> 44:45.280
or going to be the best over the long term.

44:45.280 --> 44:47.400
So I think what a lot of people get wrong

44:47.400 --> 44:50.360
is that I'm not building this company

44:50.360 --> 44:51.840
to like make the most money

44:51.840 --> 44:53.560
or get people to spend the most time on this

44:53.560 --> 44:55.720
in the next quarter or the next year.

44:55.720 --> 44:58.940
I've been doing this for 17 years at this point,

44:58.940 --> 45:00.360
and I'm still relatively young

45:00.360 --> 45:03.320
and have a lot more that I wanna do over the coming decade.

45:03.320 --> 45:08.320
So I think that it's too simplistic to say,

45:08.360 --> 45:11.800
hey, this might increase time in the near term,

45:11.800 --> 45:13.400
therefore it's what you're gonna do.

45:13.440 --> 45:15.320
Because I actually think a deeper look

45:15.320 --> 45:17.200
at it kind of what my incentives are,

45:17.200 --> 45:18.840
the incentives of a company that are focused

45:18.840 --> 45:22.320
on the long term is to basically do

45:22.320 --> 45:24.120
what people are gonna find valuable over time,

45:24.120 --> 45:26.760
not what is gonna draw people's attention today.

45:26.760 --> 45:28.560
The other thing that I'd say is that

45:29.960 --> 45:31.480
I think a lot of times people look at this

45:31.480 --> 45:33.120
from the perspective of media

45:34.560 --> 45:37.760
or kind of information or civic discourse.

45:37.760 --> 45:40.280
But one other way of looking at this

45:40.280 --> 45:42.520
is just that, okay, I'm a product designer, right?

45:42.520 --> 45:45.160
Our company, we build products.

45:45.160 --> 45:47.320
And a big part of building a product

45:47.320 --> 45:49.000
is not just the function and utility

45:49.000 --> 45:50.160
of what you're delivering,

45:50.160 --> 45:52.000
but the feeling of how it feels, right?

45:52.000 --> 45:55.640
And we spent a lot of time talking about virtual reality

45:55.640 --> 45:58.840
and how the kind of key aspect of that experience

45:58.840 --> 46:01.960
is the feeling of presence, which it's a visceral thing.

46:01.960 --> 46:03.920
It's not just about the utility that you're delivering,

46:03.920 --> 46:05.920
it's about like the sensation.

46:05.920 --> 46:10.400
And similarly, I care a lot about how people feel

46:10.400 --> 46:11.400
when they use our products.

46:12.280 --> 46:15.280
I don't want to build products that make people angry.

46:15.280 --> 46:16.680
I mean, that's like not,

46:16.680 --> 46:18.400
I think what we're here on this earth to do

46:18.400 --> 46:22.120
is to build something that people spend a bunch of time doing

46:22.120 --> 46:24.000
and it just kind of makes them angrier to other people.

46:24.000 --> 46:26.320
I mean, I think that that's not good.

46:26.320 --> 46:30.960
That's not what I think would be sort of a good use

46:30.960 --> 46:33.640
of our time or a good contribution to the world.

46:33.640 --> 46:35.720
So, okay, it's like people,

46:35.720 --> 46:38.120
they tell us on a per content basis,

46:38.120 --> 46:40.640
does this thing, do I like it, do I love it?

46:40.640 --> 46:41.600
Does it make me angry?

46:41.600 --> 46:42.920
Does it make me sad?

46:42.920 --> 46:47.200
And based on that, we choose to basically show content

46:47.200 --> 46:49.120
that makes people angry less,

46:49.120 --> 46:52.680
because of course, if you're designing a product

46:52.680 --> 46:56.280
and you want people to be able to connect

46:56.280 --> 46:59.160
and feel good over a long period of time,

46:59.160 --> 47:02.040
then that's naturally what you're gonna do.

47:02.040 --> 47:04.360
So, I don't know, I think overall,

47:05.000 --> 47:10.000
I understand at a high level,

47:10.480 --> 47:13.600
if you're not thinking too deeply about it,

47:13.600 --> 47:16.040
why that argument might be appealing,

47:16.040 --> 47:19.160
but I just think if you actually look

47:19.160 --> 47:20.840
at what our real incentives are,

47:20.840 --> 47:25.000
not just like if we were trying to optimize

47:25.000 --> 47:28.880
for the next week, but like as people working on this,

47:28.880 --> 47:30.400
like why are we here?

47:30.400 --> 47:32.840
And I think it's pretty clear

47:32.840 --> 47:34.280
that that's not actually how you would wanna

47:34.280 --> 47:35.680
design the system.

47:35.680 --> 47:37.760
I guess one other thing that I'd say is that,

47:37.760 --> 47:40.800
while we're focused on the ads business model,

47:40.800 --> 47:42.240
I do think it's important to note

47:42.240 --> 47:45.320
that a lot of these issues are not unique to ads.

47:45.320 --> 47:47.880
I mean, so take like a subscription news business model,

47:47.880 --> 47:50.240
for example, I think that has,

47:50.240 --> 47:52.200
just as many potential pitfalls.

47:53.120 --> 47:55.200
Maybe if someone's paying for a subscription,

47:55.200 --> 47:57.880
you don't get paid per piece of content that they look at,

47:57.880 --> 48:02.600
but say for example, I think like a bunch

48:02.600 --> 48:04.360
of the partisanship that we see

48:05.320 --> 48:07.320
could potentially be made worse

48:07.320 --> 48:12.320
by you have these kind of partisan news organizations

48:13.880 --> 48:15.720
that basically sell subscriptions,

48:15.720 --> 48:17.520
and they're only gonna get people on one side

48:17.520 --> 48:19.840
to basically subscribe to them.

48:19.840 --> 48:22.720
So their incentive is not to print content

48:22.720 --> 48:26.080
or produce content that's kind of centrist

48:26.080 --> 48:27.800
or down the line either.

48:27.800 --> 48:30.000
I bet that what a lot of them find is that

48:30.000 --> 48:32.440
if they produce stuff that's kind of more polarizing

48:32.440 --> 48:35.400
or more partisan, then that is what gets

48:35.400 --> 48:36.800
the more subscribers.

48:36.800 --> 48:40.200
So I think that this stuff is all,

48:40.200 --> 48:41.880
there's no perfect business model,

48:41.880 --> 48:43.400
everything has pitfalls.

48:44.280 --> 48:46.440
The thing that I think is great about advertising

48:46.440 --> 48:48.720
is it makes it's the consumer services free,

48:48.720 --> 48:50.840
which if you believe that everyone should have a voice

48:50.840 --> 48:52.000
and everyone should be able to connect,

48:52.000 --> 48:53.920
then that's a great thing,

48:53.920 --> 48:55.840
as opposed to building a luxury service

48:55.840 --> 48:57.200
that not everyone can afford.

48:57.200 --> 48:59.160
But look, I mean, every business model,

48:59.160 --> 49:00.920
you have to be careful about how you're implementing

49:00.920 --> 49:02.440
what you're doing.

49:02.440 --> 49:04.600
You responded to a few things there.

49:04.600 --> 49:06.360
You spoke to the fact that,

49:06.360 --> 49:08.920
there is a narrative of malevolence,

49:08.920 --> 49:13.600
like you're leaning into the making people angry

49:13.600 --> 49:15.680
just because it makes more money in the short term,

49:15.680 --> 49:16.520
that kind of thing.

49:16.520 --> 49:17.840
So you responded to that,

49:17.840 --> 49:22.040
but there's also kind of reality of human nature.

49:22.040 --> 49:23.640
Just like you spoke about,

49:23.640 --> 49:26.840
there is fights, arguments we get in,

49:26.840 --> 49:28.720
and we don't like ourselves afterwards,

49:28.720 --> 49:30.320
but we got into them anyway.

49:30.320 --> 49:32.880
So our long-term growth is,

49:32.880 --> 49:36.560
I believe for most of us has to do with learning,

49:36.560 --> 49:39.680
challenging yourself, improving,

49:39.680 --> 49:40.960
being kind to each other,

49:40.960 --> 49:42.920
finding a community of people

49:42.920 --> 49:47.920
that you connect with on a real human level,

49:49.240 --> 49:50.520
all that kind of stuff.

49:50.520 --> 49:54.680
But it does seem when you look at social media,

49:54.680 --> 49:56.560
that a lot of fights break out,

49:56.560 --> 49:58.200
a lot of arguments break out,

49:58.200 --> 50:03.040
a lot of viral content ends up being sort of outrage

50:03.040 --> 50:04.840
in one direction or the other.

50:04.840 --> 50:08.040
And so it's easy from that to infer the narrative

50:08.040 --> 50:10.320
that social media companies

50:10.320 --> 50:13.960
are letting this outrage become viral.

50:13.960 --> 50:16.840
And so they're increasing the division in the world.

50:16.840 --> 50:20.200
I mean, perhaps you can comment on that or further,

50:20.200 --> 50:25.200
how can you push back on this narrative?

50:25.760 --> 50:28.400
How can you be transparent about this battle?

50:28.400 --> 50:33.400
Because I think it's not just motivation or financials,

50:33.520 --> 50:35.960
it's a technical problem too,

50:35.960 --> 50:40.960
which is how do you improve long-term wellbeing

50:41.000 --> 50:43.000
of human beings?

50:43.000 --> 50:47.920
I think that going through some of the design decisions

50:47.920 --> 50:49.640
would be a good conversation.

50:49.640 --> 50:51.760
But first, I actually think,

50:51.760 --> 50:54.280
and I think you acknowledged that,

50:54.280 --> 50:56.920
that narrative is somewhat anecdotal.

50:56.920 --> 50:59.520
And I think it's worth grounding this conversation

50:59.520 --> 51:02.600
in the actual research that has been done on this,

51:02.600 --> 51:07.600
which by and large finds that social media

51:07.960 --> 51:10.760
is not a large driver of polarization.

51:10.760 --> 51:14.800
And, I mean, there's been a number of economists

51:14.800 --> 51:18.360
and social scientists and folks who have studied this.

51:18.360 --> 51:21.200
In a lot of polarization, it varies around the world.

51:21.360 --> 51:23.080
Social media is basically in every country.

51:23.080 --> 51:24.600
Facebook's in pretty much every country,

51:24.600 --> 51:27.160
except for China and maybe North Korea.

51:27.160 --> 51:32.160
And you see different trends in different places

51:32.440 --> 51:37.000
where in a lot of countries, polarization is declining.

51:37.000 --> 51:38.360
In some, it's flat.

51:38.360 --> 51:41.640
In the US, it's risen sharply.

51:41.640 --> 51:44.600
So the question is, what are the unique phenomena

51:44.600 --> 51:46.000
in the different places?

51:46.000 --> 51:47.640
And I think for the people who are trying to say,

51:47.640 --> 51:50.200
hey, social media is the thing that's doing this,

51:50.200 --> 51:52.920
I think that that clearly doesn't hold up

51:52.920 --> 51:54.480
because social media is a phenomenon

51:54.480 --> 51:56.040
that is pretty much equivalent

51:56.040 --> 51:57.720
in all of these different countries.

51:57.720 --> 52:00.600
And you have researchers like this economist at Stanford,

52:00.600 --> 52:04.400
Matthew Genskow, who's just written at length about this.

52:05.320 --> 52:10.320
And it's a bunch of books by political scientists,

52:10.400 --> 52:13.040
Ezra Klein and folks, why we're polarized,

52:13.040 --> 52:15.680
basically goes through this decades long analysis

52:15.680 --> 52:18.160
in the US before I was born,

52:18.160 --> 52:20.640
basically talking about some of the forces

52:20.640 --> 52:24.240
in kind of partisan politics and Fox News

52:24.240 --> 52:26.480
and different things that predate the internet

52:26.480 --> 52:28.360
in a lot of ways that I think

52:28.360 --> 52:30.040
are likely larger contributors.

52:30.040 --> 52:32.160
So to the contrary on this,

52:32.160 --> 52:34.600
not only is it pretty clear

52:34.600 --> 52:37.560
that social media is not a major contributor,

52:37.560 --> 52:40.040
but most of the academic studies that I've seen

52:40.040 --> 52:42.600
actually show that social media use

52:42.600 --> 52:45.360
is correlated with lower polarization.

52:46.280 --> 52:48.640
Genskow, the same person who just did the study

52:48.640 --> 52:51.640
that I cited about longitudinal polarization

52:51.640 --> 52:53.040
across different countries,

52:54.200 --> 52:57.480
also did a study that basically showed

52:57.480 --> 53:02.120
that if you looked after the 2016 election in the US,

53:02.120 --> 53:04.320
the voters who were the most polarized

53:05.280 --> 53:07.560
were actually the ones who were not on the internet.

53:07.560 --> 53:10.280
So, and there have been recent other studies,

53:10.280 --> 53:12.840
I think in Europe and around the world,

53:12.840 --> 53:16.720
basically showing that as people stop using social media,

53:16.720 --> 53:19.200
they tend to get more polarized.

53:19.200 --> 53:21.360
Then there's a deeper analysis around,

53:21.360 --> 53:24.760
okay, well, polarization actually isn't even one thing

53:24.760 --> 53:27.080
because having different opinions on something isn't,

53:27.080 --> 53:28.920
I don't think that that's by itself bad.

53:28.920 --> 53:33.920
What people who study this say is most problematic

53:33.920 --> 53:35.920
is what they call affective polarization,

53:35.920 --> 53:37.920
which is basically, are you,

53:37.920 --> 53:40.040
do you have negative feelings towards people

53:40.040 --> 53:41.040
of another group?

53:41.040 --> 53:43.760
And the way that a lot of scholars study this

53:43.760 --> 53:46.800
is they basically ask a group,

53:46.800 --> 53:50.600
would you let your kids marry someone of group X?

53:50.600 --> 53:53.320
Whatever the groups are that you're worried

53:53.320 --> 53:55.520
that someone might have negative feelings towards.

53:55.520 --> 53:58.160
And in general, use of social media

53:58.160 --> 53:59.880
has corresponded to decreases

53:59.880 --> 54:01.960
in that kind of affective polarization.

54:01.960 --> 54:05.840
So, I think we should talk through the design decisions

54:05.840 --> 54:10.720
and how we handle the kind of specific pieces of content,

54:10.720 --> 54:13.280
but overall, I think it's just worth grounding

54:13.280 --> 54:15.600
that discussion in the research that's existed

54:15.600 --> 54:17.440
that I think overwhelmingly shows

54:17.440 --> 54:19.560
that the mainstream narrative around this

54:19.560 --> 54:21.040
is just not right.

54:21.040 --> 54:23.080
But the narrative does stay cold

54:24.040 --> 54:27.880
and it's compelling to a lot of people.

54:27.880 --> 54:31.280
There's another question I'd like to ask you on this.

54:31.280 --> 54:33.720
I was looking at various polls and saw that you're

54:35.000 --> 54:38.080
one of the most disliked tech leaders today,

54:38.120 --> 54:41.440
54% unfavorable rating.

54:41.440 --> 54:43.280
Elon Musk is 23%.

54:43.280 --> 54:46.320
It's basically everybody has a very high unfavorable rating

54:46.320 --> 54:48.040
that are tech leaders.

54:48.040 --> 54:50.680
Maybe you can help me understand that.

54:50.680 --> 54:53.320
Why do you think so many people dislike you?

54:54.760 --> 54:56.920
Some even hate you.

54:56.920 --> 54:59.200
And how do you regain their trust and support?

54:59.200 --> 55:00.960
Given everything you've just said,

55:02.400 --> 55:05.400
why are you losing the battle

55:05.400 --> 55:08.160
in explaining to people

55:08.160 --> 55:11.160
what actual impact social media has on society?

55:12.480 --> 55:16.800
Well, I'm curious if that's a US survey or world.

55:16.800 --> 55:18.000
It is US, yeah.

55:18.000 --> 55:19.400
So I think that there's a few dynamics.

55:19.400 --> 55:24.400
One is that our brand has been somewhat uniquely challenged

55:27.400 --> 55:29.080
in the US compared to other places.

55:29.080 --> 55:30.600
It's not that there are, I mean, other countries,

55:30.600 --> 55:33.920
we have issues too, but I think in the US,

55:33.920 --> 55:37.600
there was this dynamic where if you look at

55:37.600 --> 55:42.600
the next sentiment of coverage or attitude towards us,

55:42.920 --> 55:44.920
before 2016, I think that there were probably

55:44.920 --> 55:47.520
very few months, if any, where it was negative.

55:47.520 --> 55:49.480
And since 2016, I think that there probably

55:49.480 --> 55:51.880
been very few months, if any, that it's been positive.

55:51.880 --> 55:53.640
The politics.

55:53.640 --> 55:55.400
But I think it's a specific thing.

55:55.400 --> 55:57.000
And this is very different from other places.

55:57.000 --> 55:59.880
So I think in a lot of other countries in the world,

55:59.880 --> 56:02.480
the sentiment towards meta and our services

56:02.720 --> 56:04.840
is extremely positive.

56:04.840 --> 56:06.600
In the US, we have more challenges.

56:06.600 --> 56:08.800
And I think compared to other companies,

56:09.800 --> 56:13.240
you can look at certain industries, I think,

56:13.240 --> 56:16.320
if you look at it from like a partisan perspective,

56:16.320 --> 56:18.040
not from like a political perspective,

56:18.040 --> 56:19.920
but just kind of culturally, it's like there are people

56:19.920 --> 56:21.080
who are probably more left of center

56:21.080 --> 56:22.520
and there are people who are more right of center

56:22.520 --> 56:25.880
and there's kind of blue America and red America.

56:25.880 --> 56:27.640
There are certain industries that I think

56:27.640 --> 56:30.880
maybe one half of the country has a more positive view

56:30.880 --> 56:32.200
towards than another.

56:32.200 --> 56:33.680
And I think we're in a,

56:36.400 --> 56:38.000
one of the positions that we're in

56:38.000 --> 56:39.800
that I think is really challenging

56:39.800 --> 56:42.920
is that because of a lot of the content decisions

56:42.920 --> 56:45.800
that we've basically had to arbitrate,

56:47.240 --> 56:49.560
and because we're not a partisan company, right?

56:49.560 --> 56:52.640
We're not a Democrat company or a Republican company.

56:52.640 --> 56:55.080
We're trying to make the best decisions we can

56:55.080 --> 56:58.480
to help people connect and help people have as much voice

56:58.480 --> 57:01.120
as they can while having some rules

57:01.120 --> 57:02.880
because we're running a community.

57:04.920 --> 57:06.800
The net effect of that is that we're kind of

57:06.800 --> 57:10.600
constantly making decisions that piss off people

57:10.600 --> 57:11.760
in both camps.

57:12.760 --> 57:16.560
And the effect that I've sort of seen

57:16.560 --> 57:20.240
is that when we make a decision that is,

57:21.480 --> 57:23.000
that's a controversial one,

57:23.000 --> 57:26.480
that's gonna upset say about half the country,

57:27.880 --> 57:30.360
those decisions are all negative sum

57:30.360 --> 57:31.960
from a brand perspective,

57:31.960 --> 57:33.680
because it's not like,

57:33.680 --> 57:35.640
if we make that decision in one way

57:35.640 --> 57:37.840
and say half the country is happy

57:37.840 --> 57:40.000
about that particular decision that we make,

57:40.000 --> 57:43.720
they tend to not say, oh, sweet, meta got that one right.

57:43.720 --> 57:46.160
They're just like, ah, you didn't mess that one up, right?

57:46.160 --> 57:48.960
But their opinion doesn't tend to go up by that much.

57:48.960 --> 57:51.800
Whereas the people who kind of are on the other side of it

57:52.840 --> 57:55.080
are like, God, how could you mess that up?

57:55.080 --> 57:57.760
How could you possibly think that that piece of content

57:57.760 --> 58:00.120
is okay and should be up and should not be censored?

58:01.120 --> 58:05.320
And so I think the, whereas if you leave it up and,

58:07.960 --> 58:09.200
or if you take it down,

58:09.200 --> 58:11.680
the people who thought it should be taken down or,

58:11.680 --> 58:12.720
it's like, all right, fine, great,

58:12.720 --> 58:14.040
you didn't mess that one up.

58:14.040 --> 58:17.880
So our internal assessment of analytics on our brand

58:17.880 --> 58:20.520
are basically any time one of these big controversial things

58:20.520 --> 58:21.960
comes up in society,

58:23.720 --> 58:26.040
our brand goes down with half of the country.

58:26.040 --> 58:29.560
And then if you just kind of extrapolate that out,

58:29.600 --> 58:33.200
it's just been very challenging for us to try to navigate

58:33.200 --> 58:36.640
what is a polarizing country in a principled way

58:36.640 --> 58:38.600
where we're not trying to kind of hue to one side

58:38.600 --> 58:39.440
or the other, we're trying to do

58:39.440 --> 58:41.040
what we think is the right thing.

58:41.040 --> 58:43.240
But that's what I think is the right thing

58:43.240 --> 58:44.080
for us to do though.

58:44.080 --> 58:47.360
So I mean, that's what we'll try to keep doing.

58:47.360 --> 58:50.160
Just as a human being, how does it feel though

58:50.160 --> 58:53.360
when you're giving so much of your day-to-day life

58:53.360 --> 58:58.040
to try to heal division, to try to do good in the world,

58:58.080 --> 59:02.280
as we've talked about, that so many people in the US,

59:02.280 --> 59:06.880
the place you call home, have a negative view of you

59:06.880 --> 59:11.400
as a leader, as a human being, and the company you love?

59:14.040 --> 59:18.640
Well, I mean, it's not great, but I mean, look,

59:18.640 --> 59:22.800
if I wanted people to think positively about me as a person,

59:25.760 --> 59:27.960
I don't know, I'm not sure if you go build a company.

59:28.920 --> 59:30.240
Or a social media company.

59:30.240 --> 59:32.040
It seems exceptionally difficult to do

59:32.040 --> 59:32.880
with a social media company.

59:32.880 --> 59:37.880
Yeah, so I mean, I don't know, there is a dynamic

59:38.560 --> 59:40.800
where a lot of the other people running these companies,

59:40.800 --> 59:44.000
internet companies, have sort of stepped back

59:44.000 --> 59:46.360
and they just do things that are sort of,

59:47.400 --> 59:49.480
I don't know, less controversial.

59:49.480 --> 59:52.720
And some of it may be that they just get tired over time.

59:52.720 --> 59:57.720
But so I don't know, I think that running a company is hard

59:58.080 --> 59:59.840
building something at scale is hard.

59:59.840 --> 01:00:01.600
You only really do it for a long period of time

01:00:01.600 --> 01:00:04.200
if you really care about what you're doing.

01:00:04.200 --> 01:00:08.560
And yeah, so I mean, it's not great, but look,

01:00:08.560 --> 01:00:13.560
I think that at some level, whether 25% of people dislike

01:00:14.560 --> 01:00:19.000
you or 75% of people dislike you, your experience

01:00:19.000 --> 01:00:21.640
as a public figure is gonna be that there's a lot

01:00:21.640 --> 01:00:23.320
of people who dislike you, right?

01:00:23.320 --> 01:00:27.920
So I actually, I'm not sure how different it is.

01:00:28.840 --> 01:00:32.720
Certainly, the country has gotten more polarized

01:00:32.720 --> 01:00:36.000
and we in particular have gotten more controversial

01:00:36.000 --> 01:00:39.080
over the last five years or so.

01:00:39.080 --> 01:00:44.080
But I don't know, I kind of think like as a public figure

01:00:45.200 --> 01:00:48.520
and leader of one of these enterprises-

01:00:48.520 --> 01:00:49.680
Comes with a job.

01:00:49.680 --> 01:00:52.000
Yeah, part of what you do is like, and look,

01:00:52.760 --> 01:00:54.600
the answer can't just be ignore it, right?

01:00:54.600 --> 01:00:56.920
Because like a huge part of the job is like,

01:00:56.920 --> 01:00:59.360
you need to be getting feedback and internalizing feedback

01:00:59.360 --> 01:01:00.760
on how you can do better.

01:01:00.760 --> 01:01:02.960
But I think increasing what you need to do is be able

01:01:02.960 --> 01:01:07.960
to figure out who are the kind of good faith critics

01:01:08.000 --> 01:01:11.600
who are criticizing you because they're trying to help you

01:01:11.600 --> 01:01:13.960
do a better job rather than tear you down.

01:01:13.960 --> 01:01:16.400
And those are the people who I just think you have to cherish

01:01:16.400 --> 01:01:20.280
and listen very closely to the things that they're saying

01:01:20.280 --> 01:01:23.040
because I think it's just as dangerous

01:01:23.040 --> 01:01:25.920
to tune out everyone who says anything negative

01:01:26.840 --> 01:01:29.320
and just listen to the people who are kind of positive

01:01:29.320 --> 01:01:32.720
and support you as it would be psychologically

01:01:32.720 --> 01:01:34.480
to pay attention trying to make people

01:01:34.480 --> 01:01:36.600
who are never gonna like you, like you.

01:01:36.600 --> 01:01:38.880
So I think that that's just kind of a dance

01:01:38.880 --> 01:01:40.120
that people have to do.

01:01:40.120 --> 01:01:44.720
But I mean, you kind of develop more of a feel for like,

01:01:44.720 --> 01:01:47.080
who actually is trying to accomplish the same types

01:01:47.120 --> 01:01:48.360
of things in the world?

01:01:48.360 --> 01:01:51.400
And who has different ideas about how to do that?

01:01:51.400 --> 01:01:52.840
And how can I learn from those people?

01:01:52.840 --> 01:01:54.800
And like, yeah, we get stuff wrong.

01:01:54.800 --> 01:01:58.280
And when the people whose opinions I respect call me out

01:01:58.280 --> 01:02:01.000
on getting stuff wrong, that hurts

01:02:01.000 --> 01:02:02.080
and makes me wanna do better.

01:02:02.080 --> 01:02:04.640
But I think at this point, I'm pretty tuned to just,

01:02:04.640 --> 01:02:07.320
all right, if I know they're kind of like operating

01:02:07.320 --> 01:02:10.760
in bad faith and they're not really trying to help,

01:02:10.760 --> 01:02:13.760
then I don't know, I think over time,

01:02:13.760 --> 01:02:15.240
it just doesn't bother you that much.

01:02:15.240 --> 01:02:17.360
But you are surrounded by people

01:02:17.360 --> 01:02:19.640
that believe in the mission, that love you.

01:02:21.200 --> 01:02:23.560
Are there friends or colleagues in your inner circle

01:02:23.560 --> 01:02:26.520
you trust that call you out on your bullshit

01:02:26.520 --> 01:02:28.560
whenever your thinking may be misguided

01:02:28.560 --> 01:02:30.880
as it is for leaders at times?

01:02:30.880 --> 01:02:33.440
I think we have a famously open company culture

01:02:34.760 --> 01:02:39.360
where we sort of encourage that kind of descent internally,

01:02:39.360 --> 01:02:42.200
which is why there's so much material internally

01:02:42.200 --> 01:02:44.440
that can leak out with people sort of disagreeing

01:02:44.520 --> 01:02:46.520
is because that's sort of the culture.

01:02:47.800 --> 01:02:50.560
Our management team, I think it's a lot of people,

01:02:50.560 --> 01:02:51.960
there are some newer folks who come in,

01:02:51.960 --> 01:02:54.760
there are some folks who've kind of been there for a while,

01:02:54.760 --> 01:02:56.800
but there's a very high level of trust.

01:02:56.800 --> 01:02:58.960
And I would say it is a relatively

01:02:58.960 --> 01:03:01.040
confrontational group of people.

01:03:01.040 --> 01:03:04.520
And my friends and family, I think will push me on this.

01:03:04.520 --> 01:03:06.360
But look, I think it's not just,

01:03:06.360 --> 01:03:09.240
but I think you need some diversity, right?

01:03:09.240 --> 01:03:13.720
It can't just be people who are your friends and family.

01:03:13.760 --> 01:03:17.920
It's also, I mean, there are journalists or analysts

01:03:17.920 --> 01:03:22.920
or peer executives at other companies

01:03:23.280 --> 01:03:27.640
or other people who sort of are insightful

01:03:27.640 --> 01:03:30.840
about thinking about the world, certain politicians

01:03:30.840 --> 01:03:32.720
or people kind of in that sphere,

01:03:32.720 --> 01:03:36.200
who I just think have like very insightful perspectives

01:03:36.200 --> 01:03:39.840
who even if they would,

01:03:39.840 --> 01:03:41.640
they come at the world from a different perspective,

01:03:41.640 --> 01:03:44.400
which is sort of what makes the perspective so valuable.

01:03:44.400 --> 01:03:46.640
But I think fundamentally we're trying to get

01:03:46.640 --> 01:03:50.720
to the same place in terms of helping people connect more,

01:03:50.720 --> 01:03:53.520
helping the whole world function better,

01:03:53.520 --> 01:03:55.640
not just one place or another.

01:03:57.160 --> 01:03:59.680
And I don't know, I mean, those are the people

01:03:59.680 --> 01:04:02.960
whose opinions really matter to me.

01:04:02.960 --> 01:04:05.680
And that's how I learn on a day-to-day basis.

01:04:05.680 --> 01:04:07.920
People are constantly sending me comments on stuff

01:04:07.920 --> 01:04:10.200
or links to things they found interesting.

01:04:10.200 --> 01:04:13.440
And I don't know, it's kind of constantly evolving

01:04:13.440 --> 01:04:14.520
this model of the world

01:04:14.520 --> 01:04:16.880
and kind of what we should be aspiring to be.

01:04:16.880 --> 01:04:20.960
You've talked about, you have a famously open culture,

01:04:20.960 --> 01:04:25.960
which comes with the criticism and the painful experiences.

01:04:27.320 --> 01:04:31.000
So let me ask you another difficult question.

01:04:31.000 --> 01:04:33.480
Frances Haugen, the Facebook whistleblower,

01:04:33.480 --> 01:04:35.840
leaked the internal Instagram research

01:04:35.840 --> 01:04:38.080
into teenagers and wellbeing.

01:04:38.080 --> 01:04:41.240
Her claim is that Instagram is choosing profit

01:04:41.240 --> 01:04:43.120
over wellbeing of teenage girls,

01:04:43.120 --> 01:04:46.720
so Instagram is, quote, toxic for them.

01:04:46.720 --> 01:04:51.360
Your response, titled, what our research really says

01:04:51.360 --> 01:04:54.240
about teen wellbeing, and Instagram says no.

01:04:54.240 --> 01:04:58.800
Instagram research shows that 11 of 12 wellbeing issues,

01:04:58.800 --> 01:05:02.720
teenage girls who said they struggle

01:05:02.720 --> 01:05:04.400
with those difficult issues also said

01:05:04.400 --> 01:05:07.600
that Instagram made them better rather than worse.

01:05:07.600 --> 01:05:11.000
Again, can you steel man and defend the point

01:05:11.000 --> 01:05:14.800
and Frances Haugen's characterization of the study

01:05:14.800 --> 01:05:17.040
and then help me understand the positive

01:05:17.040 --> 01:05:19.560
and negative effects of Instagram and Facebook

01:05:19.560 --> 01:05:20.880
on young people?

01:05:20.880 --> 01:05:25.840
So there are certainly questions around teen mental health

01:05:25.840 --> 01:05:26.680
that are really important.

01:05:26.680 --> 01:05:29.520
It's hard to, as a parent, it's like hard to imagine

01:05:29.520 --> 01:05:32.040
any set of questions that are sort of more important.

01:05:32.040 --> 01:05:34.080
I mean, I guess maybe other aspects of physical health

01:05:34.080 --> 01:05:37.240
or wellbeing are probably come to that level.

01:05:37.240 --> 01:05:40.560
But these are really important questions, right?

01:05:40.560 --> 01:05:43.760
Which is why we dedicate teams to studying them.

01:05:45.640 --> 01:05:48.840
I don't think the internet or social media are unique

01:05:48.840 --> 01:05:49.960
in having these questions.

01:05:49.960 --> 01:05:53.120
I mean, I think people, and there've been sort of magazines

01:05:53.120 --> 01:05:57.040
with promoting certain body types for women and kids

01:05:57.040 --> 01:06:01.400
for decades, but we really care about this stuff.

01:06:01.400 --> 01:06:02.720
So we wanted to study it.

01:06:02.720 --> 01:06:05.480
And of course, we didn't expect that everything

01:06:05.480 --> 01:06:06.960
was gonna be positive all the time.

01:06:06.960 --> 01:06:08.480
So I mean, the reason why you study this stuff

01:06:08.480 --> 01:06:10.720
is to try to improve and get better.

01:06:10.720 --> 01:06:13.160
So, I mean, look, the place where I disagree

01:06:13.160 --> 01:06:16.200
with the characterization, first, I thought,

01:06:16.200 --> 01:06:18.680
some of the reporting and coverage of it

01:06:18.680 --> 01:06:20.800
just took the whole thing out of proportion

01:06:20.800 --> 01:06:22.600
and that it focused on, as you said,

01:06:22.600 --> 01:06:24.240
I think there were like 20 metrics in there.

01:06:24.240 --> 01:06:27.560
And on 18 or 19, the effect of using Instagram

01:06:27.560 --> 01:06:30.880
was neutral or positive on the teens' wellbeing.

01:06:30.880 --> 01:06:34.520
And there was one area where I think it showed

01:06:34.520 --> 01:06:36.400
that we needed to improve and we took some steps

01:06:36.400 --> 01:06:38.800
to try to do that after doing the research.

01:06:38.800 --> 01:06:41.680
But I think having the coverage just focus on that one

01:06:41.680 --> 01:06:45.080
without focusing on the, I think an accurate characterization

01:06:45.080 --> 01:06:47.920
would have been that kids using Instagram,

01:06:47.920 --> 01:06:52.200
or not kids, teens, is generally positive

01:06:52.200 --> 01:06:53.720
for their mental health.

01:06:53.720 --> 01:06:55.560
But of course, that was not the narrative that came out.

01:06:55.560 --> 01:06:56.720
So I think it's hard to,

01:06:56.720 --> 01:06:59.200
that's not a kind of logical thing to straw man,

01:06:59.200 --> 01:07:01.440
but I sort of disagree, or steel man,

01:07:01.440 --> 01:07:04.040
but I sort of disagree with that overall characterization.

01:07:04.040 --> 01:07:08.800
I think anyone sort of looking at this objectively would.

01:07:09.960 --> 01:07:14.960
But then, I mean, there is this sort of intent critique

01:07:15.040 --> 01:07:16.360
that I think you were getting at before,

01:07:16.360 --> 01:07:19.680
which says, it assumes some sort of malevolence, right?

01:07:19.680 --> 01:07:23.160
It's like, which it's really hard for me

01:07:23.160 --> 01:07:26.520
to really wrap my head around this

01:07:26.520 --> 01:07:29.800
because as far as I know,

01:07:29.800 --> 01:07:31.720
it's not clear that any of the other tech companies

01:07:31.720 --> 01:07:33.320
are doing this kind of research.

01:07:33.360 --> 01:07:37.840
So why the narrative should form that we did research,

01:07:37.840 --> 01:07:38.840
because we're studying an issue

01:07:38.840 --> 01:07:40.800
because we wanted to understand it to improve

01:07:40.800 --> 01:07:43.600
and took steps after that to try to improve it,

01:07:43.600 --> 01:07:46.320
that your interpretation of that would be

01:07:46.320 --> 01:07:47.920
that we did the research

01:07:47.920 --> 01:07:49.280
and tried to sweep it under the rug.

01:07:49.280 --> 01:07:53.680
It just, it sort of is like,

01:07:53.680 --> 01:07:55.960
I don't know, it's beyond credibility to me

01:07:55.960 --> 01:07:59.040
that that's the accurate description of the actions

01:07:59.040 --> 01:08:01.200
that we've taken compared to the others in the industry.

01:08:01.200 --> 01:08:05.280
So, I don't know, that's my view on it.

01:08:05.280 --> 01:08:06.640
These are really important issues

01:08:06.640 --> 01:08:08.000
and there's a lot of stuff

01:08:08.000 --> 01:08:09.120
that I think we're gonna be working on

01:08:09.120 --> 01:08:11.400
related to teen mental health for a long time,

01:08:11.400 --> 01:08:14.280
including trying to understand this better.

01:08:14.280 --> 01:08:15.760
And I would encourage everyone else in the industry

01:08:15.760 --> 01:08:16.600
to do this too.

01:08:18.400 --> 01:08:21.920
Yeah, I would love there to be open conversations

01:08:21.920 --> 01:08:25.720
and a lot of great research being released internally

01:08:25.720 --> 01:08:27.960
and then also externally.

01:08:28.880 --> 01:08:32.760
It doesn't make me feel good to see press

01:08:32.760 --> 01:08:35.000
obviously get way more clicks

01:08:35.000 --> 01:08:39.320
when they say negative things about social media.

01:08:39.320 --> 01:08:41.560
Objectively speaking, I can just tell

01:08:42.440 --> 01:08:44.440
that there's hunger to say negative things

01:08:44.440 --> 01:08:46.080
about social media.

01:08:46.080 --> 01:08:50.760
And I don't understand how that's supposed to lead

01:08:50.760 --> 01:08:53.040
to an open conversation about the positives

01:08:53.040 --> 01:08:56.040
and the negatives, the concerns about social media,

01:08:56.040 --> 01:08:59.280
especially when you're doing that kind of research.

01:08:59.280 --> 01:09:01.720
I mean, I don't know what to do with that,

01:09:01.720 --> 01:09:03.960
but let me ask you as a father,

01:09:05.560 --> 01:09:06.760
there's a weight heavy on you

01:09:06.760 --> 01:09:10.320
that people get bullied on social networks.

01:09:10.320 --> 01:09:13.560
So, people get bullied in their private life.

01:09:13.560 --> 01:09:15.600
But now, because so much of our life

01:09:15.600 --> 01:09:17.120
is in the digital world,

01:09:17.120 --> 01:09:19.680
the bullying moves from the physical world

01:09:19.680 --> 01:09:21.240
to the digital world.

01:09:21.240 --> 01:09:23.320
So, you're now creating a platform

01:09:24.560 --> 01:09:26.560
on which bullying happens.

01:09:26.560 --> 01:09:28.200
And some of that bullying

01:09:28.200 --> 01:09:31.880
can lead to damage to mental health.

01:09:31.880 --> 01:09:35.160
And some of that bullying can lead to depression,

01:09:35.160 --> 01:09:36.360
even suicide.

01:09:37.680 --> 01:09:38.800
There's a weight heavy on you

01:09:38.800 --> 01:09:43.280
that people have committed suicide

01:09:43.280 --> 01:09:45.280
or will commit suicide

01:09:45.280 --> 01:09:48.120
based on the bullying that happens on social media.

01:09:48.120 --> 01:09:49.960
Yeah, I mean, this is,

01:09:49.960 --> 01:09:53.320
there's a set of harms that we basically track

01:09:53.320 --> 01:09:55.440
and build systems to fight against.

01:09:55.440 --> 01:10:00.440
And bullying and self-harm are,

01:10:01.240 --> 01:10:03.280
you know, I mean, these are some of the biggest things

01:10:03.280 --> 01:10:06.080
that we are most focused on.

01:10:10.960 --> 01:10:14.440
For bullying, like you say, it's gonna be,

01:10:15.440 --> 01:10:18.240
while this predates the internet,

01:10:18.240 --> 01:10:20.920
then it's probably impossible to get rid of all of it.

01:10:21.960 --> 01:10:24.160
You wanna give people tools to fight it.

01:10:24.160 --> 01:10:27.240
And you wanna fight it yourself.

01:10:27.240 --> 01:10:28.880
And you also wanna make sure that people have the tools

01:10:28.880 --> 01:10:30.240
to get help when they need it.

01:10:30.240 --> 01:10:33.280
So, I think this isn't like a question of,

01:10:33.280 --> 01:10:34.720
can you get rid of all bullying?

01:10:34.720 --> 01:10:36.160
I mean, it's like, all right.

01:10:37.160 --> 01:10:40.880
I mean, I have two daughters and they fight

01:10:40.880 --> 01:10:43.880
and push each other around and stuff too.

01:10:43.880 --> 01:10:47.120
And the question is just how do you handle that situation?

01:10:47.120 --> 01:10:51.560
And there's a handful of things that I think you can do.

01:10:52.640 --> 01:10:54.960
You know, we talked a little bit before around

01:10:54.960 --> 01:10:57.040
some of the AI tools that you can build

01:10:57.040 --> 01:11:00.120
to identify when something harmful is happening.

01:11:00.120 --> 01:11:01.520
It's actually, it's very hard in bullying

01:11:01.520 --> 01:11:03.680
because a lot of bullying is very context specific.

01:11:03.680 --> 01:11:07.280
It's not like you're trying to fit a formula of like,

01:11:07.280 --> 01:11:10.280
you know, if like looking at the different harms,

01:11:10.280 --> 01:11:12.080
you know, someone promoting a terrorist group

01:11:12.080 --> 01:11:14.400
is like probably one of the simpler things

01:11:14.400 --> 01:11:16.800
to generally find because things promoting that group

01:11:16.800 --> 01:11:18.640
are gonna, you know, look a certain way

01:11:18.640 --> 01:11:20.240
or feel a certain way.

01:11:20.240 --> 01:11:21.840
Bullying could just be, you know,

01:11:21.840 --> 01:11:23.520
someone making some subtle comment

01:11:23.520 --> 01:11:26.840
about someone's appearance that's idiosyncratic to them.

01:11:26.840 --> 01:11:28.720
And it could look at just like humor.

01:11:28.720 --> 01:11:31.000
So humor to one person can be destructive

01:11:31.000 --> 01:11:32.280
to another human being, yeah.

01:11:32.280 --> 01:11:36.400
So with bullying, I think there are certain things

01:11:36.400 --> 01:11:39.320
that you can find through AI systems.

01:11:40.280 --> 01:11:42.720
But I think it is increasingly important

01:11:42.720 --> 01:11:44.840
to just give people more agency themselves.

01:11:44.840 --> 01:11:46.520
So we've done things like making it

01:11:46.520 --> 01:11:48.520
so people can turn off comments or, you know,

01:11:48.520 --> 01:11:52.320
take a break from, you know, hearing from a specific person

01:11:52.320 --> 01:11:54.200
without having to signal at all

01:11:54.200 --> 01:11:55.680
that they're gonna stop following them

01:11:55.680 --> 01:11:58.400
or kind of make some stand that, okay,

01:11:58.400 --> 01:11:59.520
I'm not friends with you anymore.

01:11:59.520 --> 01:12:00.520
I'm not following you.

01:12:00.520 --> 01:12:02.000
I just like, I just don't wanna hear about this,

01:12:02.000 --> 01:12:06.560
but I also don't wanna signal at all publicly that,

01:12:06.560 --> 01:12:08.960
or to them, that there's been an issue.

01:12:10.960 --> 01:12:14.120
And then you get to some of the more extreme cases

01:12:14.120 --> 01:12:14.960
like you're talking about

01:12:14.960 --> 01:12:19.200
where someone is thinking about self-harm or suicide.

01:12:19.200 --> 01:12:24.120
And there we found that that is a place

01:12:24.120 --> 01:12:26.440
where AI can identify a lot,

01:12:26.440 --> 01:12:28.400
as well as people flagging things.

01:12:28.400 --> 01:12:31.080
You know, if people are expressing something

01:12:31.080 --> 01:12:33.360
that is, you know, potentially

01:12:33.360 --> 01:12:35.040
they're thinking of hurting themselves,

01:12:35.040 --> 01:12:37.560
those are cues that you can build systems

01:12:37.560 --> 01:12:39.600
and, you know, hundreds of languages around the world

01:12:39.600 --> 01:12:41.120
to be able to identify that.

01:12:41.120 --> 01:12:45.360
And one of the things that I'm actually quite proud of

01:12:45.360 --> 01:12:47.440
is we've built these systems

01:12:47.440 --> 01:12:51.000
that I think are clearly leading at this point

01:12:51.000 --> 01:12:53.040
that not only identify that,

01:12:53.040 --> 01:12:57.080
but then connect with local first responders

01:12:57.080 --> 01:12:59.720
and have been able to save, I think at this point,

01:12:59.720 --> 01:13:01.960
it's, you know, in thousands of cases,

01:13:01.960 --> 01:13:04.600
be able to get first responders to people

01:13:04.600 --> 01:13:06.960
through these systems who really need them

01:13:07.840 --> 01:13:09.600
because of specific plumbing that we've done

01:13:09.600 --> 01:13:11.680
between the AI work and being able to communicate

01:13:11.680 --> 01:13:13.800
with local first responder organizations.

01:13:13.800 --> 01:13:15.800
We're rolling that out in more places around the world.

01:13:15.800 --> 01:13:18.160
And I think the team that worked on that

01:13:18.160 --> 01:13:19.360
just did awesome stuff.

01:13:19.360 --> 01:13:23.320
So I think that that's a long way of saying, yeah,

01:13:23.320 --> 01:13:25.480
I mean, this is a heavy topic

01:13:25.480 --> 01:13:28.440
and you want to attack it in a bunch of different ways

01:13:30.000 --> 01:13:33.240
and also kind of understand that some of nature

01:13:33.400 --> 01:13:36.400
is for people to do this to each other,

01:13:36.400 --> 01:13:37.320
which is unfortunate,

01:13:37.320 --> 01:13:40.600
but you can give people tools and build things that help.

01:13:40.600 --> 01:13:43.840
It's still one hell of a burden though.

01:13:43.840 --> 01:13:46.160
A platform that allows people

01:13:46.160 --> 01:13:47.760
to fall in love with each other

01:13:48.600 --> 01:13:51.000
is also by nature going to be a platform

01:13:51.000 --> 01:13:52.880
that allows people to hurt each other.

01:13:52.880 --> 01:13:57.120
And when you're managing such a platform, it's difficult.

01:13:57.120 --> 01:13:58.200
And I think you spoke to it,

01:13:58.200 --> 01:14:01.280
but the psychology of that, of being a leader in that space,

01:14:01.320 --> 01:14:05.320
of creating technology that's playing in this space,

01:14:05.320 --> 01:14:08.760
like you mentioned, psychology is really damn difficult.

01:14:10.280 --> 01:14:13.160
And I mean, the burden of that is just great.

01:14:13.160 --> 01:14:17.240
I just wanted to hear you speak to that point.

01:14:18.720 --> 01:14:23.160
I have to ask about the thing you've brought up a few times,

01:14:23.160 --> 01:14:25.360
which is making controversial decisions.

01:14:26.560 --> 01:14:29.440
Let's talk about free speech and censorship.

01:14:29.440 --> 01:14:31.040
So there are two groups of people

01:14:32.720 --> 01:14:33.920
pressuring Metta on this.

01:14:33.920 --> 01:14:37.280
One group is upset that Facebook, the social network,

01:14:37.280 --> 01:14:39.040
allows misinformation and quotes

01:14:39.040 --> 01:14:41.480
to be spread on the platform.

01:14:41.480 --> 01:14:44.800
The other group are concerned that Facebook censors speech

01:14:44.800 --> 01:14:46.560
by calling it misinformation.

01:14:46.560 --> 01:14:48.840
So you're getting it from both sides.

01:14:48.840 --> 01:14:53.840
You, in 2019, October at Georgetown University,

01:14:54.600 --> 01:14:58.240
eloquently defended the importance of free speech,

01:14:58.240 --> 01:15:03.240
but then COVID came and the 2020 election came.

01:15:04.360 --> 01:15:06.440
Do you worry that outside pressures

01:15:06.440 --> 01:15:09.720
from advertisers, politicians, the public have forced Metta

01:15:09.720 --> 01:15:13.080
to damage the ideal of free speech that you spoke highly of?

01:15:13.960 --> 01:15:16.880
Just to say some obvious things upfront,

01:15:16.880 --> 01:15:18.840
I don't think pressure from advertisers

01:15:18.840 --> 01:15:21.440
or politicians directly in any way

01:15:21.440 --> 01:15:22.640
affects how we think about this.

01:15:22.640 --> 01:15:25.040
I think these are just hard topics.

01:15:25.040 --> 01:15:26.840
So let me just take you through our evolution

01:15:26.840 --> 01:15:28.200
from kind of the beginning of the company

01:15:28.200 --> 01:15:29.320
to where we are now.

01:15:30.200 --> 01:15:31.680
You don't build a company like this

01:15:31.680 --> 01:15:34.080
unless you believe that people expressing themselves

01:15:34.080 --> 01:15:35.680
is a good thing, right?

01:15:35.680 --> 01:15:38.120
So that's sort of the foundational thing.

01:15:38.120 --> 01:15:41.840
You can kind of think about our company as a formula

01:15:41.840 --> 01:15:44.200
where we think giving people voice

01:15:44.200 --> 01:15:47.400
and helping people connect creates opportunity, right?

01:15:47.400 --> 01:15:49.600
So those are the two things that we're always focused on

01:15:49.600 --> 01:15:50.800
are sort of helping people connect.

01:15:50.800 --> 01:15:52.040
We talked about that a lot,

01:15:52.040 --> 01:15:53.840
but also giving people voice

01:15:53.840 --> 01:15:55.760
and ability to express themselves.

01:15:55.760 --> 01:15:56.920
And by the way, most of the time

01:15:56.920 --> 01:15:58.080
when people express themselves,

01:15:58.080 --> 01:16:00.800
that's not like politically controversial content.

01:16:00.800 --> 01:16:04.000
It's like expressing something about their identity

01:16:04.000 --> 01:16:06.480
that's more related to the avatar conversation

01:16:06.480 --> 01:16:08.560
we had earlier in terms of expressing some facet,

01:16:08.560 --> 01:16:11.200
but that's what's important to people on a day-to-day basis.

01:16:11.200 --> 01:16:13.440
And sometimes when people feel strongly enough

01:16:13.440 --> 01:16:16.320
about something, it kind of becomes a political topic.

01:16:16.320 --> 01:16:19.080
That's sort of always been a thing that we've focused on.

01:16:19.080 --> 01:16:22.280
There's always been the question of safety in this,

01:16:22.280 --> 01:16:24.320
which if you're building a community,

01:16:24.320 --> 01:16:26.000
I think you have to focus on safety.

01:16:26.000 --> 01:16:28.280
We've had these community standards from early on.

01:16:28.280 --> 01:16:32.600
And there are about 20 different kinds of harm

01:16:32.600 --> 01:16:34.800
that we track and try to fight actively.

01:16:34.800 --> 01:16:36.360
And we've talked about some of them already.

01:16:36.360 --> 01:16:40.640
So it includes things like bullying and harassment.

01:16:40.640 --> 01:16:45.640
It includes things like terrorism or promoting terrorism,

01:16:45.960 --> 01:16:49.280
inciting violence, intellectual property theft.

01:16:49.280 --> 01:16:50.840
And in general, I think,

01:16:50.840 --> 01:16:53.720
call it about 18 out of 20 of those,

01:16:53.760 --> 01:16:57.200
there's not really a particularly polarized definition

01:16:57.200 --> 01:16:58.040
of that.

01:16:59.160 --> 01:17:01.440
I think you're not really gonna find many people

01:17:01.440 --> 01:17:03.760
in the country or in the world

01:17:03.760 --> 01:17:05.800
who are trying to say we should be

01:17:07.040 --> 01:17:09.320
fighting terrorist content less.

01:17:09.320 --> 01:17:12.200
I think the content where there are a couple of areas

01:17:12.200 --> 01:17:14.000
where I think that this has gotten more controversial

01:17:14.000 --> 01:17:16.320
recently, which I'll talk about.

01:17:16.320 --> 01:17:20.000
And you're right that misinformation is basically is up there.

01:17:20.000 --> 01:17:21.920
And I think sometimes the definition of hate speech

01:17:21.920 --> 01:17:22.760
is up there too.

01:17:23.640 --> 01:17:25.280
But I think in general,

01:17:25.280 --> 01:17:28.480
most of the content that I think we're working on

01:17:28.480 --> 01:17:31.640
for safety is not actually,

01:17:31.640 --> 01:17:33.240
people don't kind of have these questions.

01:17:33.240 --> 01:17:35.960
So it's sort of this subset.

01:17:35.960 --> 01:17:38.080
But if you go back to the beginning of the company,

01:17:38.080 --> 01:17:42.640
this was sort of pre deep learning days.

01:17:42.640 --> 01:17:47.640
And therefore, it was me and my roommate Dustin joined me.

01:17:48.440 --> 01:17:53.440
And if someone posted something bad,

01:17:56.000 --> 01:17:57.880
the AI technology did not exist yet

01:17:57.880 --> 01:18:01.240
to be able to go basically look at all the content.

01:18:02.480 --> 01:18:06.120
And we were a small enough outfit

01:18:06.120 --> 01:18:08.760
that no one would expect that we could review it all.

01:18:08.760 --> 01:18:10.360
Even if someone reported it to us,

01:18:10.360 --> 01:18:11.720
we basically did our best, right?

01:18:11.720 --> 01:18:12.680
It's like someone would report it

01:18:12.680 --> 01:18:16.880
and we try to look at stuff and deal with stuff.

01:18:16.920 --> 01:18:19.360
And for call it the first,

01:18:20.680 --> 01:18:23.960
I don't know, seven or eight years of the company,

01:18:23.960 --> 01:18:26.240
you know, we weren't that big of a company.

01:18:26.240 --> 01:18:27.400
You know, for a lot of that period,

01:18:27.400 --> 01:18:28.800
we weren't even really profitable.

01:18:28.800 --> 01:18:30.560
The AI didn't really exist to be able to do

01:18:30.560 --> 01:18:32.760
the kind of moderation that we do today.

01:18:32.760 --> 01:18:34.800
And then at some point,

01:18:34.800 --> 01:18:36.880
in kind of the middle of the last decade,

01:18:36.880 --> 01:18:38.160
that started to flip.

01:18:38.160 --> 01:18:43.160
And we became, it got to the point where we were

01:18:43.440 --> 01:18:45.280
sort of a larger and more profitable company.

01:18:45.280 --> 01:18:48.000
And the AI was starting to come online

01:18:48.000 --> 01:18:50.520
to be able to proactively detect

01:18:50.520 --> 01:18:52.840
some of the simpler forms of this.

01:18:52.840 --> 01:18:54.800
So things like pornography,

01:18:54.800 --> 01:18:57.600
you could train an image classifier

01:18:57.600 --> 01:18:59.520
to identify what a nipple was,

01:18:59.520 --> 01:19:01.320
or you can fight against terrorist content.

01:19:01.320 --> 01:19:02.160
You still could-

01:19:02.160 --> 01:19:03.440
There's actually papers on this, it's great.

01:19:03.440 --> 01:19:04.280
Oh, of course there are.

01:19:04.280 --> 01:19:05.120
Technical papers.

01:19:05.120 --> 01:19:06.240
Of course there are.

01:19:06.240 --> 01:19:07.920
You know, those are relatively easier things

01:19:07.920 --> 01:19:10.640
to train AI to do than, for example,

01:19:10.640 --> 01:19:14.000
understand the nuances of what is inciting violence

01:19:14.000 --> 01:19:15.800
in a hundred languages around the world

01:19:15.800 --> 01:19:20.240
and not have the false positives of like,

01:19:20.240 --> 01:19:22.360
okay, are you posting about this thing

01:19:22.360 --> 01:19:24.040
that might be inciting violence

01:19:24.040 --> 01:19:26.360
because you're actually trying to denounce it?

01:19:26.360 --> 01:19:28.280
In which case we probably shouldn't take that down.

01:19:28.280 --> 01:19:29.520
Where if you're trying to denounce something

01:19:29.520 --> 01:19:33.960
that's inciting violence in some kind of dialect

01:19:33.960 --> 01:19:37.200
in a corner of India, as opposed to,

01:19:37.200 --> 01:19:38.440
okay, actually you're posting this thing

01:19:38.440 --> 01:19:39.600
because you're trying to incite violence.

01:19:39.600 --> 01:19:42.040
Okay, building an AI that can basically

01:19:42.040 --> 01:19:43.520
get to that level of nuance

01:19:43.520 --> 01:19:45.120
and all the languages that we serve

01:19:46.280 --> 01:19:49.040
is something that I think is only really becoming possible

01:19:49.040 --> 01:19:51.880
now, not towards the middle of the last decade.

01:19:51.880 --> 01:19:54.840
But there's been this evolution.

01:19:54.840 --> 01:19:57.520
And I think what happened, you know,

01:19:57.520 --> 01:20:00.080
people sort of woke up after 2016

01:20:00.080 --> 01:20:02.520
and, you know, a lot of people are like,

01:20:02.520 --> 01:20:04.960
okay, the country is a lot more polarized

01:20:04.960 --> 01:20:08.040
and there's a lot more stuff here than we realized.

01:20:08.360 --> 01:20:12.840
Why weren't these internet companies on top of this?

01:20:12.840 --> 01:20:15.760
And I think at that point,

01:20:17.040 --> 01:20:20.640
it was reasonable feedback that, you know,

01:20:20.640 --> 01:20:23.480
some of this technology had started becoming possible.

01:20:23.480 --> 01:20:26.320
And at that point, I really did feel like

01:20:26.320 --> 01:20:28.960
we needed to make a substantially larger investment.

01:20:28.960 --> 01:20:31.440
We'd already worked on this stuff a lot on AI

01:20:31.440 --> 01:20:33.400
and on these integrity problems,

01:20:33.400 --> 01:20:36.440
but that we should basically invest, you know,

01:20:36.440 --> 01:20:38.160
have a thousand or more engineers

01:20:38.160 --> 01:20:40.160
basically work on building these AI systems

01:20:40.160 --> 01:20:42.560
to be able to go and proactively identify the stuff

01:20:42.560 --> 01:20:44.680
across all these different areas.

01:20:44.680 --> 01:20:46.360
Okay, so we went and did that.

01:20:46.360 --> 01:20:49.000
Now we've built the tools to be able to do that.

01:20:49.000 --> 01:20:51.920
And now I think it's actually a much more complicated set

01:20:51.920 --> 01:20:54.400
of philosophical rather than technical questions,

01:20:54.400 --> 01:20:57.960
which is the exact policy is, which are okay.

01:20:57.960 --> 01:21:02.960
Now, the way that we basically hold ourselves accountable

01:21:03.040 --> 01:21:05.520
is we issue these transparency reports every quarter

01:21:05.560 --> 01:21:06.640
and the metric that we track

01:21:06.640 --> 01:21:11.480
is for each of those 20 types of harmful content,

01:21:11.480 --> 01:21:13.520
how much of that content are we taking down

01:21:13.520 --> 01:21:15.320
before someone even has to report it to us?

01:21:15.320 --> 01:21:18.120
Right, so how effective is our AI at doing this?

01:21:18.120 --> 01:21:20.560
But that basically creates this big question,

01:21:20.560 --> 01:21:24.160
which is, okay, now we need to really be careful

01:21:24.160 --> 01:21:26.640
about how proactive we set the AI

01:21:26.640 --> 01:21:29.120
and where the exact policy lines are

01:21:29.120 --> 01:21:31.360
around what we're taking down.

01:21:31.360 --> 01:21:35.240
It's certainly at a point now where, you know,

01:21:35.240 --> 01:21:37.720
I felt like at the beginning of that journey

01:21:37.720 --> 01:21:39.440
of building those AI systems,

01:21:41.720 --> 01:21:43.160
there's a lot of push.

01:21:43.160 --> 01:21:44.360
There's things like, okay, you've got to do more.

01:21:44.360 --> 01:21:46.320
There's clearly a lot more bad content

01:21:46.320 --> 01:21:49.880
that people aren't reporting or that you're not getting to

01:21:49.880 --> 01:21:51.200
and you need to get more effective at that.

01:21:51.200 --> 01:21:52.920
And I was pretty sympathetic to that.

01:21:52.920 --> 01:21:54.840
But then I think at some point along the way,

01:21:54.840 --> 01:21:58.960
there started to be almost equal issues on both sides

01:21:58.960 --> 01:22:00.960
of, okay, actually you're kind of taking down

01:22:00.960 --> 01:22:02.080
too much stuff, right?

01:22:02.480 --> 01:22:05.520
Or some of the stuff is borderline

01:22:05.520 --> 01:22:07.520
and it wasn't really bothering anyone

01:22:07.520 --> 01:22:09.600
and they didn't report it.

01:22:09.600 --> 01:22:12.960
So is that really an issue that you need to take down?

01:22:12.960 --> 01:22:15.400
Whereas we still have the critique on the other side too

01:22:15.400 --> 01:22:18.520
where a lot of people think we're not doing enough.

01:22:18.520 --> 01:22:21.800
So it's become, as we built the technical capacity,

01:22:21.800 --> 01:22:25.560
I think it becomes more philosophically interesting,

01:22:25.560 --> 01:22:27.520
almost where you want to be on the line.

01:22:28.360 --> 01:22:32.040
And I just think like, you don't want one person

01:22:32.040 --> 01:22:33.360
making those decisions.

01:22:33.360 --> 01:22:36.040
So we've also tried to innovate in terms of building out

01:22:36.040 --> 01:22:37.440
this independent oversight board,

01:22:37.440 --> 01:22:40.440
which has people who are dedicated to free expression,

01:22:40.440 --> 01:22:44.520
but from around the world, who people can appeal cases to.

01:22:44.520 --> 01:22:46.360
So a lot of the most controversial cases

01:22:46.360 --> 01:22:48.160
basically go to them and they make the final binding

01:22:48.160 --> 01:22:50.000
decision on how we should handle that.

01:22:50.000 --> 01:22:51.600
And then of course, their decisions,

01:22:51.600 --> 01:22:53.960
we then try to figure out what the principles are

01:22:53.960 --> 01:22:56.640
behind those and encode them into the algorithms.

01:22:56.680 --> 01:22:58.120
And how are those people chosen,

01:22:58.120 --> 01:23:01.040
which you're outsourcing a difficult decision.

01:23:01.040 --> 01:23:06.040
Yeah, the initial people, we chose a handful of chairs

01:23:06.760 --> 01:23:11.760
for the group and we basically chose the people

01:23:13.240 --> 01:23:16.320
for a commitment to free expression

01:23:17.200 --> 01:23:20.400
and like a broad understanding of human rights

01:23:20.400 --> 01:23:22.280
and the trade-offs around free expression,

01:23:22.280 --> 01:23:24.360
but fundamentally people who are gonna lean

01:23:24.360 --> 01:23:25.600
towards free expression.

01:23:25.600 --> 01:23:27.320
Towards freedom of speech, okay.

01:23:27.320 --> 01:23:29.280
So there's also this idea of fact checkers,

01:23:29.280 --> 01:23:32.320
so jumping around to the misinformation questions,

01:23:32.320 --> 01:23:33.800
especially during COVID,

01:23:33.800 --> 01:23:36.840
which is an exceptionally speaking of pluralization.

01:23:36.840 --> 01:23:38.320
Can I speak to the COVID thing?

01:23:38.320 --> 01:23:40.960
And I mean, I think one of the hardest set of questions

01:23:40.960 --> 01:23:41.960
around free expression,

01:23:41.960 --> 01:23:43.000
because you asked about Georgetown

01:23:43.000 --> 01:23:44.560
is my stance fundamentally changed.

01:23:44.560 --> 01:23:49.160
And the answer to that is no, my stance has not changed.

01:23:49.160 --> 01:23:52.760
It is fundamentally the same as when I was talking

01:23:53.720 --> 01:23:56.520
to Georgetown from a philosophical perspective.

01:23:56.520 --> 01:23:58.280
The challenge with free speech

01:23:58.280 --> 01:24:03.280
is that everyone agrees that there is a line

01:24:03.840 --> 01:24:07.120
where if you're actually about to do physical harm

01:24:07.120 --> 01:24:10.600
to people, that there should be restrictions.

01:24:10.600 --> 01:24:14.000
So I mean, there's the famous Supreme Court

01:24:14.000 --> 01:24:15.160
historical example of like,

01:24:15.160 --> 01:24:18.080
you can't yell fire in a crowded theater.

01:24:18.080 --> 01:24:20.400
The thing that everyone disagrees on

01:24:20.400 --> 01:24:22.720
is what is the definition of real harm?

01:24:23.600 --> 01:24:25.640
Where I think some people think,

01:24:25.640 --> 01:24:29.080
okay, this should only be a very literal,

01:24:29.080 --> 01:24:30.960
I mean, take it back to the bullying conversation

01:24:30.960 --> 01:24:33.920
we were just having, where is it just harm

01:24:33.920 --> 01:24:35.960
if the person is about to hurt themselves

01:24:35.960 --> 01:24:37.680
because they've been bullied so hard,

01:24:37.680 --> 01:24:41.040
or is it actually harm as they're being bullied?

01:24:41.040 --> 01:24:43.240
And kind of at what point in the spectrum is that?

01:24:43.240 --> 01:24:45.600
And that's the part that there's not agreement on.

01:24:45.600 --> 01:24:48.120
But I think what people agree on pretty broadly

01:24:48.120 --> 01:24:50.600
is that when there is an acute threat,

01:24:50.600 --> 01:24:52.960
it does make sense from a societal perspective

01:24:52.960 --> 01:24:56.920
to tolerate less speech

01:24:56.920 --> 01:24:59.560
that could be potentially harmful in that acute situation.

01:24:59.560 --> 01:25:02.440
So I think where COVID got very difficult

01:25:02.440 --> 01:25:03.880
is I don't think anyone expected this

01:25:03.880 --> 01:25:06.000
to be going on for years.

01:25:06.000 --> 01:25:10.360
But if you'd kind of asked a priori,

01:25:10.360 --> 01:25:14.880
would a global pandemic where a lot of people are dying

01:25:14.880 --> 01:25:19.040
and catching this, is that an emergency

01:25:19.280 --> 01:25:23.520
where you'd kind of consider it that it's problematic

01:25:23.520 --> 01:25:26.840
to basically yell fire in a crowded theater?

01:25:26.840 --> 01:25:29.000
I think that that probably passes that test.

01:25:29.000 --> 01:25:32.320
So I think that it's a very tricky situation,

01:25:32.320 --> 01:25:35.240
but I think the fundamental commitment

01:25:35.240 --> 01:25:38.200
to free expression is there.

01:25:38.200 --> 01:25:39.840
And that's what I believe.

01:25:39.840 --> 01:25:41.440
And again, I don't think you start this company

01:25:41.440 --> 01:25:42.720
unless you care about people being able

01:25:42.720 --> 01:25:44.800
to express themselves as much as possible.

01:25:44.800 --> 01:25:48.840
But I think that that's the question, right?

01:25:49.680 --> 01:25:51.040
Is how do you define what the harm is

01:25:51.040 --> 01:25:52.440
and how acute that is?

01:25:52.440 --> 01:25:55.440
And what are the institutions that define that harm?

01:25:55.440 --> 01:25:59.720
A lot of the criticism is that the CDC, the WHO,

01:25:59.720 --> 01:26:03.800
the institutions we've come to trust as a civilization

01:26:03.800 --> 01:26:07.760
to give the line of what is and isn't harm

01:26:07.760 --> 01:26:11.640
in terms of health policy have failed in many ways,

01:26:11.640 --> 01:26:14.320
in small ways, in big ways, depending on who you ask.

01:26:14.320 --> 01:26:17.120
And then the perspective of meta and Facebook is like,

01:26:17.120 --> 01:26:20.120
well, where the hell do I get the information

01:26:20.120 --> 01:26:22.360
of what is and isn't misinformation?

01:26:22.360 --> 01:26:25.120
So it's a really difficult place to be in,

01:26:25.120 --> 01:26:26.680
but it's great to hear that you're leaning

01:26:26.680 --> 01:26:30.120
towards freedom of speech on this aspect.

01:26:30.120 --> 01:26:32.960
And again, I think this actually calls to the fact

01:26:32.960 --> 01:26:35.280
that we need to reform institutions

01:26:35.280 --> 01:26:36.760
that help keep an open mind

01:26:36.760 --> 01:26:38.960
of what is and isn't misinformation.

01:26:39.840 --> 01:26:44.560
And misinformation has been used to bully on the internet.

01:26:44.560 --> 01:26:46.880
I mean, I just have, you know, I'm friends with Joe Rogan

01:26:47.680 --> 01:26:50.680
and he's called as a, I remember hanging out with him

01:26:50.680 --> 01:26:52.000
in Vegas and somebody yelled,

01:26:52.000 --> 01:26:54.600
stop spreading misinformation.

01:26:54.600 --> 01:26:57.560
I mean, and there's a lot of people that follow him

01:26:57.560 --> 01:26:59.800
that believe he's not spreading misinformation.

01:26:59.800 --> 01:27:02.840
Like you can't just not acknowledge the fact

01:27:02.840 --> 01:27:05.640
that there's a large number of people

01:27:05.640 --> 01:27:08.760
that have a different definition of misinformation.

01:27:08.760 --> 01:27:10.680
And it's such a tough place to be.

01:27:10.680 --> 01:27:11.760
Like who do you listen to?

01:27:11.760 --> 01:27:14.240
Do you listen to quote unquote experts?

01:27:14.240 --> 01:27:16.760
Who gets, as a person who has a PhD

01:27:17.600 --> 01:27:20.120
I mean, I'm not sure I know what defines an expert,

01:27:21.120 --> 01:27:22.720
especially in a new,

01:27:24.080 --> 01:27:29.080
in a totally new pandemic or a new catastrophic event,

01:27:29.160 --> 01:27:31.480
especially when politics is involved

01:27:31.480 --> 01:27:35.040
and especially when the news or the media involved

01:27:35.040 --> 01:27:39.520
that can propagate sort of outrageous narratives

01:27:39.520 --> 01:27:40.720
and thereby make a lot of money.

01:27:40.720 --> 01:27:43.200
Like what the hell, where's the source of truth?

01:27:43.200 --> 01:27:45.520
And then everybody turns to Facebook.

01:27:45.520 --> 01:27:48.080
It's like, please tell me what the source of truth is.

01:27:49.080 --> 01:27:50.760
Well, I mean, well, how would you handle this

01:27:50.760 --> 01:27:52.720
if you were in my position?

01:27:52.720 --> 01:27:55.200
Is very, very, very, very difficult.

01:27:55.200 --> 01:27:56.480
I would say,

01:27:59.440 --> 01:28:02.720
I would more speak about how difficult the choices are

01:28:02.720 --> 01:28:04.080
and be transparent about like,

01:28:04.080 --> 01:28:05.400
what the hell do you do with this?

01:28:05.400 --> 01:28:07.120
Like here, you got exactly,

01:28:07.120 --> 01:28:08.840
ask the exact question you just asked me,

01:28:08.840 --> 01:28:10.160
but to the broader public.

01:28:10.160 --> 01:28:12.440
Like, okay, yeah, you guys tell me what to do.

01:28:12.440 --> 01:28:14.200
So like crowdsource it.

01:28:14.200 --> 01:28:15.800
And then the other,

01:28:15.800 --> 01:28:19.800
the other aspect is when you spoke really eloquently

01:28:19.800 --> 01:28:23.400
about the fact that there's this going back and forth

01:28:23.400 --> 01:28:25.200
and now there's a feeling like you're censoring

01:28:25.200 --> 01:28:26.680
a little bit too much.

01:28:26.680 --> 01:28:27.840
And so I would lean,

01:28:27.840 --> 01:28:30.240
I would try to be ahead of that feeling.

01:28:30.240 --> 01:28:33.080
I would now lean towards freedom of speech and say,

01:28:33.080 --> 01:28:36.200
we're not the ones that are going to define misinformation.

01:28:36.200 --> 01:28:38.560
Let it be a public debate.

01:28:38.560 --> 01:28:40.040
Let the idea stand.

01:28:40.040 --> 01:28:42.560
And I actually place,

01:28:42.560 --> 01:28:44.280
this idea of misinformation,

01:28:44.280 --> 01:28:46.360
I place the responsibility

01:28:46.360 --> 01:28:50.040
on the poor communication skills of scientists.

01:28:50.040 --> 01:28:52.560
They should be in the battlefield of ideas.

01:28:52.560 --> 01:28:54.440
And everybody who is

01:28:56.320 --> 01:28:58.880
spreading information against the vaccine,

01:28:58.880 --> 01:29:00.400
they should not be censored.

01:29:00.400 --> 01:29:03.000
They should be talked with and you should show the data.

01:29:03.000 --> 01:29:04.800
You should have open discussion

01:29:04.800 --> 01:29:07.080
as opposed to rolling your eyes and saying,

01:29:07.080 --> 01:29:08.280
I'm the expert.

01:29:08.280 --> 01:29:09.840
I know what I'm talking about.

01:29:10.640 --> 01:29:11.600
No, you need to convince people.

01:29:11.600 --> 01:29:13.240
It's a battle of ideas.

01:29:13.240 --> 01:29:15.360
So that's the whole point of freedom of speech

01:29:15.360 --> 01:29:17.120
is the way to defeat bad ideas

01:29:17.120 --> 01:29:20.080
is with good ideas with speech.

01:29:20.080 --> 01:29:22.080
So like the responsibility here falls

01:29:22.080 --> 01:29:26.560
on the poor communication skills of scientists.

01:29:26.560 --> 01:29:28.440
Thanks to social media,

01:29:30.280 --> 01:29:32.160
scientists are not communicators.

01:29:32.160 --> 01:29:34.040
They have the power to communicate.

01:29:34.040 --> 01:29:36.760
Some of the best stuff I've seen about COVID

01:29:36.760 --> 01:29:38.840
from doctors is on social media.

01:29:38.840 --> 01:29:41.520
It's a way to learn to respond really quickly,

01:29:41.520 --> 01:29:43.800
to go faster than the peer review process.

01:29:43.800 --> 01:29:45.440
And so they just need to get way better

01:29:45.440 --> 01:29:46.480
at that communication.

01:29:46.480 --> 01:29:50.040
And also by better, I don't mean just convincing.

01:29:50.040 --> 01:29:51.800
I also mean speak with humility.

01:29:51.800 --> 01:29:54.280
Don't talk down to people, all those kinds of things.

01:29:54.280 --> 01:29:56.000
And as a platform, I would say,

01:29:56.880 --> 01:29:59.800
I would step back a little bit.

01:29:59.800 --> 01:30:00.800
Not all the way, of course,

01:30:00.800 --> 01:30:03.520
because there's a lot of stuff that can cause real harm

01:30:03.520 --> 01:30:04.440
as we've talked about,

01:30:04.440 --> 01:30:06.920
but you lean more towards freedom of speech

01:30:06.920 --> 01:30:09.560
because then people from a brand perspective

01:30:09.560 --> 01:30:12.720
wouldn't be blaming you for the other ills of society,

01:30:13.720 --> 01:30:14.560
which there are many.

01:30:14.560 --> 01:30:17.880
The institutions have flaws.

01:30:17.880 --> 01:30:21.680
The political divide, obviously politicians have flaws.

01:30:21.680 --> 01:30:23.400
That's news.

01:30:23.400 --> 01:30:28.040
The media has flaws that they're all trying to work with.

01:30:28.040 --> 01:30:31.080
And because of the central place of Facebook in the world,

01:30:31.080 --> 01:30:34.320
all of those flaws somehow kind of propagate to Facebook.

01:30:34.360 --> 01:30:38.160
And you're sitting there as Plato, the philosopher,

01:30:38.160 --> 01:30:40.720
have to answer to some of the most difficult questions

01:30:40.720 --> 01:30:43.960
asking, being asked of human civilization.

01:30:43.960 --> 01:30:47.000
So I don't know, maybe this is an American answer though,

01:30:47.000 --> 01:30:48.440
to lean towards freedom of speech.

01:30:48.440 --> 01:30:50.320
I don't know if that applies globally.

01:30:51.280 --> 01:30:52.640
So yeah, I don't know.

01:30:52.640 --> 01:30:55.200
But transparency and saying,

01:30:55.200 --> 01:30:57.400
I think as a technologist,

01:30:57.400 --> 01:30:59.160
one of the things I sense about Facebook

01:30:59.160 --> 01:31:02.360
and matter when people talk about this company

01:31:02.360 --> 01:31:05.240
is they don't necessarily understand fully

01:31:05.240 --> 01:31:06.880
how difficult the problem is.

01:31:06.880 --> 01:31:09.720
You talked about AI has to catch a bunch of harmful stuff

01:31:10.680 --> 01:31:14.640
really quickly, just the sea of data you have to deal with.

01:31:14.640 --> 01:31:16.680
It's a really difficult problem.

01:31:16.680 --> 01:31:18.400
So like any of the critics,

01:31:18.400 --> 01:31:21.520
if you just hand them the helm for a week,

01:31:22.840 --> 01:31:24.360
let's see how well you can do.

01:31:25.400 --> 01:31:28.160
Like that, to me, that's definitely something

01:31:28.160 --> 01:31:31.320
that would wake people up to how difficult this problem is

01:31:31.320 --> 01:31:33.480
if there's more transparency in saying

01:31:33.480 --> 01:31:35.560
how difficult this problem is.

01:31:35.560 --> 01:31:37.800
Let me ask you about, on the AI front,

01:31:37.800 --> 01:31:41.600
just because you mentioned language and my in eloquence,

01:31:41.600 --> 01:31:44.120
translation is something I wanted to ask you about.

01:31:44.120 --> 01:31:47.760
And first, just to give a shout out to the supercomputer,

01:31:47.760 --> 01:31:51.960
you've recently announced the AI Research Supercluster, RSC.

01:31:51.960 --> 01:31:54.680
Obviously, I'm somebody who loves the GPUs.

01:31:54.680 --> 01:31:57.120
It currently has 6,000 GPUs.

01:31:57.160 --> 01:32:02.160
Nvidia DGX-A100 is the systems that have in total 6,000 GPUs.

01:32:04.120 --> 01:32:07.360
And it will eventually, maybe this year, maybe soon,

01:32:07.360 --> 01:32:10.040
will have 16,000 GPUs.

01:32:10.040 --> 01:32:11.720
So it can do a bunch of different kinds

01:32:11.720 --> 01:32:15.080
of machine learning applications.

01:32:15.080 --> 01:32:18.600
There's a cool thing on the distributed storage aspect

01:32:18.600 --> 01:32:19.720
and all that kind of stuff.

01:32:19.720 --> 01:32:23.080
So one of the applications that I think is super exciting

01:32:23.080 --> 01:32:26.360
is translation, real-time translation.

01:32:26.360 --> 01:32:29.120
I mentioned to you that having a conversation,

01:32:29.120 --> 01:32:32.160
I speak Russian fluently, I speak English somewhat fluently.

01:32:32.160 --> 01:32:34.960
And I'm having a conversation with Vladimir Putin,

01:32:34.960 --> 01:32:36.880
say, as a use case, me as a user

01:32:36.880 --> 01:32:38.520
coming to you as a use case.

01:32:38.520 --> 01:32:42.560
We both speak each other's language.

01:32:42.560 --> 01:32:45.080
I speak Russian, he speaks English.

01:32:45.080 --> 01:32:48.040
How can we have that communication go well

01:32:48.040 --> 01:32:49.440
with the help of AI?

01:32:49.440 --> 01:32:51.280
I think it's such a beautiful

01:32:51.280 --> 01:32:54.760
and a powerful application of AI to connect the world,

01:32:54.760 --> 01:32:57.600
that bridge the gap, not necessarily between me and Putin,

01:32:57.600 --> 01:33:01.040
but people that don't have that shared language.

01:33:02.000 --> 01:33:04.160
Can you just speak about your vision with translation?

01:33:04.160 --> 01:33:06.720
Because I think that's a really exciting application.

01:33:06.720 --> 01:33:09.440
If you're trying to help people connect all around the world,

01:33:09.440 --> 01:33:11.640
a lot of content is produced in one language

01:33:11.640 --> 01:33:14.760
and people in all these other places are interested in it.

01:33:14.760 --> 01:33:16.680
So being able to translate that

01:33:17.760 --> 01:33:20.600
just unlocks a lot of value on a day-to-day basis.

01:33:20.600 --> 01:33:24.440
And so the kind of AI around translation is interesting

01:33:24.440 --> 01:33:27.880
because it's gone through a bunch of iterations.

01:33:27.880 --> 01:33:31.000
But the basic state of the art is that

01:33:31.000 --> 01:33:34.760
you don't want to go through different kind of

01:33:36.080 --> 01:33:41.080
intermediate symbolic representations of language

01:33:41.400 --> 01:33:42.520
or something like that.

01:33:42.520 --> 01:33:46.920
You basically want to be able to map the concepts

01:33:46.920 --> 01:33:49.320
and basically go directly from one language to another.

01:33:49.320 --> 01:33:53.040
And you just can train bigger and bigger models

01:33:53.040 --> 01:33:54.120
in order to be able to do that.

01:33:54.120 --> 01:33:58.120
And that's where the research supercluster comes in

01:33:58.120 --> 01:34:01.080
is basically a lot of the trend in machine learning

01:34:01.080 --> 01:34:03.400
is just you're building bigger and bigger models

01:34:03.400 --> 01:34:05.720
and you just need a lot of computation to train them.

01:34:05.720 --> 01:34:08.360
So it's not that like the translation would run

01:34:08.360 --> 01:34:12.080
on the supercomputer, the training of the model,

01:34:12.080 --> 01:34:16.320
which could have billions or trillions of examples of

01:34:16.320 --> 01:34:19.080
just basically that,

01:34:19.080 --> 01:34:22.360
your training models on this supercluster

01:34:22.360 --> 01:34:26.760
in days or weeks that might take a much longer period

01:34:26.760 --> 01:34:28.120
of time on a smaller cluster.

01:34:28.120 --> 01:34:30.200
So it just wouldn't be practical for most teams to do.

01:34:30.200 --> 01:34:32.280
But the translation work,

01:34:34.560 --> 01:34:38.160
we were basically getting from being able to go

01:34:38.160 --> 01:34:40.920
between about a hundred languages seamlessly today

01:34:42.280 --> 01:34:46.720
to being able to go to about 300 languages in the near term.

01:34:46.720 --> 01:34:48.720
So from any language to any other language.

01:34:48.720 --> 01:34:51.560
Yeah, and part of the issue when you get closer

01:34:52.160 --> 01:34:57.160
to more languages is some of these get to be pretty,

01:34:59.840 --> 01:35:01.920
not very popular languages, right?

01:35:01.920 --> 01:35:04.320
Where there isn't that much content in them.

01:35:04.320 --> 01:35:09.320
So you end up having less data and you need to kind of use

01:35:09.560 --> 01:35:12.080
a model that you've built up around other examples.

01:35:12.080 --> 01:35:14.040
And this is one of the big questions around AI

01:35:14.040 --> 01:35:16.680
is like how generalizable can things be?

01:35:16.680 --> 01:35:18.760
And that I think is one of the things

01:35:18.760 --> 01:35:19.800
that's just kind of exciting here

01:35:19.800 --> 01:35:21.280
from a technical perspective.

01:35:22.200 --> 01:35:23.800
We talked about this with the metaverse,

01:35:23.800 --> 01:35:26.440
capturing the magic of human to human interaction.

01:35:26.440 --> 01:35:30.200
So me and Putin, okay, again, this is a therapy session.

01:35:30.200 --> 01:35:32.480
It's a tough example because you actually both speak

01:35:32.480 --> 01:35:34.680
Russian and English, but in the future.

01:35:34.680 --> 01:35:37.720
I see it as a touring test of a kind

01:35:37.720 --> 01:35:40.440
because we would both like to have an AI that improves

01:35:40.440 --> 01:35:42.240
because I don't speak Russian that well.

01:35:42.240 --> 01:35:44.320
He doesn't speak English that well.

01:35:44.320 --> 01:35:48.640
It would be nice to outperform our abilities.

01:35:48.640 --> 01:35:50.640
And it sets a really nice bar

01:35:50.640 --> 01:35:53.600
because I think AI can really help in translation

01:35:53.600 --> 01:35:55.720
for people that don't speak the language at all,

01:35:55.720 --> 01:36:00.120
but to actually capture the magic of the chemistry,

01:36:00.120 --> 01:36:03.240
the translation, which would make the metaverse

01:36:03.240 --> 01:36:05.840
super immersive, I mean, that's exciting.

01:36:05.840 --> 01:36:08.720
You remove the barrier of language, period.

01:36:08.720 --> 01:36:11.240
Yeah, so when people think about translation,

01:36:11.240 --> 01:36:14.240
I think a lot of that is they're thinking about text to text,

01:36:14.240 --> 01:36:17.120
but speech to speech, I think is a whole nother thing.

01:36:17.120 --> 01:36:19.080
And I mean, one of the big lessons on that,

01:36:19.080 --> 01:36:22.120
which I was referring to before is I think early models,

01:36:22.120 --> 01:36:23.800
it's like, all right, they take speech,

01:36:23.800 --> 01:36:25.080
they translate it to text,

01:36:25.080 --> 01:36:26.680
translate the text to another language,

01:36:26.680 --> 01:36:29.360
and then kind of output that as speech in that language.

01:36:29.360 --> 01:36:30.440
And you don't wanna do that.

01:36:30.440 --> 01:36:32.240
You just wanna be able to go directly from speech

01:36:32.240 --> 01:36:34.160
in one language to speech in another language

01:36:34.160 --> 01:36:36.400
and build up the models to do that.

01:36:36.400 --> 01:36:40.760
And I think one of the, there have been,

01:36:40.760 --> 01:36:42.880
when you look at the progress in machine learning,

01:36:42.880 --> 01:36:46.240
there have been big advances in the techniques.

01:36:47.200 --> 01:36:51.520
Some of the advances in self-supervised learning,

01:36:51.520 --> 01:36:52.880
which I know you talked to Jan about,

01:36:52.880 --> 01:36:55.280
and he's like one of the leading thinkers in this area.

01:36:55.280 --> 01:36:57.520
I just think that that stuff is really exciting,

01:36:57.520 --> 01:36:59.800
but then you couple that with the ability

01:36:59.800 --> 01:37:02.440
to just throw larger and larger amounts of compute

01:37:02.440 --> 01:37:03.960
at training these models,

01:37:03.960 --> 01:37:05.560
and you can just do a lot of things

01:37:05.560 --> 01:37:09.320
that were harder to do before.

01:37:09.320 --> 01:37:12.920
But we're asking more of our systems too, right?

01:37:12.920 --> 01:37:14.840
So if you think about the applications

01:37:14.840 --> 01:37:18.360
that we're gonna need for the metaverse,

01:37:18.360 --> 01:37:21.440
or think about it, let's talk about AR here for a second.

01:37:21.440 --> 01:37:23.080
You're gonna have these glasses.

01:37:23.080 --> 01:37:24.280
They're gonna look,

01:37:24.280 --> 01:37:28.120
and hopefully like a normal-ish looking pair of glasses,

01:37:28.120 --> 01:37:31.200
but they're gonna be able to put holograms in the world

01:37:31.200 --> 01:37:35.960
and intermix virtual and physical objects in your scene.

01:37:35.960 --> 01:37:39.040
And one of the things that's gonna be unique about this,

01:37:39.040 --> 01:37:41.200
compared to every other computing device

01:37:41.200 --> 01:37:42.560
that you've had before,

01:37:42.560 --> 01:37:45.160
is that this is gonna be the first computing device

01:37:45.160 --> 01:37:47.560
that has all the same signals

01:37:47.560 --> 01:37:49.640
about what's going on around you that you have, right?

01:37:49.640 --> 01:37:53.000
So your phone, I mean, you can have it take a photo

01:37:53.000 --> 01:37:56.600
or a video, but I mean, these glasses are gonna,

01:37:56.600 --> 01:37:57.480
whenever you activate them,

01:37:57.480 --> 01:37:59.000
they're gonna be able to see what you see

01:37:59.000 --> 01:38:00.240
from your perspective.

01:38:00.240 --> 01:38:01.520
They're gonna be able to hear what you hear

01:38:01.520 --> 01:38:03.440
because the microphones and all that

01:38:03.440 --> 01:38:05.800
are gonna be right around where your ears are.

01:38:05.800 --> 01:38:08.160
So you're gonna want an AI assistant

01:38:08.160 --> 01:38:10.240
that's a new kind of AI assistant

01:38:10.240 --> 01:38:13.880
that can basically help you process the world

01:38:13.880 --> 01:38:17.000
from this first-person perspective

01:38:17.000 --> 01:38:18.560
or from the perspective that you have.

01:38:18.560 --> 01:38:21.760
And the utility of that is gonna be huge,

01:38:21.760 --> 01:38:25.400
but the kinds of AI models that we're gonna need

01:38:25.400 --> 01:38:27.400
are going to be just,

01:38:28.600 --> 01:38:30.000
I don't know, there's a lot that we're gonna need

01:38:30.000 --> 01:38:31.800
to basically make advances in.

01:38:31.800 --> 01:38:33.720
But I mean, but that's why I think these concepts

01:38:33.720 --> 01:38:36.560
of the metaverse and the advances in AI

01:38:36.560 --> 01:38:38.800
are so fundamentally interlinked.

01:38:40.240 --> 01:38:42.880
That, I mean, they're kind of enabling each other.

01:38:42.880 --> 01:38:45.440
Yeah, like the world builder is a really cool idea.

01:38:45.440 --> 01:38:47.280
Like you can be like a Bob Ross,

01:38:47.280 --> 01:38:49.440
like I'm gonna put a little tree right here.

01:38:49.440 --> 01:38:51.200
I need a little tree, it's missing a little tree.

01:38:51.200 --> 01:38:53.000
And then, but at scale,

01:38:53.000 --> 01:38:55.680
like enriching your experience in all kinds of ways.

01:38:55.680 --> 01:38:56.960
You mentioned the assistant too.

01:38:56.960 --> 01:38:58.200
That's really interesting,

01:38:58.200 --> 01:39:00.800
how you can have AI assistants helping you out

01:39:00.800 --> 01:39:04.000
on different levels of sort of intimacy of communication.

01:39:04.000 --> 01:39:05.480
It could be just like scheduling

01:39:05.480 --> 01:39:08.120
or it could be like almost like therapy.

01:39:08.120 --> 01:39:09.880
Clearly I need some.

01:39:10.400 --> 01:39:11.240
Let me ask you,

01:39:11.240 --> 01:39:14.040
you're one of the most successful people ever.

01:39:14.040 --> 01:39:16.280
You've built an incredible company

01:39:16.280 --> 01:39:18.120
that has a lot of impact.

01:39:18.120 --> 01:39:21.840
What advice do you have for young people today?

01:39:23.160 --> 01:39:25.520
How to live a life they can be proud of?

01:39:25.520 --> 01:39:30.440
How to build something that can have a big positive impact

01:39:30.440 --> 01:39:31.280
on the world?

01:39:34.320 --> 01:39:37.520
Well, let's break that down

01:39:37.520 --> 01:39:39.880
because I think you proud of,

01:39:39.880 --> 01:39:41.320
have a big positive impact.

01:39:41.320 --> 01:39:42.400
Well, you're actually listening.

01:39:42.400 --> 01:39:43.920
And how to live your life

01:39:43.920 --> 01:39:47.600
are actually three different things that I think,

01:39:47.600 --> 01:39:48.960
I mean, they could line up,

01:39:48.960 --> 01:39:52.520
but and also like what age of people are you talking to?

01:39:52.520 --> 01:39:53.560
Because I mean, I can like-

01:39:53.560 --> 01:39:54.720
High school and college.

01:39:54.720 --> 01:39:56.520
So you don't really know what you're doing,

01:39:56.520 --> 01:39:59.880
but you dream big and you really have a chance

01:39:59.880 --> 01:40:02.320
to do something unprecedented.

01:40:02.320 --> 01:40:03.160
Yeah.

01:40:04.200 --> 01:40:05.040
So I guess-

01:40:05.040 --> 01:40:06.320
I'll support people my age.

01:40:06.320 --> 01:40:07.760
Okay, so let's maybe start

01:40:07.760 --> 01:40:10.440
with the kind of most philosophical

01:40:10.440 --> 01:40:12.120
and abstract version of this.

01:40:12.120 --> 01:40:16.240
Every night when I put my daughters to bed,

01:40:16.240 --> 01:40:18.440
we go through this thing and like,

01:40:20.440 --> 01:40:21.800
they call it the good night things.

01:40:21.800 --> 01:40:25.480
Cause we're basically what we talk about at night.

01:40:25.480 --> 01:40:29.760
And I just, I go through them.

01:40:29.760 --> 01:40:31.480
Sounds like a good show.

01:40:31.480 --> 01:40:32.760
The good night things.

01:40:32.760 --> 01:40:33.800
Yeah, Priscilla's always asking,

01:40:33.800 --> 01:40:35.120
she's like, can I get good night things?

01:40:35.120 --> 01:40:37.160
It's like, I don't know, you could have been too early.

01:40:37.160 --> 01:40:38.000
But it's-

01:40:41.640 --> 01:40:45.000
But I basically go through with Max and Augie,

01:40:46.400 --> 01:40:48.960
what are the things that are most important in life?

01:40:48.960 --> 01:40:50.240
Right, that I just, it's like,

01:40:50.240 --> 01:40:51.600
what do I want them to remember

01:40:51.600 --> 01:40:53.960
and just have like really ingrained in them as they grow up?

01:40:53.960 --> 01:40:56.760
And it's health, right?

01:40:56.760 --> 01:40:58.840
Making sure that you take care of yourself

01:40:58.840 --> 01:41:00.760
and keep yourself in good shape.

01:41:00.760 --> 01:41:02.960
Loving friends and family, right?

01:41:02.960 --> 01:41:05.400
Because having the relationships,

01:41:05.400 --> 01:41:08.720
the family and making time for friends,

01:41:08.720 --> 01:41:12.920
I think is perhaps one of the most important things.

01:41:13.840 --> 01:41:16.080
And then the third is maybe a little more amorphous,

01:41:16.080 --> 01:41:19.440
but it is something that you're excited about for the future.

01:41:19.440 --> 01:41:21.320
And when I'm talking to a four-year-old,

01:41:21.320 --> 01:41:23.520
often I'll ask her what she's excited about

01:41:23.520 --> 01:41:25.240
for tomorrow or the week ahead.

01:41:25.240 --> 01:41:29.600
But I think for most people, it's really hard.

01:41:29.600 --> 01:41:31.480
I mean, the world is a heavy place.

01:41:31.480 --> 01:41:34.800
And I think like the way that we navigate it

01:41:34.800 --> 01:41:37.360
is that we have things that we're looking forward to.

01:41:37.360 --> 01:41:41.680
So whether it is building AR glasses for the future

01:41:41.680 --> 01:41:45.560
or being able to celebrate my 10-year wedding anniversary

01:41:45.560 --> 01:41:47.400
with my wife that's coming up,

01:41:47.400 --> 01:41:49.400
it's like, I think people, you know,

01:41:49.400 --> 01:41:51.920
you have things that you're looking forward to.

01:41:51.920 --> 01:41:53.160
Or for the girls, it's often,

01:41:53.160 --> 01:41:54.640
I want to see mom in the morning, right?

01:41:54.640 --> 01:41:56.080
It's like just, but it's like,

01:41:56.080 --> 01:41:57.080
that's a really critical thing.

01:41:57.080 --> 01:42:00.360
And then the last thing is I ask them every day,

01:42:00.360 --> 01:42:02.640
what did you do today to help someone?

01:42:04.360 --> 01:42:07.120
Because I just think that that's a really critical thing

01:42:07.120 --> 01:42:10.760
is like, it's easy to kind of get caught up in yourself

01:42:10.760 --> 01:42:14.280
and kind of stuff that's really far down the road.

01:42:14.280 --> 01:42:17.520
But like, did you do something just concrete today

01:42:17.520 --> 01:42:18.360
to help someone?

01:42:18.360 --> 01:42:19.800
And, you know, it can just be as simple as,

01:42:19.800 --> 01:42:23.400
okay, yeah, I helped set the table for lunch, right?

01:42:23.400 --> 01:42:26.440
Or, you know, this other kid in our school

01:42:26.440 --> 01:42:27.920
was having a hard time with something

01:42:27.920 --> 01:42:29.280
and I like helped explain it to him.

01:42:29.280 --> 01:42:32.920
But those are, that's sort of like,

01:42:32.920 --> 01:42:36.080
if you were to boil down my overall life philosophy

01:42:36.080 --> 01:42:40.160
into what I try to impart to my kids,

01:42:40.160 --> 01:42:43.000
those are the things that I think are really important.

01:42:43.000 --> 01:42:44.320
So, okay, so let's say college.

01:42:44.320 --> 01:42:45.840
So if you're a graduate in college,

01:42:45.840 --> 01:42:47.760
probably more practical advice.

01:42:51.400 --> 01:42:53.160
It's almost very focused on people.

01:42:53.160 --> 01:42:57.140
And I think the most important decision

01:42:57.180 --> 01:42:59.340
that you're probably gonna make if you're in college

01:42:59.340 --> 01:43:01.620
is who you surround yourself with,

01:43:01.620 --> 01:43:02.980
because you become like the people

01:43:02.980 --> 01:43:04.620
you surround yourself with.

01:43:04.620 --> 01:43:09.620
And I sort of have this hiring heuristic at Metta,

01:43:12.420 --> 01:43:16.300
which is that I will only hire someone to work for me

01:43:16.300 --> 01:43:19.820
if I could see myself working for them.

01:43:19.820 --> 01:43:21.660
Not necessarily that I want them to run the company

01:43:21.660 --> 01:43:23.780
because I like my job, but like,

01:43:23.780 --> 01:43:25.900
but in an alternate universe, if it was their company

01:43:25.900 --> 01:43:28.420
and I was looking to go work somewhere,

01:43:28.420 --> 01:43:29.700
would I be happy to work for them?

01:43:29.700 --> 01:43:32.740
And I think that that's a helpful heuristic

01:43:33.980 --> 01:43:35.580
to help balance, you know,

01:43:35.580 --> 01:43:36.620
when you're building something like this,

01:43:36.620 --> 01:43:38.700
there's a lot of pressure to, you know,

01:43:38.700 --> 01:43:39.900
you wanna build out your teams

01:43:39.900 --> 01:43:41.420
because there's a lot of stuff that you need to get done.

01:43:41.420 --> 01:43:43.900
And then everyone always says, don't compromise on quality,

01:43:43.900 --> 01:43:45.100
but there's this question of, okay,

01:43:45.100 --> 01:43:46.220
how do you know that someone is good enough?

01:43:46.220 --> 01:43:49.020
And I think my answer is, I would want someone

01:43:49.020 --> 01:43:52.900
to be on my team if I would work for them.

01:43:52.900 --> 01:43:55.540
But I think it's actually a pretty similar answer

01:43:55.540 --> 01:43:57.500
to like, if you were gonna go,

01:43:57.500 --> 01:44:00.420
if you were choosing friends or a partner

01:44:00.420 --> 01:44:01.660
or something like that.

01:44:01.660 --> 01:44:04.140
So when you're kind of in college,

01:44:04.140 --> 01:44:05.820
trying to figure out what your circle is gonna be,

01:44:05.820 --> 01:44:06.740
trying to figure out, you know,

01:44:06.740 --> 01:44:09.100
you're evaluating different job opportunities.

01:44:10.340 --> 01:44:12.940
Who are the people, even if they're gonna be peers

01:44:12.940 --> 01:44:15.100
in what you're doing, who are the people

01:44:15.100 --> 01:44:16.980
who in an alternate university,

01:44:16.980 --> 01:44:18.700
you would wanna work for them

01:44:18.700 --> 01:44:20.380
because you think you're gonna learn a lot from them

01:44:20.380 --> 01:44:24.140
because they know, because they are kind of values aligned

01:44:24.140 --> 01:44:25.460
on the things that you care about

01:44:26.460 --> 01:44:28.220
and they're gonna push you,

01:44:28.220 --> 01:44:29.460
but also they know different things

01:44:29.460 --> 01:44:31.820
and have different experiences that are kind of more

01:44:31.820 --> 01:44:33.500
of what you wanna become like over time.

01:44:33.500 --> 01:44:36.100
So I don't know, I think probably people are too

01:44:37.020 --> 01:44:39.100
in general objective focused

01:44:39.100 --> 01:44:42.700
and maybe not focused enough on the connections

01:44:42.700 --> 01:44:46.860
and the people who they're basically building relationships.

01:44:46.860 --> 01:44:48.140
I don't know what it says about me,

01:44:48.140 --> 01:44:53.140
but my place in Austin now has seven legged robots.

01:44:53.540 --> 01:44:55.420
So I'm surrounding myself by robots,

01:44:55.420 --> 01:44:59.140
which is probably something I should look into.

01:44:59.140 --> 01:45:02.780
What kind of world would you like to see your daughters grow

01:45:02.780 --> 01:45:05.460
up in even after you're gone?

01:45:09.300 --> 01:45:11.500
Well, I think one of the promises of all the stuff

01:45:11.500 --> 01:45:15.580
that is getting built now is that it can be a world

01:45:15.580 --> 01:45:20.580
where more people have, can just live out their imagination.

01:45:21.580 --> 01:45:23.420
One of my favorite quotes,

01:45:23.420 --> 01:45:25.140
I think it was attributed to Picasso,

01:45:25.140 --> 01:45:26.780
it's that all children are artists

01:45:26.780 --> 01:45:29.580
and the challenge is how do you remain one when you grow up?

01:45:29.580 --> 01:45:33.580
And I mean, if you have kids, this is pretty clear.

01:45:33.580 --> 01:45:36.220
I mean, they're just like have wonderful imaginations

01:45:36.220 --> 01:45:38.940
and part of what I think is gonna be great

01:45:38.940 --> 01:45:41.340
about the creator economy and the metaverse

01:45:41.340 --> 01:45:43.820
and all this stuff is like this notion around

01:45:44.700 --> 01:45:46.260
that a lot more people in the future

01:45:46.260 --> 01:45:48.980
are gonna get to work doing creative stuff

01:45:48.980 --> 01:45:51.420
than what I think today we would just consider

01:45:51.420 --> 01:45:53.740
traditional labor or service.

01:45:53.740 --> 01:45:56.300
And I think that that's awesome.

01:45:56.300 --> 01:46:00.180
And that's like what a lot of what people are here to do

01:46:00.180 --> 01:46:03.180
is like collaborate together, work together,

01:46:03.180 --> 01:46:06.460
think of things that you wanna build and go do it.

01:46:06.460 --> 01:46:08.540
And I don't know, one of the things

01:46:08.540 --> 01:46:09.420
that I just think is striking,

01:46:09.420 --> 01:46:13.700
so I teach my daughters like some basic coding with Scratch.

01:46:13.700 --> 01:46:15.460
I mean, they're still obviously really young,

01:46:15.460 --> 01:46:18.580
but I think of coding as building, right?

01:46:19.260 --> 01:46:20.780
When I'm coding, I'm like building something

01:46:20.780 --> 01:46:22.300
that I want to exist.

01:46:22.300 --> 01:46:27.300
But my youngest daughter, she's very musical

01:46:27.980 --> 01:46:32.820
and pretty artistic and she thinks about coding as art.

01:46:32.820 --> 01:46:35.540
She calls it code art, not the code,

01:46:35.540 --> 01:46:37.540
but the output of what she is making.

01:46:37.540 --> 01:46:39.340
It's like she's just very interesting visually

01:46:39.340 --> 01:46:42.580
in what she can kind of output and how it can move around.

01:46:42.580 --> 01:46:45.020
And do we need to fix that?

01:46:45.020 --> 01:46:45.860
Are we good?

01:46:45.860 --> 01:46:47.460
What happened?

01:46:47.460 --> 01:46:49.460
Do we have to clap, Alexa?

01:46:49.460 --> 01:46:53.020
Yes, I was just talking about Augie and her code art.

01:46:53.020 --> 01:46:56.540
But I mean, to me, this is like a beautiful thing, right?

01:46:56.540 --> 01:47:00.260
The notion that like for me coding was this functional thing

01:47:00.260 --> 01:47:03.140
and I enjoyed it and it like helped build

01:47:03.140 --> 01:47:05.940
something utilitarian, but that for the next generation

01:47:05.940 --> 01:47:10.460
of people, it will be even more an expression

01:47:10.460 --> 01:47:14.900
of their kind of imagination and artistic sense

01:47:14.900 --> 01:47:15.940
for what they want to exist.

01:47:15.940 --> 01:47:17.620
So I don't know, if that happens,

01:47:17.620 --> 01:47:20.380
if we can help bring about this world

01:47:20.380 --> 01:47:24.380
where a lot more people can, that that's like

01:47:24.380 --> 01:47:27.820
their existence going forward is being able to basically

01:47:27.820 --> 01:47:32.820
create and live out all these different kinds of art.

01:47:32.900 --> 01:47:34.380
I just think that that's like a beautiful

01:47:34.380 --> 01:47:37.900
and wonderful thing and we'll be very freeing for humanity

01:47:37.900 --> 01:47:40.380
to spend more of our time on the things that matter to us.

01:47:40.380 --> 01:47:43.100
Yeah, allow more and more people to express their art

01:47:43.100 --> 01:47:44.460
in the full meaning of that word.

01:47:45.060 --> 01:47:46.820
That's a beautiful vision.

01:47:46.820 --> 01:47:49.260
We mentioned that you are mortal.

01:47:50.220 --> 01:47:51.820
Are you afraid of death?

01:47:51.820 --> 01:47:53.500
Do you think about your mortality?

01:47:56.220 --> 01:47:57.740
And are you afraid of it?

01:48:01.140 --> 01:48:03.020
You didn't sign up for this on a podcast.

01:48:03.020 --> 01:48:05.020
No, I mean, it's an interesting question.

01:48:06.980 --> 01:48:08.740
I mean, I'm definitely aware of it.

01:48:08.740 --> 01:48:13.740
I do a fair amount of like extreme sport type stuff.

01:48:15.620 --> 01:48:20.300
So I'm definitely aware of it.

01:48:22.380 --> 01:48:24.900
And you're flirting with it a bit.

01:48:24.900 --> 01:48:25.820
I train hard.

01:48:25.820 --> 01:48:27.260
I mean, so it's like, if I'm gonna go out

01:48:27.260 --> 01:48:29.780
in like a 15 foot wave.

01:48:29.780 --> 01:48:31.060
Go out big.

01:48:31.060 --> 01:48:31.980
Well, then it's like, all right,

01:48:31.980 --> 01:48:33.820
I'll make sure we have the right safety gear

01:48:33.820 --> 01:48:36.900
and like make sure that I'm like used to that spot

01:48:36.900 --> 01:48:37.940
and all that stuff.

01:48:37.940 --> 01:48:40.020
But like, but you know, I mean, you.

01:48:40.020 --> 01:48:41.300
The risk is still there.

01:48:41.300 --> 01:48:42.780
It takes some head blows along the way.

01:48:42.780 --> 01:48:43.780
Yes.

01:48:43.780 --> 01:48:46.300
But definitely aware of it.

01:48:47.300 --> 01:48:50.060
Definitely would like to stay safe.

01:48:50.060 --> 01:48:53.980
I have a lot of stuff that I wanna build and wanna.

01:48:53.980 --> 01:48:56.380
Does it freak you out that it's finite though?

01:48:57.460 --> 01:48:59.580
That there's a deadline when it's all over

01:49:01.180 --> 01:49:03.540
and that there'll be a time when your daughters are around

01:49:03.540 --> 01:49:05.220
and you're gone?

01:49:05.220 --> 01:49:06.060
I don't know.

01:49:06.060 --> 01:49:07.060
That doesn't freak me out.

01:49:07.060 --> 01:49:07.900
I think.

01:49:13.860 --> 01:49:16.220
Constraints are helpful.

01:49:16.220 --> 01:49:17.340
Yeah.

01:49:17.340 --> 01:49:20.540
Yeah, the finiteness makes ice cream taste

01:49:20.540 --> 01:49:21.780
more delicious somehow.

01:49:21.780 --> 01:49:23.140
The fact that it's gonna be over.

01:49:23.140 --> 01:49:25.700
There's something about that with the metaverse too.

01:49:25.700 --> 01:49:28.500
You want, we talked about this identity earlier.

01:49:28.500 --> 01:49:30.260
Like having just one with like NFTs.

01:49:30.260 --> 01:49:34.340
There's something powerful about the constraint

01:49:34.340 --> 01:49:36.940
of finiteness or uniqueness.

01:49:36.940 --> 01:49:39.820
That this moment is singular in history.

01:49:39.820 --> 01:49:40.940
But I mean, a lot of, you know,

01:49:40.940 --> 01:49:42.780
as you go through different waves of technology,

01:49:42.780 --> 01:49:45.580
I think a lot of what is interesting is what becomes

01:49:46.900 --> 01:49:49.060
in practice infinite or kind of,

01:49:49.060 --> 01:49:51.580
there can be many, many of a thing.

01:49:51.580 --> 01:49:53.700
And then what ends up still being constrained.

01:49:53.700 --> 01:49:58.700
So the metaverse should hopefully allow

01:49:59.220 --> 01:50:03.060
a very large number or maybe, you know,

01:50:03.060 --> 01:50:06.100
in practice, hopefully close to an infinite amount

01:50:06.100 --> 01:50:07.780
of expression and worlds.

01:50:07.780 --> 01:50:11.220
And, but we'll still only have a finite amount of time.

01:50:11.220 --> 01:50:12.060
Yes.

01:50:12.060 --> 01:50:17.060
I think living longer, I think is good.

01:50:18.020 --> 01:50:21.700
And obviously all of my, our philanthropic work is,

01:50:21.700 --> 01:50:23.380
it's not focused on longevity,

01:50:23.380 --> 01:50:25.940
but it is focused on trying to achieve

01:50:25.940 --> 01:50:28.020
what I think is a possible goal.

01:50:28.020 --> 01:50:30.660
In this century, which is to be able to cure,

01:50:30.660 --> 01:50:32.500
prevent or manage all diseases.

01:50:33.460 --> 01:50:36.140
So I certainly think people kind of getting sick

01:50:36.140 --> 01:50:39.260
and dying is a bad thing because I'm dedicating

01:50:39.260 --> 01:50:42.620
almost all of my capital towards advancing research

01:50:42.620 --> 01:50:44.780
in that area to push on that, which I mean,

01:50:44.780 --> 01:50:46.420
we could do a whole, another one of these podcasts

01:50:46.420 --> 01:50:49.660
about that because that's fascinating topic.

01:50:49.660 --> 01:50:51.700
I mean, this is with your wife Priscilla Chan.

01:50:51.700 --> 01:50:54.100
You formed the Chan Zuckerberg Initiative,

01:50:54.100 --> 01:50:57.020
gave away 99% or pledged to give away 99%

01:50:57.100 --> 01:50:59.260
of Facebook now meta shares.

01:50:59.260 --> 01:51:01.980
I mean, like you said, we could talk forever

01:51:01.980 --> 01:51:06.100
about all the exciting things you're working on there,

01:51:06.100 --> 01:51:11.100
including the sort of moonshot of eradicating disease

01:51:11.300 --> 01:51:13.260
by the mid-century Mark.

01:51:13.260 --> 01:51:15.380
I don't actually know if you're going to ever eradicate it,

01:51:15.380 --> 01:51:17.980
but I think you can get to a point where you

01:51:17.980 --> 01:51:20.900
can either cure things that happened, right?

01:51:20.900 --> 01:51:22.940
So people get diseases, but you can cure them.

01:51:22.940 --> 01:51:25.620
Prevent is probably closest to eradication

01:51:25.620 --> 01:51:28.860
or just be able to manage as sort of like ongoing things

01:51:28.860 --> 01:51:33.260
that are not going to ruin your life.

01:51:33.260 --> 01:51:34.300
And I think that that's possible.

01:51:34.300 --> 01:51:37.060
I think saying that there's going to be no disease at all

01:51:37.060 --> 01:51:41.500
probably is not possible within the next several decades.

01:51:41.500 --> 01:51:44.300
Basic thing is increase the quality of life

01:51:44.300 --> 01:51:47.780
and maybe keep the finiteness because it tastes,

01:51:47.780 --> 01:51:50.180
it makes everything taste more delicious.

01:51:50.180 --> 01:51:54.740
Maybe that's just being a romantic 20th century human.

01:51:54.780 --> 01:51:57.180
Maybe, but I mean, but it was an intentional decision

01:51:57.180 --> 01:52:01.820
to not focus on our philanthropy on like explicitly

01:52:01.820 --> 01:52:03.500
on longevity or living forever.

01:52:03.500 --> 01:52:04.340
Yes.

01:52:07.020 --> 01:52:09.100
If at the moment of your death, and by the way,

01:52:09.100 --> 01:52:11.540
I like that the lights went out

01:52:11.540 --> 01:52:13.420
when we start talking about death.

01:52:13.420 --> 01:52:14.260
You get to meet God.

01:52:14.260 --> 01:52:15.700
It does make it a lot more dramatic.

01:52:15.700 --> 01:52:16.540
It does.

01:52:17.980 --> 01:52:19.780
I should get closer to the mic.

01:52:19.780 --> 01:52:22.100
At the moment of your death, you get to meet God

01:52:23.060 --> 01:52:26.140
and you get to ask one question.

01:52:26.140 --> 01:52:28.100
What question would you like to ask?

01:52:29.780 --> 01:52:31.140
Or maybe a whole conversation.

01:52:31.140 --> 01:52:31.980
I don't know.

01:52:31.980 --> 01:52:32.820
It's up to you.

01:52:32.820 --> 01:52:35.020
It's more dramatic when it's just one question.

01:52:37.060 --> 01:52:40.500
Well, if it's only one question and I died,

01:52:42.980 --> 01:52:47.980
I would just want to know that Priscilla and my family

01:52:47.980 --> 01:52:49.740
like if they were going to be okay,

01:52:50.700 --> 01:52:54.460
that might depend on the circumstances of my death.

01:52:54.460 --> 01:52:57.860
But I think that in most circumstances that I can think of,

01:52:57.860 --> 01:53:00.900
that's probably the main thing that I would care about.

01:53:00.900 --> 01:53:02.620
Yeah, thank God we hear that question back.

01:53:02.620 --> 01:53:03.460
All right, fine.

01:53:03.460 --> 01:53:04.300
You get in.

01:53:04.300 --> 01:53:06.220
That's the right question to ask.

01:53:06.220 --> 01:53:07.060
Is it?

01:53:07.060 --> 01:53:07.900
I don't know.

01:53:07.900 --> 01:53:09.420
The humility and selfishness.

01:53:09.420 --> 01:53:10.580
All right, you're in.

01:53:10.580 --> 01:53:14.420
I mean, but, well, maybe.

01:53:14.420 --> 01:53:15.260
They're gonna be fine.

01:53:15.260 --> 01:53:16.340
Don't worry, you're in.

01:53:16.340 --> 01:53:17.180
But I mean, one of the things

01:53:17.340 --> 01:53:22.340
that I think I struggle with at least is on the one hand,

01:53:22.340 --> 01:53:25.620
that's probably the most, the thing that's closest to me

01:53:25.620 --> 01:53:29.420
and maybe the most common human experience.

01:53:29.420 --> 01:53:30.980
But I don't know.

01:53:30.980 --> 01:53:32.380
One of the things that I just struggle with

01:53:32.380 --> 01:53:36.140
in terms of running this large enterprise is like,

01:53:38.100 --> 01:53:41.020
should the thing that I care more about

01:53:41.020 --> 01:53:44.860
be that responsibility?

01:53:44.860 --> 01:53:49.260
And I think it's shifted over time.

01:53:49.260 --> 01:53:52.020
I mean, before I really had a family

01:53:52.020 --> 01:53:53.820
that was the only thing I cared about.

01:53:53.820 --> 01:53:58.820
And at this point, I mean, I care deeply about it,

01:53:59.940 --> 01:54:04.940
but yeah, I think that that's not as obvious of a question.

01:54:06.020 --> 01:54:07.820
Yeah, we humans are weird.

01:54:07.820 --> 01:54:12.740
You get this ability to impact millions of lives

01:54:12.780 --> 01:54:14.060
and it's definitely something,

01:54:14.060 --> 01:54:16.980
billions of lives is something you care about,

01:54:16.980 --> 01:54:21.100
but the weird humans that are closest to us,

01:54:21.100 --> 01:54:23.700
those are the ones that mean the most.

01:54:23.700 --> 01:54:26.140
And I suppose that's the dream of the metaverse

01:54:26.140 --> 01:54:29.340
is to connect, form small groups like that,

01:54:29.340 --> 01:54:31.700
where you can have those intimate relationships.

01:54:31.700 --> 01:54:33.620
Let me ask you the big, ridiculous.

01:54:33.620 --> 01:54:35.260
One, to be able to be close,

01:54:36.900 --> 01:54:39.900
not just based on who you happen to be next to.

01:54:39.900 --> 01:54:41.980
I think that's what the internet is already doing

01:54:41.980 --> 01:54:44.540
is allowing you to spend more of your time

01:54:44.540 --> 01:54:46.540
not physically proximate.

01:54:46.540 --> 01:54:49.940
I mean, I always think when you think about the metaverse,

01:54:49.940 --> 01:54:52.140
people ask this question about the real world.

01:54:52.140 --> 01:54:54.860
It's like the virtual world versus the real world.

01:54:54.860 --> 01:54:58.180
And it's like, no, the real world is a combination

01:54:58.180 --> 01:55:00.100
of the virtual world and the physical world.

01:55:00.100 --> 01:55:03.140
But I think over time, as we get more technology,

01:55:04.060 --> 01:55:06.100
the physical world is becoming less

01:55:06.100 --> 01:55:08.180
of a percent of the real world.

01:55:08.180 --> 01:55:10.100
And I think that that opens up

01:55:10.100 --> 01:55:11.380
a lot of opportunities for people.

01:55:11.380 --> 01:55:13.460
Because you can work in different places.

01:55:13.460 --> 01:55:16.700
You can stay more close to,

01:55:16.700 --> 01:55:18.460
stay closer to people who are in different places.

01:55:18.460 --> 01:55:19.300
I think that's good.

01:55:19.300 --> 01:55:21.380
Removing barriers of geography

01:55:21.380 --> 01:55:23.140
and then barriers of language.

01:55:23.140 --> 01:55:24.900
That's a beautiful vision.

01:55:25.860 --> 01:55:27.580
Big, ridiculous question.

01:55:27.580 --> 01:55:29.580
What do you think is the meaning of life?

01:55:41.380 --> 01:55:44.300
I think there are probably a couple of different ways

01:55:44.300 --> 01:55:49.300
that I would go with this.

01:55:49.300 --> 01:55:50.980
But I think it gets back to this last question

01:55:50.980 --> 01:55:51.820
that we talked about,

01:55:51.820 --> 01:55:55.780
about the duality between you have the people around you

01:55:55.780 --> 01:55:57.500
who you care the most about.

01:55:57.500 --> 01:56:00.260
And then there's like this bigger thing

01:56:00.260 --> 01:56:01.660
that maybe you're building.

01:56:02.980 --> 01:56:04.300
And I think that in my own life,

01:56:04.300 --> 01:56:06.460
I mean, I sort of think about this tension,

01:56:06.460 --> 01:56:09.140
but when it's, look, I started this whole thing

01:56:09.180 --> 01:56:11.620
in my life's work is around human connection.

01:56:11.620 --> 01:56:16.620
So I think it's intellectually,

01:56:16.620 --> 01:56:20.660
probably the thing that I go to first is just

01:56:22.660 --> 01:56:25.340
that human connection is the meaning.

01:56:26.340 --> 01:56:30.100
And I mean, I think that it's a thing that our society

01:56:30.100 --> 01:56:33.580
probably systematically under values.

01:56:33.580 --> 01:56:36.140
I mean, I just remember, you know, when I was growing up,

01:56:36.140 --> 01:56:36.980
it's like, do your homework

01:56:36.980 --> 01:56:38.900
and then go play with your friends after.

01:56:38.900 --> 01:56:40.900
And it's like, no, well, what if playing

01:56:40.900 --> 01:56:42.380
with your friends is the point?

01:56:44.380 --> 01:56:46.180
It sounds like an argument your daughter would make.

01:56:46.180 --> 01:56:47.500
Well, I mean, I don't know.

01:56:47.500 --> 01:56:48.340
I just think it's interesting.

01:56:48.340 --> 01:56:50.220
Homework doesn't even matter, man.

01:56:50.220 --> 01:56:52.500
Well, I think it's interesting because it's, you know,

01:56:52.500 --> 01:56:56.620
and people, I think people tend to think

01:56:56.620 --> 01:56:58.940
about that stuff as wasting time,

01:56:58.940 --> 01:57:00.260
or that's like what you do,

01:57:00.260 --> 01:57:01.540
and you're like, oh, I don't know,

01:57:01.540 --> 01:57:03.380
I don't know, I don't know, I don't know.

01:57:03.380 --> 01:57:05.180
So that's one.

01:57:05.180 --> 01:57:07.260
But here's maybe a different way of counting out this,

01:57:07.260 --> 01:57:10.580
which is maybe a more like religious in nature.

01:57:10.580 --> 01:57:11.620
I mean, I always like,

01:57:14.780 --> 01:57:18.020
there's a rabbi who I've studied with

01:57:18.020 --> 01:57:19.980
who kind of gave me this,

01:57:19.980 --> 01:57:24.340
we were talking through Genesis and the Bible and the Torah,

01:57:24.340 --> 01:57:27.100
and I was like, oh, I don't know,

01:57:27.100 --> 01:57:29.100
I don't know, I don't know, I don't know,

01:57:29.100 --> 01:57:31.300
I don't know, I don't know, I don't know.

01:57:31.820 --> 01:57:36.100
And they're basically walking through,

01:57:36.100 --> 01:57:40.740
it's like, okay, you go through the seven days of creation,

01:57:40.740 --> 01:57:45.660
and it's basically, it's like,

01:57:45.660 --> 01:57:48.100
why does the Bible start there?

01:57:48.100 --> 01:57:49.460
Right, it's like it could have started anywhere,

01:57:49.460 --> 01:57:52.020
right, in terms of like how to live.

01:57:52.020 --> 01:57:54.620
But basically it starts with talking about

01:57:54.620 --> 01:57:58.940
how God created people in his, her image,

01:57:59.940 --> 01:58:02.740
but the Bible starts by talking about

01:58:02.740 --> 01:58:04.780
how God created everything.

01:58:04.780 --> 01:58:09.780
So I actually think that there's like a compelling argument

01:58:11.260 --> 01:58:13.020
that I think I've always just found meaningful

01:58:13.020 --> 01:58:17.020
and inspiring that a lot of the point

01:58:18.420 --> 01:58:23.020
of what sort of religion has been telling us

01:58:23.020 --> 01:58:28.020
that we should do is to create and build things.

01:58:29.940 --> 01:58:32.020
So these things are not necessarily at odds.

01:58:32.020 --> 01:58:34.660
I mean, I think like, I mean, that's,

01:58:34.660 --> 01:58:35.980
and I think probably to some degree,

01:58:35.980 --> 01:58:37.620
you'd expect me to say something like this

01:58:37.620 --> 01:58:39.660
because I've dedicated my life to creating things

01:58:39.660 --> 01:58:40.500
that help people connect.

01:58:40.500 --> 01:58:43.700
So I mean, that's sort of the fusion of,

01:58:43.700 --> 01:58:45.180
I mean, getting back to what we talked about earlier,

01:58:45.180 --> 01:58:46.420
it's, I mean, what I studied in school

01:58:46.420 --> 01:58:48.180
was psychology and computer science, right?

01:58:48.180 --> 01:58:50.460
So it's, I mean, these are like the two themes

01:58:50.460 --> 01:58:54.340
that I care about, but I don't know, for me,

01:58:54.340 --> 01:58:56.220
that's what, that's kind of what I think about,

01:58:56.220 --> 01:58:57.060
that's what matters.

01:58:57.140 --> 01:59:00.940
To create and to love,

01:59:00.940 --> 01:59:03.060
which is the ultimate form of connection.

01:59:03.980 --> 01:59:07.220
I think this is one hell of an amazing replay experience

01:59:07.220 --> 01:59:08.060
in the metaverse.

01:59:08.060 --> 01:59:11.980
So whoever is using our avatars years from now,

01:59:11.980 --> 01:59:14.780
I hope you had fun and thank you for talking today.

01:59:14.780 --> 01:59:15.620
Thank you.

01:59:16.460 --> 01:59:18.180
Thanks for listening to this conversation

01:59:18.180 --> 01:59:19.500
with Mark Zuckerberg.

01:59:19.500 --> 01:59:20.860
To support this podcast,

01:59:20.860 --> 01:59:23.660
please check out our sponsors in the description.

01:59:23.700 --> 01:59:26.420
And now let me leave you with the end

01:59:26.420 --> 01:59:29.180
of the poem, If, by Roger Kipling.

01:59:30.860 --> 01:59:34.180
If you can talk with crowds and keep your virtue,

01:59:34.180 --> 01:59:37.860
or walk with kings, nor lose the common touch,

01:59:37.860 --> 01:59:41.260
if neither foes nor loving friends can hurt you,

01:59:41.260 --> 01:59:45.780
if all men count with you, but none too much.

01:59:47.140 --> 01:59:49.300
If you can fill the unforgiving minute

01:59:49.300 --> 01:59:52.380
with 60 seconds worth of distance run,

01:59:52.380 --> 01:59:56.380
yours is the earth and everything that's in it,

01:59:56.380 --> 01:59:59.660
and which is more, you'll be a man, my son.

02:00:01.220 --> 02:00:04.340
Thank you for listening and hope to see you next time.

