WEBVTT

00:00.000 --> 00:01.760
On one axis, you have more hardware coming in.

00:01.760 --> 00:05.080
On the other hand, you have an explosion of innovation in AI.

00:05.680 --> 00:09.000
And so what happened with both TensorFlow and PyTorch is that the explosion of

00:09.000 --> 00:13.040
innovation in AI has led to, it's not just about matrix multiplication and

00:13.040 --> 00:16.320
convolution, these things have now like 2000 different operators.

00:17.200 --> 00:19.120
And on the other hand, you have, I don't know how many pieces of

00:19.120 --> 00:20.320
hardware out there are out there.

00:20.320 --> 00:20.920
It's a lot.

00:21.200 --> 00:24.440
Part of my thesis, part of my belief of where computing goes, if you

00:24.440 --> 00:27.480
look out 10 years from now, it's not going to get simpler.

00:28.480 --> 00:30.280
Physics isn't going back to where we came from.

00:30.800 --> 00:32.560
It's only going to get weirder from here on out.

00:33.120 --> 00:33.440
Right.

00:33.440 --> 00:37.760
And so to me, the exciting part about what we're building is it's about

00:37.880 --> 00:42.800
building that universal platform, which the world can continue to get weird.

00:42.880 --> 00:44.200
Cause again, I don't think it's avoidable.

00:44.200 --> 00:48.320
It's physics, but we can help lift people scale, do things with it.

00:48.320 --> 00:50.600
And they don't have to rewrite their code every time a new device comes out.

00:51.160 --> 00:52.280
And I think that's pretty cool.

00:54.760 --> 00:57.080
The following is a conversation with Chris Latner.

00:57.440 --> 01:02.080
His third time on this podcast, as I've said many times before, he's one of the

01:02.080 --> 01:06.640
most brilliant engineers in modern computing, having created LLM compiler

01:06.640 --> 01:10.640
infrastructure project, the clan compiler, the swift programming language,

01:10.960 --> 01:14.480
a lot of key contributions to TensorFlow and TPUs as part of Google.

01:14.760 --> 01:20.240
He served as vice president of autopilot software at Tesla was a software

01:20.240 --> 01:21.880
innovator and leader at Apple.

01:21.880 --> 01:27.640
And now he co-created a new full stack AI infrastructure for distributed

01:27.640 --> 01:32.360
training, inference, and deployment on all kinds of hardware called modular,

01:32.720 --> 01:36.160
and a new programming language called Mojo.

01:36.600 --> 01:39.880
That is a superset of Python, giving you all the usability of

01:39.880 --> 01:45.240
Python, but with the performance of C, C plus plus, in many cases, Mojo

01:45.240 --> 01:51.400
code has demonstrated over 30,000 X speed up over Python.

01:51.840 --> 01:54.840
If you love machine learning, if you love Python, you should

01:54.840 --> 01:59.360
definitely give Mojo a try this programming language, this new AI

01:59.360 --> 02:01.320
framework and infrastructure.

02:01.520 --> 02:05.160
And this conversation with Chris is mind blowing.

02:05.760 --> 02:06.480
I love it.

02:07.360 --> 02:08.840
It gets pretty technical at times.

02:08.840 --> 02:11.040
So I hope you hang on for the ride.

02:11.600 --> 02:14.120
This is the Lex Freedman podcast to support it.

02:14.400 --> 02:17.200
Please check out our sponsors in the description and now with your

02:17.200 --> 02:19.760
friends, here's Chris Latner.

02:20.720 --> 02:24.800
It's been, I think, two years since we last talked and in that time, you

02:24.800 --> 02:28.880
somehow went and co-created a new programming language called Mojo.

02:29.640 --> 02:31.480
So it's optimized for AI.

02:31.480 --> 02:32.880
It's a superset of Python.

02:33.280 --> 02:34.560
Let's look at the big picture.

02:34.840 --> 02:37.080
What is the vision for Mojo?

02:37.640 --> 02:38.120
For Mojo?

02:38.120 --> 02:39.680
Well, so I mean, I think you have to zoom out.

02:39.840 --> 02:44.000
So I've been working on a lot of related technologies for many, many years.

02:44.040 --> 02:48.240
So I've worked on LLVM and a lot of things and mobile and servers and

02:48.840 --> 02:51.240
things like this, but the world's changing.

02:51.520 --> 02:56.120
And what's happened with AI is we have new GPUs and new machine learning

02:56.120 --> 03:00.160
accelerators and other ASICs and things like that, that make AI go real fast.

03:00.800 --> 03:02.280
At Google, I worked on TPUs.

03:02.480 --> 03:06.040
That's one of the biggest larger scale deployed systems that exist for AI.

03:06.400 --> 03:10.080
And really what you see is if you look across all of the things that are

03:10.080 --> 03:12.320
happening in the industry, there's this new compute platform coming.

03:12.800 --> 03:19.200
And it's not just about CPUs or GPUs or TPUs or NPUs or IPUs or whatever, all the

03:19.200 --> 03:23.560
PUs, right, it's about how do we program these things, right?

03:23.560 --> 03:28.800
And so for software folks like us, right, it doesn't do us any good if there's

03:28.800 --> 03:30.360
this amazing hardware that we can't use.

03:31.120 --> 03:35.080
And one of the things you find out really quick is that having the theoretical

03:35.080 --> 03:39.520
capability of programming something and then having the world's power and the

03:39.560 --> 03:42.880
innovation of all the, all the smart people in the world get unleashed on

03:42.880 --> 03:44.400
something can be quite different.

03:44.960 --> 03:49.640
And so really where Mojo came from was starting from a problem of we need to be

03:49.640 --> 03:52.480
able to take machine learning, take the infrastructure underneath it and make it

03:52.480 --> 03:57.280
way more accessible, way more usable, way more understandable by normal people and

03:57.280 --> 04:01.480
researchers and other folks that are not themselves like experts in GPUs and

04:01.480 --> 04:02.120
things like this.

04:02.600 --> 04:05.840
And then through that journey, we realized, Hey, we need syntax for this.

04:05.840 --> 04:07.000
We need to do programming language.

04:07.520 --> 04:13.040
So one of the main features of the language, I say so fully in jest, is that

04:13.320 --> 04:20.240
it allows you to have the file extension to be an emoji or the fire emoji, which

04:20.240 --> 04:27.120
is one of the first emojis used as a file extension I've ever seen in my life.

04:27.320 --> 04:32.160
And then you ask yourself the question, why in the 21st century are we not using

04:32.160 --> 04:34.120
Unicode for file extensions?

04:34.560 --> 04:36.200
This, I mean, it's an epic decision.

04:36.480 --> 04:39.800
I think clearly the most important decision made the most, but you could also

04:39.800 --> 04:42.160
just use Mojo as the file extension.

04:42.240 --> 04:42.920
Well, so, okay.

04:42.920 --> 04:43.760
So take a step back.

04:43.760 --> 04:45.760
I mean, come on, Lex, do you think that the world's ready for this?

04:45.760 --> 04:47.560
This is a big moment in the world, right?

04:47.680 --> 04:49.360
This is where we're releasing this onto the world.

04:49.360 --> 04:50.360
This is innovation.

04:51.840 --> 04:53.280
I mean, it really is kind of brilliant.

04:53.640 --> 04:57.600
Emojis is such a big part of our daily lives.

04:58.040 --> 04:59.600
Why isn't it not in programming?

05:00.080 --> 05:04.280
Well, and like you take a step back and look, look at what file extensions are,

05:04.360 --> 05:04.640
right?

05:04.640 --> 05:05.600
They're basically metadata.

05:06.320 --> 05:06.560
Right.

05:06.560 --> 05:09.480
And so why are we spending all the screen space on them and all this stuff?

05:09.800 --> 05:13.320
Also, you know, you have them stacked up next to text files and PDF files and

05:13.320 --> 05:16.040
whatever else, like if you're going to do something cool, you want to stand out.

05:16.120 --> 05:16.360
Right.

05:16.360 --> 05:17.600
And emojis are colorful.

05:17.680 --> 05:18.440
They're visual.

05:18.520 --> 05:19.440
They're, they're beautiful.

05:19.720 --> 05:19.920
Right.

05:19.920 --> 05:24.600
What's been the response so far from, uh, is there support on like windows on

05:24.600 --> 05:26.920
operating systems in displaying like file explorer?

05:27.000 --> 05:27.360
Yeah.

05:27.760 --> 05:30.600
The one problem I've seen is that Git doesn't escape it right.

05:31.400 --> 05:33.520
And so it thinks that the fire emoji is unprintable.

05:33.520 --> 05:35.200
And so it like prints out weird hex things.

05:35.200 --> 05:38.960
If you use the command line, get tool, but everything else, as far as I'm aware,

05:38.960 --> 05:39.440
works fine.

05:39.520 --> 05:41.560
And I, I have faith that Git can be improved.

05:41.560 --> 05:42.600
So I'm not, I'm not worried.

05:43.360 --> 05:43.920
Is fine.

05:43.960 --> 05:44.680
GitHub is fine.

05:44.880 --> 05:45.160
Yep.

05:45.320 --> 05:46.200
GitHub is fine.

05:46.200 --> 05:50.120
Visual studio code windows, like all this stuff totally ready because people

05:50.120 --> 05:53.560
will have internationalization in their normal part of their paths.

05:54.280 --> 05:55.920
So this is just like taking the next step, right?

05:56.880 --> 05:59.320
Somewhere between, oh, wow, that makes sense.

05:59.360 --> 05:59.880
Cool.

06:00.120 --> 06:01.440
I like any things too.

06:02.080 --> 06:03.520
Oh my God, you're killing my baby.

06:03.560 --> 06:04.600
Like, what are you talking about?

06:04.600 --> 06:06.640
This can never be like, I can never handle this.

06:06.640 --> 06:07.520
How am I going to type this?

06:08.400 --> 06:09.160
Like all these things.

06:09.160 --> 06:12.560
And so this is something where I think that the world will get there.

06:12.720 --> 06:14.600
We don't have to bet the whole farm on this.

06:14.600 --> 06:18.360
I think we can provide both paths, but I think it'll be great.

06:19.080 --> 06:21.360
When can we have emojis as part of the code?

06:21.520 --> 06:22.000
I wonder.

06:22.440 --> 06:22.720
Yeah.

06:22.720 --> 06:24.240
So, I mean, lots of languages provide that.

06:24.240 --> 06:26.800
So I think that we have partial support for that.

06:26.800 --> 06:30.360
It's probably not fully done yet, but, but yeah, you can, you can do that.

06:30.480 --> 06:32.200
For example, in Swift, you can do that for sure.

06:32.400 --> 06:36.480
So an example we give, gave it Apple was the dog cow.

06:37.040 --> 06:37.280
Yeah.

06:37.360 --> 06:39.840
So that's a classical Mac heritage thing.

06:39.840 --> 06:42.360
And so you use the dog and the cow emoji together and that could be your variable

06:42.360 --> 06:46.120
name, but of course the internet went and made pile of poop for everything.

06:46.360 --> 06:46.640
Yeah.

06:46.840 --> 06:50.400
So, you know, if you want to name your function pile of poop, then you can totally

06:50.400 --> 06:52.120
go to town and see how that gets through code review.

06:54.240 --> 06:54.720
Okay.

06:54.760 --> 06:57.760
So, uh, let me just ask a bunch of random questions.

06:58.080 --> 07:03.560
Uh, so is Mojo primarily designed for AIs or is it a general purpose program?

07:03.680 --> 07:04.360
Yeah, good question.

07:04.360 --> 07:05.320
So it's AI first.

07:05.960 --> 07:07.920
And so AI is driving a lot of the requirements.

07:07.920 --> 07:13.000
And so, um, modular is building and designing and driving Mojo forward.

07:13.040 --> 07:16.240
And it's not because it's an interesting project theoretically to

07:16.240 --> 07:18.120
build it's because we need it.

07:19.360 --> 07:22.560
And so at modular, we're really tackling the AI infrastructure

07:22.560 --> 07:24.360
landscape and the big problems in AI.

07:24.800 --> 07:28.920
And the reasons that it is so difficult to use and scale and adopt and deploy

07:28.920 --> 07:30.840
and like all these big problems in AI.

07:31.360 --> 07:33.320
And so we're coming out from that perspective.

07:33.400 --> 07:36.640
Now, when you do that, when you start tackling these problems, you realize

07:36.640 --> 07:42.360
that the solution to these problems isn't actually an AI specific solution.

07:43.120 --> 07:45.120
And so while we're doing this, we're building Mojo to be a fully

07:45.120 --> 07:46.160
general programming language.

07:46.200 --> 07:51.880
And that means that you can obviously tackle GPUs and CPUs and like these AI

07:51.880 --> 07:56.480
things, but it's also a really great way to build NumPy and other things like that.

07:56.480 --> 08:00.520
Or, you know, just if you look at what many Python libraries are today, often

08:00.520 --> 08:04.360
they're a layer of Python for the API and they end up being C and C++ code

08:04.360 --> 08:07.200
underneath them, that's very true in AI.

08:07.240 --> 08:09.160
That's true in lots of other domains as well.

08:09.240 --> 08:11.800
And so anytime you see this pattern, that's an opportunity for Mojo to help

08:11.800 --> 08:17.000
simplify the world and help people have one thing to optimize through

08:17.000 --> 08:20.320
simplification by having one thing.

08:20.480 --> 08:23.160
So you mentioned modular, Mojo is the programming language.

08:23.160 --> 08:25.240
Modular is the whole software stack.

08:25.640 --> 08:28.240
So just over a year ago, we started this company called Modular.

08:28.320 --> 08:28.520
Yeah.

08:28.680 --> 08:28.840
Okay.

08:28.840 --> 08:33.280
What Modular is about is it's about taking AI and upleveling it into

08:33.280 --> 08:34.520
the next generation, right?

08:34.520 --> 08:39.720
And so if you take a step back, what's gone on in the last five, six, seven,

08:39.720 --> 08:43.760
eight years is that we've had things like TensorFlow and PyTorch and these

08:43.760 --> 08:47.640
other systems come in, you've used them, you know this, and what's happened is

08:47.640 --> 08:51.720
these things have grown like crazy and they get tons of users, it's in

08:51.760 --> 08:55.480
production deployment scenarios, it's being used to power so many systems.

08:55.480 --> 08:56.960
I mean, AI is all around us now.

08:57.080 --> 09:00.520
Now it used to be controversial years ago, but now it's a thing.

09:01.080 --> 09:03.960
But the challenge with these systems is that they haven't always been

09:05.400 --> 09:08.480
thought out with current demands in mind.

09:09.040 --> 09:12.560
And so you think about it, when, where were LLMs eight years ago?

09:13.480 --> 09:14.680
Well, they didn't exist, right?

09:14.720 --> 09:18.040
AI has changed so much and a lot of what people are doing today are very

09:18.040 --> 09:19.640
different than when these systems were built.

09:20.080 --> 09:23.120
And meanwhile, the hardware side of this has gotten into a huge mess.

09:23.200 --> 09:25.800
There's tons of new chips and accelerators and every, every big

09:25.800 --> 09:27.880
company is announcing a new chip every day, it feels like.

09:28.440 --> 09:34.040
And so between that you have like this moving system on one side, moving

09:34.040 --> 09:37.080
system on the other side, and it just turns into this gigantic mess, which

09:37.080 --> 09:40.840
makes it very difficult for people to actually use AI, particularly in

09:40.880 --> 09:42.240
production deployment scenarios.

09:42.600 --> 09:45.480
And so what Modular is doing is we're helping build out that software stack

09:45.480 --> 09:46.640
to help solve some of those problems.

09:47.000 --> 09:50.320
So then people can be more productive and get more AI research into production.

09:50.960 --> 09:54.800
Now what Mojo does is it's a really, really, really important piece of that.

09:55.240 --> 09:58.560
And so that is, you know, part of that engine and part of the technology that

09:58.680 --> 10:00.200
allows us to solve these problems.

10:00.640 --> 10:05.880
So Mojo is a programming language that allows you to do the higher level

10:05.880 --> 10:07.640
programming, the low level programming.

10:07.960 --> 10:12.600
They do all kinds of programming in that spectrum that gets you closer

10:12.600 --> 10:13.680
and closer to the hardware.

10:14.080 --> 10:14.680
So take a step back.

10:14.720 --> 10:16.320
So Lex, what do you love about Python?

10:17.040 --> 10:17.800
Oh boy.

10:18.640 --> 10:19.760
Where do I begin?

10:20.080 --> 10:21.960
Um, what is love?

10:22.320 --> 10:23.640
What do I love about Python?

10:23.640 --> 10:24.720
You're, you're a guy who knows love.

10:24.720 --> 10:25.320
I know this.

10:25.360 --> 10:25.760
Yes.

10:25.840 --> 10:33.160
Um, how intuitive it is, how it feels like I'm writing natural language,

10:33.200 --> 10:40.240
English, uh, how, when I can not just write, but read other people's code,

10:40.240 --> 10:42.000
somehow I can understand it faster.

10:42.200 --> 10:46.320
It's more condensed than other languages.

10:46.320 --> 10:51.640
Like ones I'm really familiar with, like C plus plus and see, uh, there's a bunch

10:51.640 --> 10:56.840
of sexy little features, uh, we'll probably talk about some of them, but

10:56.880 --> 10:58.760
list comprehensions and stuff like this.

10:59.840 --> 11:02.880
Well, so, and, and don't forget the entire ecosystem of all the

11:03.080 --> 11:04.560
oh, yeah, that's probably huge.

11:04.560 --> 11:07.560
Cause there's always something, if you want to do anything, there's always a package.

11:07.800 --> 11:08.080
Yeah.

11:08.120 --> 11:13.040
So it's not just, uh, the ecosystem of the packages and the ecosystem

11:13.040 --> 11:17.480
of the humans that do it, that that's a really, that's an interesting dynamic.

11:17.600 --> 11:23.080
Because I think something, uh, about the, the usability and the ecosystem

11:23.080 --> 11:24.680
makes the thing viral that grows.

11:24.680 --> 11:26.840
And then it's a virtuous cycle.

11:26.920 --> 11:28.520
I think there's many things that went into that.

11:28.520 --> 11:30.920
Like, so I think that ML was very good for Python.

11:31.400 --> 11:35.080
And so I think that TensorFlow and PyTorch and these systems embracing

11:35.080 --> 11:37.600
Python really took and help Python grow.

11:38.040 --> 11:41.200
But I think that the major thing underlying it is that Python's

11:41.200 --> 11:43.800
like the universal connector, right?

11:43.800 --> 11:46.680
It really helps bring together lots of different systems so you can compose

11:46.680 --> 11:49.680
them and build out larger systems without having to understand how it works.

11:50.320 --> 11:52.360
But then what is the problem with Python?

11:53.200 --> 11:56.600
Well, I guess you could say several things, but probably that is slow.

11:57.240 --> 11:58.920
I think that's usually what people complain about.

11:59.160 --> 11:59.360
Right.

11:59.360 --> 12:03.640
And so, so, I mean, other people complain about tabs and spaces versus

12:03.640 --> 12:07.520
curly braces or whatever, but I mean, those people are just wrong because

12:07.640 --> 12:09.840
it is actually just better to use indentation.

12:11.160 --> 12:11.600
Wow.

12:11.840 --> 12:12.520
Strong words.

12:12.920 --> 12:14.480
So actually a small tangent.

12:14.640 --> 12:15.680
Let's take that.

12:15.760 --> 12:17.160
Let's take all kinds of tangents.

12:17.360 --> 12:18.000
Oh, come on, Lex.

12:18.000 --> 12:18.680
You can push me on it.

12:18.680 --> 12:19.200
I can take it.

12:19.200 --> 12:20.560
Design, design.

12:21.120 --> 12:24.040
Listen, I've recently left Emacs for VS code.

12:24.120 --> 12:24.440
Okay.

12:24.480 --> 12:28.480
The kind of hate mail I had to receive because on the way to doing that, I also

12:28.480 --> 12:33.600
said I've considered Vim and chose not to and went with VS code.

12:33.600 --> 12:35.760
And you're touching on deep religions, right?

12:36.480 --> 12:39.360
Anyway, tabs is an interesting design decision.

12:39.360 --> 12:42.760
And so you've really written a new programming language here.

12:42.880 --> 12:43.280
Yes.

12:43.280 --> 12:47.200
It is a superset of Python, but you can make a bunch of different

12:47.200 --> 12:51.400
interesting decisions here and you chose actually to stick with Python

12:51.400 --> 12:55.120
as a, in terms of some of the syntax.

12:55.280 --> 12:56.640
Well, so, so let me explain why.

12:56.680 --> 12:56.920
Right.

12:56.920 --> 13:01.920
So, uh, I mean, you can explain this in many rational ways.

13:02.800 --> 13:06.520
I think that the annotation is beautiful, but that's not a rational explanation.

13:06.560 --> 13:06.800
Right.

13:06.800 --> 13:08.120
So, but I can defend it rationally.

13:08.160 --> 13:08.360
Right.

13:08.360 --> 13:12.400
So first of all, Python one has millions of programmers.

13:12.840 --> 13:13.320
It's huge.

13:13.320 --> 13:13.880
It's everywhere.

13:13.880 --> 13:14.840
It owns machine learning.

13:14.920 --> 13:15.080
Right.

13:15.080 --> 13:18.000
And so factually it is the thing, right?

13:18.520 --> 13:22.480
Second of all, if you look at it, C code, C plus plus code, Java, whatever,

13:22.520 --> 13:28.000
Swift, curly brace languages also run through formatting tools and get indented.

13:29.200 --> 13:32.920
And so if they're not indented correctly, first of all, we'll twist your brain

13:32.920 --> 13:36.880
around and can lead to bugs and there's notorious bugs that have happened

13:36.880 --> 13:40.480
across time where the, the annotation was wrong or misleading and it wasn't

13:40.480 --> 13:41.160
formatted right.

13:41.160 --> 13:42.960
And so it turned into an issue.

13:43.280 --> 13:43.600
Right.

13:43.600 --> 13:47.200
And so what ends up happening in modern large scale code basis is people

13:47.200 --> 13:48.400
run automatic formatters.

13:49.200 --> 13:52.040
So now what you end up with is indentation and curly braces.

13:53.480 --> 13:58.800
Well, if you're going to have, you know, the notion of grouping, why

13:58.800 --> 14:00.240
not have one thing, right?

14:00.240 --> 14:02.200
And get rid of all the clutter and have a more beautiful thing.

14:02.440 --> 14:02.680
Right.

14:02.720 --> 14:04.000
I'll see you look at many of these languages.

14:04.000 --> 14:07.240
It's like, okay, well, you can have curly braces or you can omit them if

14:07.240 --> 14:10.520
there's one statement, or you just like enter this entire world of complicated

14:10.520 --> 14:14.840
design space that objectively you don't need if you have Python style indentation.

14:15.320 --> 14:18.520
So, yeah, I would love to actually see statistics on errors made because of

14:18.560 --> 14:23.920
indentation, like how many errors are made in Python versus in C++ that have

14:23.920 --> 14:26.160
to do with basic formatting, all that kind of stuff.

14:26.160 --> 14:26.960
I would love to see.

14:27.200 --> 14:30.560
I think it's, it's probably pretty minor because once you get, uh, like

14:30.600 --> 14:32.040
you use VS code, I do too.

14:32.360 --> 14:34.800
So if you get VS code set up, it does the indentation for you generally.

14:35.160 --> 14:35.400
Right.

14:35.400 --> 14:39.000
And so you don't, you know, it's actually really nice to not have to fight it.

14:39.360 --> 14:43.280
And then what you can see is the editor's telling you how your code will work by

14:43.280 --> 14:45.040
indenting it, which I think is pretty cool.

14:45.200 --> 14:51.760
I honestly don't think I've ever, I don't remember having an error in Python

14:51.760 --> 14:53.000
because I intended stuff wrong.

14:53.560 --> 14:55.880
So, I mean, I think that there's, again, this is a religious thing.

14:55.880 --> 15:00.480
And so I can joke about it and I love, I love to kind of, you know, I

15:00.480 --> 15:03.800
realized that this is such a polarizing thing and everybody wants to argue about

15:03.800 --> 15:06.680
it, and so I like poking at the bear a little bit, right.

15:06.680 --> 15:11.040
But, but frankly, right, come back to the first point, Python one, like it's huge.

15:11.040 --> 15:11.760
It's an AI.

15:11.840 --> 15:13.560
Um, it's the right thing for us.

15:13.600 --> 15:16.840
Like we see Mojo as being an incredible part of the Python ecosystem.

15:17.040 --> 15:20.840
We're not looking to break Python or change it or quote unquote, fix it.

15:21.240 --> 15:22.640
We love Python for what it is.

15:22.720 --> 15:25.280
Our view is that Python is just not done yet.

15:26.320 --> 15:28.600
And so if you look at, you know, you mentioned Python being slow.

15:28.720 --> 15:30.600
Well, there's a couple of different things that go into that, which we

15:30.600 --> 15:33.960
can talk about if you want, but one of them is it just doesn't have those

15:34.080 --> 15:36.640
features that you would use to do C like programming.

15:37.520 --> 15:41.480
And so if you say, okay, well, I'm forced out of Python into C for certain use

15:41.480 --> 15:45.560
cases, well, then what we're doing is we're saying, okay, well, why, why is that?

15:45.760 --> 15:49.720
Can we just add those features that are missing from Python back up to Mojo?

15:50.080 --> 15:52.600
And then you can have everything that's great about Python, all the things that

15:52.600 --> 15:56.240
you're talking about that you love, plus not be forced out of it when you do

15:56.240 --> 16:00.160
something a little bit more computationally intense or weird or

16:00.600 --> 16:02.400
hardwarey or whatever it is that you're doing.

16:02.920 --> 16:06.680
Well, uh, a million questions I want to ask, but high level again, is it

16:06.680 --> 16:08.440
compiled or is it an interpreter language?

16:08.440 --> 16:11.080
So Python is just in time compilation.

16:11.120 --> 16:12.240
What's, what's Mojo?

16:13.880 --> 16:16.400
So Mojo, a complicated answer does all the things.

16:16.800 --> 16:19.400
So it's interpreted as shit compiled and it's statically compiled.

16:20.560 --> 16:23.560
Um, and so this is for a variety of reasons.

16:23.680 --> 16:28.120
Um, so, uh, one of the things that makes Python beautiful is that it's very

16:28.120 --> 16:32.920
dynamic and because it's dynamic, one of the things they added is that it has

16:32.920 --> 16:34.400
this powerful metaprogramming feature.

16:35.040 --> 16:39.760
And so if you look at something like PyTorch or TensorFlow or, or, um, I mean,

16:39.760 --> 16:44.640
even a simple, simple use case, like you'd find a class that has the plus method,

16:45.240 --> 16:45.400
right?

16:45.400 --> 16:48.720
You can overload the Dunder methods like Dunder add, for example.

16:48.720 --> 16:50.600
And then the plus method works on your class.

16:51.000 --> 16:54.840
And so it has very nice and very expressive dynamic metaprogramming

16:54.840 --> 16:57.120
features in Mojo.

16:57.120 --> 16:58.600
We want all those features come in.

16:58.720 --> 16:59.640
Like we don't want to break Python.

16:59.640 --> 17:00.480
We want it all to work.

17:00.760 --> 17:05.000
But the problem is, is he can't run those super dynamic features on an embedded

17:05.040 --> 17:08.560
processor or on a GPU, right?

17:08.560 --> 17:11.920
Or if you could, you probably don't want to just because of the performance.

17:11.920 --> 17:17.080
And so we entered this question of saying, okay, how do you get the power of this

17:17.120 --> 17:22.400
dynamic metaprogramming into a language that has to be super efficient in specific

17:22.400 --> 17:22.880
cases?

17:23.120 --> 17:25.600
And so what we did was we said, okay, we'll take that interpreter.

17:25.840 --> 17:27.600
Python has an interpreter in it, right?

17:28.000 --> 17:30.080
Take the interpreter and allow it to run it compile time.

17:31.440 --> 17:33.760
And so now what you get is you get compile time metaprogramming.

17:34.400 --> 17:38.560
And so this is super interesting and super powerful because one of the big

17:38.560 --> 17:42.840
advantages you get is you get Python style, expressive APIs, you get the ability

17:42.840 --> 17:45.000
to have overloaded operators.

17:45.000 --> 17:48.080
And if you look at what happens inside of like PyTorch, for example, with

17:48.080 --> 17:51.480
automatic differentiation and eager mode and like all these things, they're using

17:51.480 --> 17:55.400
these really dynamic and powerful features at runtime, but we can take those

17:55.400 --> 17:57.640
features and lift them so that they run at compile time.

17:58.160 --> 18:05.200
So you're, because C++ is metaprogramming with templates, but it's really messy.

18:05.320 --> 18:06.160
It's super messy.

18:06.160 --> 18:10.600
It's, it's always, um, it was accidentally, I mean, different people have different

18:10.600 --> 18:11.160
interpretations.

18:11.520 --> 18:14.560
My interpretation is that it was made accidentally powerful.

18:14.640 --> 18:18.840
It was not designed to be Turing complete, for example, but that was discovered kind

18:18.840 --> 18:20.440
of along the way accidentally.

18:21.000 --> 18:24.320
Um, and so there've been a number of languages in the space.

18:24.360 --> 18:28.400
And so they usually have templates or code instantiation, code copying

18:28.400 --> 18:29.520
features of various sorts.

18:30.240 --> 18:34.280
Um, some more modern languages or some more newer, newer languages, let's say,

18:34.320 --> 18:40.240
like, you know, they're fairly, um, unknown, like Zig, for example, um, says,

18:40.240 --> 18:44.400
okay, well, let's take all of those types that you can run it, all those things

18:44.400 --> 18:47.160
that you can do at runtime and allow them to happen at compile time.

18:48.200 --> 18:52.600
And so one of the problems with C++, I mean, which is one of, one of the

18:52.600 --> 18:57.680
problems with C++ is okay.

18:57.760 --> 18:59.600
I mean, everybody hates me for a variety of reasons.

18:59.600 --> 19:00.600
Anyways, I'm sure, right.

19:01.600 --> 19:03.360
I've written enough the way they show love.

19:03.400 --> 19:07.600
I have written enough C++ code to earn a little bit of grumpiness with C++, but,

19:08.000 --> 19:12.480
um, but one of the problems with it is that the metaprogramming system templates

19:12.960 --> 19:17.760
is just a completely different universe from the normal runtime programming world.

19:18.200 --> 19:21.000
And so if you do metaprogramming and programming, it's just like a different

19:21.000 --> 19:24.720
universe, different syntax, different concepts, different stuff going on.

19:24.720 --> 19:29.000
And so again, one of our goals with Mojo is to make things really easy to use,

19:29.080 --> 19:29.880
easy to learn.

19:29.920 --> 19:31.640
And so there's a natural stepping stone.

19:32.680 --> 19:36.120
And so as you do this, you say, okay, well, I have to do programming at runtime.

19:36.520 --> 19:38.040
I have to do programming at compile time.

19:39.160 --> 19:40.520
Why are these different things?

19:41.320 --> 19:42.360
How hard is that to pull it out?

19:42.360 --> 19:47.680
Cause that sounds to me as a fan of metaprogramming and C++ even, how, how

19:47.680 --> 19:49.000
hard is it to pull that off?

19:49.000 --> 19:51.720
That sounds really, really exciting because you can do the same style

19:51.720 --> 19:54.200
programming at compile time and at runtime.

19:54.200 --> 19:55.720
That's really, really exciting.

19:56.120 --> 19:59.680
And so, I mean, in terms of the compiler implementation details, it's hard.

20:00.600 --> 20:01.920
I won't, I won't be shy about that.

20:01.920 --> 20:02.640
It's super hard.

20:02.920 --> 20:06.560
It requires, I mean, what Mojo has underneath the covers is a completely new

20:06.560 --> 20:09.080
approach to the design of the compiler itself.

20:09.640 --> 20:13.240
And so this builds on these technologies like MLIR that you mentioned, but it

20:13.240 --> 20:18.800
also includes other like caching and other interpreters and JIT compilers and

20:18.800 --> 20:21.680
other stuff like that, like an interpreter inside the within the compiler.

20:21.720 --> 20:22.120
Yes.

20:23.400 --> 20:29.280
And so it really takes the standard model of programming languages and kind of

20:29.920 --> 20:32.360
twisted and unifies it with the runtime model, right.

20:32.400 --> 20:33.880
Which I think is really cool.

20:34.120 --> 20:37.280
And to me, the value of that is that again, many of these languages have

20:37.280 --> 20:40.080
metaprogramming features, like they grow macros or something, right?

20:40.280 --> 20:40.960
Lisp, right?

20:42.320 --> 20:43.520
I know your roots, right?

20:44.400 --> 20:46.720
You know, and this is a powerful thing, right?

20:46.720 --> 20:50.240
And so, you know, if you go back to Lisp, one of the most powerful things about it

20:50.240 --> 20:54.080
is that it said that the metaprogramming and the programming are the same, right?

20:54.080 --> 20:57.520
And so that made it way simpler, way more consistent, way easier to understand

20:57.520 --> 20:59.760
reason about, and it made it more composable.

20:59.760 --> 21:02.160
So if you go to the library, you can use it both at runtime and

21:02.160 --> 21:04.280
compile time, which is pretty cool.

21:04.360 --> 21:04.680
Yeah.

21:04.760 --> 21:08.800
And then for machine learning, I think metaprogramming, I think we could

21:08.800 --> 21:11.120
generally say is extremely useful.

21:11.840 --> 21:16.360
And so you get features, I mean, I'll jump around, but there's the feature of

21:16.360 --> 21:20.560
auto-tuning and adaptive compilation just blows my mind.

21:20.800 --> 21:21.280
Well, so, okay.

21:21.280 --> 21:22.040
So let's come back to that.

21:22.040 --> 21:22.320
Sure thing.

21:22.320 --> 21:22.720
All right.

21:22.760 --> 21:25.040
So, so what, what, what is, what is, what is machine learning?

21:25.040 --> 21:26.480
Like what, or what is a machine learning model?

21:26.480 --> 21:28.280
Like you take a PyTorch model off the internet, right?

21:28.880 --> 21:32.520
Um, it's really interesting to me because what a PI, what PyTorch and what

21:32.520 --> 21:35.880
TensorFlow and all these frameworks are kind of pushing compute into is they're

21:35.880 --> 21:41.120
pushing into like this abstract specification of a compute problem, which

21:41.120 --> 21:43.360
then gets mapped in a whole bunch of different ways, right?

21:43.360 --> 21:45.960
And so this is why it became a metaprogramming problem is that you want

21:45.960 --> 21:49.640
to be able to say, cool, I have, I have this neural net now run it with batch

21:49.640 --> 21:51.520
size a thousand, right?

21:51.520 --> 21:56.040
Do, do, do, do a mapping across batch or, okay, I want to take this problem.

21:56.040 --> 21:58.640
Now running across a thousand CPUs or GPUs.

21:59.040 --> 21:59.280
Right.

21:59.600 --> 22:04.560
And so like this, this problem of like, just describe the compute and then map

22:04.560 --> 22:08.640
it and do things and transform it or, or like, actually it's very profound.

22:08.640 --> 22:11.280
And that's one of the things that makes machine learning systems really special.

22:11.840 --> 22:15.440
Uh, maybe can you describe auto-tuning and how do you pull off?

22:15.640 --> 22:19.280
I mean, I guess adaptive compilation is what we're talking about is metaprogramming.

22:19.640 --> 22:20.640
How do you pull off auto-tune?

22:20.680 --> 22:23.240
I mean, is that, is that as profound as I think it is?

22:23.240 --> 22:26.920
It just seems like a really like, uh, you know, we'll mention list

22:26.920 --> 22:32.240
comprehensions to me from a quick glance at Mojo, uh, which by the way, I

22:32.240 --> 22:37.560
have to absolutely like dive in, uh, as I realized how amazing this is, I

22:37.680 --> 22:41.800
absolutely must have, and, uh, it, that looks like just an incredible feature

22:41.800 --> 22:43.040
for machine learning people.

22:43.160 --> 22:43.400
Yeah.

22:43.440 --> 22:44.680
Well, so, so what is auto-tuning?

22:44.680 --> 22:45.480
So take a step back.

22:46.200 --> 22:47.600
Auto-tuning is a feature in Mojo.

22:47.680 --> 22:51.160
It's not so very, very little of what we're doing is actually research.

22:51.240 --> 22:55.000
Like many of these ideas have existed in other systems and other places.

22:55.000 --> 22:58.480
And so what we're doing is we're pulling together good ideas, remixing them and

22:58.480 --> 23:00.920
making them into hopefully a beautiful system, right?

23:01.600 --> 23:06.800
And so auto-tuning the observation is that it turns out hardware systems,

23:07.360 --> 23:08.680
algorithms are really complicated.

23:09.240 --> 23:12.240
Turns out maybe you don't actually want to know how the hardware works.

23:13.160 --> 23:13.520
Right.

23:13.560 --> 23:14.680
A lot of people don't, right?

23:14.680 --> 23:17.440
And so there are lots of really smart hardware people.

23:17.440 --> 23:21.480
I know a lot of them, uh, where they know everything about, okay, the,

23:21.720 --> 23:24.320
the cache size is this and the number of registers is that.

23:24.320 --> 23:27.120
And if you use this, what length of vector, it's going to be super efficient

23:27.120 --> 23:28.800
because it maps directly onto what it can do.

23:28.800 --> 23:31.720
And like all this kind of stuff for the GPU has SMS and it has a

23:31.720 --> 23:33.040
warp size of whatever, right?

23:33.440 --> 23:35.600
All the stuff that goes into these things where the title size of a

23:35.600 --> 23:38.640
TPU is 128, like these, these factoids, right?

23:39.200 --> 23:43.080
My belief is that most normal people, and I love hardware people also,

23:43.080 --> 23:46.760
I'm not trying to offend literally everybody in the internet, um, but, uh,

23:46.800 --> 23:50.280
most programmers actually don't want to know this stuff, right?

23:50.280 --> 23:53.000
And so if you come at it from the perspective of how do we allow people

23:53.000 --> 23:57.920
to build both more abstracted, but also more portable code, because, you

23:57.920 --> 24:00.680
know, it could be that the vector length changes or the cache size changes,

24:00.680 --> 24:03.320
or it could be that the tile size of your matrix changes or the number,

24:03.600 --> 24:07.280
you know, an a 100 versus an H 100 versus a Volta versus a whatever

24:07.440 --> 24:09.200
GPU have different characteristics, right?

24:09.360 --> 24:13.160
A lot of the algorithms that you run are actually the same, but the

24:13.160 --> 24:16.040
parameters, these magic numbers you have to fill in end up being really

24:16.040 --> 24:18.760
fiddly numbers that an expert has to go figure out.

24:19.040 --> 24:22.400
And so what auto tuning does is says, okay, well, guess what?

24:22.440 --> 24:24.800
There's a lot of compute out there, right?

24:24.840 --> 24:27.960
So instead of having humans go randomly try all the things or do a grid

24:27.960 --> 24:32.440
search or go search some complicated multidimensional space, how about we

24:32.440 --> 24:34.120
have computers do that, right?

24:34.120 --> 24:35.440
And so auto tuning does that.

24:36.000 --> 24:36.240
Right.

24:36.240 --> 24:39.160
And so auto tuning does is you can say, Hey, here's my algorithm.

24:40.080 --> 24:43.800
If it's a, a matrix operation or something like that, you can say, okay,

24:43.800 --> 24:45.400
I'm going to carve it up into blocks.

24:45.400 --> 24:46.920
I'm going to do those blocks in parallel.

24:46.920 --> 24:50.800
And I want to this, this with 128 things that I'm running on, I want to

24:50.880 --> 24:52.360
cut it this way or that way or whatever.

24:52.760 --> 24:54.720
And you can say, Hey, go see which one's actually

24:54.720 --> 24:56.160
empirically better on the system.

24:57.240 --> 25:00.000
And then the result of that, you cash for that system.

25:00.080 --> 25:00.320
Yep.

25:01.280 --> 25:05.440
And so come back to twisting your compiler brain, right?

25:05.440 --> 25:08.600
So not only does the compiler have an interpreter that she used to do

25:08.600 --> 25:12.880
metaprogramming, that compiler, that interpreter, that metaprogramming now

25:12.880 --> 25:17.840
has to actually take your code and go run it on a target machine, see, see

25:17.840 --> 25:20.480
which one it likes the best and then stitch it in and then keep going.

25:20.600 --> 25:20.840
Right.

25:20.840 --> 25:23.200
So part of the compilation is machine specific.

25:23.240 --> 25:23.480
Yeah.

25:23.480 --> 25:25.720
Well, so, I mean, this is an optional feature, right?

25:25.720 --> 25:27.920
So you don't have to use it for everything, but yeah, if you, if you're,

25:28.040 --> 25:32.560
so one, one of, one of the things that we're in the quest of is ultimate

25:32.680 --> 25:34.280
performance, right?

25:34.280 --> 25:36.600
And ultimate performance is important for a couple of reasons, right?

25:36.600 --> 25:39.320
So if you're an enterprise, you're looking to save costs and compute

25:39.320 --> 25:42.840
and things like this, ultimate performance translates to, you know, fewer

25:42.840 --> 25:46.880
servers, like if you care about the environment, Hey, better performance

25:46.880 --> 25:49.360
leads to more efficiency, right?

25:49.360 --> 25:52.840
I mean, you could joke and say like, you know, Python's bad for the environment.

25:54.280 --> 25:56.920
And so if you can move to Mojo, it's like at least 10 X better, just out

25:56.920 --> 25:58.480
of the box and keep going, right.

26:00.120 --> 26:03.240
But, but performance is also interesting because it leads to better products.

26:03.880 --> 26:07.120
And so in the space of machine learning, right, if you reduce the latency

26:07.320 --> 26:09.840
of a model, so that it runs faster.

26:09.840 --> 26:12.480
So every time you query the server running the model, it takes less time.

26:12.800 --> 26:14.760
Well, then the product team can go and make the model bigger.

26:15.520 --> 26:19.720
Well, that's actually makes it so you have a better experience as a customer.

26:19.880 --> 26:21.240
And so a lot of people care about that.

26:21.440 --> 26:25.400
So for auto tuning, for like tile size, you mentioned 128 for TPU, you would

26:25.400 --> 26:30.760
specify like a bunch of options to try just in the code, just simple statement.

26:31.000 --> 26:35.800
And then you can just set and forget and know depending where it compiles, it'll

26:35.840 --> 26:38.000
actually be the fastest and yeah, exactly.

26:38.000 --> 26:40.440
And the beauty of this is that it helps you in a whole bunch of different ways.

26:40.440 --> 26:40.640
Right.

26:40.640 --> 26:44.240
So if you're building, so often what'll happen is that, you know, you've written

26:44.240 --> 26:45.560
a bunch of software yourself, right.

26:45.560 --> 26:47.920
You, you wake up one day, you say, I have an idea.

26:47.920 --> 26:49.080
I'm going to go cut up some code.

26:49.360 --> 26:50.120
I get to work.

26:50.920 --> 26:53.560
I forget about it and move on with life.

26:53.560 --> 26:56.360
I come back six months or a year or two years or three years later, you dust it

26:56.360 --> 27:00.720
off and you go use it again in a new environment and maybe your GP is different.

27:00.720 --> 27:03.920
Maybe you're running on a server instead of a laptop, maybe whatever.

27:04.040 --> 27:04.320
Right.

27:04.680 --> 27:08.320
And so the problem now is you say, okay, well, I mean, again, not everybody

27:08.320 --> 27:11.440
cares about performance, but if you do, you say, okay, well, I want to take

27:11.440 --> 27:12.720
advantage of all these new features.

27:13.200 --> 27:14.640
I don't want to break the old thing though.

27:15.520 --> 27:15.760
Right.

27:15.760 --> 27:20.400
And so the typical way of handling this kind of stuff before is, you know, if

27:20.440 --> 27:24.480
you're talking about C++ templates, or you're talking about C with macros, you

27:24.480 --> 27:27.960
end up with if-defs, you get like all these weird things get layered in, make

27:27.960 --> 27:31.080
the code super complicated, and then how do you test it, right?

27:31.080 --> 27:34.480
It becomes this, this crazy complexity, multidimensional space you have to

27:34.480 --> 27:38.040
worry about and you know, that just doesn't scale very well.

27:39.040 --> 27:42.400
Actually, let me just jump around before I go to some specific features, like

27:42.400 --> 27:47.400
the increase in performance here that we're talking about can be just insane.

27:48.040 --> 27:55.360
You write them Moja can provide a 35,000 X speed up over Python.

27:55.960 --> 27:56.760
How does it do that?

27:57.040 --> 27:57.320
Yeah.

27:57.360 --> 28:00.400
So it can even do more, but we'll get to that.

28:00.520 --> 28:06.480
So, so first of all, when we say that we're talking about what's called C

28:06.480 --> 28:09.680
Python, it's the default Python that everybody uses when you type Python

28:09.680 --> 28:12.120
three, that's like typically the one you use, right?

28:12.600 --> 28:16.360
See, Python is an interpreter and so interpreters, they have an extra

28:16.360 --> 28:20.320
layer of like byte codes and things like this that they have to go read,

28:20.320 --> 28:23.120
parse, interpret, and it makes them kind of slow from that perspective.

28:23.480 --> 28:26.400
And so one of the first things we do is we move to a compiler.

28:27.160 --> 28:29.520
And so I'm just moving to a compiler, getting the interpreter out of the

28:29.520 --> 28:33.080
loop is two to five to 10 X speed up, depending on the code.

28:33.400 --> 28:38.440
So just out of the gate, just using more modern techniques, right?

28:39.000 --> 28:41.760
Now, if you do that, one of the things you can do is you can start to look

28:41.760 --> 28:45.080
at how C Python started to lay out data.

28:45.920 --> 28:50.200
And so one of the things that C Python did, and this isn't part of the Python

28:50.200 --> 28:55.280
spec necessarily, but this is just sets of decisions, is that if you take an

28:55.280 --> 28:59.520
integer, for example, it'll put it in an object because in Python, everything's

28:59.520 --> 29:04.360
an object, and so they do the very logical thing of keeping the memory

29:04.360 --> 29:06.160
representation of all objects the same.

29:06.680 --> 29:09.560
So all objects have a header, they have like payload data.

29:09.560 --> 29:12.560
And what this means is that every time you pass around an object, you're

29:12.560 --> 29:14.360
passing around a pointer to the data.

29:15.480 --> 29:16.760
Well, this has overhead, right?

29:16.760 --> 29:20.000
It turns out that modern computers don't like chasing pointers very

29:20.000 --> 29:20.960
much and things like this.

29:20.960 --> 29:24.400
It means that you have to allocate the data, means you have to reference

29:24.400 --> 29:27.400
count it, which is another way that Python uses to keep track of memory.

29:27.800 --> 29:29.360
And so this has a lot of overhead.

29:29.480 --> 29:35.880
And so if you say, okay, let's try to get that out of the heap, out of a box, out

29:35.880 --> 29:42.200
of an indirection and into the registers, that's another 10 X.

29:42.200 --> 29:47.000
So it adds up if you're reference counting every single thing you create,

29:47.040 --> 29:47.800
that adds up.

29:47.920 --> 29:48.200
Yep.

29:48.240 --> 29:51.160
And if you look at, you know, people complain about the Python gil, this is

29:51.160 --> 29:53.200
one of the things that hurts parallelism.

29:54.000 --> 29:56.360
That's because of the reference counting, right?

29:56.360 --> 29:59.280
And so the gil and reference counting are very tightly intertwined in Python.

29:59.320 --> 30:01.520
It's not the only thing, but it's very tightly intertwined.

30:02.000 --> 30:03.720
And so then you lean into this and you say, okay, cool.

30:03.760 --> 30:07.160
Well, modern computers, they can do more than one operation at a time.

30:07.840 --> 30:08.560
And so they have vectors.

30:08.600 --> 30:09.240
What is a vector?

30:09.280 --> 30:12.280
Well, a vector allows you to take one, instead of taking one piece of data,

30:12.280 --> 30:16.520
doing an add or multiply, and then pick up the next one, you can now do a four or

30:16.520 --> 30:18.680
eight or 16 or 32 at a time, right?

30:18.680 --> 30:21.160
Well, Python doesn't expose that because of reasons.

30:21.560 --> 30:23.240
And so now you can say, okay, well, you can adopt that.

30:24.000 --> 30:24.920
Now you have threads.

30:25.000 --> 30:27.680
Now you have like additional things like you can control memory hierarchy.

30:27.680 --> 30:30.800
And so what Mojo allows you to do is it allows you to start taking advantage of

30:31.200 --> 30:34.240
all these powerful things that have been built into the hardware over time.

30:34.360 --> 30:38.440
And it gives, the library gives very nice features.

30:38.520 --> 30:41.800
So you can say, just parallelize this, do this in parallel, right?

30:41.920 --> 30:47.360
So it's very, very powerful weapons against slowness, which is why people have

30:47.360 --> 30:50.960
been, I think having fun, like just taking code and making it go fast because it's

30:51.200 --> 30:53.920
just kind of an adrenaline rush to see like how fast you can get things.

30:54.400 --> 30:57.160
Before I talk about some of the interesting stuff with parallelization, all

30:57.160 --> 31:00.000
that, let's, let's first talk about like the basics.

31:00.000 --> 31:01.480
We talked to indentation, right?

31:01.480 --> 31:02.800
So this thing looks like Python.

31:04.400 --> 31:05.480
It's sexy and beautiful.

31:05.480 --> 31:09.160
Like Python, as I mentioned, is it a typed language?

31:09.200 --> 31:10.720
So what's the role of types?

31:10.800 --> 31:11.560
Yeah, good question.

31:11.560 --> 31:13.240
So Python has types.

31:13.840 --> 31:18.000
It has strings, has integers, it has dictionaries and like all that stuff,

31:18.400 --> 31:20.400
but they all live at runtime, right?

31:20.400 --> 31:23.800
And so because all those types live at runtime and Python, you never,

31:24.160 --> 31:25.560
or you don't have to spell them.

31:26.520 --> 31:29.080
Python also has like this whole typing thing going on now.

31:29.080 --> 31:30.000
And a lot of people use it.

31:30.600 --> 31:31.360
I'm not talking about that.

31:31.360 --> 31:32.440
That's, that's kind of a different thing.

31:32.440 --> 31:33.480
We can go back to that if you want.

31:33.480 --> 31:38.800
But, but typically the, um, you know, you just say, I take, I have a deaf

31:38.840 --> 31:40.240
and my deaf takes two parameters.

31:40.240 --> 31:42.240
I'm going to call them A and B and I don't have to write a type.

31:42.520 --> 31:42.760
Okay.

31:43.440 --> 31:45.960
So that is great.

31:45.960 --> 31:49.000
But what that does is that forces what's called a consistent representation.

31:49.160 --> 31:52.680
So these things have to be a pointer to an object with the object header, and

31:52.680 --> 31:54.000
they all have to look the same.

31:54.400 --> 31:57.640
And then when you dispatch a method, you go through all the same different

31:57.640 --> 32:00.680
paths, no matter what the, the receiver, whatever that type is.

32:01.200 --> 32:04.280
So what Mojo does is it allows you to have more than one kind of type.

32:04.320 --> 32:06.920
And so what it does is allows you to say, okay, cool.

32:06.920 --> 32:09.960
I have, I have an object and objects behave like Python does.

32:10.000 --> 32:11.960
And so it's fully dynamic and that's all great.

32:11.960 --> 32:15.640
And for many things, classes, like that's all very powerful and very important.

32:16.360 --> 32:19.840
But if you want to say, Hey, it's an integer and it's 32 bits or 64

32:19.840 --> 32:23.760
bits or whatever it is, or it's a floating point value, it's 64 bits.

32:24.320 --> 32:27.760
Well, then the compiler can take that and it can use that to do way better

32:27.760 --> 32:30.600
optimization and turns out again, getting rid of the indirection.

32:30.680 --> 32:34.920
That's huge means you can get better code completion because you have, um,

32:34.960 --> 32:36.760
because compiler knows what the type is.

32:36.760 --> 32:38.800
And so it knows what operations work on it.

32:38.880 --> 32:40.360
And so that's actually pretty huge.

32:40.840 --> 32:45.520
And so what Mojo does is it allows you to progressively adopt types into your

32:45.520 --> 32:49.280
program and so you can start again, it's compatible with Python.

32:49.320 --> 32:52.120
And so then you can add however many types you want, wherever you want them.

32:52.560 --> 32:54.120
And if you don't want to deal with it, you don't have to deal with it.

32:54.600 --> 32:54.880
Right.

32:55.000 --> 33:00.000
And so one of, one of, you know, our opinions on this is that it's not that

33:00.120 --> 33:02.520
types are the right thing or the wrong thing.

33:03.240 --> 33:04.320
It's that they're a useful thing.

33:05.480 --> 33:06.600
Well, so it's kind of optional.

33:06.600 --> 33:09.200
It's not strict typing and you don't have to specify type.

33:09.240 --> 33:09.680
Exactly.

33:10.520 --> 33:10.800
Okay.

33:10.800 --> 33:13.960
So it's starting from the thing that Python is kind of reaching towards right

33:13.960 --> 33:17.040
now with trying to inject types into it.

33:17.240 --> 33:18.840
What is the very different approach?

33:18.840 --> 33:19.480
But yes.

33:19.680 --> 33:19.920
Yeah.

33:20.160 --> 33:21.000
What's the different approach?

33:21.200 --> 33:26.800
I'm actually one of the people that have not been using types very much in Python.

33:26.880 --> 33:27.560
So that's okay.

33:27.880 --> 33:28.760
Why did you say?

33:29.560 --> 33:31.760
It's just, well, because I know the importance.

33:31.760 --> 33:34.720
It's like adults use strict typing.

33:35.400 --> 33:38.000
And so I, I refuse to grow up in that sense.

33:38.000 --> 33:43.520
It's a, it's a kind of rebellion, but I just know that, um, it probably reduces

33:43.520 --> 33:46.680
the amount of errors, even just for forget about performance improvements.

33:46.720 --> 33:49.080
It probably reduces errors when you do strict typing.

33:49.120 --> 33:49.320
Yeah.

33:49.320 --> 33:51.240
So, I mean, I think it's, it's interesting if you look at that, right.

33:51.240 --> 33:56.200
And the reason I'm giving you a hard time is that, that there's this, this

33:56.240 --> 34:00.040
cultural norm, this pressure, this, like, there has to be a right way to do things.

34:00.040 --> 34:01.880
Like, you know, only grownups only do it one way.

34:01.880 --> 34:03.280
And if you don't do that, you should feel bad.

34:03.320 --> 34:03.640
Yes.

34:03.680 --> 34:03.920
Right.

34:03.920 --> 34:06.760
Like some people feel like Python's a guilty pleasure or something.

34:07.200 --> 34:09.200
And that's like, when it gets serious, I need to go rewrite it.

34:09.200 --> 34:09.520
And right.

34:09.880 --> 34:10.200
Exactly.

34:10.200 --> 34:11.880
Well, I mean, cool.

34:11.880 --> 34:15.200
I understand history and I understand kind of where this comes from, but I

34:15.200 --> 34:16.600
don't think it has to be a guilty pleasure.

34:16.680 --> 34:16.960
Yeah.

34:17.640 --> 34:20.120
So if you look at that, you say, why do you have to rewrite it?

34:20.120 --> 34:21.360
Well, you have to rewrite it to deploy.

34:22.280 --> 34:23.360
Well, why do you want to deploy?

34:23.360 --> 34:26.120
Well, you care about performance or you care about predictability or you

34:26.320 --> 34:30.320
want, you know, a tiny thing on the server that has no dependencies or, you

34:30.320 --> 34:33.240
know, you have objectives that you're trying to attain.

34:34.120 --> 34:36.800
So what if Python can achieve those objectives?

34:37.600 --> 34:40.240
So if you want types, well, maybe you want types because you want to make sure

34:40.240 --> 34:41.320
you're passing on the right thing.

34:41.800 --> 34:42.080
Sure.

34:42.080 --> 34:42.760
You can add a type.

34:43.400 --> 34:45.720
If you don't care, you're prototyping some stuff.

34:45.720 --> 34:46.800
You're hacking some things out.

34:46.800 --> 34:48.640
You're like pulling some random code off the internet.

34:49.000 --> 34:49.800
It should just work.

34:50.760 --> 34:51.040
Right.

34:51.040 --> 34:53.040
And you shouldn't be like pressured.

34:53.080 --> 34:56.520
You shouldn't feel bad about doing the right thing or the thing that feels good.

34:56.560 --> 34:58.800
Now, if you're in a team, right.

34:58.800 --> 35:01.920
You're working at some massive internet company and you have 400

35:01.920 --> 35:03.240
million lines of Python code.

35:03.760 --> 35:07.080
Well, they, they may have a house rule that you use types, right.

35:07.080 --> 35:09.720
Because it makes it easier for different humans to talk to each other and understand

35:09.720 --> 35:11.920
what's going on and bugs at scale.

35:11.960 --> 35:12.200
Right.

35:12.600 --> 35:15.360
And so there, there are lots of good reasons why you might want to use types,

35:15.840 --> 35:18.520
but that doesn't mean that everybody should use them all the time.

35:18.600 --> 35:18.840
Right.

35:18.840 --> 35:22.520
So what Mojo does is it says, cool, well, allow people to use types.

35:22.640 --> 35:25.440
And if you use types, you get nice things out of it, right.

35:25.440 --> 35:26.960
You get better performance and things like this.

35:26.960 --> 35:27.240
Right.

35:27.600 --> 35:32.200
But Mojo is a full compatible superset of Python.

35:33.040 --> 35:33.320
Right.

35:33.360 --> 35:36.000
And so that means it has to work without types.

35:37.040 --> 35:38.520
It has to support all the dynamic things.

35:38.520 --> 35:39.400
It has to support all the packages.

35:39.400 --> 35:43.640
It has support for comprehension, list comprehensions and things like this.

35:43.640 --> 35:43.840
Right.

35:43.840 --> 35:47.080
And so that, that, that starting point, I think is really important.

35:47.080 --> 35:50.960
And I think that, again, you can look at why I care so much about this.

35:51.040 --> 35:52.600
And there's many different aspects of that.

35:52.600 --> 35:56.320
One of which is the world went through a very challenging migration

35:56.320 --> 35:57.600
from Python two to Python three.

35:59.160 --> 35:59.400
Right.

35:59.400 --> 36:03.680
And this, this migration took many years and it was very painful for many teams.

36:03.680 --> 36:03.920
Right.

36:03.920 --> 36:06.240
And there's a lot of, a lot of things that went on in that.

36:06.760 --> 36:09.160
Um, I'm not an expert in all the details.

36:09.160 --> 36:12.200
I honestly don't want to be, I don't want the world to have to go through that.

36:12.960 --> 36:13.280
Right.

36:13.280 --> 36:16.640
And, you know, people can ignore Mojo and if it's not their thing, that's, that's

36:16.640 --> 36:19.440
cool, but if they want to use Mojo, I don't want them to have to rewrite all their code.

36:19.960 --> 36:20.880
I mean, this, okay.

36:20.880 --> 36:25.360
The superset part is, it's just, I mean, there's so much brilliant stuff here

36:25.360 --> 36:27.720
that definitely is, is, is incredible.

36:28.040 --> 36:32.280
Um, we'll talk about that first of all, how's the typing implemented differently

36:32.920 --> 36:36.480
in, uh, in Python versus, uh, Mojo.

36:36.560 --> 36:40.840
So the, this heterogeneous flexibility you said is definitely implemented.

36:40.920 --> 36:41.200
Yeah.

36:41.360 --> 36:45.000
So I'm not a full expert in the whole backstory on types in Python.

36:45.000 --> 36:46.600
So I'll give you, I'll give you that.

36:46.600 --> 36:47.600
I can give you my understanding.

36:48.080 --> 36:53.600
Um, my understanding is basically like many dynamic languages, the ecosystem

36:53.600 --> 36:57.440
went through a phase where people went from writing scripts to writing a large

36:57.440 --> 37:03.440
scale, huge code bases in Python and at scale kind of helps have types.

37:03.920 --> 37:05.640
People want to be able to reason about interfaces.

37:05.640 --> 37:09.480
What, what do you expect to string or an inter like these basic things.

37:09.480 --> 37:09.720
Right.

37:10.200 --> 37:13.800
And so what the Python community started doing is it started saying, okay, let's

37:13.800 --> 37:17.240
have tools on the side, checker tools, right?

37:17.240 --> 37:22.200
The go and like enforce invariance, check for bugs, try to identify things.

37:22.440 --> 37:24.640
These are called static analysis tools generally.

37:24.800 --> 37:27.120
And so these tools run over your code and try to look for bugs.

37:27.920 --> 37:30.440
What ended up happening is there's so many of these things, so many different

37:30.440 --> 37:33.640
weird patterns and different approaches on specifying the types and different

37:33.640 --> 37:36.800
things going on that the Python community realized and recognize, Hey,

37:36.800 --> 37:37.920
hey, hey, there's a thing here.

37:38.880 --> 37:40.960
And so what they started to do is they started to standardize the

37:40.960 --> 37:42.760
syntax for adding types to Python.

37:43.440 --> 37:46.400
Now, one of the challenges that they had is that they're coming from kind

37:46.400 --> 37:48.760
of this fragmented world where there's lots of different tools, they have

37:48.760 --> 37:51.840
different trade-offs and interpretations and the types mean different things.

37:51.840 --> 37:55.840
And so if you look at types in Python, according to the Python spec,

37:56.600 --> 37:59.200
the types are ignored, right?

37:59.200 --> 38:01.760
So according to the Python spec, you can write pretty much

38:01.760 --> 38:04.280
anything in a type position.

38:04.280 --> 38:04.560
Okay.

38:05.040 --> 38:09.000
And, um, uh, you can technically, you can write any expression.

38:09.360 --> 38:09.640
Okay.

38:10.120 --> 38:13.680
Now that's beautiful because you can extend it.

38:13.680 --> 38:14.360
You can do cool things.

38:14.360 --> 38:15.520
You can write, build your own tools.

38:15.520 --> 38:18.280
You can build your own house linter or something like that.

38:18.280 --> 38:18.520
Right.

38:18.880 --> 38:22.920
But it's also a problem because any existing Python program may

38:22.920 --> 38:25.560
be using different tools and they have different interpretations.

38:25.600 --> 38:29.000
And so if you adopt somebody's package into your ecosystem, try

38:29.000 --> 38:31.840
around the tool you prefer, it may throw out tons of weird errors

38:31.840 --> 38:34.080
and warnings and problems just because it's incompatible

38:34.080 --> 38:35.200
with how these things work.

38:35.800 --> 38:39.000
Also because they're added late and they're not checked by the Python

38:39.000 --> 38:41.720
interpreter is always kind of more of a hint than it is a requirement.

38:42.560 --> 38:46.400
Also, uh, the CPython implementation can't use them for performance.

38:46.640 --> 38:48.240
And so it's really, that's a big one, right?

38:48.240 --> 38:50.920
So as you can utilize the, for the compilation, for the

38:50.920 --> 38:51.960
just in time compilation.

38:52.000 --> 38:52.280
Okay.

38:52.480 --> 38:52.880
Exactly.

38:52.880 --> 38:55.960
And this, this all comes back to the design principle of it's it's

38:55.960 --> 38:56.960
kind of, they're kind of hints.

38:57.040 --> 38:59.280
They're kind of, the definition is a little bit murky.

38:59.320 --> 39:01.800
It's unclear exactly the interpretation in a bunch of cases.

39:01.800 --> 39:05.480
And so because of that, you can't actually, um, even if you want to,

39:05.480 --> 39:08.840
it's really difficult to use them to say like, it is going to be an

39:08.840 --> 39:10.920
end and if it's not, it's a problem, right?

39:10.920 --> 39:12.280
A lot of code would break if you did that.

39:13.040 --> 39:14.560
So, so in mojo, right?

39:14.560 --> 39:16.320
So you can still use those kinds of type annotations.

39:16.320 --> 39:16.840
It's fine.

39:17.120 --> 39:20.960
But in mojo, if you declare a type and you use it, then it means

39:20.960 --> 39:24.480
it is going to be that type and the compiler helps you check that

39:24.480 --> 39:25.560
and enforce it and it's safe.

39:26.080 --> 39:30.400
Um, and it's not, it's not a like best effort hint kind of a thing.

39:30.680 --> 39:34.680
So if you try to shove a string type thing into a integer, you get an

39:34.680 --> 39:37.680
error from the compiler, compile time.

39:38.960 --> 39:39.760
Nice.

39:39.800 --> 39:40.120
Okay.

39:40.120 --> 39:41.520
What kind of basic types are there?

39:41.840 --> 39:42.040
Yeah.

39:42.040 --> 39:48.840
So, uh, mojo is, um, pretty hardcore in terms of what it tries to do in the

39:48.840 --> 39:55.400
language, which is the philosophy there is that we, um, again, if you, if you

39:55.400 --> 39:57.880
look at Python, right, Python is a beautiful language because it's so

39:57.880 --> 39:58.800
extensible, right?

39:58.800 --> 40:03.640
And so all of the different things in Python, like for loops and plus, and

40:03.640 --> 40:07.160
like all these things can be accessed through these underbar, unbar methods.

40:07.720 --> 40:08.000
Okay.

40:08.520 --> 40:12.040
So you have to say, okay, if I make something that is super fast, I can

40:12.040 --> 40:13.120
go all the way down to the metal.

40:13.680 --> 40:15.880
Why do I need to have integers built into the language?

40:17.080 --> 40:17.240
Right.

40:17.240 --> 40:20.520
And so what mojo does is it says, okay, well, we can have this notion of structs.

40:20.680 --> 40:22.320
So you have classes in Python.

40:22.320 --> 40:26.240
Now you can have structs, classes are dynamic, structs are static.

40:27.080 --> 40:27.320
Cool.

40:27.320 --> 40:28.320
We can get high performance.

40:28.320 --> 40:30.800
We can write C plus plus kind of code with structs.

40:30.800 --> 40:33.360
If you want these things mix and work beautifully together.

40:33.960 --> 40:36.880
Um, but what that means is that you can go and implement strings

40:36.880 --> 40:40.680
and ints and floats and arrays and all that kind of stuff in the language.

40:41.440 --> 40:41.680
Right.

40:41.680 --> 40:47.840
And so that's really cool because, you know, to me as a, uh, ideal, idealizing

40:47.840 --> 40:51.560
compile compiler language type of person, what I want to do is I want to get magic

40:51.600 --> 40:55.520
out of the compiler and put it in the libraries because if somebody can, you

40:55.520 --> 40:59.080
know, if we can build an integer that's beautiful and it has an amazing API, it

40:59.080 --> 41:02.440
does all the things you'd expect an integer to do, but you don't like it.

41:03.080 --> 41:04.040
Maybe you want a big integer.

41:04.040 --> 41:05.880
Maybe you want to like sideways integer.

41:05.880 --> 41:06.240
I don't know.

41:06.320 --> 41:11.840
Like what, what all the space of integers are, um, then, uh, then you can do that.

41:11.880 --> 41:13.320
And it's not a second class citizen.

41:14.720 --> 41:18.640
And so if you look at certain other languages like C plus plus one, I also

41:18.640 --> 41:25.680
love and use a lot, um, int is hard coded in the language, but complex is not.

41:26.920 --> 41:31.560
And so isn't it kind of weird that you have this STD complex class, but you

41:31.560 --> 41:36.200
have int and complex tries to look like a natural numeric type and things like

41:36.200 --> 41:40.560
this, but integers and floating point have these like special promotion rules

41:40.560 --> 41:43.320
and other things like that that are magic and they're hacked into the compiler.

41:43.760 --> 41:45.520
And because of that, you can't actually make something that

41:45.520 --> 41:46.600
works like the built-in types.

41:47.520 --> 41:49.600
Is there something provided as a standard?

41:49.880 --> 41:54.680
Because, uh, you know, because it's AI first, you know, numerical

41:54.680 --> 41:56.440
types are so important here.

41:56.480 --> 42:01.080
So is there something like a nice standard implementation of integer inflow?

42:01.120 --> 42:01.280
Yeah.

42:01.280 --> 42:02.880
So, so we're still building all that stuff out.

42:02.880 --> 42:05.040
So we provide integers and floats and all that kind of stuff.

42:05.040 --> 42:08.000
We also provide like buffers and tensors and things like that

42:08.000 --> 42:09.600
that you'd expect in an ML context.

42:10.080 --> 42:13.520
Honestly, we need to keep designing and redesigning and working with the

42:13.520 --> 42:14.960
community to build that out and make that better.

42:14.960 --> 42:16.160
That's not our strength right now.

42:17.080 --> 42:18.160
Give us six months or a year.

42:18.200 --> 42:19.280
And I think it'll be way better.

42:19.320 --> 42:23.040
But, um, but the power of putting in the library means that we can have

42:23.040 --> 42:27.000
teams of experts that aren't compiler engineers that can help us design

42:27.000 --> 42:28.480
and refine and drive us forward.

42:28.680 --> 42:32.640
So, uh, one of the exciting things we should mention here is that this is,

42:32.680 --> 42:35.000
uh, this is new and fresh.

42:35.400 --> 42:37.120
This cake is unbaked.

42:37.800 --> 42:38.680
It's almost baked.

42:38.680 --> 42:42.680
You can tell it's delicious, but it's not fully ready to be consumed.

42:42.760 --> 42:43.040
Yep.

42:43.080 --> 42:43.840
That's very fair.

42:43.960 --> 42:46.920
It is very useful, but it's very useful if you're a super low level

42:46.920 --> 42:49.400
programmer right now, and what we're doing is we're working our way up the

42:49.400 --> 42:56.160
stack and so the way I would look at Mojo today in May and 2023, um, is

42:56.160 --> 42:57.240
that it's like a 0.1.

42:58.080 --> 43:01.640
So I think that, you know, a year from now, it's gonna be way more

43:01.640 --> 43:03.440
interesting to a variety of people.

43:03.880 --> 43:07.320
But what we're doing is we're, we decided to release it early so that

43:07.320 --> 43:08.720
people can get access to and play with them.

43:08.720 --> 43:09.800
We can build with the community.

43:10.280 --> 43:15.320
We, um, have a big roadmap, fully published, being transparent about

43:15.320 --> 43:17.080
this and a lot of people are involved in this stuff.

43:17.080 --> 43:19.800
And so what we're doing is we're really optimizing for building

43:20.160 --> 43:24.000
this thing the right way and building it the right way is kind of interesting

43:24.000 --> 43:26.160
working with the community because everybody wants it yesterday.

43:27.120 --> 43:31.800
And so it's sometimes it's kind of, you know, there's some dynamics there,

43:31.880 --> 43:34.160
but I think it's a good, it's the right thing.

43:34.200 --> 43:35.480
So there's a discord also.

43:35.480 --> 43:37.320
So the dynamics is pretty interesting.

43:37.800 --> 43:42.920
Sometimes the community probably can be very chaotic and, uh, introduce a lot

43:42.920 --> 43:47.840
of stress, Guido famously quit over the stress of the Walrus operator.

43:47.920 --> 43:52.600
I mean, you know, broke, maybe that was exactly.

43:52.920 --> 43:55.920
And so like, it could be very stressful to develop, but can you just

43:56.320 --> 43:57.720
add tangent upon a tangent?

43:58.080 --> 44:04.320
Is it stressful to, to, uh, to work through the design of various features

44:04.320 --> 44:07.040
here, given that the community is so richly involved?

44:07.240 --> 44:11.080
Well, so, um, so I've been doing open development and community stuff for

44:11.160 --> 44:13.360
decades now, somehow this has happened to me.

44:13.640 --> 44:17.440
Um, so I've, I've learned some tricks, but the, the thing that always gets me

44:17.440 --> 44:18.520
is I want to make people happy.

44:19.320 --> 44:19.520
Right.

44:19.520 --> 44:24.240
And so this, this is maybe not all people all happy all the time, but generally

44:24.240 --> 44:25.600
I want, I want people to be happy.

44:25.640 --> 44:25.840
Right.

44:25.840 --> 44:31.440
And so the challenge is that again, we're tapping into some long, some deep

44:31.440 --> 44:35.720
seated, long tensions and pressures, both in the, the Python world, but also in

44:35.720 --> 44:38.000
the AI world and the hardware world and things like this.

44:38.360 --> 44:40.200
And so people just want us to move faster.

44:40.400 --> 44:40.680
Right.

44:41.040 --> 44:44.640
And so again, our decision was let's release this early.

44:44.680 --> 44:48.160
Let's get people used to it or access to it and play with it.

44:48.160 --> 44:53.240
And like, let's, let's build in the open, which we could have, you know, had the,

44:53.280 --> 44:58.560
the, uh, language monk sitting in the cloister up on the hilltop, like beavering

44:58.560 --> 44:59.600
away, trying to build something.

44:59.600 --> 45:02.160
But in my experience, you get something that's way better if you work with the

45:02.160 --> 45:03.680
community, right.

45:04.240 --> 45:05.760
And so, yes, it can be frustrating.

45:05.760 --> 45:07.360
It can be challenging for lots of people involved.

45:07.360 --> 45:10.840
And, you know, if you, I mean, if you mentioned our discord, we have over 10,000

45:10.840 --> 45:14.240
people on the discord, 11,000 people or something, keep in mind, we released

45:14.240 --> 45:19.440
mojo like two weeks ago, so, um, so it's very cool.

45:19.480 --> 45:24.120
Um, but what that means is that, um, you know, 10, 11,000 people all will

45:24.120 --> 45:25.760
want something different, right.

45:25.800 --> 45:28.840
And so what we've done is we've tried to say, okay, cool.

45:28.840 --> 45:33.440
Here's our roadmap here, here in the roadmap, isn't completely arbitrary.

45:33.480 --> 45:37.120
It's based on here's the logical order in which to build these features or add,

45:37.200 --> 45:38.840
add these capabilities and things like that.

45:38.840 --> 45:41.720
And what we've done is we spun really fast on like bug fixes.

45:41.800 --> 45:45.720
And so we actually have very few bugs, which is cool.

45:45.760 --> 45:48.960
I mean, actually for a project in the state, but then what we're doing

45:48.960 --> 45:50.800
is we're dropping in features very deliberately.

45:51.240 --> 45:52.160
I mean, this is fun to watch.

45:52.160 --> 45:56.320
Cause you got the two gigantic communities of like, uh, hardware, like

45:56.320 --> 46:01.520
systems engineers, and then you have the machine learning Python people

46:01.640 --> 46:07.120
that are like higher level and it's just too like, like army, like, uh,

46:07.840 --> 46:08.560
they've been at war.

46:08.640 --> 46:09.880
Yeah, they've been at war.

46:10.520 --> 46:10.760
Right.

46:10.760 --> 46:13.400
And so, so here's a token novel or something.

46:13.680 --> 46:16.320
So here's the test again, like it's, it's super funny for, for something

46:16.320 --> 46:17.680
that's only been out for two weeks.

46:17.680 --> 46:17.880
Right.

46:17.880 --> 46:19.480
People are so impatient.

46:19.800 --> 46:20.120
Right.

46:20.160 --> 46:21.280
But, okay, cool.

46:21.320 --> 46:25.480
Let's fast forward a year, like any year's time module will be actually quite

46:25.480 --> 46:27.720
amazing and solve tons of problems and be very good.

46:28.400 --> 46:30.360
Um, people still have these problems.

46:31.120 --> 46:31.280
Right.

46:31.280 --> 46:34.720
And so you, you, you look at this and you say, and the way I look at this

46:34.720 --> 46:39.640
at least is to say, okay, well, we're solving big longstanding problems.

46:40.720 --> 46:43.480
To me, I, again, working on many different problems, I want to

46:43.480 --> 46:44.280
make sure we do it right.

46:45.000 --> 46:45.200
Right.

46:45.200 --> 46:49.400
There's like a responsibility you feel, because if you mess it up, right.

46:49.720 --> 46:52.120
There's very few opportunities to do projects like this and have them

46:52.120 --> 46:53.480
really have impact on the world.

46:53.880 --> 46:57.520
If we do it right, then maybe we can take those feuding armies and

46:57.520 --> 46:58.960
actually heal some of those wounds.

46:59.000 --> 46:59.280
Yeah.

46:59.360 --> 47:03.040
This is like, this feels, this feels like a speech by George Washington

47:03.040 --> 47:04.200
or Abraham Lincoln or something.

47:05.400 --> 47:07.480
And you look at this and it's like, okay, well, how different are we?

47:07.840 --> 47:08.120
Yeah.

47:08.360 --> 47:09.560
We all want beautiful things.

47:09.600 --> 47:10.720
We all want something that's nice.

47:10.720 --> 47:11.880
We all want to be able to work together.

47:11.880 --> 47:13.200
We all want our stuff to be used.

47:13.240 --> 47:13.400
Right.

47:13.400 --> 47:17.640
And so if we can help heal that now, I'm not optimistic that all people will

47:17.640 --> 47:21.040
use mojo and they'll stop using C plus plus, like that's not my goal, right.

47:21.040 --> 47:24.200
But, um, but if we can heal some of that, I think that'd be pretty cool.

47:24.320 --> 47:24.640
Yeah.

47:24.640 --> 47:28.200
And, and we start by putting the people who like braces into the Gulag.

47:28.640 --> 47:33.080
No, uh, so, so, so there are proposals for adding braces to mojo and we

47:33.080 --> 47:33.920
just tell what you're saying.

47:33.920 --> 47:34.680
We tell them, no.

47:35.080 --> 47:35.480
Okay.

47:37.600 --> 47:38.080
Politely.

47:38.280 --> 47:38.440
Yeah.

47:38.440 --> 47:41.800
Anyway, so there's a lot of amazing features on the roadmap and those

47:41.800 --> 47:43.600
already implemented, it'd be awesome.

47:43.760 --> 47:44.920
I could just ask you a few things.

47:45.600 --> 47:50.200
So, uh, the, the other performance improvement comes from immutability.

47:50.360 --> 47:54.480
So what's the, what's this bar and this let thing that we got going on?

47:55.120 --> 47:56.280
Well, what's the mutability?

47:56.920 --> 47:57.200
Yeah.

47:57.200 --> 48:01.960
So one of the things that is, uh, useful and it's not always required, but it's

48:01.960 --> 48:04.880
useful is knowing whether something can change up from underneath you.

48:05.600 --> 48:05.720
Right.

48:05.720 --> 48:09.280
And so, and Python, you have a pointer to an array, right.

48:09.280 --> 48:11.920
And so you pass that pointer to an array around to things.

48:13.280 --> 48:16.400
If you pass into a function, they may take that and scrolled away

48:16.400 --> 48:17.760
in some other data structure.

48:18.200 --> 48:20.440
And so you get your array back and you go to use it.

48:20.440 --> 48:22.520
And now somebody else is like putting stuff in your array.

48:23.000 --> 48:24.080
How do you reason about that?

48:24.240 --> 48:27.240
It gets to be very complicated, at least lots of bugs.

48:27.560 --> 48:27.800
Right.

48:28.240 --> 48:31.560
And so one of the things that, you know, again, this is not something

48:31.560 --> 48:35.080
mojo forces on you, but something that mojo enables is a thing called value

48:35.080 --> 48:40.840
semantics and what value semantics do is they take collections like arrays,

48:41.240 --> 48:45.560
like dictionaries, also tensors and strings and things like this that are

48:45.560 --> 48:49.400
much higher level and make them behave like proper values.

48:49.480 --> 48:53.160
And so it makes it look like if you pass these things around, you get a

48:53.160 --> 48:54.600
logical copy of all the data.

48:55.240 --> 48:57.720
And so if I pass you an array, it's your array.

48:57.720 --> 48:58.840
You can go do what you want to it.

48:58.840 --> 48:59.800
You're not going to hurt my array.

49:00.320 --> 49:04.120
Now that is an interesting and very powerful design principle.

49:04.120 --> 49:05.320
Defines away a ton of bugs.

49:05.880 --> 49:08.160
You have to be careful to implement it in an efficient way.

49:08.560 --> 49:08.800
Yeah.

49:08.800 --> 49:11.840
Is there a performance hit that's significant?

49:12.920 --> 49:16.280
Generally not if you implement it the right way, but it requires a

49:16.280 --> 49:20.040
lot of very low level getting the language right bits.

49:20.520 --> 49:23.800
I assume there'd be a huge performance hit because it's a really, the

49:23.800 --> 49:25.800
benefit is really nice because you don't get into the complex.

49:25.800 --> 49:26.280
Absolutely.

49:26.320 --> 49:29.080
Well, the trick is, is you can't do, you can't do copies.

49:29.840 --> 49:34.520
So you have to provide the behavior of copying without doing the copy.

49:35.200 --> 49:35.720
Yeah.

49:38.280 --> 49:39.000
How do you do that?

49:39.000 --> 49:39.800
It's not magic.

49:39.880 --> 49:41.800
It's just, it's, it's actually pretty cool.

49:42.120 --> 49:44.840
Well, so first, before we talk about how that works, let's talk about

49:44.840 --> 49:46.040
how it works in Python, right?

49:46.040 --> 49:50.160
So in Python, you define a person class or maybe a person class is a bad

49:50.160 --> 49:52.200
idea that you define a database class, right?

49:52.240 --> 49:54.680
And database class has an array of records, something like that.

49:54.680 --> 49:54.960
Right.

49:55.440 --> 49:58.960
And so the problem is that if you pass in a record or a class instance

49:59.000 --> 50:04.000
into the database, it'll take ahold of that object and then it assumes it has it.

50:04.960 --> 50:08.080
And if you're passing an object in, you have to know that that database is

50:08.080 --> 50:11.200
going to take, take it and therefore you shouldn't change it after you put

50:11.200 --> 50:11.920
it in the database, right?

50:11.920 --> 50:14.760
This is, this is kind of have to know that you just have to kind of know that.

50:14.760 --> 50:15.040
Right.

50:15.560 --> 50:17.960
And so you roll out version one of the database.

50:18.000 --> 50:19.360
You just kind of have to know that.

50:19.720 --> 50:21.560
Of course, Lex uses his own database, right?

50:21.680 --> 50:21.960
Yeah.

50:22.040 --> 50:22.280
Right.

50:22.280 --> 50:22.840
Cause you built it.

50:22.840 --> 50:24.000
You understand how this works, right?

50:24.920 --> 50:25.840
Somebody else joins the team.

50:25.840 --> 50:26.560
They don't know this.

50:26.600 --> 50:26.880
Yes.

50:27.000 --> 50:27.200
Right.

50:27.200 --> 50:28.920
And so now they suddenly get bugs.

50:29.560 --> 50:31.040
You're having to maintain the database.

50:31.120 --> 50:34.800
You shake your fist, you argue the 10th time this happens.

50:34.800 --> 50:36.560
You're like, okay, we have to do something different.

50:36.600 --> 50:36.840
Right.

50:36.840 --> 50:39.960
And so what you do is you go change your Python code and you change your database

50:39.960 --> 50:43.080
class to copy the record every time you add it.

50:43.520 --> 50:46.480
And so what ends up happening is you say, okay, I will do what's called a

50:46.480 --> 50:49.120
defensive copy inside the database.

50:49.520 --> 50:53.680
And then that way, if somebody passes something in, I will have my own copy of

50:53.680 --> 50:56.480
it and they can go do whatever and they're not going to break my thing.

50:57.600 --> 50:57.880
Okay.

50:58.040 --> 51:00.480
This is usually the two design patterns.

51:00.480 --> 51:03.480
If you look in PyTorch, for example, this is cloning a tensor.

51:03.640 --> 51:05.960
Like there's a specific thing and you have to know where to call it.

51:05.960 --> 51:07.800
And if you don't call it in the right place, you get these bugs and

51:08.160 --> 51:09.320
this is state of the art, right?

51:10.520 --> 51:11.400
So a different approach.

51:11.480 --> 51:12.880
So it's used in many languages.

51:12.880 --> 51:17.040
So I've worked with it in Swift is you say, okay, well, let's provide value

51:17.040 --> 51:21.680
semantics and so we want to provide the view that you get a logically independent

51:21.680 --> 51:24.080
copy, but we want to do that lazily.

51:24.920 --> 51:29.120
And so what we do is you say, okay, if you pass something into a function, it

51:29.120 --> 51:30.200
doesn't actually make a copy.

51:30.440 --> 51:32.600
What it actually does is it just increments the reference to it.

51:33.160 --> 51:36.320
And if you pass it around, you stick in your database, it can go into the

51:36.320 --> 51:39.320
database, you own it, and then you come back out of the stack.

51:39.320 --> 51:40.440
Nobody's copied anything.

51:40.920 --> 51:43.720
You come back out of the stack and then the caller let's go of it.

51:44.240 --> 51:47.160
Well, then you've just handed it off to the database.

51:47.480 --> 51:49.920
You've transferred it and there's no copies made.

51:50.800 --> 51:55.480
Now, on the other hand, if, you know, your coworker goes and hands you a record

51:55.480 --> 51:58.680
and you pass it in, you stick it in the database, and then you go to town and

51:58.680 --> 52:03.440
you start modifying it, what happens is you get a copy lazily on demand.

52:04.480 --> 52:07.240
And so what this does is gives you copies only when you need them.

52:07.800 --> 52:11.120
And it also, so it defines where the bugs, but also generally reduces

52:11.120 --> 52:12.520
the number of copies in practice.

52:12.600 --> 52:14.960
And so, but the implementation details are tricky here.

52:15.320 --> 52:15.560
Yeah.

52:16.000 --> 52:18.680
So this is, yes, something with reference counting.

52:19.600 --> 52:25.840
But to make it performant across a number of different kinds of objects.

52:26.200 --> 52:26.480
Yeah.

52:26.480 --> 52:27.720
Well, so you need a couple of things.

52:27.720 --> 52:31.680
And so there's many, so this concept has existed in many different worlds.

52:31.680 --> 52:34.680
And so again, it's not novel research at all, right?

52:35.160 --> 52:39.040
The magic is getting the design right so that you can do this in a reasonable way.

52:39.200 --> 52:39.400
Right.

52:39.400 --> 52:41.080
And so there's a number of components that go into this.

52:41.080 --> 52:45.880
One is when you're passing around, so we're talking about Python and reference

52:45.880 --> 52:49.320
counting and the expense of doing that when you're passing values around, you

52:49.320 --> 52:51.800
don't want to do extra reference counting for no good reason.

52:52.160 --> 52:55.200
And so you have to make sure that you're efficient and you transfer ownership

52:55.200 --> 52:58.720
instead of duplicating references and things like that, which is a very low

52:58.720 --> 53:04.160
level problem, you also have to adopt this and you have to build these data structures.

53:04.240 --> 53:07.760
And so if you say, you know, Mojo has to be compatible with Python.

53:07.760 --> 53:12.160
So of course the default list is a reference semantic list that works

53:12.480 --> 53:13.720
the way you'd expect in Python.

53:14.120 --> 53:16.200
But then you have to design a value semantic list.

53:16.800 --> 53:19.600
And so you just have to implement that and then you implement the logic within.

53:20.000 --> 53:24.000
And so the, the role of the language here is to provide all the low level hooks

53:24.040 --> 53:28.600
that allow the author of the type to be able to get and express this behavior

53:28.600 --> 53:32.800
without forcing it into all cases or hard coding this into the language itself.

53:32.880 --> 53:34.000
But there's a ownership.

53:34.000 --> 53:37.080
So you're, you're constantly transferring, you're tracking who owns the thing.

53:37.080 --> 53:37.400
Yes.

53:37.440 --> 53:39.040
And so there's a whole system called ownership.

53:39.040 --> 53:42.760
And so this is related to work done in the Rust community.

53:43.360 --> 53:45.640
Also the Swift community has done a bunch of work and there's a bunch of

53:45.640 --> 53:49.280
different other languages that have all kind of C++ actually has copy

53:49.280 --> 53:51.480
constructors and destructors and things like that.

53:51.480 --> 53:54.400
And so, and I mean, C++ has everything.

53:54.400 --> 53:57.040
So it has moved constructors and has like this whole world of things.

53:57.040 --> 54:01.840
And so this is, this is a body of work that's kind of been developing

54:01.840 --> 54:03.000
for many, many years now.

54:03.240 --> 54:07.400
And so Mojo takes some of the best ideas out of all these systems and

54:07.400 --> 54:11.760
remixes in a nice way so that you get the power of something like the Rust

54:11.760 --> 54:15.000
programming language, but you don't have to deal with it when you don't

54:15.000 --> 54:18.280
want to, which is a major thing in terms of teaching and learning and being

54:18.280 --> 54:19.800
able to use and scale these systems.

54:20.240 --> 54:23.680
Uh, how does that play with argument conventions?

54:23.800 --> 54:24.320
What are they?

54:24.320 --> 54:25.160
Why are they important?

54:25.480 --> 54:26.600
How does the value of semantics?

54:26.600 --> 54:29.920
How does the transfer ownership, uh, work with, with the arguments

54:29.920 --> 54:30.960
when they're passed into functions?

54:31.120 --> 54:35.240
So if you go deep into systems programming land, this isn't, again,

54:35.520 --> 54:37.800
this is not something for everybody, but if you go deep into systems

54:37.880 --> 54:42.720
programming land, what you encounter is you encounter these types that get weird.

54:43.680 --> 54:45.760
So if you're used to Python, you think about everything.

54:46.000 --> 54:47.240
I can just copy it around.

54:47.240 --> 54:50.000
I can go change it and mutate it and do these things.

54:50.000 --> 54:50.760
And it's all cool.

54:51.320 --> 54:55.160
Um, if you get into systems programming land, you get into these things like

54:55.200 --> 55:01.080
I have an atomic number or I have a mutex or I have a, um, uniquely owned

55:01.080 --> 55:03.120
database handle, things like this.

55:03.120 --> 55:03.400
Right.

55:03.760 --> 55:05.680
So these types, you can't necessarily copy.

55:05.760 --> 55:08.680
Sometimes you can't necessarily even move them to a different address.

55:09.400 --> 55:13.440
And so what Mojo allows you to do is it allows you to express, Hey, I don't

55:13.440 --> 55:15.160
want to get a copy of this thing.

55:15.800 --> 55:17.360
I want to actually just get a reference to it.

55:18.080 --> 55:20.960
And by doing that, what you can say is you can say, okay, if I'm defining

55:20.960 --> 55:25.120
something weird, like a, you know, atomic number or something, it's like, it has

55:25.120 --> 55:30.440
to be so an atomic number is a, uh, an area in memory that multiple threads can

55:30.440 --> 55:34.080
access at a time without synchronous, without, without locks, right.

55:34.160 --> 55:38.600
And so, uh, and so like the definition of atomic numbers, multiple different

55:38.600 --> 55:39.680
things have to be poking at that.

55:39.680 --> 55:41.120
Therefore they have to agree on where it is.

55:42.200 --> 55:42.360
Right.

55:42.360 --> 55:44.760
And so you can't just like move it out from underneath one because it

55:44.760 --> 55:46.200
kind of breaks what, what it means.

55:46.640 --> 55:49.240
And so that's, that's an example of a type that you can't even, you

55:49.240 --> 55:50.400
can't copy, you can't move it.

55:50.400 --> 55:52.840
Like once you create it, it has to be where it was.

55:52.920 --> 55:53.200
Right.

55:53.800 --> 55:57.520
Now, if you look at, um, many other examples, like a database handle, right.

55:57.520 --> 56:01.640
So, okay, well, what happens, how do you copy a database handle?

56:01.640 --> 56:02.960
Do you copy the whole database?

56:03.000 --> 56:04.760
That's not something you necessarily want to do.

56:05.320 --> 56:09.360
Um, the, there's a lot of types like that where you want to be able to

56:09.360 --> 56:10.960
say that they are uniquely owned.

56:11.640 --> 56:18.840
So there's always one of this thing and, or if, if I create a thing, I don't copy it.

56:19.400 --> 56:22.840
And so what Mojo allows you to do is it allows you to say, Hey, I want to pass

56:22.840 --> 56:24.480
around a reference to the same without copying it.

56:24.680 --> 56:27.080
And so it has borrowed conventions.

56:27.080 --> 56:30.800
So you can say, you can use it, but you don't get to change it.

56:31.280 --> 56:33.080
You can pass it by mutable reference.

56:33.280 --> 56:37.000
And so if you do that, then you can, you get a reference to it, but you can change

56:37.000 --> 56:39.400
it and so it manages all that kind of stuff.

56:39.640 --> 56:43.760
So it's, uh, it's just a really nice implementation of like a C plus plus

56:43.760 --> 56:48.960
has, uh, you know, different kinds of pointers, smart, smart, different,

56:48.960 --> 56:51.440
different kinds of applications of smart pointers that you can, uh,

56:51.760 --> 56:53.360
explicitly define this allows you.

56:53.560 --> 56:57.520
But you're saying that's more like, um, the weird case versus the common case.

56:57.720 --> 57:00.640
Well, it depends on where I mean, I mean, I don't, I

57:00.720 --> 57:01.760
don't think I'm a normal person.

57:01.760 --> 57:07.920
So, I mean, I'm not one to call other people weird, but the, uh, uh, but you

57:07.920 --> 57:10.840
know, if you talk to a normal Python, a typical Python programmer, you're

57:10.840 --> 57:12.320
typically not thinking about this, right?

57:12.320 --> 57:13.920
This is a lower level of abstraction.

57:13.960 --> 57:16.520
Now, if you talk to a C plus plus programmer, certainly if you talk to a

57:16.520 --> 57:18.800
rust programmer, again, they're not weird.

57:18.800 --> 57:19.440
They're delightful.

57:19.480 --> 57:21.080
Like the, these are all good people, right?

57:21.480 --> 57:24.760
Um, those, those folks will think about all the time, right?

57:24.760 --> 57:28.680
And so I look at this as there's a spectrum between very deep, low level

57:28.680 --> 57:31.480
systems, I'm going to go poke the bits and care about how they're laid out in

57:31.480 --> 57:35.600
memory all the way up to application and scripting and other things like this.

57:35.600 --> 57:37.760
And so it's not that anybody's right or wrong.

57:37.760 --> 57:40.480
It's about how do we build one system that scales.

57:41.240 --> 57:46.200
By the way, the, the idea of an atomic number has been something that always

57:46.360 --> 57:54.320
brought me deep happiness because the flip side of that, the, the idea that

57:54.680 --> 58:00.920
threads can just modify stuff, um, asynchronously, just the whole idea of

58:00.920 --> 58:03.640
concurrent programming is a source of infinite stress for me.

58:04.160 --> 58:09.280
Well, so this is where you jump into, um, you know, again, you zoom out and get

58:09.280 --> 58:12.400
out of programming languages or compilers and you just look what the industry has done.

58:13.400 --> 58:15.400
My mind is constantly blown by this, right?

58:15.400 --> 58:20.160
And you look at what, you know, Moore's law, Moore's law has this idea that

58:20.200 --> 58:24.240
like computers for a long time, single thread performance is always the same.

58:24.320 --> 58:26.520
It just got faster and faster and faster and faster for free.

58:27.200 --> 58:31.680
But then physics and other things intervened and power consumption,

58:31.680 --> 58:32.840
like other things started to matter.

58:32.840 --> 58:36.520
And so what ended up happening is we went from single core computers to

58:36.520 --> 58:39.040
multi-core, then we went to accelerators, right?

58:39.040 --> 58:43.000
And this, this trend towards specialization of hardware is only going to continue.

58:43.440 --> 58:49.240
And so for years, us programming language nerds and compiler people have been saying,

58:49.240 --> 58:51.760
okay, well, how do we tackle multi-core, right?

58:51.760 --> 58:53.560
For a while, it was like multi-core is the future.

58:53.560 --> 58:54.720
We have to get on top of this thing.

58:55.320 --> 58:56.760
And then it was multi-core is the default.

58:56.800 --> 58:57.760
What are we doing with this thing?

58:57.760 --> 59:00.880
And then it's like, there's chips with hundreds of cores in them.

59:01.600 --> 59:02.320
What happened?

59:02.360 --> 59:02.880
Right.

59:03.280 --> 59:08.440
And so I'm super inspired by the fact that, you know, in the face of this, you

59:08.440 --> 59:13.000
know, those machine learning people invented this idea of a tensor, right?

59:13.000 --> 59:13.760
And what is the tensor?

59:13.760 --> 59:18.240
A tensor is an, like an arithmetic and algebraic concept.

59:18.240 --> 59:22.960
It's like an abstraction around a gigantic parallelizable data set.

59:23.120 --> 59:23.440
Right.

59:23.920 --> 59:27.200
And because of that, and because of things like TensorFlow and PyTorch, we're able to

59:27.200 --> 59:30.920
say, okay, we'll express the math of the system.

59:31.560 --> 59:34.080
This enables you to do automatic differentiations, enables you to do

59:34.080 --> 59:35.240
like all these cool things.

59:35.760 --> 59:40.520
Um, and, and it's, it's an abstract representation because you have that

59:40.520 --> 59:44.240
abstract representation, you can now map it onto these parallel machines without

59:44.240 --> 59:48.200
having to, um, control, okay, put that right here, put that right there, put that

59:48.200 --> 59:52.240
right there, and this has enabled an explosion in terms of AI compute.

59:52.800 --> 59:54.240
Accelerators, like all the stuff.

59:54.280 --> 59:56.080
And so that's super, super excited.

59:56.320 --> 01:00:00.520
What about the, the deployment and the execution across multiple machines?

01:00:00.760 --> 01:00:06.280
So, uh, you write that the modular compute platform dynamically partitions

01:00:06.280 --> 01:00:10.120
models with billions of parameters and distributes their execution across

01:00:10.120 --> 01:00:16.240
multiple machines, uh, enabling unparalleled efficiency, by the way, the

01:00:16.240 --> 01:00:20.280
use of unparalleled in that sentence anyway, enabling unparalleled efficiency

01:00:20.280 --> 01:00:22.640
scale and the reliability for the largest workloads.

01:00:22.840 --> 01:00:29.000
So how, how do you do this, um, abstraction of, uh, distributed

01:00:29.000 --> 01:00:31.200
deployment of, of, of large.

01:00:31.360 --> 01:00:31.680
Yeah.

01:00:31.680 --> 01:00:34.960
So what, one of the really interesting, um, tensions, so there's a whole

01:00:34.960 --> 01:00:36.080
bunch of stuff that goes into that.

01:00:36.160 --> 01:00:38.080
I'll pick a random walkthrough.

01:00:38.560 --> 01:00:42.640
Uh, if you, if you go back and replay the history of machine learning, right?

01:00:42.640 --> 01:00:44.760
I mean, the brief, the brief, the most recent history of machine

01:00:44.760 --> 01:00:46.600
learning, cause this is, as you know, very deep.

01:00:47.240 --> 01:00:52.520
I, uh, I knew Lex when he had an AI podcast, right?

01:00:52.560 --> 01:00:52.840
Yep.

01:00:54.120 --> 01:00:58.080
Um, so, uh, so if you look at just TensorFlow and PyTorch, which is pretty

01:00:58.080 --> 01:00:59.600
recent history in the big picture, right?

01:00:59.600 --> 01:01:02.480
But TensorFlow is all about graphs.

01:01:03.080 --> 01:01:06.520
PyTorch, I think pretty unarguably ended up winning.

01:01:06.640 --> 01:01:07.560
And why did it win?

01:01:07.560 --> 01:01:09.760
Mostly because of usability, right?

01:01:09.760 --> 01:01:11.960
And the usability of PyTorch is, I think, huge.

01:01:11.960 --> 01:01:16.000
And I think, again, that's a huge testament to the power of taking

01:01:16.240 --> 01:01:19.880
abstract theoretical, technical concepts and bring it to the masses, right?

01:01:20.600 --> 01:01:26.320
Now the challenge with what the TensorFlow versus the PyTorch design

01:01:26.360 --> 01:01:30.320
points was that TensorFlow is kind of difficult to use for researchers, but

01:01:30.320 --> 01:01:31.640
it was actually pretty good for deployment.

01:01:32.320 --> 01:01:33.880
PyTorch is really good for researchers.

01:01:33.880 --> 01:01:36.320
It kind of not super great for deployment, right?

01:01:36.320 --> 01:01:39.960
And so I think that we as an industry have been struggling.

01:01:40.200 --> 01:01:43.760
And if you look at what deploying a machine learning model today means is

01:01:43.760 --> 01:01:47.680
that you'll have researchers who are, I mean, wicked smart, of course, but

01:01:47.680 --> 01:01:52.640
they're wicked smart at model architecture and data and calculus.

01:01:53.480 --> 01:01:55.320
Like they're wicked smart in various domains.

01:01:55.680 --> 01:01:58.560
They don't want to know anything about the hardware or deployment or C++ or

01:01:58.560 --> 01:01:59.440
things like this, right?

01:01:59.440 --> 01:02:02.560
And so what's happened is you get people who train the model, they throw

01:02:02.560 --> 01:02:06.320
over, throw it over the fence and then you have people that try to deploy the model.

01:02:08.840 --> 01:02:13.040
Well, every time you have a team A does X, they throw it over the fence and team

01:02:13.040 --> 01:02:18.800
Y does something, team B does Y, like you have a problem because of course it

01:02:18.800 --> 01:02:19.760
never works the first time.

01:02:20.040 --> 01:02:23.480
And so you throw it over the fence, they figure out, okay, it's too slow.

01:02:23.480 --> 01:02:29.240
It won't fit, doesn't use the right operator, the tool crashes, whatever

01:02:29.240 --> 01:02:31.760
the problem is, then they have to throw it back over the fence.

01:02:32.480 --> 01:02:35.880
And every time you throw a thing over a fence, it takes three weeks of project

01:02:35.880 --> 01:02:37.840
managers and meetings and things like this.

01:02:37.840 --> 01:02:41.840
And so what we've seen today is that getting models in production can take

01:02:42.400 --> 01:02:43.400
weeks or months.

01:02:43.640 --> 01:02:44.760
Like it's not atypical, right?

01:02:44.760 --> 01:02:48.880
I talked to lots of people and you talk about like VP of software, some internet

01:02:48.880 --> 01:02:52.200
company trying to deploy a model and they're like, why do I need a team of 45

01:02:52.200 --> 01:02:52.600
people?

01:02:53.480 --> 01:02:55.440
Like, it's so easy to train a model.

01:02:55.440 --> 01:02:57.040
Why, why can't I deploy it?

01:02:57.200 --> 01:02:57.480
Right.

01:02:58.000 --> 01:03:01.520
And if you dig into this, every layer is problematic.

01:03:01.640 --> 01:03:05.040
So if you look at the language piece, I mean, this is tip of the iceberg.

01:03:05.400 --> 01:03:09.360
It's a very exciting tip of the iceberg for folks, but you've got Python on one

01:03:09.360 --> 01:03:10.880
side and C++ on the other side.

01:03:11.240 --> 01:03:12.560
Python doesn't really deploy.

01:03:13.040 --> 01:03:17.000
I mean, can theoretically, technically in some cases, but often a lot of production

01:03:17.000 --> 01:03:19.760
teams will want to get things out of Python because they get better performance

01:03:19.760 --> 01:03:21.200
and control and whatever else.

01:03:21.560 --> 01:03:22.640
So Mojo can help with that.

01:03:23.800 --> 01:03:27.200
If you look at serving, so you talk about gigantic models.

01:03:27.280 --> 01:03:29.680
Well, a gigantic model won't fit on one machine.

01:03:30.960 --> 01:03:34.200
And so now you have this model, it's written in Python.

01:03:34.200 --> 01:03:35.760
It has to be rewritten in C++.

01:03:36.120 --> 01:03:39.400
Now it also has to be carved up so that half of it runs on one machine, half of

01:03:39.400 --> 01:03:40.280
it runs on another machine.

01:03:40.880 --> 01:03:42.720
Or maybe it runs on 10 machines.

01:03:43.440 --> 01:03:46.840
Also now suddenly the complexity is exploding, right?

01:03:47.200 --> 01:03:51.320
And the reason for this is that if you, if you look into TensorFlow PyTorch, these

01:03:51.320 --> 01:03:54.800
systems, they weren't really designed for this world, right?

01:03:54.800 --> 01:03:58.720
They were designed for, you know, back in the day when we were starting and doing

01:03:58.720 --> 01:04:02.600
things where it was a different, much simpler world, like you want to run

01:04:02.600 --> 01:04:06.760
ResNet-50 or some ancient model architecture like this, it was just a, it

01:04:06.760 --> 01:04:08.000
was a completely different world.

01:04:08.160 --> 01:04:09.480
Trained on one GPU.

01:04:09.480 --> 01:04:10.040
Exactly.

01:04:10.040 --> 01:04:11.280
Doing fast on one GPU.

01:04:11.440 --> 01:04:12.840
Yeah, AlexNet, right?

01:04:12.920 --> 01:04:13.760
The major breakthrough.

01:04:14.160 --> 01:04:17.600
And, um, and the world has changed, right?

01:04:17.600 --> 01:04:20.880
And so now the challenge is, is that TensorFlow PyTorch, these systems, they

01:04:20.880 --> 01:04:22.760
weren't actually designed for LLMs.

01:04:22.760 --> 01:04:24.560
Like that was not, that was not a thing.

01:04:24.920 --> 01:04:28.480
And so what, where TensorFlow actually has amazing power in terms of scale and

01:04:28.480 --> 01:04:29.840
deployment and things like that.

01:04:29.840 --> 01:04:33.840
And I think Google is, I mean, maybe not unmatched, but they're like incredible

01:04:33.840 --> 01:04:39.440
in terms of their capabilities and gigantic scale, um, many researchers using

01:04:39.440 --> 01:04:40.520
PyTorch, right?

01:04:40.520 --> 01:04:42.600
And so PyTorch doesn't have those same capabilities.

01:04:42.600 --> 01:04:44.280
And so what Modular can do is it can help with that.

01:04:44.800 --> 01:04:48.040
Now, if you take a step back and say, like, what is Modular doing, right?

01:04:48.040 --> 01:04:53.600
So Modular has like a, a bitter enemy that we're fighting against in the industry.

01:04:54.120 --> 01:04:58.400
And it's one of these things where everybody knows it, but nobody is

01:04:58.840 --> 01:05:00.240
usually willing to talk about it.

01:05:00.880 --> 01:05:02.240
The bitter enemy.

01:05:02.240 --> 01:05:05.880
The bitter thing that we have to destroy that we're all struggling with.

01:05:05.880 --> 01:05:07.720
And it's like all around, it's like fish can't see water.

01:05:08.240 --> 01:05:09.000
It's complexity.

01:05:09.640 --> 01:05:09.960
Sure.

01:05:10.000 --> 01:05:10.480
Yes.

01:05:11.000 --> 01:05:11.640
Complexity.

01:05:12.280 --> 01:05:13.600
That was very philosophical of you.

01:05:14.960 --> 01:05:18.160
And so if you look at it, yes, it is on the hardware side.

01:05:18.200 --> 01:05:18.520
Yes.

01:05:18.640 --> 01:05:21.680
All these, all these accelerators, all these software stacks that go with the

01:05:21.680 --> 01:05:24.680
accelerator, all these, like there's massive complexity over there.

01:05:24.680 --> 01:05:29.600
You look at what's happening on the modeling side, massive amount of complexity.

01:05:29.640 --> 01:05:30.720
Like things are changing all the time.

01:05:30.720 --> 01:05:33.360
People are inventing, turns out the research is not done.

01:05:34.280 --> 01:05:34.520
Right.

01:05:34.520 --> 01:05:35.880
And so people want to be able to move fast.

01:05:35.880 --> 01:05:40.280
Transformers are amazing, but there's a diversity even within transformers.

01:05:40.280 --> 01:05:41.640
And what's the next transformer.

01:05:42.000 --> 01:05:42.280
Right.

01:05:42.720 --> 01:05:46.600
And you look into serving also huge amounts of complexity.

01:05:46.600 --> 01:05:51.240
It turns out that all the cloud providers have all their very weird, but very

01:05:51.240 --> 01:05:53.560
cool hardware for networking and all this kind of stuff.

01:05:53.560 --> 01:05:55.160
And it's all very complicated.

01:05:55.160 --> 01:05:56.000
People aren't using that.

01:05:56.280 --> 01:05:59.160
You look at classical serving, right?

01:05:59.240 --> 01:06:01.520
There, there's this whole world of people who know how to write high

01:06:01.520 --> 01:06:04.720
performance servers with zero copy networking and like all, all this

01:06:04.960 --> 01:06:10.000
fancy asynchronous IO and like all these fancy things in the, in the serving

01:06:10.000 --> 01:06:13.680
community, very little that has pervaded into the machine learning world.

01:06:14.560 --> 01:06:14.800
Right.

01:06:14.800 --> 01:06:15.560
And why is that?

01:06:15.560 --> 01:06:18.680
Well, it's because again, these systems have been built up over many years.

01:06:19.000 --> 01:06:21.280
They, they haven't been rethought.

01:06:21.640 --> 01:06:23.480
There hasn't been a first principles approach to this.

01:06:23.880 --> 01:06:28.160
And so what Modular is doing is we're saying, okay, we've built many of these

01:06:28.160 --> 01:06:31.400
things, like, so I've worked on TensorFlow and TPUs and things like that.

01:06:31.400 --> 01:06:34.600
Other folks on our team have like worked on PyTorch core.

01:06:34.920 --> 01:06:36.400
We've worked on Onyx one time.

01:06:36.400 --> 01:06:38.160
We've worked on many of these other systems.

01:06:38.160 --> 01:06:42.640
And so built systems like the Apple accelerators and all that kind of stuff.

01:06:42.640 --> 01:06:44.840
Like our team is quite amazing.

01:06:44.840 --> 01:06:49.000
And so one of the things that roughly everybody at Modular is grumpy about is

01:06:49.000 --> 01:06:53.400
that when you're working on one of these projects, you have a first order goal.

01:06:54.240 --> 01:06:58.120
Get the hardware to work, get the system to enable one more model, get this

01:06:58.200 --> 01:07:02.800
product out the door, enable the specific workload or make it solve this problem

01:07:02.800 --> 01:07:04.520
for this, this product team, right.

01:07:04.920 --> 01:07:07.640
And nobody's been given a chance to actually do that step back.

01:07:08.000 --> 01:07:10.040
And so we, as an industry, we didn't take two steps forward.

01:07:10.320 --> 01:07:14.360
We took like 18 steps forward in terms of all this really cool technology across

01:07:14.360 --> 01:07:17.880
compilers and systems and runtimes and heterogeneous computing, like all this

01:07:17.880 --> 01:07:21.760
kind of stuff and like all this technology has been, you know, I wouldn't say,

01:07:22.280 --> 01:07:25.520
beautifully designed, but it's been proven in different quadrants.

01:07:25.840 --> 01:07:31.240
Like, you know, you look at Google with TPUs, massive, huge exaflops of compute

01:07:31.640 --> 01:07:34.880
strapped together and into machines that researchers are programming

01:07:34.880 --> 01:07:36.360
in Python in a notebook.

01:07:37.000 --> 01:07:37.760
That's huge.

01:07:37.760 --> 01:07:38.640
That's amazing.

01:07:38.720 --> 01:07:39.320
That's incredible.

01:07:39.320 --> 01:07:39.520
Right.

01:07:39.520 --> 01:07:40.320
It's incredible.

01:07:40.320 --> 01:07:43.920
And so you look at the technology that goes into that and the, the

01:07:43.920 --> 01:07:45.360
algorithms are actually quite general.

01:07:46.080 --> 01:07:49.840
And so lots of other hardware out there and lots of other teams out there

01:07:49.840 --> 01:07:54.160
don't have the sophistication or maybe the, the years working on it or the,

01:07:54.200 --> 01:07:55.960
the budget or whatever that Google does.

01:07:56.000 --> 01:07:56.280
Right.

01:07:56.280 --> 01:07:59.120
And so they should be getting access to the same algorithms, but

01:07:59.120 --> 01:08:00.040
they just don't have that.

01:08:00.120 --> 01:08:00.280
Right.

01:08:00.280 --> 01:08:04.760
And so what Modular is doing is we're saying, cool, this is not research anymore.

01:08:04.800 --> 01:08:07.640
Like we've, we've built auto tuning in many systems.

01:08:08.040 --> 01:08:09.320
We've built programming languages.

01:08:09.320 --> 01:08:09.640
Right.

01:08:09.760 --> 01:08:13.120
And so like have, have, you know, implemented C++, have implemented

01:08:13.120 --> 01:08:14.640
Swift, have implemented many of these things.

01:08:15.000 --> 01:08:21.600
And so, you know, this it's hard, but it's not research and you look at accelerators.

01:08:21.600 --> 01:08:24.840
Well, we know there's a bunch of different weird kinds of accelerators,

01:08:24.840 --> 01:08:26.520
but they actually cluster together.

01:08:27.120 --> 01:08:27.320
Right.

01:08:27.320 --> 01:08:30.720
And you look at GPUs, well, there's a couple of major vendors of GPUs and they

01:08:30.720 --> 01:08:34.000
maybe don't always get along, but their architectures are very similar.

01:08:34.520 --> 01:08:38.240
You look at CPUs, CPUs are still super important for the deployment side of

01:08:38.240 --> 01:08:41.920
things and you see new, new architectures coming out from all the cloud providers

01:08:41.920 --> 01:08:45.360
and things like this, and they're all super important to the world, right.

01:08:45.360 --> 01:08:49.280
But they don't have the 30 years of development that the entrenched people do.

01:08:49.360 --> 01:08:49.680
Right.

01:08:49.720 --> 01:08:53.640
And so what Modular can do is we're saying, okay, all this complexity,

01:08:54.000 --> 01:08:56.160
like it's not, it's not bad complexity.

01:08:56.160 --> 01:08:58.080
It's actually innovation.

01:08:59.040 --> 01:08:59.320
Right.

01:08:59.320 --> 01:09:03.840
And so it's innovation that's happening and it's for good reasons, but I have

01:09:03.840 --> 01:09:05.360
sympathy for the poor software people.

01:09:05.800 --> 01:09:06.080
Right.

01:09:06.080 --> 01:09:08.400
I mean, again, I'm a generally software person too.

01:09:08.400 --> 01:09:12.520
I love hardware, but software people want to build applications and products

01:09:12.520 --> 01:09:15.200
and solutions that scale over many years.

01:09:15.920 --> 01:09:18.640
They don't want to build a solution for one generation of hardware

01:09:18.640 --> 01:09:20.680
with one vendor's tools, right.

01:09:20.680 --> 01:09:23.720
And because of this, they need something that scales with them.

01:09:23.720 --> 01:09:27.920
They need something that works on cloud and mobile, right.

01:09:27.920 --> 01:09:30.520
Because, you know, their product manager said, Hey, I want it to be,

01:09:30.760 --> 01:09:34.840
have lower latency and it's better for personalization or whatever they decide.

01:09:34.840 --> 01:09:35.120
Right.

01:09:35.440 --> 01:09:36.400
Products evolve.

01:09:36.480 --> 01:09:40.400
And so the challenge with the machine learning technology and the infrastructure

01:09:40.400 --> 01:09:43.960
that we have today in the industry is that it's all these point solutions.

01:09:44.720 --> 01:09:47.320
And because there are all these point solutions, it means that as your product

01:09:47.320 --> 01:09:50.560
evolves, you have to like switch from technology stacks or switch to different

01:09:50.560 --> 01:09:50.960
vendor.

01:09:51.320 --> 01:09:53.440
And what that does is that slows down progress.

01:09:54.120 --> 01:10:00.600
So basically a lot of the things we've developed in those little silos for

01:10:00.600 --> 01:10:04.360
machine learning tasks, you want to make that the first class citizen of a

01:10:04.360 --> 01:10:07.680
general purpose programming language that can then be compiled across all

01:10:07.680 --> 01:10:08.600
these kinds of hardware.

01:10:08.680 --> 01:10:10.520
Well, so it's not really about a programming language.

01:10:10.640 --> 01:10:13.800
I mean, the programming language is a component of the mission, right.

01:10:13.800 --> 01:10:17.760
And the mission is are not literal, but our joking mission is to save the world

01:10:17.760 --> 01:10:18.960
from terrible AI software.

01:10:19.640 --> 01:10:20.120
Excellent.

01:10:21.760 --> 01:10:26.040
So, so, you know, if you look at this mission, you need a syntax.

01:10:26.960 --> 01:10:29.320
So that's the, so yeah, she knew programming language, right.

01:10:29.320 --> 01:10:33.040
And, and like, we wouldn't have to build the programming language if one existed.

01:10:33.720 --> 01:10:33.800
Right.

01:10:33.800 --> 01:10:35.200
So if Python was already good enough, then cool.

01:10:35.200 --> 01:10:36.320
We would just used it, right.

01:10:36.320 --> 01:10:40.200
We're not just doing very large scale, expensive engineering projects for the

01:10:40.200 --> 01:10:42.880
sake of it, like it's to solve a problem, right.

01:10:43.320 --> 01:10:46.800
It's also about accelerators.

01:10:47.120 --> 01:10:51.280
It's also about exotic numerics and BFLOTE 16 and matrix multiplications

01:10:51.280 --> 01:10:54.920
and convolutions and like this, this kind of stuff within the stack.

01:10:54.920 --> 01:10:56.920
There are things like kernel fusion.

01:10:57.680 --> 01:11:00.920
That's a esoteric, but really important thing that leads to much better

01:11:00.920 --> 01:11:05.920
performance and much more general research hackability together.

01:11:06.760 --> 01:11:10.480
And that that's enabled by the ASICs that's enabled by certain hardware.

01:11:10.640 --> 01:11:15.760
So it's like, where's the dance between, I mean, there's several questions here.

01:11:15.760 --> 01:11:17.920
Like, how do you add a piece of hardware to this stack?

01:11:18.440 --> 01:11:18.640
Yeah.

01:11:18.640 --> 01:11:23.680
If a new piece of, like, if I have this genius invention of a specialized

01:11:23.680 --> 01:11:28.120
accelerator, how do I add that to the modular framework and also how does

01:11:28.320 --> 01:11:34.920
modular as a standard start to define the kinds of hardware that should be developed?

01:11:35.080 --> 01:11:35.280
Yeah.

01:11:35.280 --> 01:11:37.640
So let me take a step back and talk about status quo.

01:11:38.280 --> 01:11:38.480
Okay.

01:11:39.160 --> 01:11:44.480
And so if you go back to TensorFlow one, PyTorch one, this kind of timeframe,

01:11:45.680 --> 01:11:47.840
and these have all evolved and gotten way more complicated.

01:11:47.840 --> 01:11:50.640
So let's go back to the glorious simple days, right?

01:11:50.640 --> 01:11:53.120
These things basically were CPUs and CUDA.

01:11:54.000 --> 01:11:58.560
And so what you do is you say, go do a dense layer and a dense layer

01:11:58.560 --> 01:12:00.360
has a matrix multiplication, right?

01:12:00.360 --> 01:12:03.760
And so when you say that, you say, go do this big operation of matrix

01:12:03.760 --> 01:12:04.440
multiplication.

01:12:04.880 --> 01:12:07.920
And if it's on a GPU, kick off a CUDA kernel.

01:12:08.200 --> 01:12:12.640
If it's on a CPU, go do like an Intel algorithm or something like that with

01:12:12.640 --> 01:12:13.880
the Intel MKL, okay?

01:12:14.600 --> 01:12:19.200
Now that's really cool if you're either Nvidia or Intel, right?

01:12:19.200 --> 01:12:22.520
But then more hardware comes in, right?

01:12:22.520 --> 01:12:25.400
And, and on one axis, you have more hardware coming in.

01:12:25.400 --> 01:12:28.720
On the other hand, you have an explosion of innovation in AI.

01:12:29.320 --> 01:12:32.640
And so what happened with both TensorFlow and PyTorch is that the explosion of

01:12:32.640 --> 01:12:36.680
innovation in AI has led to, it's not just about matrix multiplication and

01:12:36.680 --> 01:12:37.360
convolution.

01:12:37.360 --> 01:12:39.960
These things have now like 2000 different operators.

01:12:40.840 --> 01:12:43.440
And on the other hand, you have, I don't know how many pieces of hardware there

01:12:43.440 --> 01:12:43.960
are out there.

01:12:43.960 --> 01:12:45.600
It's a lot, okay?

01:12:45.600 --> 01:12:47.240
It's, it's not, it's not even hundreds.

01:12:47.240 --> 01:12:48.320
It's probably thousands, okay?

01:12:48.800 --> 01:12:52.640
And across all of edge and across like all, all of the different things that

01:12:52.640 --> 01:12:53.760
are used at scale.

01:12:53.960 --> 01:12:54.880
Yeah, exactly.

01:12:54.880 --> 01:12:59.720
I mean, also it's not just like, it's not a handful of TPU alternatives.

01:12:59.720 --> 01:13:00.080
Correct.

01:13:00.920 --> 01:13:05.720
It's every, every phone often with many different chips inside of it from

01:13:05.720 --> 01:13:06.920
different vendors, right?

01:13:07.280 --> 01:13:10.080
Like it's AI is everywhere.

01:13:10.120 --> 01:13:11.040
It's a thing, right?

01:13:11.080 --> 01:13:12.640
Why are they all making their own chips?

01:13:12.680 --> 01:13:14.400
Like why, why is everybody making their own thing?

01:13:15.120 --> 01:13:16.040
Uh, well, so because-

01:13:16.040 --> 01:13:16.840
Is that a good thing?

01:13:17.800 --> 01:13:20.240
So Chris's philosophy on hardware, right?

01:13:20.240 --> 01:13:25.040
So my philosophy is that there isn't one right solution, right?

01:13:25.040 --> 01:13:27.480
And so I think that again, we're at the end of Moore's law,

01:13:27.680 --> 01:13:29.000
specialization happens.

01:13:29.480 --> 01:13:35.320
If you, if you're building, if you're training GPT-5, he wants some crazy

01:13:35.320 --> 01:13:37.360
supercomputer data center thingy.

01:13:37.960 --> 01:13:42.400
If you're making a smart camera that runs on batteries, you want something

01:13:42.400 --> 01:13:43.160
that looks very different.

01:13:43.760 --> 01:13:45.800
If you're building a phone, you want something that looks very different.

01:13:45.800 --> 01:13:49.240
If you have something like a laptop, you want something that looks maybe

01:13:49.240 --> 01:13:51.080
similar, but a different scale, right?

01:13:51.080 --> 01:13:55.280
And so AI ends up touching all of our lives, robotics, right?

01:13:55.280 --> 01:13:56.920
And like lots of different things.

01:13:57.280 --> 01:14:00.880
And so as you look into this, these have different power envelopes.

01:14:00.960 --> 01:14:03.440
There's different trade-offs in terms of the algorithms, there's new

01:14:03.440 --> 01:14:06.480
innovations and sparsity and other data formats and things like that.

01:14:06.840 --> 01:14:10.720
And so, uh, hardware innovation, I think is a really good thing, right?

01:14:10.720 --> 01:14:12.880
And what I'm interested in is unlocking that innovation.

01:14:12.880 --> 01:14:16.920
There's also like analog and quantum and like all the, the, the

01:14:16.920 --> 01:14:17.960
really weird stuff, right?

01:14:18.360 --> 01:14:21.840
And so if somebody can come up with a chip that uses analog computing and

01:14:21.840 --> 01:14:23.400
it's a hundred X more power efficient.

01:14:23.880 --> 01:14:27.920
Think what that would mean in terms of the daily impact on the products we use.

01:14:27.960 --> 01:14:28.800
That'd be huge.

01:14:29.400 --> 01:14:33.720
Now, if you're building an analog computer, you may not be a compiler specialist,

01:14:34.560 --> 01:14:34.760
right?

01:14:34.960 --> 01:14:36.360
These are different skill sets, right?

01:14:36.400 --> 01:14:40.280
And so you can hire some compiler people if you're running a big company, maybe,

01:14:40.640 --> 01:14:45.400
but it turns out these are really, uh, like exotic new generation of

01:14:45.400 --> 01:14:47.920
compilers, like this, this is a different thing, right?

01:14:47.920 --> 01:14:50.960
And so if you, if you take a step back out and come back to what is the status

01:14:50.960 --> 01:14:55.720
quo, status quo is that if you're Intel or you're Nvidia, you continue, you're

01:14:55.720 --> 01:14:59.360
keep up with the industry and you chase and okay, there's 1900.

01:14:59.360 --> 01:15:00.280
Now there's 2000.

01:15:00.280 --> 01:15:03.520
Now there's 2,100 and you have a huge team of people that are like trying to

01:15:03.520 --> 01:15:04.800
keep up and tune and optimize.

01:15:04.800 --> 01:15:08.800
And even when, uh, one of the big guys comes out with a new generation of their

01:15:08.800 --> 01:15:12.160
chip, they have to go back and rewrite all these things, right?

01:15:12.160 --> 01:15:14.560
So really it's only powered by having hundreds of people.

01:15:14.560 --> 01:15:17.200
They're all like frantically trying to keep up.

01:15:17.240 --> 01:15:19.040
And what that does is that keeps out the little guys.

01:15:19.880 --> 01:15:23.200
And sometimes they're not so little guys, the big guys that are also just not,

01:15:23.240 --> 01:15:24.640
not in those dominant positions.

01:15:24.640 --> 01:15:29.560
And so, um, and so what has been happening, and so a lot of, you talk about

01:15:29.560 --> 01:15:33.280
the rise of new exotic, crazy accelerators is people have been trying to turn this

01:15:33.280 --> 01:15:37.600
from a, let's go write lots of special kernels problem into a compiler problem.

01:15:38.600 --> 01:15:40.960
And so we, and I contributed to this as well.

01:15:41.800 --> 01:15:44.400
We, we, as an industry went into it, like, let's go make this compiler

01:15:44.400 --> 01:15:46.920
problem phase let's call it.

01:15:47.560 --> 01:15:49.680
Much of the industry is still in this phase by the way.

01:15:49.680 --> 01:15:51.480
So it's an, I wouldn't say this phase is over.

01:15:51.880 --> 01:15:56.280
And so the idea is to say, look, okay, what a compiler does is it provides a

01:15:56.280 --> 01:16:02.320
much more general extensible, uh, hackable interface for dealing

01:16:02.320 --> 01:16:04.440
with the general case, right?

01:16:04.440 --> 01:16:09.320
And so, um, within machine learning algorithms, for example, people figured

01:16:09.320 --> 01:16:13.240
out that, Hey, if I do a matrix multiplication and I do a ReLU, right.

01:16:13.760 --> 01:16:19.640
The classic activation function, it is way faster to do one pass over the

01:16:19.640 --> 01:16:23.920
data and then do the ReLU on the output where I'm writing out the data.

01:16:24.040 --> 01:16:26.240
Cause ReLU is just a maximum operation, right?

01:16:26.240 --> 01:16:26.840
Max with zero.

01:16:27.360 --> 01:16:30.280
And so it's an amazing optimization.

01:16:30.280 --> 01:16:33.520
Take Matmul, ReLU squished together in one operation.

01:16:33.520 --> 01:16:34.520
Now we have Matmul, ReLU.

01:16:35.400 --> 01:16:39.200
Well, wait a second, if I do that, now I just went from having, you know,

01:16:39.200 --> 01:16:42.480
two operators to three, but now I figure out, okay, well, there's a lot

01:16:42.480 --> 01:16:47.920
activation functions, what about, uh, uh, leaky ReLU, what about like a million

01:16:47.920 --> 01:16:48.920
things that are out there, right?

01:16:49.320 --> 01:16:53.320
And so as I start fusing these in, now I just get permutations of all these

01:16:53.320 --> 01:16:54.480
algorithms, right?

01:16:54.480 --> 01:16:56.720
And so what the compiler people said is they said, Hey, cool.

01:16:56.720 --> 01:16:59.560
Well, I will go enumerate all the algorithms and I will enumerate all the

01:16:59.560 --> 01:17:01.640
pairs and I will actually generate a kernel for you.

01:17:02.280 --> 01:17:05.200
And I think that this has been very, very useful for the industry.

01:17:05.200 --> 01:17:09.320
This is one of the things that powers Google TPUs, uh, PyTorch 2s, like

01:17:09.320 --> 01:17:12.840
rolling out really cool compiler stuff with Triton and this other technology

01:17:12.840 --> 01:17:13.480
and things like this.

01:17:13.880 --> 01:17:17.440
And so the compiler people are kind of coming into their four and saying like,

01:17:17.480 --> 01:17:19.400
awesome, this is a compiler problem, we'll compiler it.

01:17:20.760 --> 01:17:21.440
Here's the problem.

01:17:22.320 --> 01:17:23.480
Not everybody's a compiler person.

01:17:23.680 --> 01:17:25.360
I love compiler people, trust me, right?

01:17:25.400 --> 01:17:27.840
But not everybody can or should be a compiler person.

01:17:27.840 --> 01:17:32.000
It turns out that there are people that know analog computers really well, or

01:17:32.000 --> 01:17:36.760
they know some GPU internal architecture thing really well, or they know some

01:17:36.760 --> 01:17:41.960
crazy sparse numeric interesting algorithm that is the cusp of research,

01:17:42.280 --> 01:17:43.360
but they're not compiler people.

01:17:43.560 --> 01:17:47.120
And so one of the challenges with this new wave of technology, trying to turn

01:17:47.120 --> 01:17:50.960
everything into a compiler is again, is excluded a ton of people.

01:17:51.560 --> 01:17:53.400
And so you look at what does Mojo do?

01:17:53.440 --> 01:17:57.480
What does the modular stack do is brings programmability back into this world.

01:17:57.760 --> 01:18:01.960
Like it enables, I wouldn't say normal people, but like a new, you know, a

01:18:01.960 --> 01:18:05.440
different kind of delightful nerd that cares about numerics or cares about

01:18:05.440 --> 01:18:08.880
hardware, cares about things like this to be able to express that in the stack

01:18:08.880 --> 01:18:12.760
and extend the stack without having to actually go hack the compiler itself.

01:18:12.920 --> 01:18:18.400
So extend the stack on the, on the algorithm side and then on the hardware side.

01:18:18.400 --> 01:18:18.640
Yeah.

01:18:18.640 --> 01:18:21.480
So again, go back to like the simplest example of int, right?

01:18:21.840 --> 01:18:25.200
And so what both Swift and Mojo and other things like this did is we said,

01:18:25.200 --> 01:18:28.160
okay, pull magic out of the compiler and put it in the standard library.

01:18:29.040 --> 01:18:29.160
Right.

01:18:29.160 --> 01:18:31.920
And so what modular is doing with the engine that we're providing and like

01:18:31.920 --> 01:18:36.080
this, this very deep technology stack, right, which goes into heterogeneous

01:18:36.080 --> 01:18:39.600
runtimes and like a whole bunch of really cool, really cool things.

01:18:40.040 --> 01:18:45.240
Um, this, this whole stack allows that stack to be extended and hacked and

01:18:45.240 --> 01:18:49.680
changed by researchers and by hardware innovators and by people who know things

01:18:49.680 --> 01:18:53.360
that we don't know, cause you know, modular has some smart people, but we

01:18:53.360 --> 01:18:55.280
don't have all the smart people it turns out, right.

01:18:55.880 --> 01:18:57.800
Uh, what are heterogeneous runtimes?

01:18:57.880 --> 01:18:58.160
Yeah.

01:18:58.160 --> 01:19:01.560
So, uh, so what is heterogeneous, right?

01:19:01.560 --> 01:19:04.400
So heterogeneous just means many different kinds of things together.

01:19:04.720 --> 01:19:08.800
And so the simple, simplest example you might come up with is a CPU and a GPU.

01:19:09.760 --> 01:19:13.560
And so it's a simple heterogeneous computer to say, I will run my data

01:19:13.560 --> 01:19:16.360
loading and pre-processing and other algorithms on the CPU.

01:19:16.800 --> 01:19:19.720
And then once I get it into the right shape, I shove it into the GPU.

01:19:19.720 --> 01:19:23.080
I do a lot of matrix multiplications and convolutions and things like this.

01:19:23.440 --> 01:19:27.480
And I get it back out and I do some reductions and summaries and they shove

01:19:27.480 --> 01:19:31.160
it across the wire to across the network to another machine, right?

01:19:31.240 --> 01:19:36.760
And so you've got now what are effectively two computers, a CPU and a

01:19:36.760 --> 01:19:40.160
GPU talking to each other, working together in a heterogeneous system.

01:19:40.920 --> 01:19:43.560
Um, but that was 10 years ago.

01:19:44.240 --> 01:19:44.600
Okay.

01:19:45.280 --> 01:19:47.960
Look at a modern cell phone, modern cell phone.

01:19:47.960 --> 01:19:51.080
You've got CPUs and they're not just CPUs.

01:19:51.080 --> 01:19:53.000
There's like big dot little CPUs.

01:19:53.000 --> 01:19:55.400
And so there's multiple different kinds of CPUs that are working

01:19:55.400 --> 01:19:57.040
together that are multi-core.

01:19:57.280 --> 01:19:58.360
You've got GPUs.

01:19:58.760 --> 01:20:00.800
You've got neural network accelerators.

01:20:01.040 --> 01:20:04.560
You got dedicated hardware blocks for, for media.

01:20:04.680 --> 01:20:07.200
So for video decode and JPEG code and things like this.

01:20:07.560 --> 01:20:10.040
And so you've got this massively complicated system, and this isn't just

01:20:10.040 --> 01:20:13.920
cell phones, every laptop these days is doing the same thing and all of these

01:20:13.920 --> 01:20:19.600
blocks can run at the same time and need to be choreographed, right?

01:20:19.600 --> 01:20:22.440
And so again, one of the cool things about machine learning is that it's

01:20:22.440 --> 01:20:25.800
moving things to like data flow graphs and higher level abstractions and

01:20:25.800 --> 01:20:30.560
tensors and these things that it doesn't specify here's how to do the algorithm.

01:20:30.840 --> 01:20:33.960
It gives the system a lot more flexibility in terms of how to translate

01:20:33.960 --> 01:20:36.800
or map or compile it onto the system that you have.

01:20:37.240 --> 01:20:40.200
And so what you need, you know, at the bottom, this part of the layer, there

01:20:40.200 --> 01:20:42.800
is a way for all these devices to talk to each other.

01:20:43.440 --> 01:20:45.640
And so this is one thing that, you know, I'm very passionate about.

01:20:45.640 --> 01:20:50.560
I mean, you know, I'm a nerd, but, um, but all these, all these machines

01:20:50.560 --> 01:20:54.400
and all these systems are effectively parallel computers running at the same

01:20:54.400 --> 01:20:56.480
time, sending messages to each other.

01:20:56.680 --> 01:20:58.280
And so they're all fully asynchronous.

01:20:59.160 --> 01:21:02.240
Well, this is actually a small version of the same problem you have in a data

01:21:02.240 --> 01:21:04.160
center, right in a data center.

01:21:04.160 --> 01:21:07.560
You now have multiple different machines, sometimes very specialized,

01:21:07.560 --> 01:21:11.800
sometimes with GPUs or TPUs in one node and sometimes with disks in another

01:21:11.800 --> 01:21:15.480
node, and so you get a much larger scale heterogeneous computer.

01:21:15.760 --> 01:21:19.120
And so what ends up happening is you have this like multi-layer abstraction

01:21:19.640 --> 01:21:23.960
of hierarchical parallelism, hierarchical asynchronous communication

01:21:24.400 --> 01:21:28.000
and making that again, the enemy, my enemy is complexity.

01:21:28.480 --> 01:21:32.120
By getting that away from being different specialized systems, every

01:21:32.120 --> 01:21:36.080
different part of the stack and having more consistency and uniformity, I

01:21:36.080 --> 01:21:39.640
think we can help lift the world and make it much simpler and actually get used.

01:21:39.680 --> 01:21:42.760
But how do you leverage like the strengths of the different specialized systems?

01:21:42.760 --> 01:21:44.600
So we're looking inside the smartphone.

01:21:44.840 --> 01:21:45.080
Yeah.

01:21:45.080 --> 01:21:48.240
I think there's just what I got, I don't know, five, six computers,

01:21:48.240 --> 01:21:49.480
essentially inside a smartphone.

01:21:49.920 --> 01:21:57.520
Uh, how do you, uh, without trying to minimize the explicit, uh, making

01:21:57.520 --> 01:22:00.480
it explicit, which, which computer is supposed to be used for which operation?

01:22:00.520 --> 01:22:00.720
Yeah.

01:22:00.720 --> 01:22:03.760
So there's, there's a pretty well known algorithm and what you're

01:22:03.760 --> 01:22:05.600
doing is you're looking at two, two factors.

01:22:05.600 --> 01:22:09.200
You're looking at the factor of sending data from one thing to another, right?

01:22:09.200 --> 01:22:11.920
Cause it takes time to get it from that side of the chip to that side of the chip

01:22:12.000 --> 01:22:15.080
and things like this, and then you're looking at what is the time it takes

01:22:15.080 --> 01:22:17.920
to do an operation on a particular block.

01:22:18.400 --> 01:22:21.960
So take CPUs, CPUs are fully general.

01:22:22.040 --> 01:22:23.160
They can do anything, right?

01:22:23.680 --> 01:22:25.640
But then you have a neural net accelerator that's really

01:22:25.640 --> 01:22:26.840
good at matrix multiplications.

01:22:27.320 --> 01:22:27.600
Okay.

01:22:27.960 --> 01:22:32.360
And so you say, okay, well, if my workload is all matrix multiplications, I start up,

01:22:32.400 --> 01:22:34.360
I send the data over to the neural net thing.

01:22:34.480 --> 01:22:36.120
It goes and does matrix multiplications.

01:22:36.120 --> 01:22:37.680
When it's done, it sends me back the result.

01:22:38.120 --> 01:22:38.720
All is good.

01:22:39.280 --> 01:22:39.480
Right.

01:22:39.480 --> 01:22:43.600
And so the simplest thing is just saying, do matrix, do matrix operations over there.

01:22:43.840 --> 01:22:44.080
Right.

01:22:44.720 --> 01:22:47.320
But then you realize you get a little bit more complicated because you

01:22:47.320 --> 01:22:49.480
can do matrix multiplications on a GPU.

01:22:49.480 --> 01:22:52.800
You can do it on a neural net accelerator.

01:22:52.800 --> 01:22:55.760
You can do it on CPU and they'll have different trade-offs and costs.

01:22:56.160 --> 01:22:57.680
And it's not just matrix multiplication.

01:22:58.040 --> 01:23:02.000
And so what you actually look at is you look at, I have generally a graph of

01:23:02.000 --> 01:23:04.680
compute, I want to do a partitioning.

01:23:04.760 --> 01:23:08.640
I want to look at the communication, the bi-section bandwidth and like the

01:23:08.640 --> 01:23:12.480
overhead and the sending of all these different things and, and build a model

01:23:12.480 --> 01:23:15.720
for this and then decide, okay, it's an optimization problem of where do I

01:23:15.720 --> 01:23:16.720
want to place this compute?

01:23:17.920 --> 01:23:21.920
So it's the old school theoretical computer science problem of scheduling.

01:23:22.160 --> 01:23:27.800
And then how does presumably it's possible to somehow magically

01:23:27.800 --> 01:23:29.240
include autotune into this?

01:23:30.480 --> 01:23:30.920
Absolutely.

01:23:30.960 --> 01:23:35.880
So, I mean, in my opinion, this is an opinion, this is not, uh, not

01:23:35.880 --> 01:23:39.560
everybody would agree with this, but in my opinion, the world benefits from

01:23:39.560 --> 01:23:42.880
simple and predictable systems at the bottom that you can control.

01:23:43.800 --> 01:23:47.960
But then once you have a predictable execution layer, you can build lots

01:23:47.960 --> 01:23:49.280
of different policies on top of it.

01:23:49.760 --> 01:23:50.040
Right.

01:23:50.120 --> 01:23:56.080
And so one policy can be that the human programmer says, do that here, do that

01:23:56.080 --> 01:23:57.320
here, do that here, do that here.

01:23:57.320 --> 01:24:01.760
And like fully manually controls everything and the systems just do it.

01:24:02.000 --> 01:24:02.280
Right.

01:24:02.840 --> 01:24:05.280
Then you quickly get in the mode of like, I don't want to have to tell it to do it.

01:24:06.000 --> 01:24:08.920
And so the next logical step that people typically take is they

01:24:08.920 --> 01:24:10.320
write some terrible heuristic.

01:24:11.200 --> 01:24:13.240
Oh, if it's a matrix multiplication, do it over there.

01:24:13.320 --> 01:24:14.920
Or if it's floating point, do it on the GPU.

01:24:14.920 --> 01:24:16.880
If it's integer, do it on the CPU, like something like that.

01:24:16.920 --> 01:24:17.120
Right.

01:24:17.640 --> 01:24:21.920
And, and then you, you then get into this mode of like people care more and more

01:24:21.920 --> 01:24:25.640
and more, and you say, okay, well, let's actually, um, like make the heuristic

01:24:25.640 --> 01:24:27.640
better, let's get into auto-tune it.

01:24:27.640 --> 01:24:35.000
Let's actually do a search of the space to decide, well, what is actually better.

01:24:35.040 --> 01:24:35.280
Right.

01:24:35.280 --> 01:24:38.440
Well, then you get into this problem where you realize this is not a small space.

01:24:38.480 --> 01:24:44.200
This is a many dimensional hyperdimensional space that you cannot exhaustively search.

01:24:45.200 --> 01:24:47.680
So, do you know of any algorithms that are good at searching

01:24:47.680 --> 01:24:49.400
very complicated spaces for?

01:24:50.080 --> 01:24:53.240
Don't tell me you're going to turn this into a machine learning problem.

01:24:53.360 --> 01:24:56.560
So then you turn into a machine learning problem, and then you have a space of

01:24:56.560 --> 01:25:00.000
genetic algorithms and reinforcement learning and like all these, all these,

01:25:00.000 --> 01:25:03.960
but can you include that into the stack, into the, into the module stack?

01:25:04.000 --> 01:25:04.320
Yeah.

01:25:04.480 --> 01:25:04.800
Yeah.

01:25:04.880 --> 01:25:05.800
And where does it sit?

01:25:05.800 --> 01:25:06.360
Where does it live?

01:25:06.360 --> 01:25:08.560
Is it separate thing or is it part of the compilation?

01:25:08.840 --> 01:25:11.240
So you start from simple and predictable models.

01:25:11.920 --> 01:25:15.680
And so you can have full control and you can have coarse grained knobs

01:25:15.680 --> 01:25:18.000
that like nudge systems so you don't have to do this.

01:25:18.360 --> 01:25:22.400
But if you really care about getting the best, you know, the last ounce out of a

01:25:22.400 --> 01:25:24.880
problem, then you can use additional tools.

01:25:25.280 --> 01:25:27.680
And they're the cool thing is you don't want to do this every time you run a

01:25:27.680 --> 01:25:30.400
model, you want to figure out the right answer and then cache it.

01:25:31.560 --> 01:25:34.320
And once you do that, you can get, you can say, okay, cool.

01:25:34.320 --> 01:25:36.000
I can get up and running very quickly.

01:25:36.320 --> 01:25:39.400
I can get good execution out of my system.

01:25:39.920 --> 01:25:41.760
I can decide if something's important.

01:25:41.760 --> 01:25:44.720
And if it's important, I can go through a bunch of machines at it and do a big

01:25:44.720 --> 01:25:47.960
expensive search over the space using whatever technique I feel like it's

01:25:48.440 --> 01:25:49.280
really up to the problem.

01:25:49.800 --> 01:25:51.400
And then when I get the right answer, cool.

01:25:51.400 --> 01:25:52.280
I can just start using it.

01:25:53.280 --> 01:25:53.480
Right.

01:25:53.480 --> 01:25:57.360
And so you can get out of this, um, this trade-off between, okay, am I going to

01:25:57.360 --> 01:26:00.320
like spend forever doing a thing or do I get up and running quickly?

01:26:00.320 --> 01:26:04.520
And as a quality result, like these, these are actually not in contention

01:26:04.520 --> 01:26:06.400
with each other, if the system's designed to scale.

01:26:07.400 --> 01:26:11.720
You started and did a little bit of a whirlwind overview of how you get the

01:26:11.720 --> 01:26:17.040
35,000 X, uh, speed up or more over Python.

01:26:17.480 --> 01:26:21.040
Um, Jeremy Howard did a really great presentation about sort of the basic,

01:26:21.440 --> 01:26:22.360
like look at the code.

01:26:22.400 --> 01:26:23.560
Here's how you get the speed up.

01:26:23.880 --> 01:26:28.120
Like you said, that's something we could, uh, probably developers can do for their

01:26:28.120 --> 01:26:32.080
own code to see how you can get these gigantic speed ups, but can you maybe

01:26:32.080 --> 01:26:35.160
speak to the machine learning task in general, how do you, how do you make some

01:26:35.160 --> 01:26:36.800
of this code fast and specifics?

01:26:36.800 --> 01:26:44.440
Like what would you say is the main bottleneck, uh, for, um, machine learning

01:26:44.440 --> 01:26:49.000
tasks, so are we talking about, uh, Matt mall matrix multiplication?

01:26:49.000 --> 01:26:49.920
How do you make that fast?

01:26:50.280 --> 01:26:52.840
So, I mean, if you just look at the Python problem, right?

01:26:52.840 --> 01:26:55.040
You can say, how do I make Python faster?

01:26:55.960 --> 01:26:58.920
And there's been a lot of people that have been working on the, okay, I don't

01:26:58.920 --> 01:27:01.440
make Python two X faster, 10 X faster or something like that, right?

01:27:01.440 --> 01:27:03.640
And there've been a ton of projects in that vein, right?

01:27:04.320 --> 01:27:06.840
Mojo started from the, what can the hardware do?

01:27:08.400 --> 01:27:09.680
Like, what is the limit of physics?

01:27:09.720 --> 01:27:09.920
Yeah.

01:27:09.960 --> 01:27:10.800
What is the speed of light?

01:27:11.960 --> 01:27:13.160
Like how fast can this thing go?

01:27:13.160 --> 01:27:15.040
And then how do I express that?

01:27:15.160 --> 01:27:15.440
Yeah.

01:27:15.560 --> 01:27:15.720
Right.

01:27:15.720 --> 01:27:19.800
And so it wasn't, it wasn't anchored relatively on make Python a little bit

01:27:19.800 --> 01:27:22.520
faster at saying, cool, I know what the hardware can do.

01:27:22.520 --> 01:27:24.080
Let's unlock that right now.

01:27:24.600 --> 01:27:29.920
When you just say how, how gutsy that is to be in the meeting and as opposed to

01:27:29.920 --> 01:27:33.160
trying to see how do we get the improvement, it's like, what can the physics do?

01:27:34.040 --> 01:27:36.800
I mean, maybe I'm a special kind of nerd, but you look at that.

01:27:37.240 --> 01:27:38.480
What is the limit of physics?

01:27:38.520 --> 01:27:40.000
How fast can these things go?

01:27:40.120 --> 01:27:40.400
Right.

01:27:41.240 --> 01:27:44.360
When you start looking at that, typically it ends up being a memory problem.

01:27:45.240 --> 01:27:45.440
Right.

01:27:45.440 --> 01:27:49.560
And so today, uh, particularly with these specialized accelerators, the

01:27:49.560 --> 01:27:53.960
problem is that you can do a lot of math within them, but you get bottleneck

01:27:54.080 --> 01:27:59.200
sending data back and forth to memory, whether it be local memory or distant

01:27:59.200 --> 01:28:00.800
memory or disc or whatever it is.

01:28:01.400 --> 01:28:04.760
And, and that, that bottleneck, particularly as the training sizes get

01:28:04.760 --> 01:28:09.120
large, as you start doing tons of inferences all over the place, like that

01:28:09.120 --> 01:28:10.640
becomes a huge bottleneck for people.

01:28:10.640 --> 01:28:10.880
Right.

01:28:12.080 --> 01:28:15.520
So again, what happened is we went through a phase of many years where

01:28:15.520 --> 01:28:19.720
people took the special case and hand tuned it and tweaked it and tricked it

01:28:19.720 --> 01:28:21.800
out and they knew exactly how the hardware worked and they knew the model

01:28:21.800 --> 01:28:23.080
and they made it, they made it fast.

01:28:24.000 --> 01:28:24.800
Didn't generalize.

01:28:25.520 --> 01:28:29.560
And so you can make, you know, resident 50 or some, or Alex net or something

01:28:29.560 --> 01:28:31.760
conception V1, like you can, you can do that, right.

01:28:31.760 --> 01:28:33.040
Because the models are small.

01:28:33.480 --> 01:28:34.440
They fit in your head.

01:28:34.920 --> 01:28:35.200
Right.

01:28:35.200 --> 01:28:38.400
But as the models get bigger, more complicated, as the machines get more

01:28:38.400 --> 01:28:40.160
complicated, it stops working.

01:28:40.480 --> 01:28:40.720
Right.

01:28:40.760 --> 01:28:44.200
And so this is where things like kernel fusion come in.

01:28:44.560 --> 01:28:45.520
So what is kernel fusion?

01:28:45.520 --> 01:28:49.360
This is this idea of saying, let's avoid going to memory and let's do that by

01:28:49.360 --> 01:28:56.200
building a new hybrid kernel and a numerical algorithm that actually keeps

01:28:56.200 --> 01:28:59.440
things in the accelerator instead of having to write all the way out to

01:28:59.440 --> 01:29:00.400
memory, right.

01:29:01.160 --> 01:29:03.680
What's happened with, with these accelerators now is you get multiple

01:29:03.680 --> 01:29:06.960
levels of memory, like in a GPU, for example, you'll have global memory

01:29:06.960 --> 01:29:09.640
and local memory and like all these things.

01:29:10.160 --> 01:29:15.120
Um, if you zoom way into how hardware works, the register file is actually

01:29:15.120 --> 01:29:18.600
a memory, so the registers are like an L zero cash.

01:29:18.720 --> 01:29:24.600
And so a lot of taking advantage of the hardware ends up being fully

01:29:24.600 --> 01:29:28.480
utilizing the full power in all of its capability.

01:29:28.840 --> 01:29:30.640
And this has a number of problems, right?

01:29:30.640 --> 01:29:33.560
One of which is again, the complexity of disaster, right?

01:29:33.560 --> 01:29:34.640
There's too much hardware.

01:29:35.080 --> 01:29:39.440
Even if you just say, let's look at the chips from one line of vendor, like

01:29:39.440 --> 01:29:44.040
Apple or Intel or whatever it is, each version of the chip comes out with new

01:29:44.040 --> 01:29:47.520
features and they change things so that it takes more time or less time to do

01:29:47.520 --> 01:29:50.960
different things and you can't rewrite all the software whenever a new chip comes

01:29:50.960 --> 01:29:51.720
in, right?

01:29:52.000 --> 01:29:54.400
And so this is where you need a much more scalable approach.

01:29:54.440 --> 01:29:58.040
And this is what Mojo and what the modular stack provides is it provides

01:29:58.440 --> 01:30:02.480
this infrastructure and the system for factoring all this complexity and then

01:30:02.480 --> 01:30:04.080
allowing people to express algorithms.

01:30:04.120 --> 01:30:08.360
You talk about auto-tuning, for example, express algorithms in a more portable

01:30:08.360 --> 01:30:12.440
way so that when a new chip comes out, you don't have to rewrite it all.

01:30:13.480 --> 01:30:16.680
So to me, like, you know, I kind of joke like, what is a compiler?

01:30:16.760 --> 01:30:19.000
Well, there's many ways to explain that.

01:30:19.360 --> 01:30:23.520
You convert thing A into thing B and you convert source code to machine code.

01:30:23.520 --> 01:30:28.400
Like you can talk about many, many things that compilers do, but to me,

01:30:28.400 --> 01:30:30.040
it's about a bag of tricks.

01:30:30.680 --> 01:30:34.640
It's about a system and a framework that you can hang complexity.

01:30:35.080 --> 01:30:38.160
It's a system that can then generalize and it can work on problems that are

01:30:38.160 --> 01:30:39.840
bigger than fit in one human's head.

01:30:40.920 --> 01:30:41.240
Right.

01:30:41.360 --> 01:30:45.760
And so what that means, what a good stack and what the modular stack provides is

01:30:46.240 --> 01:30:49.800
the ability to walk up to it with a new problem and it'll generally work quite

01:30:49.800 --> 01:30:50.120
well.

01:30:51.440 --> 01:30:54.000
And that's something that a lot of machine learning infrastructure and tools

01:30:54.000 --> 01:30:55.680
and technologies don't have.

01:30:56.600 --> 01:30:59.680
Typical state of the art today as you walk up, particularly if you're deploying,

01:30:59.680 --> 01:31:02.840
if you walk up with a new model, you try to push it through the converter and the

01:31:02.840 --> 01:31:03.720
converter crashes.

01:31:06.360 --> 01:31:07.240
That's crazy.

01:31:07.400 --> 01:31:12.320
The state of ML tooling today is not anything that a C programmer would ever

01:31:12.320 --> 01:31:13.400
accept, right?

01:31:13.800 --> 01:31:17.160
And it's always been this kind of flaky set of tooling that's never been

01:31:17.160 --> 01:31:22.200
integrated well and it's been never worked together because it's not designed

01:31:22.200 --> 01:31:22.560
together.

01:31:22.960 --> 01:31:24.040
It's built by different teams.

01:31:24.040 --> 01:31:25.440
It's built by different hardware vendors.

01:31:25.440 --> 01:31:26.720
It's built by different systems.

01:31:26.720 --> 01:31:28.320
It's built by different internet companies.

01:31:28.320 --> 01:31:30.640
They're trying to solve their problems, right?

01:31:30.680 --> 01:31:34.840
And so that means that we get this fragmented, terrible mess of complexity.

01:31:35.800 --> 01:31:40.320
So, I mean, the specifics of, and Jeremy showed this, there's the vectorized

01:31:40.320 --> 01:31:46.280
function, which I guess is built into Mojo.

01:31:47.240 --> 01:31:49.240
Vectorized, as he showed, is built into the library.

01:31:49.360 --> 01:31:50.840
Into the library instead of the library.

01:31:51.960 --> 01:31:57.840
Vectorized, paralyze, which vectorizes more low level, paralyzes higher level.

01:31:58.160 --> 01:32:03.880
There's the tiling thing, which is how he demonstrated the autotune, I think.

01:32:04.080 --> 01:32:09.480
So think about this in like levels, hierarchical levels of abstraction, right?

01:32:09.480 --> 01:32:13.800
And so at the very, if you zoom all the way into a compute problem, you have one

01:32:13.800 --> 01:32:15.480
floating point number, right?

01:32:15.480 --> 01:32:19.120
And so then you say, okay, I want to be, I can do things one at a time in an

01:32:19.120 --> 01:32:21.760
interpreter, it's pretty slow, right?

01:32:21.800 --> 01:32:24.720
So I can get to doing one, one at a time in a compiler.

01:32:24.880 --> 01:32:30.520
I can see that I can get to doing four or eight or 16 at a time with vectors.

01:32:30.600 --> 01:32:31.960
That's called vectorization.

01:32:32.720 --> 01:32:36.360
Then you can say, Hey, I have a whole bunch of different, you know, what, what a

01:32:36.360 --> 01:32:40.960
multi-core computer is, is this basically a bunch of computers, right?

01:32:40.960 --> 01:32:44.000
So they're all independent computers that can talk to each other and they share

01:32:44.000 --> 01:32:44.440
memory.

01:32:44.960 --> 01:32:48.760
And so now what Parallelize does is it says, okay, run multiple instances of this

01:32:48.760 --> 01:32:52.280
on different computers and now they can all work together on a problem, right?

01:32:52.280 --> 01:32:56.000
And so what you're doing is you're saying, keep going out to the next level out.

01:32:56.800 --> 01:32:59.280
And as you do that, how do I take advantage of this?

01:32:59.360 --> 01:33:02.480
So tiling is a memory optimization, right?

01:33:02.480 --> 01:33:06.320
It says, okay, let's make sure that we're keeping the data close to the compute

01:33:06.720 --> 01:33:11.200
part of the problem instead of sending it all back and forth through memory every,

01:33:11.240 --> 01:33:12.720
every time I load a block.

01:33:12.960 --> 01:33:16.920
And the size of the block size is, is all, that's how you get to the autotune to

01:33:16.920 --> 01:33:18.000
make sure it's optimized.

01:33:18.080 --> 01:33:18.360
Yeah.

01:33:18.400 --> 01:33:21.280
Well, so all of these, the details matter so much to get good performance.

01:33:22.040 --> 01:33:25.840
This is another funny thing about machine learning and high performance computing

01:33:25.880 --> 01:33:30.800
that is very different than C compilers we all grew up, grew up with where, you

01:33:30.800 --> 01:33:34.360
know, if you get a new version of GCC or a new version of Clang or something like

01:33:34.360 --> 01:33:39.120
that, you know, maybe something will go 1% faster, right?

01:33:39.160 --> 01:33:42.960
And so compiler engineers will work really, really, really hard to get half a

01:33:42.960 --> 01:33:45.760
percent out of your C code, something like that.

01:33:46.280 --> 01:33:50.200
But when you're talking about an accelerator or an AI application, or you're

01:33:50.200 --> 01:33:54.480
talking about these kinds of algorithms, and these are things people used to

01:33:54.480 --> 01:33:56.040
write in Fortran, for example, right?

01:33:57.400 --> 01:34:02.960
If you get it wrong, it's not 5% or 1%, it could be 2X or 10X, right?

01:34:02.960 --> 01:34:07.600
If you think about it, you really want to make use of the full memory you have,

01:34:07.600 --> 01:34:11.320
the cache, for example, but if you use too much space, it doesn't fit in the

01:34:11.320 --> 01:34:14.160
cache, now you're going to be thrashing all the way back out to main memory.

01:34:14.720 --> 01:34:18.520
And these can be 2X, 10X major performance differences.

01:34:18.520 --> 01:34:21.960
And so this is where getting these magic numbers and these things right is

01:34:21.960 --> 01:34:23.240
really actually quite important.

01:34:23.920 --> 01:34:27.320
So you mentioned that Mojo is a superset of Python.

01:34:29.720 --> 01:34:34.920
Can you run Python code as if it's Mojo code?

01:34:35.160 --> 01:34:41.800
Yes, yes, so, and this has two sides of it, so Mojo's not done yet, so I'll give

01:34:41.800 --> 01:34:45.840
you a disclaimer, Mojo's not done yet, but already we see people that take small

01:34:45.840 --> 01:34:50.360
pieces of Python code, move it over, they don't change it, and you can get 12X

01:34:50.360 --> 01:34:53.720
speedups, like somebody was just tweeting about that yesterday, which is pretty

01:34:53.720 --> 01:34:54.600
cool, right?

01:34:54.640 --> 01:34:56.640
And again, interpreters, compilers, right?

01:34:56.640 --> 01:35:01.400
And so without changing any code, without, also this is not with, this is not JIT

01:35:01.760 --> 01:35:07.920
compiling or doing anything fancy, this is just basic stuff, move it straight over.

01:35:08.480 --> 01:35:11.800
Now Mojo will continue to grow out, and as it grows out, it will have more and

01:35:11.800 --> 01:35:15.800
more and more features, and our North Star is to be a full superset of Python,

01:35:15.800 --> 01:35:19.440
and so you can bring over basically arbitrary Python code and have it just

01:35:19.440 --> 01:35:25.480
work, and it may not always be 12X faster, but it should be at least as fast and way

01:35:25.480 --> 01:35:27.560
faster in many cases, this is the goal, right?

01:35:28.200 --> 01:35:33.040
Now we'll take time to do that, and Python is a complicated language, there's not

01:35:33.040 --> 01:35:37.680
just the obvious things, but there's also non-obvious things that are complicated,

01:35:37.680 --> 01:35:41.800
like we have to be able to talk to CPython packages, to talk to the C API,

01:35:41.800 --> 01:35:44.520
and there's a bunch of, there's a bunch of pieces to process.

01:35:44.520 --> 01:35:49.880
So you have to, I mean, just to make explicit the obvious, it may not be so

01:35:49.880 --> 01:35:53.440
obvious until you think about it, so, you know, to run Python code, that means you

01:35:53.440 --> 01:35:56.760
have to run all the Python packages and libraries.

01:35:57.760 --> 01:35:59.520
So that means what?

01:35:59.960 --> 01:36:07.280
What's the relationship between Mojo and CPython, the interpreter that presumably

01:36:07.280 --> 01:36:09.600
would be tasked with getting those packages to work?

01:36:09.600 --> 01:36:14.320
Yep, so in the fullness of time, Mojo will solve for all the problems, and you'll

01:36:14.320 --> 01:36:17.560
be able to move Python packages over and run them in Mojo.

01:36:17.920 --> 01:36:19.120
Without the CPython?

01:36:19.160 --> 01:36:21.560
Without CPython, someday, right?

01:36:21.560 --> 01:36:25.240
It's not today, but someday, and that'll be a beautiful day because then you'll

01:36:25.240 --> 01:36:29.040
get a whole bunch of advantages and you'll get massive speed ups and things like this.

01:36:29.040 --> 01:36:30.360
But you can do that one at a time, right?

01:36:30.360 --> 01:36:31.480
You can move packages one at a time.

01:36:31.480 --> 01:36:33.880
Exactly, but we're not willing to wait for that.

01:36:34.680 --> 01:36:35.880
Python is too important.

01:36:35.880 --> 01:36:37.320
The ecosystem is too broad.

01:36:37.880 --> 01:36:40.320
We want to both be able to build Mojo out.

01:36:40.600 --> 01:36:44.600
We also want to do it the right way without time, like without intense time pressure.

01:36:44.600 --> 01:36:48.840
We're obviously moving fast, but, and so what we do is we say, okay, well, let's

01:36:48.840 --> 01:36:52.520
make it so you can import an arbitrary existing package.

01:36:53.480 --> 01:36:58.200
Arbitrary, including like you write your own on your local disk or whatever.

01:36:58.200 --> 01:37:02.600
It's not, it's not like a standard, like an arbitrary package and import that using

01:37:02.600 --> 01:37:06.360
CPython because CPython already runs all the packages, right?

01:37:06.360 --> 01:37:11.560
And so what we do is we built an integration layer where we can actually use CPython.

01:37:11.560 --> 01:37:17.320
Again, I'm practical to actually just load and use all the existing packages as they are.

01:37:17.960 --> 01:37:21.560
The downside of that is you don't get the benefits of Mojo for those packages, right?

01:37:21.960 --> 01:37:25.320
And so they'll run as fast as they do in the traditional CPython way.

01:37:26.440 --> 01:37:29.560
But what that does is that gives you an incremental migration path.

01:37:29.560 --> 01:37:33.960
And so if you say, hey, cool, well, here's a, you know, the Python ecosystem is vast.

01:37:33.960 --> 01:37:37.640
I want all of it to just work, but there's certain things that are really important.

01:37:37.640 --> 01:37:40.600
And so if I, if I'm doing weather forecasting or something,

01:37:41.640 --> 01:37:43.720
well, I want to be able to load all the data.

01:37:43.720 --> 01:37:44.440
I want to be able to work with it.

01:37:44.440 --> 01:37:47.080
And then I have my own crazy algorithm inside of it.

01:37:47.080 --> 01:37:49.160
Well, normally I'd write that in C++.

01:37:50.120 --> 01:37:54.840
If I can write in Mojo and have one system that scales, well, that's way easier to work with.

01:37:54.840 --> 01:37:59.480
Is it hard to do that, to have that layer that's running CPython?

01:38:00.040 --> 01:38:02.280
Because is there some communication back and forth?

01:38:02.280 --> 01:38:03.880
Yes, it's complicated.

01:38:03.880 --> 01:38:05.000
I mean, this is what we do.

01:38:05.000 --> 01:38:08.680
So, I mean, we make it look easy, but it is complicated.

01:38:08.680 --> 01:38:13.240
But what we do is we use the CPython existing interpreter.

01:38:13.240 --> 01:38:16.440
So it's running its own bytecodes and that's how it provides full compatibility.

01:38:17.000 --> 01:38:22.200
And then it gives us CPython objects and we use those objects as is.

01:38:22.840 --> 01:38:26.840
And so that way we're fully compatible with all the CPython objects and all the,

01:38:27.880 --> 01:38:31.480
you know, it's not just the Python part, it's also the C packages,

01:38:31.480 --> 01:38:34.360
the C libraries underneath them, because they're often hybrid.

01:38:34.360 --> 01:38:37.080
And so we can fully run and we're fully compatible with all that.

01:38:37.080 --> 01:38:40.120
And the way we do that is that we have to play by the rules, right?

01:38:40.120 --> 01:38:44.280
And so we keep objects in that representation when they're coming from that world.

01:38:44.280 --> 01:38:47.240
What's the representation that's being used in memory?

01:38:47.240 --> 01:38:50.600
We'd have to know a lot about how the CPython interpreter works.

01:38:51.160 --> 01:38:53.480
It has, for example, reference counting,

01:38:53.480 --> 01:38:57.480
but also different rules on how to pass pointers around and things like this.

01:38:57.480 --> 01:38:58.760
Super low level fiddly.

01:38:58.760 --> 01:39:02.040
And it's not like Python, it's like how the interpreter works.

01:39:02.040 --> 01:39:04.680
Okay. And so that gets all exposed out.

01:39:04.680 --> 01:39:08.840
And then you have to define wrappers around the low level C code, right?

01:39:08.840 --> 01:39:12.600
And so what this means is you have to know not only C,

01:39:13.560 --> 01:39:17.800
which is a different role from Python, obviously, not only Python,

01:39:17.800 --> 01:39:20.360
but the wrappers, but the interpreter and the wrappers

01:39:20.360 --> 01:39:22.360
and the implementation details and the conventions.

01:39:22.360 --> 01:39:24.840
And it's just this really complicated mess.

01:39:24.840 --> 01:39:28.040
And when you do that, now suddenly you have a debugger that bugs Python,

01:39:28.600 --> 01:39:30.920
they can't step into C code, right?

01:39:30.920 --> 01:39:33.000
So you have this two world problem, right?

01:39:33.000 --> 01:39:38.360
And so by pulling this all into Mojo, what you get is you get one world.

01:39:38.360 --> 01:39:41.960
You get the ability to say, cool, I have untyped, very dynamic,

01:39:41.960 --> 01:39:43.240
beautiful, simple code.

01:39:44.200 --> 01:39:46.520
Okay, I care about performance for whatever reason, right?

01:39:46.520 --> 01:39:49.400
There's lots of reasons you might care.

01:39:49.400 --> 01:39:51.960
And so then you add types, you can parallelize things,

01:39:51.960 --> 01:39:54.120
you can vectorize things, you can use these techniques,

01:39:54.120 --> 01:39:56.840
which are general techniques to solve a problem.

01:39:56.840 --> 01:39:59.640
And then you can do that by staying in the system.

01:39:59.640 --> 01:40:03.960
And if you have that one Python package that's really important to you,

01:40:03.960 --> 01:40:07.400
you can move it to Mojo, you get massive performance benefits on that

01:40:07.400 --> 01:40:09.000
and other advantages.

01:40:09.560 --> 01:40:11.800
If you like SAC types, it's nice if they're enforced.

01:40:12.520 --> 01:40:14.520
Some people like that, right, rather than being hints.

01:40:14.520 --> 01:40:15.800
So there's other advantages too.

01:40:18.280 --> 01:40:20.200
And then you can do that incrementally as you go.

01:40:22.200 --> 01:40:25.080
So one different perspective on this will be

01:40:26.920 --> 01:40:32.360
why Mojo instead of making CPython faster or redesigning CPython?

01:40:32.360 --> 01:40:36.040
Yeah, well, I mean, you could argue Mojo is redesigning CPython.

01:40:37.240 --> 01:40:41.000
But why not make CPython faster and better and other things like that?

01:40:41.000 --> 01:40:42.120
There's lots of people working on that.

01:40:42.760 --> 01:40:46.600
So actually, there's a team at Microsoft that is really improving.

01:40:46.600 --> 01:40:51.080
I think CPython 3.11 came out in October, something like that.

01:40:51.080 --> 01:40:55.480
And it was 15% faster, 20% faster across the board,

01:40:56.040 --> 01:41:00.280
which is pretty huge given how mature Python is and things like this.

01:41:00.280 --> 01:41:02.520
And so that's awesome.

01:41:02.520 --> 01:41:03.000
I love it.

01:41:04.440 --> 01:41:05.400
Doesn't run on GPU.

01:41:06.440 --> 01:41:10.040
It doesn't do AI stuff, like it doesn't do vectors, doesn't do things.

01:41:11.480 --> 01:41:14.040
20% is good, 35,000 times is better.

01:41:14.920 --> 01:41:19.320
So I'm a huge fan of that work, by the way.

01:41:19.320 --> 01:41:20.920
And it composes well with what we're doing.

01:41:20.920 --> 01:41:23.800
And so it's not like we're fighting or anything like that.

01:41:23.800 --> 01:41:26.120
It's actually just goodness for the world.

01:41:26.120 --> 01:41:27.720
But it's just a different path.

01:41:27.720 --> 01:41:31.800
And again, we're not working forwards from making Python a little bit better.

01:41:31.800 --> 01:41:34.440
We're working backwards from what is the limit of physics.

01:41:35.160 --> 01:41:38.760
What's the process of porting Python code to Mojo?

01:41:38.920 --> 01:41:43.320
What's involved in that process?

01:41:43.320 --> 01:41:44.920
Is there tooling for that?

01:41:44.920 --> 01:41:45.400
Not yet.

01:41:45.400 --> 01:41:48.200
So we're missing some basic features right now.

01:41:48.200 --> 01:41:51.480
And so we're continuing to drop out new features on a weekly basis.

01:41:51.480 --> 01:41:57.960
But at the fullness of time, give us a year and a half, maybe two years.

01:41:57.960 --> 01:41:59.800
Is it an automatable process?

01:41:59.800 --> 01:42:02.760
So when we're ready, it will be very automatable.

01:42:02.760 --> 01:42:03.400
Yes.

01:42:03.400 --> 01:42:04.360
Is it automatable?

01:42:04.920 --> 01:42:10.440
Is it possible to automate, in the general case, the Python to Mojo conversion?

01:42:10.440 --> 01:42:10.920
Yeah.

01:42:10.920 --> 01:42:11.960
You're saying it's possible.

01:42:11.960 --> 01:42:15.720
Well, so and this is why, I mean, among other reasons why we use tabs.

01:42:16.520 --> 01:42:17.160
Yes.

01:42:17.160 --> 01:42:17.480
Right.

01:42:17.480 --> 01:42:22.840
So first of all, by being a superset, it's like C versus C++.

01:42:22.840 --> 01:42:24.280
Can you move C code to C++?

01:42:25.560 --> 01:42:25.880
Yes.

01:42:25.880 --> 01:42:26.600
Yeah.

01:42:26.600 --> 01:42:26.840
Right.

01:42:26.840 --> 01:42:29.640
And you can move C code to C++.

01:42:29.640 --> 01:42:32.360
And then you can adopt classes.

01:42:32.360 --> 01:42:33.400
You can adopt templates.

01:42:33.400 --> 01:42:37.080
You can adopt other references or whatever C++ features you want.

01:42:37.640 --> 01:42:42.840
After you move C code to C++, you can't use templates in C, right?

01:42:42.840 --> 01:42:45.400
And so if you leave it a C, fine, you can't use the cool features.

01:42:45.400 --> 01:42:46.600
But it still works, right?

01:42:46.600 --> 01:42:48.760
And C and C++ code work together.

01:42:48.760 --> 01:42:51.000
And so that's the analogy, right?

01:42:51.000 --> 01:43:00.120
Now, here, right, there's not a Python is bad and a Mojo is good, right?

01:43:00.120 --> 01:43:02.120
Mojo just gives you superpowers, right?

01:43:02.120 --> 01:43:04.040
And so if you want to stay with Python, that's cool.

01:43:05.160 --> 01:43:08.920
But the tooling should be actually very beautiful and simple

01:43:08.920 --> 01:43:11.960
because we're doing the hard work of defining a superset.

01:43:11.960 --> 01:43:12.680
Right.

01:43:12.680 --> 01:43:13.800
So you're right.

01:43:13.800 --> 01:43:17.480
So there's several things to say there, but also the conversion tooling

01:43:17.480 --> 01:43:20.520
should probably give you hints as to how you can improve the code.

01:43:20.520 --> 01:43:22.440
And then exactly, once you're in the new world,

01:43:22.440 --> 01:43:25.960
then you can build all kinds of cool tools to say, hey, should you adopt this feature?

01:43:26.680 --> 01:43:29.720
And we haven't built those tools yet, but I fully expect those tools will exist.

01:43:29.720 --> 01:43:32.440
And then you can like, you know, quote, unquote, modernize your code

01:43:32.440 --> 01:43:33.720
or however you want to look at it.

01:43:33.720 --> 01:43:34.440
Right.

01:43:34.440 --> 01:43:37.320
So, I mean, one of the things that I think is really interesting about Mojo

01:43:37.320 --> 01:43:41.640
is that there have been a lot of projects to improve Python over the years.

01:43:42.680 --> 01:43:46.440
Everything from, you know, getting Python run on the Java virtual machine,

01:43:47.480 --> 01:43:49.160
PyPy, which is a JIT compiler.

01:43:49.160 --> 01:43:50.760
There's tons of these projects out there

01:43:50.760 --> 01:43:53.560
that have been working on improving Python in various ways.

01:43:54.360 --> 01:43:55.640
They fall into one or two camps.

01:43:56.200 --> 01:44:00.520
So PyPy is a great example of a camp that is trying to be compatible with Python.

01:44:01.400 --> 01:44:02.520
Even there, not really.

01:44:02.520 --> 01:44:05.480
It doesn't work with all the C packages and stuff like that.

01:44:05.480 --> 01:44:08.120
But they're trying to be compatible with Python.

01:44:08.120 --> 01:44:10.760
There's also another category of these things where they're saying,

01:44:10.760 --> 01:44:12.200
well, Python is too complicated.

01:44:13.240 --> 01:44:15.800
And, you know, I'm going to cheat on the edges.

01:44:15.800 --> 01:44:20.200
And, you know, like integers in Python can be an arbitrary size integer.

01:44:20.920 --> 01:44:25.160
Like if you care about fitting in a, going fast in a register in a computer,

01:44:25.160 --> 01:44:26.600
that's really annoying.

01:44:26.600 --> 01:44:26.840
Right.

01:44:26.840 --> 01:44:29.400
And so you can choose to pass on that.

01:44:29.400 --> 01:44:29.560
Right.

01:44:29.560 --> 01:44:32.920
You can say, well, people don't really use big integers that often.

01:44:32.920 --> 01:44:35.160
Therefore, I'm going to just not do it and it'll be fine.

01:44:37.080 --> 01:44:38.120
Not a Python superset.

01:44:39.080 --> 01:44:41.560
Or you can do the hard thing and say, okay, this is Python.

01:44:42.360 --> 01:44:46.760
You can't be a superset of Python without being a superset of Python.

01:44:46.760 --> 01:44:49.320
And that's a really hard technical problem.

01:44:49.880 --> 01:44:52.040
But it's, in my opinion, worth it.

01:44:52.040 --> 01:44:52.280
Right.

01:44:52.360 --> 01:44:55.560
And it's worth it because it's not about any one package.

01:44:55.560 --> 01:44:56.680
It's about this ecosystem.

01:44:56.680 --> 01:44:58.760
It's about what Python means for the world.

01:44:58.760 --> 01:45:02.760
And it also means we don't want to repeat the Python 2 to Python 3 transition.

01:45:02.760 --> 01:45:06.600
Like we want, we want people to be able to adopt this stuff quickly.

01:45:06.600 --> 01:45:09.320
And so by doing that work, we can help lift people.

01:45:09.880 --> 01:45:10.120
Yeah.

01:45:10.120 --> 01:45:13.400
The challenge, it's really interesting technical philosophical challenge of

01:45:14.840 --> 01:45:17.960
really making a language a superset of another language.

01:45:19.720 --> 01:45:21.240
That's breaking my brain a little bit.

01:45:21.240 --> 01:45:22.920
Well, it paints you into corners.

01:45:22.920 --> 01:45:25.240
So again, I'm very happy with Python.

01:45:26.600 --> 01:45:29.000
All joking aside, I think that the annotation thing is not

01:45:29.640 --> 01:45:31.640
the actual important part of the problem.

01:45:32.680 --> 01:45:33.000
Right.

01:45:33.000 --> 01:45:36.840
But the fact that Python has amazing dynamic metaprogramming features

01:45:36.840 --> 01:45:40.040
and they translate to beautiful static metaprogramming features,

01:45:40.040 --> 01:45:41.640
I think is profound.

01:45:41.640 --> 01:45:42.920
I think that's huge.

01:45:42.920 --> 01:45:43.080
Right.

01:45:43.080 --> 01:45:45.960
And so Python, I've talked with Guido about this.

01:45:45.960 --> 01:45:49.720
It's like, it was not designed to do what we're doing.

01:45:49.720 --> 01:45:52.680
That was not the reason they built it this way, but because they really cared

01:45:52.680 --> 01:45:55.320
and they were very thoughtful about how they designed the language,

01:45:55.320 --> 01:45:57.320
it scales very elegantly in the space.

01:45:57.880 --> 01:46:01.960
But if you look at other languages, for example, C and C++, right.

01:46:02.520 --> 01:46:07.720
If you're building a superset, you get stuck with the design decisions of the subset.

01:46:09.080 --> 01:46:09.400
Right.

01:46:09.400 --> 01:46:15.480
And so, you know, C++ is way more complicated because of C in the legacy

01:46:15.480 --> 01:46:19.080
than it would have been if they would have theoretically designed a from scratch thing.

01:46:20.120 --> 01:46:23.960
And there's lots of people right now that are trying to make C++ better

01:46:23.960 --> 01:46:25.160
and re-syntax C++.

01:46:25.160 --> 01:46:25.720
It's going to be great.

01:46:25.720 --> 01:46:26.920
We'll just change all the syntax.

01:46:27.800 --> 01:46:29.960
But if you do that, now suddenly you have zero packages.

01:46:30.920 --> 01:46:32.040
You don't have compatibility.

01:46:32.040 --> 01:46:35.800
So what are the, if you could just linger on that,

01:46:35.800 --> 01:46:39.880
what are the biggest challenges of keeping that superset status?

01:46:41.080 --> 01:46:42.360
What are the things you're struggling with?

01:46:42.360 --> 01:46:44.600
Is it all boiled down to having a big integer?

01:46:45.560 --> 01:46:47.880
No, I mean, what are the other things?

01:46:47.880 --> 01:46:50.840
Usually it's the, it's a long tail of weird things.

01:46:50.840 --> 01:46:52.840
So let me give you a war story.

01:46:52.840 --> 01:46:57.800
So war story in the space is you go way back in time.

01:46:57.800 --> 01:46:59.720
Project I worked on is called Clang.

01:47:00.920 --> 01:47:03.640
Clang, what it is, is a C, C++ parser.

01:47:03.640 --> 01:47:03.960
Right.

01:47:03.960 --> 01:47:08.840
And when I started working on Clang, it must have been like 2006 or something.

01:47:08.840 --> 01:47:12.360
It was 2007, 2006 when I first started working on it.

01:47:12.360 --> 01:47:12.860
Right.

01:47:13.560 --> 01:47:14.680
It's funny how time flies.

01:47:15.640 --> 01:47:16.140
Yeah.

01:47:17.320 --> 01:47:22.120
I started that project and I'm like, okay, well, I want to build a C parser,

01:47:22.120 --> 01:47:24.040
C++ parser for LLVM.

01:47:24.760 --> 01:47:28.680
It's going to be the word, GCC is yucky.

01:47:28.680 --> 01:47:31.480
You know, this is me in earlier times.

01:47:31.480 --> 01:47:32.040
It's yucky.

01:47:32.040 --> 01:47:32.840
It's unprincipled.

01:47:32.840 --> 01:47:37.240
It has all these weird features, like all these bugs, like it's yucky.

01:47:37.240 --> 01:47:41.320
So I'm going to build a standard compliance C and C++ parser.

01:47:41.320 --> 01:47:42.760
It's going to be beautiful.

01:47:42.760 --> 01:47:45.720
It'll be amazing, well-engineered, all the cool things an engineer wants to do.

01:47:46.520 --> 01:47:49.160
And so I started implementing and building it out and building it out and building it out.

01:47:49.160 --> 01:47:52.040
And then I got to include standard io.h.

01:47:53.960 --> 01:47:57.000
And all of the headers in the world use all the GCC stuff.

01:47:58.680 --> 01:47:59.320
Okay.

01:47:59.320 --> 01:47:59.880
This is in.

01:47:59.880 --> 01:48:05.080
So again, come back away from theory back to reality, right?

01:48:06.280 --> 01:48:07.960
I was at a fork in the road.

01:48:07.960 --> 01:48:12.040
I could have built an amazingly beautiful academic thing that nobody would ever use.

01:48:13.560 --> 01:48:17.240
Or I could say, well, it's yucky in various ways.

01:48:18.280 --> 01:48:21.480
All these design mistakes, accents of history, the legacy.

01:48:21.480 --> 01:48:27.480
At that point, GCC was like over 20 years old, which, by the way, now LLVM is over 20 years old.

01:48:27.480 --> 01:48:30.280
And so it's funny how time catches up to you, right?

01:48:30.280 --> 01:48:35.480
And so you say, okay, well, what is easier, right?

01:48:35.480 --> 01:48:39.240
I mean, as an engineer, it's actually much easier for me to go implement

01:48:39.880 --> 01:48:42.680
long tail compatibility, weird features, even if they're distasteful.

01:48:42.920 --> 01:48:47.880
And just do the hard work and figure it out, reverse engineer, understand what it is,

01:48:47.880 --> 01:48:50.120
write a bunch of test cases, try to understand the behavior.

01:48:51.080 --> 01:48:55.080
It's way easier to do all that work as an engineer than it is to go talk to all C

01:48:55.080 --> 01:48:58.120
programmers and argue with them and try to get them to rewrite their code.

01:49:00.760 --> 01:49:02.760
Because that breaks a lot more things.

01:49:02.760 --> 01:49:03.240
Yeah.

01:49:03.240 --> 01:49:07.080
And you have realities like nobody actually understands how the code

01:49:07.080 --> 01:49:11.720
works because it was written by the person who quit 10 years ago, right?

01:49:11.720 --> 01:49:16.280
And so this software is kind of frustrating that way.

01:49:16.280 --> 01:49:18.920
But that's how the world works.

01:49:18.920 --> 01:49:19.160
Yeah.

01:49:19.160 --> 01:49:22.440
Unfortunately, it can never be this perfect, beautiful thing.

01:49:23.000 --> 01:49:27.160
Well, there are occasions in which you get to build like, you know, you invent a new

01:49:27.960 --> 01:49:29.240
data structure or something like that.

01:49:29.240 --> 01:49:32.040
Or there's this beautiful algorithm that just like makes you super happy.

01:49:32.040 --> 01:49:33.800
And I love that moment.

01:49:33.800 --> 01:49:37.800
But when you're working with people and you're working with code and dusty

01:49:37.800 --> 01:49:39.480
decode bases and things like this, right?

01:49:40.520 --> 01:49:42.760
That's not about what's theoretically beautiful.

01:49:42.760 --> 01:49:43.880
It's about what's practical.

01:49:43.880 --> 01:49:45.640
What's real, what people actually use.

01:49:45.640 --> 01:49:49.480
And I don't meet a lot of people that say, I want to rewrite all my code.

01:49:50.520 --> 01:49:51.320
Just for the sake of it.

01:49:52.440 --> 01:49:54.120
By the way, there could be interesting possibilities.

01:49:54.120 --> 01:49:57.720
And we'll probably talk about it where AI can help rewrite some code that might be

01:49:58.920 --> 01:50:02.760
farther out future, but it's a really interesting one, how that could create more

01:50:03.080 --> 01:50:09.560
or be a tool in the battle against this monster of complexity that you mentioned.

01:50:09.560 --> 01:50:09.800
Yeah.

01:50:12.520 --> 01:50:17.240
You mentioned Guido, the benevolent dictator for life of Python.

01:50:17.240 --> 01:50:18.920
What does he think about Mojo?

01:50:18.920 --> 01:50:20.280
Have you talked to him much about it?

01:50:21.080 --> 01:50:22.200
I have talked with him about it.

01:50:22.200 --> 01:50:23.240
He found it very interesting.

01:50:23.880 --> 01:50:25.960
We actually talked with Guido before it launched.

01:50:25.960 --> 01:50:27.880
And so he was aware of it before it went public.

01:50:28.600 --> 01:50:31.240
I have a ton of respect for Guido for a bunch of different reasons.

01:50:31.240 --> 01:50:37.000
You talk about walrus operator and like Guido is pretty amazing in terms of

01:50:37.960 --> 01:50:44.200
steering such a huge and diverse community and like driving it forward.

01:50:44.200 --> 01:50:48.360
And I think Python is what it is thanks to him, right?

01:50:48.360 --> 01:50:52.920
And so to me, it was really important starting to work on Mojo to get his feedback

01:50:52.920 --> 01:50:55.400
and get his input and get his eyes on this, right?

01:50:56.120 --> 01:51:02.520
Now, a lot of what Guido was and is I think concerned about is how do we not fragment

01:51:02.520 --> 01:51:03.080
the community?

01:51:03.800 --> 01:51:05.480
We don't want a Python 2 to Python 3 thing.

01:51:06.600 --> 01:51:09.000
That was really painful for everybody involved.

01:51:09.000 --> 01:51:11.960
And so we spent quite a bit of time talking about that and some of the tricks I learned

01:51:11.960 --> 01:51:13.480
from Swift, for example.

01:51:13.480 --> 01:51:17.640
So in the migration from Swift, we managed to not just convert

01:51:18.760 --> 01:51:21.800
Objective-C into a slightly prettier Objective-C, which we did.

01:51:22.440 --> 01:51:28.120
We then converted, not entirely, but almost an entire community to a completely different

01:51:28.120 --> 01:51:30.120
language, right?

01:51:30.120 --> 01:51:33.960
And so there's a bunch of tricks that you learn along the way that are directly relevant

01:51:33.960 --> 01:51:34.760
to what we do.

01:51:34.760 --> 01:51:40.600
And so this is where, for example, you leverage CPython while bringing up the new thing.

01:51:41.320 --> 01:51:45.080
That approach is, I think, proven and comes from experience.

01:51:45.080 --> 01:51:47.880
And so Guido was very interested in like, okay, cool.

01:51:48.520 --> 01:51:50.360
I think that Python is really his legacy.

01:51:50.360 --> 01:51:51.240
It's his baby.

01:51:51.240 --> 01:51:53.000
I have tons of respect for that.

01:51:53.000 --> 01:51:55.720
Incidentally, I see Mojo as a member of the Python family.

01:51:55.720 --> 01:51:58.920
I'm not trying to take Python away from Guido and from the Python community.

01:52:01.080 --> 01:52:05.320
And so to me, it's really important that we're a good member of that community.

01:52:05.320 --> 01:52:09.400
And so I think that, again, you would have to ask Guido this, but I think that he was

01:52:09.400 --> 01:52:14.040
very interested in this notion of like, cool, Python gets beaten up for being slow.

01:52:15.640 --> 01:52:18.840
Maybe there's a path out of that, right?

01:52:18.840 --> 01:52:23.000
And that, you know, the future is Python, right?

01:52:23.000 --> 01:52:28.200
I mean, look at the far outside case on this, right?

01:52:28.200 --> 01:52:32.760
And I'm not saying this is Guido's perspective, but, you know, there's this path of saying

01:52:32.760 --> 01:52:37.000
like, okay, well, suddenly Python can suddenly go all the places it's never been able to

01:52:37.000 --> 01:52:38.440
go before, right?

01:52:38.440 --> 01:52:42.280
And that means that Python can go even further and can have even more impact on the world.

01:52:42.280 --> 01:52:47.240
So in some sense, Mojo could be seen as Python 4.0.

01:52:48.040 --> 01:52:49.160
I would not say that.

01:52:49.160 --> 01:52:51.320
I think that would drive a lot of people really crazy.

01:52:51.320 --> 01:52:53.960
Because of the PTSD of the 3.02.

01:52:53.960 --> 01:52:57.640
I'm willing to annoy people about Emacs versus Vim versus Spaces.

01:52:57.640 --> 01:52:58.440
Not that one.

01:52:58.440 --> 01:52:58.920
I don't know.

01:52:58.920 --> 01:53:00.280
That might be a little bit far even for me.

01:53:00.280 --> 01:53:02.120
Like my skin may not be that thick.

01:53:02.120 --> 01:53:07.640
But the point is the step to being a superset and allowing all of these capabilities, I

01:53:07.640 --> 01:53:10.120
think, is the evolution of a language.

01:53:10.120 --> 01:53:11.960
It feels like an evolution of a language.

01:53:12.680 --> 01:53:17.560
So he's interested by the ideas that you're playing with, but also concerned about the

01:53:17.560 --> 01:53:18.280
fragmentation.

01:53:18.280 --> 01:53:20.760
So what are the ideas you've learned?

01:53:20.760 --> 01:53:21.720
What are you thinking about?

01:53:21.720 --> 01:53:24.280
How do we avoid fragmenting the community?

01:53:24.280 --> 01:53:31.720
Where the Pythonistas and the, I don't know what to call the Mojo people.

01:53:32.360 --> 01:53:33.160
Magicians.

01:53:33.160 --> 01:53:33.880
Magicians.

01:53:33.880 --> 01:53:34.360
I like it.

01:53:35.320 --> 01:53:41.640
Can coexist happily and share code and basically just have these big code bases that are

01:53:41.640 --> 01:53:46.040
using CPython and more and more moving towards Mojo.

01:53:46.040 --> 01:53:48.520
Well, so again, these are lessons I learned from Swift.

01:53:48.520 --> 01:53:51.080
And here we face very similar problems, right?

01:53:51.080 --> 01:53:53.960
In Swift, you have Objective-C, SuperDynamic.

01:53:56.520 --> 01:53:59.800
They're very different syntax, right?

01:53:59.800 --> 01:54:02.520
But you're talking to people who have large scale code bases.

01:54:03.080 --> 01:54:07.800
I mean, Apple's got the biggest, largest scale code base of Objective-C code, right?

01:54:07.800 --> 01:54:11.640
And so, you know, none of the companies, none of the iOS developers, none of the other

01:54:11.640 --> 01:54:14.680
developers want to rewrite everything all at once since you want to be able to adopt

01:54:14.680 --> 01:54:16.120
things piece at a time.

01:54:16.120 --> 01:54:19.560
And so a thing that I found that worked very well in the Swift community was saying,

01:54:20.120 --> 01:54:20.840
okay, cool.

01:54:20.840 --> 01:54:23.080
And this is when Swift was very young.

01:54:23.080 --> 01:54:26.920
And she said, okay, you have a million line of code Objective-C app.

01:54:27.800 --> 01:54:29.240
Don't rewrite it all.

01:54:29.240 --> 01:54:35.240
But when you implement a new feature, go implement that new class using Swift, right?

01:54:35.320 --> 01:54:39.480
And so now this turns out is a very wonderful thing for an app developer.

01:54:40.280 --> 01:54:44.920
But it's a huge challenge for this compiler team and the systems people that are implementing

01:54:44.920 --> 01:54:45.480
this, right?

01:54:45.480 --> 01:54:50.440
And this comes back to what is this trade-off between doing the hard thing that enables

01:54:50.440 --> 01:54:53.960
scale versus doing the theoretically pure and ideal thing, right?

01:54:53.960 --> 01:54:58.840
And so Swift had adopted and built a lot of different machinery to deeply integrate with

01:54:58.840 --> 01:55:00.120
the Objective-C runtime.

01:55:00.120 --> 01:55:02.520
And we're doing the same thing with Python, right?

01:55:02.520 --> 01:55:07.640
Now, what happened in the case of Swift is that Swift's language got more and more and

01:55:07.640 --> 01:55:09.800
more mature over time, right?

01:55:09.800 --> 01:55:13.240
And incidentally, Mojo is a much simpler language than Swift in many ways.

01:55:13.240 --> 01:55:16.760
And so I think that Mojo will develop way faster than Swift for a variety of reasons.

01:55:17.720 --> 01:55:21.400
But as the language gets more mature, in parallel with that, you have new people starting

01:55:21.400 --> 01:55:23.480
new projects, right?

01:55:23.480 --> 01:55:27.080
And so when the language is mature and somebody is starting a new project, that's when they

01:55:27.080 --> 01:55:27.720
say, okay, cool.

01:55:27.720 --> 01:55:29.800
I'm not dealing with a million lines of code.

01:55:29.800 --> 01:55:32.360
I'll just start and use the new thing for my whole stack.

01:55:33.080 --> 01:55:37.640
Now, the problem is, again, you come back to where communities and where people that

01:55:37.640 --> 01:55:43.080
work together, you build a new subsystem or a new feature, a new thing in Swift, or you

01:55:43.080 --> 01:55:49.240
build a new thing in Mojo, then you end up being used on the other side, right?

01:55:49.240 --> 01:55:51.880
And so then you need to work on integration back the other way.

01:55:52.680 --> 01:55:55.240
And so it's not just Mojo talking to Python.

01:55:55.240 --> 01:55:57.800
It's also Python talking to Mojo, right?

01:55:57.880 --> 01:56:01.160
And so what I would love to see, and I don't want to see this next month, right?

01:56:01.160 --> 01:56:05.160
But what I want to see over the course of time is I would love to see people that are

01:56:05.160 --> 01:56:13.160
building these packages, like NumPy or TensorFlow or these packages that are half Python,

01:56:13.160 --> 01:56:14.040
half C++.

01:56:15.000 --> 01:56:21.560
And if you say, okay, cool, I want to get out of this Python C++ world into a unified

01:56:21.560 --> 01:56:26.120
world, and so I can move to Mojo, but I can't give up all my Python clients.

01:56:27.080 --> 01:56:32.840
Because these libraries get used by everybody, and they're not all going to switch all once,

01:56:32.840 --> 01:56:34.840
and maybe never, right?

01:56:34.840 --> 01:56:39.720
Well, so the way we should do that is we should vend Python interfaces to the Mojo types.

01:56:40.760 --> 01:56:42.760
And that's what we did in Swift, and it worked great.

01:56:42.760 --> 01:56:46.120
I mean, it was a huge implementation challenge for the compiler people, right?

01:56:46.120 --> 01:56:50.760
But there's only a dozen of those compiler people, and there are millions of users.

01:56:50.840 --> 01:56:57.240
And so it's a very expensive, capital-intensive, like, skill set-intensive problem.

01:56:57.240 --> 01:57:00.040
But once you solve that problem, it really helps adoption.

01:57:00.040 --> 01:57:02.920
It really helps the community progressively adopt technologies.

01:57:02.920 --> 01:57:07.080
And so I think that this approach will work quite well with the Python and the Mojo world.

01:57:07.080 --> 01:57:11.640
So for a package, port it to Mojo and then create a Python interface.

01:57:11.640 --> 01:57:12.140
Yep.

01:57:13.880 --> 01:57:19.560
So how do just to linger on these packages, NumPy, PyTorch, and TensorFlow?

01:57:19.560 --> 01:57:19.880
Yeah.

01:57:19.880 --> 01:57:21.320
How do they play nicely together?

01:57:21.320 --> 01:57:24.040
So is Mojo supposed to be...

01:57:24.040 --> 01:57:25.560
Let's talk about the machine learning ones.

01:57:26.840 --> 01:57:32.760
Is Mojo kind of vision to replace PyTorch and TensorFlow to incorporate it?

01:57:32.760 --> 01:57:34.920
What's the relationship in this?

01:57:34.920 --> 01:57:37.240
All right. So take a step back.

01:57:37.240 --> 01:57:39.240
So I wear many hats.

01:57:40.360 --> 01:57:43.000
So you're angling in on the Mojo side.

01:57:43.000 --> 01:57:43.400
Yes.

01:57:43.400 --> 01:57:44.760
Mojo is a programming language.

01:57:44.760 --> 01:57:50.120
And so it can help solve the C, C++ Python feud that's happening.

01:57:50.120 --> 01:57:51.800
The fire emoji got me. I'm sorry.

01:57:51.800 --> 01:57:53.560
We should be talking modular.

01:57:53.560 --> 01:57:54.060
Yes.

01:57:54.520 --> 01:57:56.680
Okay. So the fire emoji is amazing. I love it.

01:57:58.280 --> 01:57:58.920
It's a big deal.

01:57:59.640 --> 01:58:04.280
The other side of this is the fire emoji is in service of solving some big AI problems.

01:58:04.280 --> 01:58:04.920
Yes.

01:58:04.920 --> 01:58:09.000
Right. And so the big AI problems are, again, this fragmentation, this hardware nightmare,

01:58:09.080 --> 01:58:15.320
this explosion of new potential, but that's not getting felt by the industry.

01:58:16.520 --> 01:58:20.360
When you look at how does the modular engine help TensorFlow and PyTorch,

01:58:20.360 --> 01:58:21.320
it's not replacing them.

01:58:22.120 --> 01:58:26.200
In fact, when I talk to people, again, they don't like to rewrite all their code.

01:58:26.200 --> 01:58:29.400
You have people that are using a bunch of PyTorch, a bunch of TensorFlow.

01:58:29.960 --> 01:58:33.160
They have models that they've been building over the course of many years.

01:58:33.160 --> 01:58:35.880
And when I talk to them, there's a few exceptions,

01:58:35.880 --> 01:58:38.120
but generally they don't want to rewrite all their code.

01:58:39.400 --> 01:58:42.920
And so what we're doing is we're saying, okay, well, you don't have to rewrite all your code.

01:58:42.920 --> 01:58:47.160
What happens is the modular engine goes in there and goes underneath TensorFlow and PyTorch.

01:58:47.160 --> 01:58:48.600
It's fully compatible.

01:58:48.600 --> 01:58:51.880
And it just provides better performance, better predictability, better tooling.

01:58:52.680 --> 01:58:56.760
It's a better experience that helps lift TensorFlow and PyTorch and make them even better.

01:58:56.760 --> 01:59:00.120
I love Python. I love TensorFlow. I love PyTorch.

01:59:00.120 --> 01:59:03.800
This is about making the world better because we need AI to go further.

01:59:04.360 --> 01:59:07.000
But if I have a process that trains a model

01:59:07.000 --> 01:59:11.240
and I have a process that performs inference on that model and I have the model itself,

01:59:12.280 --> 01:59:15.400
what should I do with that in the long arc of history?

01:59:16.600 --> 01:59:23.800
In terms of if I use PyTorch to train it, should I rewrite stuff in Mojo if I care about performance?

01:59:24.440 --> 01:59:26.440
Oh, so I mean, again, it depends.

01:59:26.440 --> 01:59:30.760
So if you care about performance, then writing in Mojo is going to be way better than writing in Python.

01:59:30.760 --> 01:59:34.600
But if you look at LLM companies, for example,

01:59:34.760 --> 01:59:38.440
you look at OpenAI, rumored, and you look at many of the other folks that are working on

01:59:40.200 --> 01:59:43.640
many of these LLMs and other innovative machine learning models.

01:59:44.280 --> 01:59:47.560
On the one hand, they're innovating in the data collection and the model,

01:59:47.560 --> 01:59:54.920
billions of parameters in the model architecture and the RLEHF and all the cool things that people

01:59:54.920 --> 01:59:59.240
are talking about. But on the other hand, they're spending a lot of time writing CUDA girls.

01:59:59.480 --> 02:00:00.600
Mm-hmm.

02:00:00.600 --> 02:00:05.880
Right. And so you say, wait a second, how much faster could all this progress go if they were

02:00:05.880 --> 02:00:09.880
not having to handwrite all these CUDA girls? Right. And so there are a few technologies that

02:00:09.880 --> 02:00:14.440
are out there and people have been working on this problem for a while and they're trying to

02:00:14.440 --> 02:00:18.120
solve subsets of the problem, again, kind of fragmenting the space. And so what Mojo provides

02:00:18.120 --> 02:00:22.200
for these kinds of companies is the ability to say, cool, I can have a unifying theory.

02:00:23.160 --> 02:00:28.120
Right. And again, the better together, the unifying theory, the two-world problem or the

02:00:28.120 --> 02:00:32.280
three-world problem or the end-world problem. This is the thing that is slowing people down.

02:00:32.280 --> 02:00:35.480
And so as we help solve this problem, I think it'll be very helpful for making

02:00:36.040 --> 02:00:37.400
this whole cycle go faster.

02:00:38.040 --> 02:00:42.040
So obviously, we've talked about the transition from Objective C to Swift,

02:00:42.040 --> 02:00:47.880
if designed this programming language. And you've also talked quite a bit about the use

02:00:47.880 --> 02:00:55.240
of Swift for machine learning context. Why have you decided to move away from

02:00:56.040 --> 02:01:02.040
maybe an intense focus on Swift for the machine learning context versus sort of designing

02:01:02.600 --> 02:01:05.640
a new programming language that happens to be a superset?

02:01:05.640 --> 02:01:08.120
You're saying this is an irrational set of life choices I make?

02:01:08.120 --> 02:01:16.520
Did you go to the desert and did you meditate on it? Okay. All right. No, it was bold and needed.

02:01:16.520 --> 02:01:22.040
And I think, I mean, it's just bold. And sometimes to take those leaps is a difficult leap to take.

02:01:22.840 --> 02:01:26.920
Yeah. Well, so, okay. I mean, I think there's a couple of different things. So actually,

02:01:26.920 --> 02:01:33.400
I left Apple back in 2017, like January 2017. So it's been a number of years that

02:01:33.400 --> 02:01:35.960
I left Apple. And the reason I left Apple was to do AI.

02:01:38.680 --> 02:01:46.200
Okay. So, and again, I won't comment on Apple and AI, but at the time, right, I wanted to get

02:01:46.200 --> 02:01:49.400
into and understand and understand the technology, understand the applications,

02:01:49.480 --> 02:01:54.200
workloads. And so I was like, okay, I'm going to go dive deep into applied AI and then the

02:01:54.200 --> 02:01:58.600
technology underneath it. Right. I found myself at Google.

02:01:59.240 --> 02:02:02.520
And that was like when TPUs were waking up.

02:02:02.520 --> 02:02:08.360
Exactly. And so I found myself at Google and Jeff Dean, who's a rock star, as you know,

02:02:08.360 --> 02:02:14.440
right. And 2017, TensorFlow is like really taking off and doing incredible things.

02:02:15.000 --> 02:02:19.320
And I was attracted to Google to help them with the TPUs. Right. And TPUs are an innovative

02:02:19.320 --> 02:02:24.760
hardware accelerator platform, have now, I mean, I think proven massive scale and like

02:02:24.760 --> 02:02:30.360
done incredible things. Right. And so one of the things that this led into is a bunch of

02:02:30.360 --> 02:02:35.160
different projects, which I'll skip over. Right. One of which was the Swift for TensorFlow project.

02:02:35.160 --> 02:02:40.280
Right. And so that project was a research project. And so the idea of that is say,

02:02:40.280 --> 02:02:44.040
okay, well, let's look at innovative new programming models where we can get

02:02:44.600 --> 02:02:48.840
a fast programming language. We can get automatic differentiation into language.

02:02:48.840 --> 02:02:55.160
Let's push the boundaries of these things in a research setting. Right. Now that project,

02:02:55.160 --> 02:02:59.160
I think, lasted two, three years. There's some really cool outcomes of that. So one of the

02:02:59.160 --> 02:03:06.120
things that's really interesting is I published a talk at an LLVM conference in 2018. Again,

02:03:06.120 --> 02:03:11.400
this seems like so long ago about graph program abstraction, which is basically the thing that's

02:03:11.400 --> 02:03:16.200
in PyTorch 2. And so PyTorch 2 with all this Dynamo Rio thing, it's all about this graph

02:03:16.200 --> 02:03:22.200
program abstraction thing from Python bytecodes. And so a lot of the research that was done ended

02:03:22.200 --> 02:03:26.680
up pursuing and going out through the industry and influencing things. And I think it's super

02:03:26.680 --> 02:03:30.840
exciting and awesome to see that. But the Swift for TensorFlow project itself did not work out

02:03:30.840 --> 02:03:35.960
super well. And so there's a couple of different problems with that. One of which is that you may

02:03:35.960 --> 02:03:43.080
have noticed Swift is not Python. There's a few people that write Python code. Yes. And so it

02:03:43.080 --> 02:03:47.720
turns out that all of ML is pretty happy with Python. It's actually a problem that

02:03:47.720 --> 02:03:53.000
other programming languages have as well, that they're not Python. We'll probably maybe briefly

02:03:53.000 --> 02:03:57.800
talk about Julia, who's a very interesting, beautiful programming language, but it's not

02:03:57.800 --> 02:04:03.560
Python. Exactly. Well, and so if you're saying, I'm going to solve a machine learning problem

02:04:03.560 --> 02:04:08.120
where all the programmers are Python programmers, and you say the first thing you have to do is

02:04:08.120 --> 02:04:13.560
switch to a different language. Well, your new thing may be good or bad or whatever, but if it's

02:04:13.560 --> 02:04:19.240
a new thing, the adoption barrier is massive. It's still possible. Still possible. Yeah,

02:04:19.240 --> 02:04:23.400
absolutely. The world changes and evolves and there's definitely room for new and good ideas,

02:04:23.400 --> 02:04:29.240
but it just makes it so much harder. Right. And so lesson learned, Swift is not Python,

02:04:29.240 --> 02:04:32.760
and people are not always in search of like learning a new thing for the sake of learning

02:04:32.760 --> 02:04:36.200
a new thing. And if you want to be compatible with all the world's code turns out,

02:04:36.200 --> 02:04:43.320
meet the world where it is. Right. Second thing is that, you know, a lesson learned is that Swift

02:04:43.320 --> 02:04:49.000
as a very fast and efficient language, kind of like Mojo, but a different take on it still,

02:04:50.520 --> 02:04:56.200
really worked well with eager mode. And so eager mode is something that PyTorch does,

02:04:56.200 --> 02:05:02.120
and it proved out really well, and it enables really expressive and dynamic and easy to debug

02:05:02.200 --> 02:05:07.160
and easy to debug programming. TensorFlow at the time was not set up for that.

02:05:08.280 --> 02:05:12.040
Let's say that was not. The timing is also important in this world. Yeah,

02:05:12.040 --> 02:05:18.760
yeah. And TensorFlow is a good thing and it has many, many strengths, but you could say

02:05:19.320 --> 02:05:22.520
Swift for TensorFlow is a good idea, except for the Swift and except for the TensorFlow part.

02:05:24.600 --> 02:05:28.360
So because it's not Python and TensorFlow because it's not. It wasn't set up for eager

02:05:28.360 --> 02:05:34.680
mode at the time. Yeah. It was 1.0. Exactly. And so one of the things about that is in the

02:05:34.680 --> 02:05:39.560
context of it being a research project, I'm very happy with the fact that we built a lot of really

02:05:39.560 --> 02:05:43.400
cool technology. We learned a lot of things. I think the ideas went on to have influence

02:05:43.400 --> 02:05:47.720
in other systems like PyTorch. A few people use that I hear. Right. And so I think that's super

02:05:47.720 --> 02:05:52.680
cool. And for me personally, I learned so much from it. Right. And I think a lot of the engineers

02:05:52.680 --> 02:05:57.880
that worked on it also learned a tremendous amount. And so, you know, I think that that's just

02:05:57.880 --> 02:06:02.120
really exciting to see. And, you know, I'm sorry that the project didn't work out. I wish it did,

02:06:02.120 --> 02:06:09.240
of course. Right. But, you know, it's a research project and so you're there to learn from it.

02:06:09.240 --> 02:06:16.680
Well, it's interesting to think about the evolution of programming as we come up with these

02:06:17.400 --> 02:06:22.840
whole new set of algorithms in machine learning and artificial intelligence and what's going to

02:06:22.840 --> 02:06:29.240
win out because it could be a new programming language. Yeah, it could be. I mean, I just

02:06:29.240 --> 02:06:37.960
mentioned Julia. I think there's a lot of ideas behind Julia that Mojo shares. What are your

02:06:37.960 --> 02:06:45.320
thoughts about Julia in general? So I will have to say that when we launched Mojo, one of the

02:06:45.320 --> 02:06:51.080
biggest things I didn't predict was the response from the Julia community. And so I was not,

02:06:51.080 --> 02:06:55.960
I mean, I've, okay, let me take a step back. I've known the Julia folks for a really long time.

02:06:55.960 --> 02:07:00.760
They're an adopter of LLVM a long time ago. They've been pushing state of the art in a

02:07:00.760 --> 02:07:05.960
bunch of different ways. Julia is a really cool system. I had always thought of Julia as being

02:07:05.960 --> 02:07:12.680
mostly a scientific computing focused environment. Right. And I thought that was its focus. I

02:07:12.680 --> 02:07:19.160
neglected to understand that one of their missions is to like help make Python work end to end.

02:07:20.120 --> 02:07:23.880
And so I think that was my error for not understanding that. And so I could have been

02:07:23.880 --> 02:07:29.080
maybe more sensitive to that, but there's major differences between what Mojo is doing and what

02:07:29.080 --> 02:07:34.200
Julia is doing. So as you say, Julia is not Python. Right. And so one of the things that

02:07:34.760 --> 02:07:39.960
a lot of the Julia people came out and said is like, okay, well, if we put a ton of more energy

02:07:39.960 --> 02:07:46.360
and ton more money or engineering or whatever into Julia, maybe that would be better than starting

02:07:46.360 --> 02:07:51.320
Mojo. Right. Well, I mean, maybe that's true, but it still wouldn't make Julia into Python.

02:07:52.280 --> 02:07:57.160
So if you've worked backwards from the goal of let's build something for Python programmers

02:07:57.160 --> 02:08:04.440
without requiring them to relearn syntax, then Julia just isn't there. Right. I mean,

02:08:04.440 --> 02:08:09.880
that's a different thing. Right. And so if you anchor on, I love Julia and I want Julia to go

02:08:09.880 --> 02:08:14.680
further, then you can look at it from a different lens. But the lens we were coming at was, hey,

02:08:14.760 --> 02:08:20.280
everybody is using Python. Syntax isn't broken. Let's take what's great about Python and make

02:08:20.280 --> 02:08:24.200
it even better. And so it was just a different starting point. So I think Julia is a great

02:08:24.200 --> 02:08:28.360
language. The community is a lovely community. They're doing really cool stuff, but it's just a

02:08:28.360 --> 02:08:34.040
slightly different angle. But it does seem that Python is quite sticky. Is there some

02:08:36.280 --> 02:08:40.840
philosophical almost thing you could say about why Python by many measures seems to be the most

02:08:40.840 --> 02:08:45.000
popular programming language in the world? Well, I can tell you things I love about it. Maybe

02:08:45.000 --> 02:08:50.360
that's one way to answer the question. Right. So huge package ecosystem, super lightweight

02:08:50.360 --> 02:08:55.880
and easy to integrate. It has very low startup time. Right. So what startup time you mean?

02:08:57.160 --> 02:09:03.000
Yeah. So if you look at certain other languages, you say like go and it just takes like Java,

02:09:03.000 --> 02:09:08.040
for example, it takes a long time to compile all the things. And then the VM starts up and

02:09:08.040 --> 02:09:11.560
the garbage collectors kicks in and then it revs its engines. And then it can plow through a lot

02:09:11.560 --> 02:09:17.960
of internet stuff or whatever. Right. Python is like scripting. It just goes. Right. Python has

02:09:17.960 --> 02:09:22.200
very low compile time. Like, so you're not sitting there waiting. Python integrates into notebooks

02:09:22.200 --> 02:09:27.400
in a very elegant way that makes exploration super interactive. And it's awesome. Right.

02:09:27.400 --> 02:09:34.200
Python is also it's like almost the glue of computing because it has such a simple object

02:09:34.200 --> 02:09:39.000
representation. A lot of things plug into it. That dynamic metaprogramming thing we were talking

02:09:39.000 --> 02:09:43.640
about also enables really expressive and beautiful APIs. Right. So there's lots of reasons that you

02:09:43.640 --> 02:09:49.160
can look at technical things that Python has done and say like, okay, wow, this is actually

02:09:49.160 --> 02:09:54.520
a pretty amazing thing. And any one of those you can neglect. People all just talk about indentation

02:09:55.400 --> 02:10:00.360
and ignore like the fundamental things. But then you also look at the community side. Right. So

02:10:00.360 --> 02:10:05.160
Python owns machine learning. Machine learning is pretty big. Yeah. And it's growing. And it's

02:10:05.160 --> 02:10:09.080
growing. Right. And it's growing in importance. Right. And so and there's a reputation and prestige

02:10:09.080 --> 02:10:13.640
to machine learning to where like if you're a new programmer, you're thinking about like

02:10:14.440 --> 02:10:18.920
which programming language do I use? Well, I should probably care about machine learning. Therefore,

02:10:18.920 --> 02:10:24.520
let me try Python and kind of builds and builds and builds. And even go back before that. Like

02:10:24.520 --> 02:10:29.640
my kids learn Python. Right. Not because I'm telling them to learn Python, but because

02:10:29.640 --> 02:10:34.520
were they rebelling against you or what? Well, they also learn scratch and things like this,

02:10:34.520 --> 02:10:38.920
too. But it's because Python is taught everywhere. Right. Because it's easy to learn. Right. And

02:10:38.920 --> 02:10:47.320
because it's pervasive. Right. In my day, we learn Java and C++. Yeah. Well, uphill both directions.

02:10:47.320 --> 02:10:52.040
But yes, I guess Python is the main language of teaching software engineering schools now. Yeah.

02:10:52.040 --> 02:10:57.400
Well, if you look at if you look at this, there's these growth cycles. Right. If you look at what

02:10:57.480 --> 02:11:02.680
causes things to become popular and then gain in popularity, there's reinforcing feedback loops

02:11:02.680 --> 02:11:06.520
and things like this. And I think Python has done again, the whole community has done a really good

02:11:06.520 --> 02:11:10.760
job of building those growth loops and help propel the ecosystem. And I think that again,

02:11:10.760 --> 02:11:13.960
you look at what you can get done with just a few lines of code. It's amazing.

02:11:14.520 --> 02:11:22.840
So this kind of self building loop is interesting to understand because when you look at Mojo,

02:11:22.840 --> 02:11:28.920
what it stands for, some of the features, it seems sort of clear that this is a good

02:11:28.920 --> 02:11:33.960
direction for programming languages to evolve in the machine learning community. But it's still

02:11:33.960 --> 02:11:40.200
not obvious that it will because of this, whatever the engine of popularity, of virality.

02:11:41.160 --> 02:11:46.440
Is there something you could speak to? Like how do you get people to switch? Yeah. Well, I mean,

02:11:46.440 --> 02:11:51.800
I think that the viral growth loop is to switch people to Unicode. Yes. I think the Unicode

02:11:51.800 --> 02:11:54.680
file extensions are what I'm betting on. I think that's going to be the thing.

02:11:54.680 --> 02:11:59.080
Yeah. Tell the kids that you could use the fire emoji and they'd be like, what?

02:11:59.080 --> 02:12:05.160
Exactly. Well, in all seriousness, like, I mean, I think there's really, I'll give you two

02:12:05.720 --> 02:12:11.880
opposite answers. One is I hope if it's useful, if it solves problems and people care about

02:12:11.880 --> 02:12:18.520
this problem being solved, they'll adopt the tech. That's kind of the simple answer. And when you're

02:12:18.520 --> 02:12:23.880
looking to get tech adopted, the question is, is it solving an important problem people need solved?

02:12:23.880 --> 02:12:31.240
And is the adoption cost low enough that they're willing to make the switch and cut over and do

02:12:31.240 --> 02:12:36.520
the pain upfront so that they can actually do it? Right. And so hopefully Mojo will be that for a

02:12:36.520 --> 02:12:42.280
bunch of people. And people building these hybrid packages are suffering. It's really painful. And

02:12:42.280 --> 02:12:46.760
so I think that we have a good shot of helping people. But the other side is like, it's okay if

02:12:46.760 --> 02:12:51.880
people don't use Mojo. It's not my job to say everybody should do this. I'm not saying Python

02:12:51.880 --> 02:12:56.120
is bad. I hope Python, CPython, all these implementations, because Python ecosystem

02:12:56.120 --> 02:12:59.720
is not just CPython. It's also a bunch of different implementations with different

02:12:59.720 --> 02:13:05.640
trade-offs. And this ecosystem is really powerful and exciting, as are other programming languages.

02:13:05.640 --> 02:13:10.920
It's not like TypeScript or something is going to go away. And so there's not a winner-take-all

02:13:10.920 --> 02:13:15.960
thing. And so I hope that Mojo is exciting and useful to people. But if it's not, that's also fine.

02:13:15.960 --> 02:13:24.760
But I also wonder what the use case for why you should try Mojo would be. So practically speaking,

02:13:25.800 --> 02:13:31.480
it seems like there's entertainment. There's the dopamine hit of saying,

02:13:31.480 --> 02:13:37.800
holy shit, this is 10 times faster. This little piece of code is 10 times faster in Mojo.

02:13:37.800 --> 02:13:40.520
Out of the box before you get to 35,000.

02:13:40.520 --> 02:13:46.920
Exactly. I mean, just even that. I mean, that's the dopamine hit that every programmer sort of

02:13:46.920 --> 02:13:54.760
dreams of is the optimization. It's also the drug that can pull you in and have you waste

02:13:54.760 --> 02:14:02.200
way too much of your life optimizing and over-optimizing, right? So what do you see

02:14:02.200 --> 02:14:07.640
that would be like comedy? This is very hard to predict, of course. But if you look 10 years

02:14:07.640 --> 02:14:14.600
from now and Mojo is super successful, what do you think would be the thing where people try it

02:14:14.600 --> 02:14:18.440
and then use it regularly and it kind of grows and grows and grows and grows?

02:14:18.440 --> 02:14:26.200
So you talk about dopamine hit. And so again, humans are not one thing. And some people love

02:14:26.200 --> 02:14:29.000
rewriting their code and learning new things and throwing themselves in the deep end and

02:14:29.000 --> 02:14:34.920
trying out new things. In my experience, most people don't. They're too busy. They have other

02:14:34.920 --> 02:14:40.520
things going on. By number, most people don't like this. I want to rewrite all my code.

02:14:42.280 --> 02:14:48.200
But even those people, the too busy people, the people that don't actually care about the

02:14:48.200 --> 02:14:52.280
language, just care about getting stuff done, those people do like learning new things,

02:14:53.400 --> 02:14:57.320
right? And so you talk about the dopamine rush of 10x faster. Wow, that's cool. I want to do

02:14:57.320 --> 02:15:01.560
that again. Well, it's also like, here's the thing I've heard about in a different domain

02:15:01.560 --> 02:15:05.880
and I don't have to rewrite all my code. I can learn a new trick, right? Well, that's called

02:15:05.880 --> 02:15:12.120
growth. And so, and so one thing that I think is cool about Mojo, and again, those will take a

02:15:12.120 --> 02:15:16.600
little bit of time for, for example, the blog posts and the books and like all that kind of stuff

02:15:16.600 --> 02:15:21.160
develop and the language needs to get further along. But what we're doing, you talk about types,

02:15:21.160 --> 02:15:25.640
like you can say, look, you can start with the world you already know, and you can progressively

02:15:25.640 --> 02:15:31.160
learn new things and adopt them where it makes sense. If you never do that, that's cool. You're

02:15:31.160 --> 02:15:35.480
not a bad person. If you, if you get really excited about it and want to go all the way in

02:15:35.480 --> 02:15:39.960
the deep end and rewrite everything and like whatever, that's cool, right? But I think the

02:15:39.960 --> 02:15:44.760
middle path is actually the more likely one where it's, you know, you, you come out with a new,

02:15:45.400 --> 02:15:49.960
a new idea and you discover, wow, that makes my code way simpler, way more beautiful, way faster,

02:15:49.960 --> 02:15:55.640
way whatever. And I think that's what people like. Now, if you fast forward and you said like 10

02:15:55.640 --> 02:16:00.360
years out, right? I can give you a very different answer on that, which is, I mean,

02:16:01.320 --> 02:16:03.880
if you go back and look at what computers look like 20 years ago,

02:16:05.240 --> 02:16:11.400
every 18 months, they got faster for free, right? 2x faster every 18 months. It was like clockwork.

02:16:11.400 --> 02:16:16.120
It was, it was free, right? You go back 10 years ago and we entered in this world where

02:16:16.120 --> 02:16:21.880
suddenly we had multi-core CPUs and we had GPUs. And if you squint and turn your head,

02:16:21.880 --> 02:16:27.320
what a GPU is, is it's just a many core, very simple CPU thing kind of, right? And so,

02:16:28.360 --> 02:16:31.320
and 10 years ago, it was CPUs and GPUs and graphics.

02:16:33.960 --> 02:16:41.320
Today, we have CPUs, GPUs, graphics, and AI, because it's so important because the compute

02:16:41.320 --> 02:16:46.040
is so demanding because of the smart cameras and the watches and all the different places the AI

02:16:46.040 --> 02:16:52.120
needs to work in our lives. It's caused this explosion of hardware. And so part of my thesis,

02:16:52.120 --> 02:16:55.480
part of my belief of where computing goes, if you look out 10 years from now,

02:16:56.120 --> 02:17:00.040
is it's not going to get simpler. Physics isn't going back to where we came from.

02:17:00.680 --> 02:17:05.640
It's only going to get weirder from here on out, right? And so to me, the exciting part about what

02:17:05.640 --> 02:17:11.960
we're building is it's about building that universal platform, which the world can continue

02:17:11.960 --> 02:17:16.840
to get weird because again, I don't think it's avoidable, it's physics, but we can help lift

02:17:16.840 --> 02:17:20.040
people scale, do things with it, and they don't have to rewrite their code every time a new device

02:17:20.040 --> 02:17:24.840
comes out. And I think that's pretty cool. And so if Mojo can help with that problem, then I think

02:17:24.840 --> 02:17:29.080
that it will be hopefully quite interesting and quite useful to a wide range of people

02:17:29.080 --> 02:17:33.960
because there's so much potential and like there's so many, you know, maybe analog computers will

02:17:33.960 --> 02:17:38.520
become a thing or something, right? And we need to be able to get into a mode where we can move

02:17:38.520 --> 02:17:43.640
this programming model forward, but do so in a way where we're lifting people and growing them

02:17:43.640 --> 02:17:46.600
instead of forcing them to rewrite all their code and exploding them.

02:17:46.600 --> 02:17:50.680
Do you think there'll be a few major libraries that go Mojo first?

02:17:53.640 --> 02:17:58.840
Well, so I mean, the modular engines all Mojo. So I can't come back to like, we're not building

02:17:58.840 --> 02:18:02.600
Mojo because it's fun. We're building Mojo because we had to to solve these accelerators.

02:18:02.600 --> 02:18:05.640
That's the origin story. But I mean ones that are currently in Python.

02:18:05.640 --> 02:18:08.920
Yeah. So I think that a number of these projects will. And so one of the things again,

02:18:08.920 --> 02:18:13.080
this is just my best guess. Like each of the package maintainers also has, I'm sure,

02:18:13.080 --> 02:18:16.680
plenty of other things going on. People don't like really don't like rewriting code just for

02:18:16.680 --> 02:18:23.800
the sake of rewriting code. But sometimes like people are excited about like adopting a new idea.

02:18:23.800 --> 02:18:27.720
Yeah. It turns out that while rewriting code is generally not people's first

02:18:28.920 --> 02:18:34.040
thing, turns out that redesigning something while you rewrite it and using a rewrite as an

02:18:34.040 --> 02:18:40.600
excuse to redesign can lead to the 2.0 of your thing. That's way better than the 1.0, right?

02:18:40.600 --> 02:18:45.960
And so I have no idea. I can't predict that. But there's a lot of these places where again,

02:18:45.960 --> 02:18:51.240
if you have a package that is half C and half Python, right, you just solve the pain,

02:18:51.240 --> 02:18:56.280
make it easier to move things faster, make it easy to debug and evolve your tech. Adopting

02:18:56.280 --> 02:18:59.560
Mojo kind of makes sense to start with. And then it gives you this opportunity to rethink these

02:18:59.560 --> 02:19:08.440
things. So the two big gains are that there's a performance gain and then there's the portability

02:19:08.440 --> 02:19:12.760
to all kinds of different devices. And there's safety, right? So you talk about real types.

02:19:13.960 --> 02:19:17.800
I mean, not saying this is for everybody, but that's actually a pretty big thing, right?

02:19:17.800 --> 02:19:23.080
Yeah, types are. And so there's a bunch of different aspects of what value Mojo provides.

02:19:23.080 --> 02:19:27.400
And so, I mean, it's funny for me, like I've been working on these kinds of technologies and tools

02:19:27.960 --> 02:19:33.240
for too many years now. But you look at Swift, right? And we talked about Swift for TensorFlow,

02:19:33.240 --> 02:19:41.160
but Swift as a programming language, right? Swift's now 13 years old from when I started it.

02:19:42.120 --> 02:19:48.440
Because I started in 2010, if I remember. And so that project, and I was involved with it for

02:19:49.000 --> 02:19:53.320
12 years or something, right? That project has gone through its own really interesting story,

02:19:53.320 --> 02:19:58.440
right? And it's a mature, successful, used by millions of people system, right? Certainly not

02:19:58.440 --> 02:20:03.640
dead yet, right? But also going through that story arc, I learned a tremendous amount about building

02:20:03.640 --> 02:20:08.520
languages, about building compilers, about working with community and things like this. And so that

02:20:08.520 --> 02:20:14.120
experience, like I'm helping channel and bring directly into Mojo and other systems, same thing.

02:20:14.120 --> 02:20:18.680
Apparently I like building and iterating and evolving things. And so you look at this LLVM

02:20:18.680 --> 02:20:23.800
thing I worked on 20 years ago, and you look at MLIR, right? And so a lot of the lessons learned

02:20:23.800 --> 02:20:30.760
in LLVM got fed into MLIR. And I think that MLIR is a way better system than LLVM was. And Swift

02:20:30.760 --> 02:20:37.240
is a really good system, and it's amazing. But I hope that Mojo will take the next step forward

02:20:37.240 --> 02:20:45.400
in terms of design. In terms of running Mojo, people can play with it. What's Mojo Playground?

02:20:45.480 --> 02:20:51.720
Yeah. And from the interface perspective, and from the hardware perspective, what's this

02:20:52.520 --> 02:20:57.560
incredible thing running on? Yeah, so right now, so here we are two weeks after launch.

02:20:57.560 --> 02:21:01.480
Yes. We decided that, okay, we have this incredible set of technology that

02:21:02.360 --> 02:21:07.160
we think might be good, but we have not given it to lots of people yet. And so we were very

02:21:07.160 --> 02:21:11.880
conservative and said, let's put it in a workbook. So if it crashes, we can do something about it.

02:21:11.880 --> 02:21:17.080
We can monitor and track that. And so again, things are still super early, but we're having

02:21:18.120 --> 02:21:25.960
one person a minute sign up with over 70,000 people two weeks in. It's kind of crazy.

02:21:25.960 --> 02:21:32.280
So you can sign up to Mojo Playground, and you can use it in the cloud, in your browser.

02:21:32.280 --> 02:21:35.320
And so what that's running on, yeah, what that's running on is that's running on

02:21:36.200 --> 02:21:41.560
cloud VMs. And so you share a machine with a bunch of other people. But it turns out there's

02:21:41.560 --> 02:21:45.160
a bunch of them now because there's a lot of people. And so what you're doing is you're

02:21:45.160 --> 02:21:48.920
getting free compute, and you're getting to play with this thing in kind of a limited,

02:21:48.920 --> 02:21:54.440
controlled way so that we can make sure that it doesn't totally crash and be embarrassing.

02:21:55.320 --> 02:21:58.840
So now a lot of the feedback we've gotten is people want to download it around locally. So

02:21:58.840 --> 02:22:02.920
we're working on that right now. And so that's the goal to be able to download locally.

02:22:02.920 --> 02:22:06.520
Yeah, that's what everybody expects. And so we're working on that right now. And so we just want

02:22:06.520 --> 02:22:11.160
to make sure that we do it right. And I think this is one of the lessons I learned from Swift also,

02:22:11.160 --> 02:22:16.760
by the way, is that when we launched Swift, gosh, it feels like forever ago, it was 2014.

02:22:17.320 --> 02:22:23.480
And we, I mean, it was super exciting. I and we, the team had worked on Swift for a number of

02:22:23.480 --> 02:22:30.760
years in secrecy. Okay. And we, four years into this development, roughly, of working on this

02:22:30.760 --> 02:22:36.760
thing, at that point, about 250 people at Apple knew about it. Okay, so it was secret. Apple's

02:22:36.760 --> 02:22:42.200
good at secrecy. And it was a secret project. And so we launched this at WWC, a bunch of hoopla

02:22:42.200 --> 02:22:47.000
and excitement and said, developers are going to be able to develop and submit apps to the app store

02:22:47.000 --> 02:22:52.680
in three months. Okay. Well, several interesting things happened, right? So first of all, we learned

02:22:52.680 --> 02:22:59.880
that, A, it had a lot of bugs. It was not actually production quality. And it was extremely stressful

02:22:59.880 --> 02:23:05.000
in terms of like, trying to get it working for a bunch of people. And so what happened was we went

02:23:05.000 --> 02:23:09.160
from zero to, you know, I don't know how many developers Apple had at the time, but a lot of

02:23:09.160 --> 02:23:14.440
developers overnight, and they ran into a lot of bugs. And it was really embarrassing. And it was

02:23:14.440 --> 02:23:18.840
very stressful for everybody involved, right? It was also very exciting because everybody was

02:23:18.840 --> 02:23:23.000
excited about that. The other thing I learned is that when that happened, roughly every software

02:23:23.000 --> 02:23:27.560
engineer who did not know about the project at Apple, their head exploded when it was launched,

02:23:27.560 --> 02:23:31.720
because they didn't know it was coming. And so they're like, wait, what is this? I signed up

02:23:31.720 --> 02:23:35.160
to work for Apple because I love Objective-C. Why is there a new thing? Right? And so

02:23:37.240 --> 02:23:43.080
now what that meant practically is that the push from launch to first of all the fall,

02:23:43.080 --> 02:23:49.560
but then to 2.0 and 3.0 and like all the way forward was super painful for the engineering

02:23:49.560 --> 02:23:55.000
team and myself. It was very stressful. The developer community was very grumpy about it

02:23:55.000 --> 02:23:58.440
because they're like, okay, well, wait a second, you're changing and breaking my code. And like,

02:23:58.440 --> 02:24:03.560
we have to fix the bugs. And it was just like a lot of tension and friction on all sides.

02:24:04.920 --> 02:24:09.480
There's a lot of technical debt in the compiler because we have to run really fast. You have to

02:24:09.480 --> 02:24:13.000
go implement the thing and unblock the use case and do the thing. And you know it's not right,

02:24:13.000 --> 02:24:17.560
but you never have time to go back and do it right. And I'm very proud of the Swift team because

02:24:17.560 --> 02:24:25.560
they've come, I mean, we, but they came so far and made so much progress over this time since

02:24:25.560 --> 02:24:29.880
launch. It's pretty incredible. And Swift is a very, very good thing, but I just don't want

02:24:29.880 --> 02:24:35.960
to do that again. Right. And so more iterate more through the development process. And so what we're

02:24:35.960 --> 02:24:41.400
doing is we're not launching it when it's hopefully 0.9 with no testers. We're launching it and saying

02:24:41.400 --> 02:24:46.360
it's 0.1. Right. And so we're saying expectations of saying like, okay, well, don't use this for

02:24:46.360 --> 02:24:51.960
production. Right. If you're interested in what we're doing, we'll do it in an open way and we can

02:24:52.040 --> 02:24:56.600
do it together, but don't use it in production yet. Like we'll get there, but let's do it the

02:24:56.600 --> 02:25:02.920
right way. And I'm also saying we're not in a race. The thing that I want to do is build the

02:25:02.920 --> 02:25:08.600
world's best thing. Right. Because if you do it right and it lifts the industry, it doesn't matter

02:25:08.600 --> 02:25:14.040
if it takes an extra two months. Like two months is worth waiting. And so doing it right and not

02:25:14.040 --> 02:25:20.200
being overwhelmed with technical debt and things like this is like, again, war wounds, lessons

02:25:20.280 --> 02:25:24.440
learned, whatever you want to say, I think is absolutely the right thing to do. Even though

02:25:24.440 --> 02:25:28.680
right now people are very frustrated that you can't download it or it doesn't have feature

02:25:28.680 --> 02:25:34.760
X or something like this. What have you learned in a little bit of time since it's been

02:25:35.880 --> 02:25:42.120
released into the wild that people have been complaining about feature X or Y or Z? What have

02:25:42.120 --> 02:25:48.280
they been complaining about? What they have been excited about? Like almost like detailed things

02:25:48.280 --> 02:25:53.560
versus I think everyone would be very excited about the big vision. Yeah. Yeah. Well, so,

02:25:53.560 --> 02:25:57.240
I mean, I've been very pleased. I mean, in fact, I mean, we've been massively overwhelmed

02:25:57.240 --> 02:26:03.240
with response, which is a good problem to have. It's kind of like a success disaster in a sense.

02:26:03.240 --> 02:26:10.680
Right. And so, I mean, if you go back in time, when we started Modular, which is just not yet

02:26:10.680 --> 02:26:16.680
a year and a half ago, so it's still a pretty new company, new team, small, but very good team of

02:26:16.680 --> 02:26:21.880
people. Like we started with extreme conviction that there's a set of problems that we need to

02:26:21.880 --> 02:26:26.760
solve. And if we solve it, then people will be interested in what we're doing. Right. But again,

02:26:26.760 --> 02:26:32.600
you're building in basically secret, right? You're trying to figure it out. The creation is a messy

02:26:32.600 --> 02:26:36.520
process. You're having to go through different paths and understand what you want to do and how

02:26:36.520 --> 02:26:41.560
to explain it. Often when you're doing disruptive and new kinds of things, just knowing how to

02:26:41.560 --> 02:26:47.560
explain it is super difficult. Right. And so when we launched, we hoped people would be excited,

02:26:48.200 --> 02:26:54.360
but, you know, I'm an optimist, but I'm also like, don't want to get ahead of myself. And so when

02:26:54.360 --> 02:26:59.240
people found out about Mojo, I think their heads exploded a little bit. Right. And, you know,

02:26:59.240 --> 02:27:03.480
here's a, I think a pretty credible team that has built some languages and some tools before. And

02:27:03.480 --> 02:27:09.320
so they have some lessons learned and are tackling some of the deep problems in the Python ecosystem

02:27:09.320 --> 02:27:13.240
and giving it the love and attention that it should be getting. And I think people got very

02:27:13.240 --> 02:27:17.560
excited about that. And so if you look at that, I mean, I think people are excited about ownership

02:27:17.560 --> 02:27:20.760
and taking a step beyond rust. Right. And there's people that are very excited about that. And

02:27:20.760 --> 02:27:26.680
there's people that are excited about, you know, just like I made game of life go 400 times faster.

02:27:27.640 --> 02:27:30.840
Right. And things like that. And that's really cool. There are people that are really excited

02:27:30.840 --> 02:27:35.880
about the, okay, I really hate writing stuff in C++. Save me. Like systems in your, they're like

02:27:35.880 --> 02:27:40.440
stepping up like, yeah, yes. So that's, that's, that's, that's, that's me by the way. Also,

02:27:41.480 --> 02:27:48.520
I really want to stop writing C++, but the, I get third person excitement when people tweet

02:27:49.320 --> 02:27:55.080
here, I made this code game of life or whatever faster. And you're like, yeah. Yeah. And also

02:27:55.080 --> 02:28:02.680
like, I would also say that, let me, let me cast blame out to people who deserve it. Sure. These

02:28:02.680 --> 02:28:08.520
terrible people who convinced me to do some of this. Yes. Jeremy Howard. Yes. That guy.

02:28:09.480 --> 02:28:13.800
Well, he's been pushing for this kind of thing. He's been pushing for years. Yeah. He's wanted

02:28:13.800 --> 02:28:16.920
this for a long, long time. He's wanted this for years. And so for people who don't know Jeremy

02:28:16.920 --> 02:28:20.680
Howard, he's like, he's like one of the most legit people in the machine learning community.

02:28:20.680 --> 02:28:26.760
He's, as a grassroots, he really teaches. He's an incredible educator. He's an incredible teacher,

02:28:26.760 --> 02:28:31.720
but also legit in terms of a machine learning engineer himself. Yeah. And he's been running

02:28:31.720 --> 02:28:40.360
the fast.ai and looking, I think for exactly what you exactly. And so, I mean, the first time,

02:28:40.360 --> 02:28:45.160
so I met Jeremy pretty early on, but the first time I sat up and I'm like,

02:28:46.120 --> 02:28:51.160
this guy is ridiculous is when I was at Google and we're bringing up TPUs and we had a whole

02:28:51.160 --> 02:28:57.400
team of people and we're, there was this competition called Dawnbench of who can train

02:28:58.120 --> 02:29:05.400
a image net fastest. Right. Yes. And Jeremy and one of his researchers crushed Google

02:29:06.920 --> 02:29:11.080
not through sheer force of the amazing amount of compute and the number of TPUs and stuff like

02:29:11.080 --> 02:29:16.040
that, that he just decided that progressive imagery sizing was the right way to train the model.

02:29:16.040 --> 02:29:22.440
And if you're an epoch faster and make the whole thing go, go vroom, right. And I'm like, this guy

02:29:22.520 --> 02:29:26.920
is incredible. Right. And so you can say, anyways, come back to, you know,

02:29:26.920 --> 02:29:33.080
where's Mojo coming from. Chris finally listened to Jeremy. It's all his fault.

02:29:33.080 --> 02:29:40.760
There's a kind of very refreshing, pragmatic view that he has about machine learning that

02:29:42.360 --> 02:29:50.120
I don't know if it's like this mix of a desire for efficiency, but ultimately grounded in a desire

02:29:50.120 --> 02:29:54.920
to make machine learning more accessible to a lot of people. I don't know what that is. I guess

02:29:54.920 --> 02:30:01.160
that's coupled with efficiency and performance, but it's not just obsessed about performance.

02:30:01.160 --> 02:30:06.440
So a lot of AI and AI research ends up being that it has to go fast enough to get scale.

02:30:07.080 --> 02:30:10.760
So a lot of people don't actually care about performance, particularly on the research side

02:30:10.760 --> 02:30:15.480
until it allows them to have more, a bigger data set. Right. And so suddenly now you care about

02:30:15.480 --> 02:30:19.880
distributed compute and like all these exotic HPC, like you don't actually want to know about

02:30:19.880 --> 02:30:24.040
that. You just want to be able to do more experiments faster and do so with bigger data

02:30:24.040 --> 02:30:28.760
sets. Right. And so Jeremy has been really pushing the limits. And one of the things I'll say about

02:30:28.760 --> 02:30:35.160
Jeremy, and there's many things I could say about Jeremy cause I'm a fanboy of his, but he, it fits

02:30:35.160 --> 02:30:41.240
in his head. And Jeremy actually takes the time where many people don't to really dive deep into

02:30:42.040 --> 02:30:48.200
why is the beta parameter of the atom optimizer equal to this. Right. And he'll go survey and

02:30:48.200 --> 02:30:52.200
understand what are all the activation functions and the trade-offs and why is it that everybody

02:30:52.200 --> 02:30:58.520
that does, you know, this model pick that thing. So the why, not just trying different values,

02:30:58.520 --> 02:31:03.800
like really what is going on here. Right. And so as a consequence of that, like he's always, he,

02:31:03.800 --> 02:31:08.840
again, he makes time, but he, he spends time to understand things at a depth that a lot of people

02:31:08.840 --> 02:31:15.080
don't. And as you say, he then brings it and teaches people and he's, his mission is to help

02:31:15.080 --> 02:31:21.000
lift, you know, his website says making AI uncool again. Like it's about like forget about the hype.

02:31:21.000 --> 02:31:25.240
It's actually practical and useful. Let's teach people how to do this. Right. Now the problem

02:31:25.240 --> 02:31:29.560
Jeremy struggled with is that he's pushing the envelope, right? Research isn't about doing the

02:31:29.560 --> 02:31:35.080
thing that is staying on the happy path or the, the well-paved road. Right. And so a lot of the

02:31:35.080 --> 02:31:39.400
systems today have been these really fragile, fragile, fragmented things or special case in

02:31:39.400 --> 02:31:43.400
this happy path. And if you fall off the happy path, you get eaten by an alligator.

02:31:45.320 --> 02:31:54.600
So what about, so Python has this giant ecosystem of packages and as a package repository,

02:31:54.600 --> 02:32:00.520
do you have ideas of how to do that? Well, from Mojo, how to do a repository of packages?

02:32:00.520 --> 02:32:04.840
Well, so that's another really interesting problem that I knew about, but I didn't

02:32:04.840 --> 02:32:10.680
understand how big of a problem it was. Python packaging. A lot of people have very big pain

02:32:10.680 --> 02:32:15.240
points and a lot of scars with Python packaging. Oh, you mean, so there's several things building

02:32:15.240 --> 02:32:20.280
and distributing and managing dependencies and versioning and all this stuff. So from the

02:32:20.280 --> 02:32:25.000
perspective of if you want to create your own package. Yes. And then, or you want to build on

02:32:25.000 --> 02:32:29.800
top of a bunch of other people's packages and then they get updated and it's like this. Now I'm not an

02:32:29.800 --> 02:32:35.480
expert in this, so I don't know the answer. I think this is one of the reasons why it's great

02:32:35.480 --> 02:32:42.760
that we work as a team and there's other really good and smart people involved. But one of the

02:32:42.760 --> 02:32:47.640
things I've heard from smart people who've done a lot of this is that the packaging becomes a

02:32:47.640 --> 02:32:52.600
huge disaster when you get the Python and C together. And so if you have this problem where

02:32:52.600 --> 02:32:58.120
you have code split between Python and C, now not only do you have to package the C code,

02:32:58.120 --> 02:33:03.560
you have to build the C code. C doesn't have a package manager. C doesn't have a dependency

02:33:03.560 --> 02:33:09.080
versioning management system. And so I'm not experienced in the state of the art and

02:33:10.680 --> 02:33:14.520
all the different Python package managers, but my understanding is that's a massive

02:33:14.520 --> 02:33:18.680
part of the problem. And I think Mojo solves that part of the problem directly heads on.

02:33:19.240 --> 02:33:24.120
Now, one of the things I think we'll do with the community, and this isn't, again, we're not solving

02:33:24.120 --> 02:33:28.360
all the world's problems at once, we have to be kind of focused to start with, is that I think

02:33:28.360 --> 02:33:33.320
that we will have an opportunity to reevaluate packaging. And so I think that we can come back

02:33:33.320 --> 02:33:37.240
and say, okay, well, given the new tools and technologies and the cool things we have that

02:33:37.240 --> 02:33:41.720
we've built up, because we have not just syntax, we have an entirely new compiler stack that works

02:33:41.720 --> 02:33:45.960
in a new way, maybe there's other innovations we can bring together and maybe we can help solve

02:33:45.960 --> 02:33:50.440
that problem. So almost a tangent to that question from the user perspective of packages.

02:33:50.440 --> 02:33:58.120
It was always surprising to me that it was not easier to sort of explore and find packages.

02:34:01.320 --> 02:34:09.800
With pip install, it's an incredible ecosystem. It's just interesting that it wasn't made,

02:34:09.800 --> 02:34:18.520
it's still, I think, not made easier to discover packages to do like search and discovery,

02:34:18.520 --> 02:34:22.920
as YouTube calls it. Well, I mean, it's kind of funny because this is one of the challenges of

02:34:22.920 --> 02:34:28.840
these intentionally decentralized communities. And so I don't know what the right answer is for

02:34:28.840 --> 02:34:33.640
Python. I mean, there are many people that would, or I don't even know the right answer for Mojo.

02:34:35.080 --> 02:34:39.240
So there are many people that would have much more informed opinions than I do. But it's

02:34:39.240 --> 02:34:45.320
interesting if you look at this, right? Open source communities, there's Git, Git is a fully

02:34:45.320 --> 02:34:50.040
decentralized, anybody can do it any way they want. But then there's GitHub, right? And GitHub,

02:34:50.040 --> 02:34:55.800
centralized, commercial in that case, right, thing, really help pull together and help solve

02:34:55.800 --> 02:35:01.000
some of the discovery problems and help build a more consistent community. And so maybe there's

02:35:01.000 --> 02:35:06.440
opportunities for something like a GitHub. Although even GitHub, I might be wrong on this,

02:35:06.440 --> 02:35:12.200
but the search and discovery for GitHub is not that great. Like I still use Google search.

02:35:13.000 --> 02:35:16.760
Yeah. Well, I mean, maybe that's because GitHub doesn't want to replace Google search.

02:35:17.720 --> 02:35:23.640
Right. And I think there is room for specialized solutions to specific problems. Sure. I don't know.

02:35:23.640 --> 02:35:27.640
I don't know the right answer for GitHub either. They can go figure that out.

02:35:28.600 --> 02:35:32.200
But the point is to have an interface that's usable, that's accessible to people of all

02:35:32.200 --> 02:35:36.600
different skill levels. Well, and again, like what are the benefit of standards, right? Standards

02:35:36.600 --> 02:35:41.640
allow you to build these next level up ecosystem, the next level up infrastructure, next level up

02:35:41.640 --> 02:35:48.600
things. And so again, come back to, I hate complexity. C plus Python is complicated.

02:35:49.160 --> 02:35:53.720
It makes everything more difficult to deal with. It makes it difficult to port, move code around,

02:35:53.720 --> 02:35:58.520
work with, all these things get more complicated. And so, I mean, I'm not an expert, but maybe

02:35:58.520 --> 02:36:03.000
Mojo can help a little bit by helping reduce the amount of C in this ecosystem and make it

02:36:03.000 --> 02:36:08.200
therefore scale better. So any kind of packages that are hybrid in nature would be a natural fit

02:36:08.200 --> 02:36:13.800
to move to Mojo. Which is a lot of them, by the way. A lot of them, especially that are doing

02:36:13.800 --> 02:36:20.440
some interesting stuff computation wise. Let me ask you about some features. Yeah. So we talked

02:36:20.440 --> 02:36:26.360
about obviously indentation, that it's a typed language or optionally typed. Is that the right

02:36:26.360 --> 02:36:31.560
way to say it? It's either optionally or progressively. I think so. So people have

02:36:31.560 --> 02:36:36.280
very strong opinions on the right word to use. Yeah. I don't know. I look forward to your letters.

02:36:37.240 --> 02:36:43.160
So there's the var versus let, but let is for constants. Var is an optional.

02:36:43.880 --> 02:36:51.880
Yeah, var makes it mutable. So you can reassign. Okay. Then there's function overloading.

02:36:51.880 --> 02:36:56.760
Oh, okay. Yeah. I mean, there's a lot of source of happiness for me, but function overloading,

02:36:56.760 --> 02:37:05.400
that's, I guess, is that for performance or is that, why does Python not have function overloading?

02:37:06.920 --> 02:37:11.880
So I can speculate. So Python is a dynamic language. The way it works is that

02:37:14.200 --> 02:37:19.800
Python and Objective-C are actually very similar worlds if you ignore syntax.

02:37:20.840 --> 02:37:29.080
And so Objective-C is straight line derived from Smalltalk, a really venerable, interesting

02:37:29.880 --> 02:37:33.240
language that much of the world has forgotten about, but the people that remember it

02:37:33.240 --> 02:37:38.200
love it generally. And the way that Smalltalk works is that every object has a dictionary in

02:37:38.200 --> 02:37:43.240
it. And the dictionary maps from the name of a function or the name of a value within an object

02:37:43.800 --> 02:37:48.360
to its implementation. And so the way you call a method in Objective-C is you say,

02:37:49.000 --> 02:37:53.160
go look up, the way I call foo is I go look up foo, I get a pointer to the function back,

02:37:53.160 --> 02:37:58.440
and then I call it. Okay. That's how Python works. Right. And so now the problem with that is that

02:37:59.320 --> 02:38:04.760
the dictionary within a Python object, all the keys are strings, and it's a dictionary,

02:38:04.760 --> 02:38:07.880
so you can only have one entry per name. You think it's as simple as that?

02:38:07.880 --> 02:38:13.960
I think it's as simple as that. And so now, why do they never fix this? Why do they not change it

02:38:13.960 --> 02:38:20.520
to not be a dictionary? Why do they not do other things? Well, you don't really have to in Python

02:38:20.520 --> 02:38:25.720
because it's dynamic. And so you can say, I get into the function, now if I got passed an integer,

02:38:25.720 --> 02:38:31.080
do some dynamic tests for it. If it's a string, go do another thing. There's another additional

02:38:31.080 --> 02:38:34.360
challenge, which is even if you did support overloading, you're saying, okay, well,

02:38:34.360 --> 02:38:38.760
here's a version of a function for integers and a function for strings. Well, you'd have,

02:38:38.760 --> 02:38:42.280
even if you could put it in that dictionary, you'd have to have the caller do the dispatch.

02:38:43.000 --> 02:38:46.360
And so every time you call the function, you'd have to say, like, isn't an integer, is it a string?

02:38:46.360 --> 02:38:50.120
And so you'd have to figure out where to do that test. And so in a dynamic language,

02:38:50.600 --> 02:38:59.400
overloading is something you don't have to have. But now you get into a type language. And in Python,

02:38:59.400 --> 02:39:06.120
if you subscript with an integer, then you get typically one element out of a collection.

02:39:06.120 --> 02:39:12.200
If you subscript with a range, you get a different thing out. And so often in type languages,

02:39:12.200 --> 02:39:17.320
you'll want to be able to express the fact that, cool, I have different behavior depending on what

02:39:17.320 --> 02:39:20.760
I actually pass into this thing. If you can model that, it can make it safer and more

02:39:20.760 --> 02:39:26.200
predictable and faster and like all these things. It somehow feels safe for yes,

02:39:26.200 --> 02:39:30.600
but also feels empowering. Like in terms of clarity, like you don't have to design

02:39:30.600 --> 02:39:36.360
whole different functions. Yeah. Well, this is also one of the challenges with the existing

02:39:36.360 --> 02:39:41.960
Python typing systems is that in practice, like you take subscripts, like in practice,

02:39:41.960 --> 02:39:46.760
a lot of these functions, they don't have one signature. They actually have different behavior

02:39:46.760 --> 02:39:51.640
in different cases. And so this is why it's difficult to retrofit this into existing Python

02:39:51.640 --> 02:39:58.360
code and make it play well with typing. You kind of have to design for that. Okay. So there's an

02:39:58.360 --> 02:40:04.120
interesting distinction that people, the program Python might be interested in is def versus FN.

02:40:05.480 --> 02:40:13.960
So it's two different ways to define a function. And FN is a stricter version of def. What's the

02:40:13.960 --> 02:40:18.520
coolness that comes from the strictness? So here you get into, what is the trade-off with

02:40:18.520 --> 02:40:25.560
the superset? Yes. Okay. So a superset, you have to, or you really want to be compatible.

02:40:25.560 --> 02:40:30.680
Like if you're doing a superset, you've decided compatibility with existing code is the important

02:40:30.680 --> 02:40:34.840
thing. Even if some of the decisions they made were maybe not what you choose. Yeah. Okay.

02:40:35.960 --> 02:40:39.560
So that means you put a lot of time in compatibility and it means that you get locked

02:40:39.560 --> 02:40:44.520
into decisions of the past, even if they may not have been a good thing. Right now,

02:40:45.240 --> 02:40:50.680
systems programmers typically like to control things. Right. And they want to make sure that,

02:40:50.680 --> 02:40:55.160
you know, not, not in all cases, of course, and even systems programmers are not one thing. Right.

02:40:55.160 --> 02:41:00.200
But, but often you want predictability. And so one of the things that Python has, for example,

02:41:00.200 --> 02:41:04.920
as you know, is that if you define a variable, you just say X equals four, I have a variable name to

02:41:04.920 --> 02:41:13.560
X. Now I say some long method, some, some long name equals 17. Print out some long name. Oops,

02:41:13.560 --> 02:41:19.240
but I typo-ed it. Right. Well, the compiler, the Python compiler doesn't know in all cases,

02:41:19.240 --> 02:41:23.640
what you're defining and what you're using. And did you typo the use of it or the definition?

02:41:24.440 --> 02:41:29.480
Right. And so for people coming from type languages, again, I'm not saying they're

02:41:29.480 --> 02:41:33.000
right or wrong, but that drives them crazy because they want the compiler to tell them,

02:41:33.000 --> 02:41:37.160
you typo the name of this thing. Right. And so what FN does is it turns on,

02:41:37.160 --> 02:41:41.240
as you say, it's a strict mode. And so it says, okay, well, you have to actually declare,

02:41:41.240 --> 02:41:45.160
intentionally declare your variables before you use them. That gives you more predictability,

02:41:45.160 --> 02:41:50.920
more error checking and things like this, but you don't have to, you don't have to use it.

02:41:51.560 --> 02:41:56.520
And this is a way that Mojo is both compatible because devs work the same way that devs have

02:41:56.520 --> 02:42:00.440
already always worked, but it provides a new alternative that gives you more control and

02:42:00.440 --> 02:42:03.960
allows certain kinds of people that have a different philosophy to be able to express that

02:42:03.960 --> 02:42:09.640
and get that. But usually if you're writing Mojo code from scratch, you'll be using FN.

02:42:10.600 --> 02:42:15.320
It depends. Again, it depends on your mentality. Right. It's not, it's not that def is Python and

02:42:15.880 --> 02:42:21.400
FN is Mojo. Mojo has both and it loves both. Right. It really depends on. That is just strict.

02:42:21.400 --> 02:42:25.720
Yeah, exactly. Are you, are you playing around and scripting something out and is it a one-off

02:42:25.720 --> 02:42:30.360
throwaway script? Cool. Like Python is great at that. I'll still be using FN.

02:42:30.440 --> 02:42:37.240
But yeah. Well, so I love strictness. Okay. Well, so control power. You also like suffering, right?

02:42:37.960 --> 02:42:40.760
Yes. Go hand in hand. How many, how many pull-ups?

02:42:42.600 --> 02:42:48.280
Uh, I've lost count at this at this point. So, and that's cool. I love you for that. Yeah. Some,

02:42:48.280 --> 02:42:52.600
and I love other people who like strict things. Right. But, but I don't want to say that that's

02:42:52.600 --> 02:42:56.360
the right thing because Python's also very beautiful for hacking around and doing stuff

02:42:56.360 --> 02:43:00.360
and research and these other cases where you may not want that. See, I just feel like

02:43:01.320 --> 02:43:05.480
uh, maybe I'm wrong in that, but it feels like strictness leads to faster debugging.

02:43:05.480 --> 02:43:11.000
So in terms of going from even on a small project from zero to completion, it just,

02:43:11.960 --> 02:43:16.600
I guess it depends how many bugs you generate usually. Well, so I mean, it's again, lessons

02:43:16.600 --> 02:43:21.640
learned and looking at the ecosystem, it's really, I mean, I think it's, if you study some of these

02:43:21.640 --> 02:43:27.080
languages over time, like the Ruby community, for example, now Ruby is a pretty well-developed,

02:43:27.080 --> 02:43:31.240
pretty established community, but along their path, they really invested in unit testing.

02:43:32.120 --> 02:43:36.520
So I think that the Ruby community has really pushed forward the state of the art of testing

02:43:37.160 --> 02:43:41.160
because they didn't have a type system that caught a lot of bugs at compile time. Right. And so

02:43:41.880 --> 02:43:45.560
you can have the best of both worlds. You can have good testing and good types and things like this.

02:43:45.560 --> 02:43:49.160
But, but I thought that that it was really interesting to see how certain challenges

02:43:49.160 --> 02:43:53.800
get solved. And in Python, for example, the interactive notebook kind of experiences and

02:43:53.800 --> 02:43:57.720
stuff like this are really amazing. And if you type out something, it doesn't matter,

02:43:57.720 --> 02:44:01.000
it just tells you that's fine. Right. And so I think that the trade-offs are very different

02:44:01.000 --> 02:44:05.720
if you're building a, you know, a large scale production system versus you're building and

02:44:05.720 --> 02:44:10.280
exploring a notebook. And speaking of control, the hilarious thing, if you look at code, I write

02:44:10.280 --> 02:44:17.800
just for myself for fun. It's like littered with asserts everywhere. It's a kind of, yeah, you'd

02:44:17.800 --> 02:44:26.440
like tests. It's basically saying in a dictatorial way, this should be true now. Otherwise everything

02:44:26.440 --> 02:44:34.360
stops. And that is the sign. I love you, man. But that is a sign of somebody who likes control.

02:44:34.360 --> 02:44:38.760
Yeah. And so, yes, I think that you'll like FN. I think you'll like Mojo.

02:44:38.760 --> 02:44:46.040
Therapy session. Yes, I definitely will. Speaking of asserts, exceptions are called errors.

02:44:46.040 --> 02:44:51.240
Why is it called errors? So we, I mean, we use the same, we're the same as Python,

02:44:51.240 --> 02:44:56.360
right? But we implement in a very different way. Right. And so if you look at other languages,

02:44:56.360 --> 02:45:02.120
like we'll pick on C++, our favorite, right? C++ has a thing called zero cost exception handling.

02:45:02.760 --> 02:45:08.600
Okay. And this is, in my opinion, something to learn lessons from.

02:45:09.560 --> 02:45:11.480
It's a nice polite way of saying it.

02:45:11.480 --> 02:45:18.520
And so zero cost exception handling, the way it works is that it's called zero cost because

02:45:19.400 --> 02:45:25.400
if you don't throw an exception, there's supposed to be no overhead for the non-error code. And so

02:45:25.400 --> 02:45:33.640
it takes the error path out of the common path. It does this by making throwing an error extremely

02:45:33.720 --> 02:45:39.160
expensive. And so if you actually throw an error with a C++ compiler using exceptions,

02:45:39.160 --> 02:45:42.920
has to go look up in tables on the side and do all this stuff. And so throwing an error could be

02:45:42.920 --> 02:45:49.240
like 10,000 times more expensive than referring for a function. Right. Also it's called zero cost

02:45:49.240 --> 02:45:53.880
exceptions, but it's not zero cost by any stretch of the imagination, because it massively blows

02:45:53.880 --> 02:46:00.280
out your code, your binary. It also adds a whole bunch of different paths because of destructors

02:46:00.280 --> 02:46:04.520
and other things like that that exist in C++. And it reduces the number of optimizations. It

02:46:04.520 --> 02:46:10.600
has all these effects. And so this thing that was called zero cost exceptions, it really ain't.

02:46:12.360 --> 02:46:20.200
Now, if you fast forward to newer languages, and this includes Swift and Rust and Go and now Mojo,

02:46:23.000 --> 02:46:26.200
and Python's a little bit different because it's interpreted. And so it's got a little bit of a

02:46:26.200 --> 02:46:28.760
different thing going on. But if you look at it, if you look at compiled languages,

02:46:30.840 --> 02:46:36.840
many newer languages say, okay, well, let's not do that zero cost exception handling thing.

02:46:36.840 --> 02:46:44.280
Let's actually treat throwing an error the same as returning a variant, returning either the

02:46:44.280 --> 02:46:50.840
normal result or an error. Now, programmers generally don't want to deal with all the

02:46:50.840 --> 02:46:56.840
typing machinery and pushing around a variant. And so you use all the syntax that Python gives

02:46:56.840 --> 02:47:02.360
us. For example, try and catch functions that raise and things like this. You can put a raises

02:47:03.000 --> 02:47:06.920
decorator on your functions, stuff like this, if you want to control that. And then

02:47:07.960 --> 02:47:12.440
the language can provide syntax for it. But under the hood, the way the computer executes it,

02:47:12.440 --> 02:47:15.480
throwing an error is basically as fast as returning something.

02:47:16.280 --> 02:47:19.000
So it's exactly the same way from a compiled perspective.

02:47:19.000 --> 02:47:26.120
And so this is actually, I mean, it's a fairly nerdy thing, which is why I love it. But this

02:47:26.120 --> 02:47:34.040
has a huge impact on the way you design your APIs. So in C++, huge communities turn off exceptions

02:47:34.920 --> 02:47:41.720
because the cost is just so high. And so the zero cost cost is so high. And so that means you can't

02:47:41.720 --> 02:47:48.520
actually use exceptions in many libraries. And even for the people that do use it,

02:47:48.520 --> 02:47:53.400
well, okay, how and when do you want to pay the cost? If I try to open a file,

02:47:53.400 --> 02:47:58.360
should I throw an error? Well, what if I'm probing around looking for something, right?

02:47:58.360 --> 02:48:01.800
I'm looking it up in many different paths. Well, if it's really slow to do that,

02:48:01.800 --> 02:48:07.000
maybe I'll add another function that doesn't throw an error, returns an error code instead.

02:48:07.000 --> 02:48:10.760
And I have two different versions of the same thing. And so it causes you to fork your APIs.

02:48:11.560 --> 02:48:17.080
And so, you know, one of the things I learned from Apple and IsoLove is the art of API design

02:48:17.080 --> 02:48:20.680
is actually really profound. I think this is something that Python's also done a pretty good

02:48:20.680 --> 02:48:25.400
job at in terms of building out this large scale package ecosystem. It's about having standards

02:48:25.400 --> 02:48:30.600
and things like this. And so, you know, we wouldn't want to enter a mode where, you know,

02:48:30.600 --> 02:48:34.200
there's this theoretical feature that exists in language, but people don't use it in practice.

02:48:34.920 --> 02:48:39.160
Now, I'll also say one of the other really cool things about this implementation approach is

02:48:39.160 --> 02:48:43.640
that it can run on GPUs and it can run on accelerators and things like this. And that

02:48:43.640 --> 02:48:48.280
standard zero cost exception thing would never work on an accelerator. And so this is also part

02:48:48.280 --> 02:48:53.400
of how Mojo can scale all the way down to like little embedded systems and to running on GPUs

02:48:53.400 --> 02:49:01.080
and things like that. Can you actually say about the maybe, is there some high level way to describe

02:49:01.080 --> 02:49:08.040
the challenge of exceptions and how they work in code during compilation? So it's just this idea

02:49:08.040 --> 02:49:14.280
of percolating up a thing, an error. Yeah. Yeah. So the way to think about it is,

02:49:15.000 --> 02:49:18.680
think about a function that doesn't return anything, just as a simple case, right? And so you have

02:49:20.280 --> 02:49:24.120
function one calls function two, calls function three, calls function four,

02:49:24.920 --> 02:49:29.720
along that call stack that are tri-blocks, right? And so if you have function one calls function

02:49:29.720 --> 02:49:34.360
two, function two has a tri-block and then within it, it calls function three, right?

02:49:34.360 --> 02:49:39.720
Well, what happens if function three throws? Well, actually start simpler. What happens if

02:49:39.720 --> 02:49:43.960
it returns? Well, if it returns, it's supposed to go back out and continue executing and then fall

02:49:43.960 --> 02:49:48.760
off the bottom of the tri-block and keep going and it all's good. If the function throws,

02:49:48.760 --> 02:49:54.200
you're supposed to exit the current function and then get into the accept clause, right? And then

02:49:54.200 --> 02:49:59.160
do whatever code's there and then keep falling on and going on. And so the way that a compiler

02:49:59.160 --> 02:50:04.040
like Mojo works is that the call to that function, which happens in the accept block,

02:50:04.600 --> 02:50:10.200
calls a function and then instead of returning nothing, it actually returns, you know, a variant

02:50:10.200 --> 02:50:15.960
between nothing and an error. And so if you return normally, fall off the bottom or do return,

02:50:17.320 --> 02:50:23.720
you return nothing. And if you throw an error, you return the variant that is, I'm an error,

02:50:23.720 --> 02:50:28.680
right? So when you get to the call, you say, okay, cool. I called a function. Hey, I know locally,

02:50:28.680 --> 02:50:33.960
I'm in a tri-block, right? And so I call the function and then I check to see what it returns.

02:50:33.960 --> 02:50:39.240
Aha, if it's that error thing, jump to the accept block. And that's all done for you behind the

02:50:39.240 --> 02:50:43.160
scenes. Exactly. And so the compiler does all this for you. And I mean, one of the things,

02:50:43.160 --> 02:50:47.000
if you dig into how this stuff works in Python, it gets a little bit more complicated because you

02:50:47.000 --> 02:50:53.560
have finally blocks, which now you need to go into, do some stuff and then those can also throw and

02:50:53.560 --> 02:50:59.560
return. Wait, what nested? And like the stuff matters for compatibility. Like there's really,

02:50:59.560 --> 02:51:03.960
there's nest them. There's with clauses. And so with clauses are kind of like finally blocks

02:51:03.960 --> 02:51:08.280
with some special stuff going on. And so there's nesting in general, nesting of anything, nesting

02:51:08.280 --> 02:51:15.800
of functions should be illegal. It just feels like it adds a level of complexity. I'm merely

02:51:15.800 --> 02:51:22.280
an implementer. And so this is again, one of the trade-offs you get when you decide to build a

02:51:22.280 --> 02:51:27.320
superset is you get to implement a full fidelity implementation of the thing that you decided

02:51:28.040 --> 02:51:34.680
is good. And so, yeah, I mean, we can, we can complain about the reality of the world and

02:51:34.680 --> 02:51:40.040
shake our fist, but it always feels like you shouldn't be allowed to do that. Like to declare

02:51:40.040 --> 02:51:46.120
functions and send functions inside functions. Oh, wait, wait, wait. What happened to Lex,

02:51:46.120 --> 02:51:51.480
the Lisp guy? No, I understand that. But Lisp is what I used to do in college.

02:51:52.440 --> 02:51:57.000
So now you've grown up. You know, we've all done things in college. We're not proud.

02:51:58.520 --> 02:52:02.200
I love Lisp. I love Lisp. Okay. Yeah. I was going to say you're afraid of me

02:52:02.200 --> 02:52:07.560
irritating the whole internet. I love Lisp. It worked as a joke in my head.

02:52:09.320 --> 02:52:14.280
So nested functions are joking aside actually really great for certain things. And so these

02:52:14.280 --> 02:52:19.160
are also called closures. Closures are pretty cool and you can pass callbacks. There's a lot

02:52:19.160 --> 02:52:26.920
of good patterns and so. So speaking of which I don't think you have nested functions implemented

02:52:26.920 --> 02:52:33.080
yet in Mojo. We don't have Lambda syntax, but we do have nested functions. Yeah. There's a few

02:52:33.080 --> 02:52:37.880
things on the roadmap that you have that it'd be cool to sort of just fly through because it's

02:52:37.880 --> 02:52:43.640
interesting to see, you know, how many features there are in a language, small and big. Yep.

02:52:43.640 --> 02:52:47.880
They have to implement. Yeah. So first of all, there's tuple support and that has to do

02:52:47.880 --> 02:52:52.360
with some very specific aspects of it. Like the parentheses are not parentheses that.

02:52:52.360 --> 02:52:57.240
Yeah. This is just a totally syntactic thing. Syntactic thing. Okay. There's, but it's cool still.

02:52:59.000 --> 02:53:03.640
So keyword arguments and functions. Yeah. So this is where in Python you can say

02:53:03.640 --> 02:53:08.520
call a function X equals four. Yeah. And X is the name of the argument. That's a nice sort of

02:53:08.520 --> 02:53:13.000
documenting, self-documenting feature. Yeah. I mean, and again, this isn't rocket science to

02:53:13.000 --> 02:53:18.200
implement. It's just the laundry. It's just on the list. The bigger features are things like

02:53:18.200 --> 02:53:24.600
traits. So traits are when you want to define abstract. So when you get into typed languages,

02:53:25.160 --> 02:53:29.320
you need the ability to write generics. And so you want to say, I want to write this function.

02:53:29.320 --> 02:53:34.520
And now I want to work on all things that are arithmetic-like. Well, what does arithmetic-like

02:53:34.520 --> 02:53:41.080
mean? Well, arithmetic-like is a categorization of a bunch of types. And so again, you can define

02:53:41.080 --> 02:53:45.880
many different ways and I'm not going to go into ring theory or something, but the, you know,

02:53:45.880 --> 02:53:50.200
you can say it's arithmetic-like if you can add, subtract, multiply, divide it, for example. Right.

02:53:50.200 --> 02:53:56.120
And so what you're saying is you're saying there's a set of traits that apply to a broad variety of

02:53:56.120 --> 02:54:01.480
types. And so there are all these types of arithmetic-like, all these tensors and floating

02:54:01.480 --> 02:54:06.680
point integer, and like there's this category of types. And then I can define on an orthogonal

02:54:06.680 --> 02:54:12.920
axis algorithms that then work against types that have those properties. And so this is a,

02:54:13.480 --> 02:54:18.600
again, it's a widely known thing. It's been implemented in Swift and Rust and many languages.

02:54:18.600 --> 02:54:26.840
So it's not Haskell, which is where everybody learns their tricks from. But we need to implement

02:54:26.840 --> 02:54:33.160
that and that'll enable a new level of expressivity. So classes. Yeah, classes are a big deal.

02:54:33.160 --> 02:54:39.160
It's a big deal still to be implemented. Like you said, lambda syntax,

02:54:40.040 --> 02:54:42.760
and there's like detailed stuff like whole module import,

02:54:45.160 --> 02:54:49.880
support for top level code at Filescope. So, and then global variables also.

02:54:51.560 --> 02:54:54.440
So being able to have variables outside of a top level.

02:54:54.440 --> 02:54:58.680
And so this comes back to the where Mojo came from and the fact that this is a point one,

02:54:58.920 --> 02:55:05.560
and so we're building, so Modular is building an AI stack. And an AI stack has a bunch of problems

02:55:05.560 --> 02:55:09.960
working with hardware and writing high-performance kernels and doing this kernel fusion thing I was

02:55:09.960 --> 02:55:13.880
talking about and getting the most out of the hardware. And so we've really prioritized and

02:55:13.880 --> 02:55:21.160
built Mojo to solve Modular's problem. Now our North Star is build out and support all the things.

02:55:21.160 --> 02:55:24.840
And so we're making incredible progress. By the way, Mojo is only like seven months old.

02:55:25.800 --> 02:55:29.320
So that's another interesting thing. I mean, part of the reason I wanted to mention some

02:55:29.320 --> 02:55:33.960
of these things is like, there's a lot to do. And it's pretty cool how you just kind of,

02:55:35.000 --> 02:55:38.440
sometimes you take for granted how much there is in a programming language,

02:55:38.440 --> 02:55:42.520
how many cool features you kind of rely on. And this is kind of a nice reminder when you

02:55:42.520 --> 02:55:46.280
lay it as a to-do list. Yeah. And so, I mean, but also you look into,

02:55:47.000 --> 02:55:54.040
it's amazing how much is also there. And you take it for granted that a value, if you define it,

02:55:54.040 --> 02:55:59.640
it will get destroyed automatically. Like that little feature itself is actually really complicated

02:55:59.640 --> 02:56:04.440
given the way the ownership system has to work. And the way that works within Mojo is a huge step

02:56:04.440 --> 02:56:08.280
forward from what Rust and Swift have done. But can you say that again, when a value,

02:56:08.280 --> 02:56:11.960
when you define it gets destroyed automatically? Yeah. So like, say you have a string, right? So

02:56:11.960 --> 02:56:16.200
you just find a string on the stack, okay? Or whatever that means, like in your local function,

02:56:17.240 --> 02:56:23.240
right? And so you say, like, whether it be in a def, and so you just say x equals hello world,

02:56:23.240 --> 02:56:28.600
right? Well, if your string type requires you to allocate memory, then when it's destroyed,

02:56:28.600 --> 02:56:33.960
you have to deallocate it. So in Python and Mojo, you define that with the del method, right?

02:56:34.760 --> 02:56:43.720
Where does that get run? Well, it gets run sometime between the last use of the value and

02:56:45.240 --> 02:56:50.200
the end of the program. Like in this, you now get into garbage collection, you get into like all

02:56:50.200 --> 02:56:57.080
these long debated, you talk about religions and trade-offs and things like this. This is a hugely

02:56:57.080 --> 02:57:03.960
hotly contested world. If you look at C++, the way this works is that if you define a variable

02:57:03.960 --> 02:57:10.840
or a set of variables within a function, they get destroyed in a last in first out order. So it's

02:57:10.840 --> 02:57:16.600
like nesting, okay? This has a huge problem because if you define, you have a big scope

02:57:16.600 --> 02:57:20.600
and you define a whole bunch of values at the top, and then you use them and then you do a whole

02:57:20.600 --> 02:57:24.680
bunch of code that doesn't use them, they don't get destroyed until the very end of that scope,

02:57:25.320 --> 02:57:30.680
right? And so this also destroys tail calls, so good functional programming, right? This has a

02:57:30.680 --> 02:57:35.240
bunch of different impacts on, you know, you talk about reference counting optimizations and things

02:57:35.240 --> 02:57:40.440
like this, a bunch of very low level things. And so what Mojo does is it has a different approach

02:57:40.440 --> 02:57:44.600
on that from any language I'm familiar with, where it destroys them as soon as possible.

02:57:44.600 --> 02:57:49.240
And by doing that, you get better memory use, you get better predictability, you get tail calls

02:57:49.240 --> 02:57:53.320
that work, you get a bunch of other things, you get better ownership tracking. There's a bunch of

02:57:53.320 --> 02:57:59.800
these very simple things that are very fundamental, that are already built in there in Mojo today,

02:57:59.800 --> 02:58:03.640
that are the things that nobody talks about generally, but when they don't work right,

02:58:03.640 --> 02:58:10.120
you find out and you have to complain about. Is it trivial to know what's the soonest possible

02:58:10.520 --> 02:58:13.880
what's the soonest possible to delete a thing that's not going to be used again?

02:58:13.880 --> 02:58:18.440
Yeah, well, I mean, it's generally trivial. It's after the last use of it. So if you define x as

02:58:18.440 --> 02:58:22.600
a string, and then you have some use of x somewhere in your code within that scope,

02:58:22.600 --> 02:58:27.080
you mean within scope that is accessible? Yeah, exactly. So you can only use something

02:58:27.080 --> 02:58:31.080
within its scope. And so then it doesn't wait until the end of the scope to delete it,

02:58:31.960 --> 02:58:36.600
it destroys it after the last use. So there's kind of some very eager machine

02:58:36.600 --> 02:58:39.560
that's just sitting there and deleting. And it's all in the compiler, so it's not

02:58:39.560 --> 02:58:47.080
at runtime, which is also cool. And this is actually non-trivial because you have control

02:58:47.080 --> 02:58:51.560
flow. And so it gets complicated pretty quickly. And so getting this right was not-

02:58:51.560 --> 02:58:54.120
Also, you have to insert delete in a lot of places.

02:58:54.120 --> 02:58:58.200
Potentially, yeah, exactly. So the compiler has to reason about this. And this is where,

02:58:58.200 --> 02:59:01.800
again, it's experience building languages and not getting this right. So again,

02:59:01.800 --> 02:59:07.000
you get another chance to do it and you get basic things like this. But it's extremely powerful

02:59:07.000 --> 02:59:11.240
when you do that. And so there's a bunch of things like that that kind of combine together.

02:59:12.120 --> 02:59:16.040
And this comes back to the, you get a chance to do it the right way, do it the right way,

02:59:16.040 --> 02:59:19.960
and make sure that every brick you put down is really good. So that when you put more bricks

02:59:19.960 --> 02:59:24.760
on top of it, they stack up to something that's beautiful. Well, there's also, like how many

02:59:26.680 --> 02:59:31.400
design discussions do there have to be about particular details, like implementation of

02:59:31.400 --> 02:59:38.440
particular small features? Because the features that seem small, I bet some of them might be like

02:59:39.560 --> 02:59:44.680
really require really big design decisions. Yeah. Well, so, I mean, let me give you another

02:59:44.680 --> 02:59:50.760
example of this. Python has a feature called async await. So it's a new feature. I mean,

02:59:50.760 --> 02:59:57.480
in the long arc of history, it's a relatively new feature that allows way more expressive

02:59:57.480 --> 03:00:03.000
asynchronous programming. Okay. Again, this is a, Python's a beautiful thing. And they did

03:00:03.000 --> 03:00:08.040
things that are great for Mojo for completely different reasons. The reason that async await

03:00:08.040 --> 03:00:12.040
got added to Python, as far as I know, is because Python doesn't support threads.

03:00:13.880 --> 03:00:19.080
And so Python doesn't support threads, but you want to work with networking and other things

03:00:19.080 --> 03:00:23.080
like that that can block. I mean, Python does support threads. It's just not its strength. And

03:00:23.080 --> 03:00:30.120
so they added this feature called async await. It's also seen in other languages like Swift and

03:00:30.120 --> 03:00:35.960
JavaScript and many other places as well. Async await and Mojo is amazing because we have a high

03:00:35.960 --> 03:00:42.040
performance heterogeneous compute runtime underneath the covers that then allows non-blocking

03:00:42.040 --> 03:00:47.720
IO. So you get full use of your accelerator. That's huge. It turns out it's actually really

03:00:47.720 --> 03:00:52.040
an important part of fully utilizing the machine. You talk about design discussions.

03:00:52.760 --> 03:00:58.280
That took a lot of discussions and it probably will require more iteration. And so my philosophy

03:00:58.280 --> 03:01:02.600
with Mojo is that we have a small team of really good people that are pushing forward and they're

03:01:02.600 --> 03:01:08.200
very good at the extremely deep, knowing how the compiler and runtime and like all the low level

03:01:08.200 --> 03:01:13.880
stuff works together. But they're not perfect. Same thing as the Swift team. And this is where

03:01:13.880 --> 03:01:18.920
one of the reasons we released Mojo much earlier is so we can get feedback. And we've already

03:01:18.920 --> 03:01:26.120
renamed a keyword due to community feedback. We use an ampersand and now it's named in out.

03:01:26.840 --> 03:01:30.840
We're not renaming existing Python keywords because that breaks compatibility. We're

03:01:30.840 --> 03:01:36.520
renaming things we're adding and making sure that they are designed well. We get usage experience.

03:01:36.520 --> 03:01:40.520
We iterate and work with the community because again, if you scale something really fast and

03:01:40.520 --> 03:01:43.720
everybody writes all their code and they start using it in production, then it's impossible to

03:01:43.720 --> 03:01:48.360
change. And so you want to learn from people. You want to iterate and work on that early on. And

03:01:48.360 --> 03:01:51.800
this is where design discussions, it's actually quite important.

03:01:51.800 --> 03:01:55.960
Could you incorporate an emoji into the language, into the main language?

03:01:58.120 --> 03:01:58.920
Do you have a favorite one?

03:01:59.480 --> 03:02:05.400
Well, I really like in terms of humor, like raw, full whatever, rolling on the floor laughing.

03:02:06.200 --> 03:02:10.920
So that could be like, what would that be the use case for that? Like an exception,

03:02:10.920 --> 03:02:14.040
throw an exception of some sort. I should totally file a feature request.

03:02:16.600 --> 03:02:18.920
Or maybe a hard one. It has to be a hard one.

03:02:19.720 --> 03:02:23.320
People have told me that I'm insane. So this is this is this is I'm liking this.

03:02:24.600 --> 03:02:29.160
I'm going to I'm going to use the viral nature of the internet to actually get this to get this

03:02:29.160 --> 03:02:33.720
past. I mean, it's funny you come back to the flame emoji file extension, right? The,

03:02:33.720 --> 03:02:40.520
you know, we have the option to use the flame emoji, which just even that concept cause,

03:02:40.520 --> 03:02:43.240
for example, the people at GitHub say, now I've seen everything.

03:02:45.560 --> 03:02:49.000
Yeah, there's something it kind of is reinvigorating. It's like,

03:02:50.680 --> 03:02:55.080
it's like, oh, that's possible. That's really cool. That for some reason, that makes everything

03:02:55.080 --> 03:02:59.480
else really exciting. The world is ready for this stuff. And so, you know, when we have a package

03:02:59.480 --> 03:03:04.680
manager, we'll clearly have to innovate by having the compiled package thing be the little box with

03:03:04.680 --> 03:03:10.680
the bow on it, right? I mean, it has to be done. It has to be done. Is there some stuff on the

03:03:10.680 --> 03:03:15.880
roadmap that you're particularly stressed about or excited about that you're thinking about a lot?

03:03:15.880 --> 03:03:21.080
I mean, as a today snapshot, which will be obsolete tomorrow, the lifetime stuff is really

03:03:21.080 --> 03:03:28.040
exciting. And so lifetimes give you safe references to memory without dangling pointers. And so this

03:03:28.040 --> 03:03:31.640
has been done in languages like Rust before. And so we have a new approach, which is really cool.

03:03:31.640 --> 03:03:37.400
I'm very excited about that. That'll be out to the community very soon. The traits feature is

03:03:37.400 --> 03:03:42.600
really a big deal. And so that's blocking a lot of API design. And so there's that. I think that's

03:03:42.600 --> 03:03:50.200
really exciting. A lot of it is these kind of table stakes features. One of the things that is,

03:03:50.200 --> 03:03:57.640
again, also lessons learned with Swift is that programmers in general like to add syntactic sugar

03:03:58.840 --> 03:04:03.240
and so it's like, oh, well, this annoying thing, like in Python, you have to spell

03:04:03.240 --> 03:04:09.080
unbar, unbar, add. Why can't I just use plus? Def plus. Come on. Why can't I just do that,

03:04:09.080 --> 03:04:13.000
right? And so trigger a little bit of syntactic sugar. It makes sense. It's beautiful. It's

03:04:13.000 --> 03:04:20.200
obvious. We're trying not to do that. And so for two different reasons, one of which is that,

03:04:20.200 --> 03:04:26.680
again, lesson learned with Swift. Swift has a lot of syntactic sugar, which may be a good thing,

03:04:26.680 --> 03:04:32.680
maybe not. I don't know. But because it's such an easy and addictive thing to do, sugar like makes

03:04:32.680 --> 03:04:38.200
your blood get crazy, right? Like the community will really dig into that and want to do a lot

03:04:38.200 --> 03:04:42.440
of that. And I think it's very distracting from building the core abstractions. The second is,

03:04:42.440 --> 03:04:48.040
we want to be a good member of the Python community, right? And so we want to work with

03:04:48.040 --> 03:04:53.000
the broader Python community. And yeah, we're pushing forward a bunch of systems programming

03:04:53.000 --> 03:04:57.000
features, and we need to build them out to understand them. But once we get a long ways

03:04:57.000 --> 03:05:00.440
forward, I want to make sure that we go back to the Python community and say, okay, let's do some

03:05:00.440 --> 03:05:03.880
design reviews. Let's actually talk about this stuff. Let's figure out how we want this stuff

03:05:03.880 --> 03:05:08.040
all to work together. And syntactic sugar just makes all that more complicated. So.

03:05:09.080 --> 03:05:15.320
And yeah, list comprehensions are yet to be implemented. And my favorite, I mean, dictionaries.

03:05:16.680 --> 03:05:22.200
Yeah, there's some basics. 0.1. 0.1. Yeah. But nonetheless, it's actually still quite

03:05:22.200 --> 03:05:28.840
interesting and useful. As you mentioned, Modular is very new. Mojo is very new. It's

03:05:28.840 --> 03:05:36.440
a relatively small team that's building up this gigantic stack, this incredible stack that's going

03:05:36.440 --> 03:05:45.000
to perhaps define the future of development of our AI overlords. We just hope it will be useful.

03:05:45.480 --> 03:05:54.600
As do all of us. So what have you learned from this process of building up a team? Maybe one

03:05:54.600 --> 03:06:03.160
question is, how do you hire great programmers, great people that operate in this compiler,

03:06:03.880 --> 03:06:12.680
hardware, machine learning, software, interface design space, and maybe are a little bit fluid

03:06:12.920 --> 03:06:18.440
in what they can do? Language design too. So building a company is just as interesting

03:06:18.440 --> 03:06:23.880
in different ways as building a language. Like different skill sets, different things, but

03:06:23.880 --> 03:06:26.680
super interesting. And I've built a lot of teams in a lot of different places.

03:06:27.720 --> 03:06:33.080
If you zoom in from the big problem into recruiting, well, so here's our problem.

03:06:33.080 --> 03:06:39.320
Okay. I'll be very straightforward about this. We started Modular with a lot of conviction about

03:06:39.320 --> 03:06:43.400
we understand the problems. We understand the customer pain points. We need to work backwards

03:06:43.400 --> 03:06:47.480
from the suffering in the industry. And if we solve those problems, we think it'll be useful

03:06:47.480 --> 03:06:53.000
for people. But the problem is that the people we need to hire, as you say, are all these super

03:06:53.000 --> 03:07:02.200
specialized people that have jobs at big tech worlds. And I don't think we have product market

03:07:02.200 --> 03:07:08.040
fit in the way that a normal startup does. And we don't have product market fit challenges because

03:07:08.040 --> 03:07:11.880
right now everybody's using AI and so many of them are suffering and they want help.

03:07:11.880 --> 03:07:17.240
And so again, we started with strong conviction. Now, again, you have to hire and recruit the best

03:07:17.240 --> 03:07:21.640
and the best all have jobs. And so what we've done is we said, okay, well, let's build an amazing

03:07:21.640 --> 03:07:26.440
culture. Start with that. That's usually not something a company starts with. Usually you

03:07:26.440 --> 03:07:31.080
hire a bunch of people and then people start fighting and it turns into a gigantic mess.

03:07:31.080 --> 03:07:35.400
And then you try to figure out how to improve your culture later. My co-founder Tim in particular is

03:07:35.400 --> 03:07:39.880
super passionate about making sure that that's right. And we've spent a lot of time early on

03:07:39.880 --> 03:07:44.040
to make sure that we can scale. Can you comment, sorry, before we get to the second,

03:07:44.040 --> 03:07:49.320
what makes for a good culture? So, I mean, there's many different cultures and I have learned many

03:07:49.320 --> 03:07:54.600
things from many different people. You worked with several very unique, almost famously unique

03:07:54.600 --> 03:07:58.600
cultures. And some of them I learned what to do and some of them I learned what not to do.

03:07:59.560 --> 03:08:09.560
And so we want an inclusive culture. I believe in amazing people working together. And so I've

03:08:09.560 --> 03:08:14.120
seen cultures where you have amazing people and they're fighting each other. I see amazing people

03:08:14.120 --> 03:08:19.480
and they're told what to do. Doubt, shout, line up and do what I say. It doesn't matter if it's the

03:08:19.480 --> 03:08:24.680
right thing, do it. And neither of these is the, and I've seen people that have no direction,

03:08:24.680 --> 03:08:28.680
they're just kind of floating in different places and they want to be amazing. They just don't know

03:08:28.680 --> 03:08:34.120
how. And so a lot of it starts with have a clear vision. And so we have a clear vision of what

03:08:34.120 --> 03:08:41.320
we're doing. And so I kind of grew up at Apple in my engineering life. And so a lot of the Apple

03:08:41.320 --> 03:08:47.080
DNA rubbed off on me. My co-founder Tim also is like a strong product guy. And so what we learned

03:08:47.080 --> 03:08:52.760
is, I was taught at Apple that you don't work from building cool technology. You don't work

03:08:52.760 --> 03:08:56.440
from like come up with cool products and think about the features you'll have in the big check

03:08:56.440 --> 03:09:00.520
boxes and stuff like this. Cause if you go talk to customers, they don't actually care about your

03:09:00.520 --> 03:09:06.680
product. They don't care about your technology. What they care about is their problems, right?

03:09:06.680 --> 03:09:10.760
And if your product can help solve their problems, well, hey, they might be interested in that,

03:09:11.560 --> 03:09:14.040
right? And so if you speak to them about their problems, if you understand and you have

03:09:14.040 --> 03:09:18.440
compassion, you understand what people are working with, then you can work backwards to building an

03:09:18.440 --> 03:09:22.360
amazing product. So the vision starts by defining the problem. And then you can work

03:09:22.360 --> 03:09:27.160
backwards in solving technology. And at Apple, like it's, I think pretty famously said that,

03:09:27.160 --> 03:09:33.720
you know, for every, you know, there's a hundred nos for every yes. I would refine that to say

03:09:33.720 --> 03:09:38.840
that there's a hundred not yet for every yes. But famously, if you go back to the iPhone,

03:09:38.840 --> 03:09:43.960
for example, right? The iPhone one, I mean, many people laughed at it because it didn't have 3G.

03:09:43.960 --> 03:09:50.840
It didn't have copy and paste, right? And then a year later, okay, finally it has 3G, but it still

03:09:50.840 --> 03:09:54.120
doesn't have copy and paste. It's a joke. Nobody will ever use this product, blah, blah, blah,

03:09:54.120 --> 03:09:59.320
blah, blah, blah, blah, right? Well, year three, it had copy and paste and people stopped talking

03:09:59.320 --> 03:10:04.440
about it, right? And so, and so being laser focused and having conviction and understanding

03:10:05.000 --> 03:10:08.840
what the core problems are and giving the team the space to be able to build the right tech

03:10:09.480 --> 03:10:16.120
is really important. Also, I mean, you come back to recruiting, you have to pay well, right? So we

03:10:16.120 --> 03:10:19.560
have to pay industry-leading salaries and have good benefits and things like this. That's a big

03:10:19.560 --> 03:10:29.720
piece. We're a remote first company and so we have to, so remote first has a very strong set of

03:10:29.720 --> 03:10:35.000
pros and cons. On the one hand, you can hire people from wherever they are and you can attract

03:10:35.000 --> 03:10:39.880
amazing talent even if they live in strange places or unusual places. On the other hand,

03:10:39.880 --> 03:10:46.280
you have time zones. On the other hand, you have like everybody on the internet will fight if they

03:10:46.280 --> 03:10:50.680
don't understand each other. And so we've had to learn how to like have a system where we actually

03:10:50.680 --> 03:10:54.280
fly people in and we get the whole company together periodically and then we get work

03:10:54.280 --> 03:10:59.160
groups together and we plan and execute together. And there's like an intimacy to the in-person

03:10:59.160 --> 03:11:04.280
brainstorming that I guess you lose, but maybe you don't. Maybe if you get to know each other

03:11:04.280 --> 03:11:08.200
well and you trust each other, maybe you can do that. Yeah. Well, so when the pandemic first hit,

03:11:08.200 --> 03:11:12.600
I mean, I'm curious about your experience too. The first thing I missed was having whiteboards.

03:11:12.600 --> 03:11:18.760
Yeah. Right. Those design discussions where like I can high intensity work through things,

03:11:18.760 --> 03:11:22.200
get things done, work through the problem of the day, understand where you're on,

03:11:22.200 --> 03:11:29.080
figure out and solve the problem and move forward. But we figured out ways to work around that now

03:11:29.080 --> 03:11:35.000
with all these screen sharing and other things like that that we do. The thing I miss now is

03:11:35.000 --> 03:11:38.920
sitting down at a lunch table with the team. Yeah. The spontaneous things like those,

03:11:39.560 --> 03:11:45.720
the coffee bar things and the bumping into each other and getting to know people outside of the

03:11:45.720 --> 03:11:51.480
transactional solve a problem over Zoom. And I think there's just a lot of stuff that,

03:11:52.520 --> 03:11:56.200
I'm not an expert at this. I don't know who is. Hopefully there's some people,

03:11:56.200 --> 03:12:01.480
but there's stuff that somehow is missing on Zoom. Even with the whiteboard, if you look at that,

03:12:02.840 --> 03:12:06.360
if you have a room with one person at the whiteboard and then there's like three other

03:12:06.360 --> 03:12:13.400
people at a table, there's a, first of all, there's a social aspect to that where you're

03:12:13.400 --> 03:12:17.560
just shooting the shit a little bit, almost like- Yeah. As people just kind of coming in and-

03:12:17.560 --> 03:12:25.560
Yeah. That, but also while like it's a breakout discussion that happens for like seconds at a time,

03:12:25.560 --> 03:12:30.280
maybe an inside joke or it's like this interesting dynamic that happens that Zoom-

03:12:30.280 --> 03:12:31.320
And you're bonding. Yeah.

03:12:31.320 --> 03:12:33.800
You're bonding. You're bonding. But through that bonding,

03:12:34.520 --> 03:12:39.320
you get the excitement. There's certain ideas are like complete bullshit and you'll see that

03:12:39.320 --> 03:12:45.080
in the faces of others that you won't see necessarily on Zoom. And like something,

03:12:45.800 --> 03:12:50.600
it feels like that should be possible to do without being in person.

03:12:50.600 --> 03:12:53.960
Well, I mean, being in person is a very different thing. I don't-

03:12:53.960 --> 03:12:59.000
It's worth it, but you can't always do it. And so again, we're still learning and we're also

03:12:59.080 --> 03:13:05.400
learning as like humanity with this new reality, right? But what we found is that getting people

03:13:05.400 --> 03:13:09.720
together, whether it be a team or the whole company or whatever, is worth the expense

03:13:09.720 --> 03:13:16.680
because people work together and are happier after that. There's a massive period of time where you

03:13:16.680 --> 03:13:20.920
go out and things start getting frayed, pull people together, and then you realize that we're

03:13:20.920 --> 03:13:24.200
all working together. We see things the same way. We work through the disagreement or the

03:13:24.200 --> 03:13:28.040
misunderstanding. We're talking across each other and then you work much better together.

03:13:28.040 --> 03:13:30.600
And so things like that I think are really quite important.

03:13:30.600 --> 03:13:35.800
What about people that are kind of specialized in very different aspects of the stack working

03:13:35.800 --> 03:13:38.200
together? What are some interesting challenges there?

03:13:38.200 --> 03:13:41.080
Yeah. Well, so I mean, there's lots of interesting people, as you can tell. I'm

03:13:41.880 --> 03:13:44.360
hard to deal with too. But-

03:13:44.360 --> 03:13:45.880
You're one of the most lovable people.

03:13:47.560 --> 03:13:54.600
So there's different philosophies in building teams. For me, and so some people say,

03:13:54.680 --> 03:13:59.800
hire 10x programmers, and that's the only thing, whatever that means, right? What I believe in is

03:13:59.800 --> 03:14:05.640
building well-balanced teams, teams that have people that are different in them. Like if you

03:14:05.640 --> 03:14:11.800
have all generals and no troops, or all troops and no generals, or you have all people that think in

03:14:11.800 --> 03:14:16.280
one way and not the other way, what you get is you get a very biased and skewed and weird situation

03:14:16.280 --> 03:14:20.600
where people end up being unhappy. And so what I like to do is I like to build teams of people

03:14:20.600 --> 03:14:26.440
where they're not all the same. We do have teams that are focused on runtime or compiler, GPU,

03:14:26.440 --> 03:14:32.520
or whatever the speciality is, but people bring a different take and have a different perspective.

03:14:32.520 --> 03:14:37.080
And I look for people that complement each other. And particularly if you look at leadership teams

03:14:37.080 --> 03:14:41.640
and things like this, you don't want everybody thinking the same way. You want people bringing

03:14:41.640 --> 03:14:45.320
different perspectives and experiences. And so I think that's really important.

03:14:45.320 --> 03:14:49.400
That's team, but what about building a company as ambitious as Modular?

03:14:49.400 --> 03:14:52.040
So what are some interesting questions there?

03:14:52.920 --> 03:14:58.120
Oh, I mean, so many. Like, so one of the things I love about, okay, so Modular is the first

03:14:58.120 --> 03:15:05.960
company I built from scratch. One of the first things that was profound was I'm not cleaning

03:15:05.960 --> 03:15:09.480
up somebody else's mess, right? And so if you look at-

03:15:09.480 --> 03:15:10.840
That's liberating to some degree.

03:15:10.840 --> 03:15:16.920
It's super liberating. And also many of the projects I've built in the past

03:15:16.920 --> 03:15:24.680
have not been core to the product of the company. Swift is not Apple's product, right? MLIR is not

03:15:25.240 --> 03:15:31.240
Google's revenue machine or whatever, right? It's important, but it's like working on the

03:15:31.240 --> 03:15:38.440
accounting software for the retail giant or something, right? It's like enabling infrastructure

03:15:38.440 --> 03:15:45.000
and technology. And so at Modular, the tech we're building is here to solve people's problems.

03:15:45.000 --> 03:15:49.560
It is directly the thing that we're giving to people. And so this is a really big difference.

03:15:49.560 --> 03:15:53.880
And what it means for me as a leader, but also for many of our engineers, is they're working

03:15:53.880 --> 03:15:58.840
on the thing that matters. And that's actually pretty, I mean, again, for compiler people and

03:15:58.840 --> 03:16:03.560
things like that, that's usually not the case, right? And so that's also pretty exciting and

03:16:04.200 --> 03:16:10.440
quite nice. But one of the ways that this manifests is it makes it easier to make decisions.

03:16:11.160 --> 03:16:16.680
And so one of the challenges I've had in other worlds is it's like, okay, well, community matters

03:16:17.400 --> 03:16:22.360
somehow for the goodness of the world, or open source matters theoretically, but I don't want

03:16:22.360 --> 03:16:29.640
to pay for a t-shirt, right? Or some swag. Well, t-shirts cost 10 bucks each. You can have 100

03:16:29.640 --> 03:16:35.160
t-shirts for a thousand dollars to a megacorp, a thousand dollars is uncountably, can't count

03:16:35.160 --> 03:16:40.280
that low, right? But justifying it and getting a t-shirt, by the way, if you'd like a t-shirt.

03:16:41.000 --> 03:16:47.240
Well, I would 100% like a t-shirt. Are you joking? You can have a fire emoji t-shirt.

03:16:49.480 --> 03:16:54.520
I will treasure this. I will pass it down to my grandchildren. And so, you know, it's very

03:16:54.520 --> 03:16:57.160
liberating to be able to decide, I think that Lex should have a t-shirt,

03:16:58.760 --> 03:17:07.480
right? And it becomes very simple because I like Lex. This is awesome. So

03:17:09.640 --> 03:17:16.680
I have to ask you about the, one of the interesting developments with large language models

03:17:16.840 --> 03:17:26.280
is that they're able to generate code recently really well. Yes. To a degree that maybe,

03:17:27.880 --> 03:17:32.920
I don't know if you understand, but I have, I struggle to understand because it forces me

03:17:32.920 --> 03:17:40.520
to ask questions about the nature of programming, of the nature of thought, because the language

03:17:40.520 --> 03:17:45.320
models are able to predict the kind of code I was about to write so well. Yep. That it makes me

03:17:45.320 --> 03:17:49.880
wonder like how unique my brain is and where the valuable ideas actually come from. Like how much

03:17:49.880 --> 03:17:58.920
do I contribute in terms of ingenuity, innovation to code I write or design and that kind of stuff.

03:18:00.280 --> 03:18:03.800
When you stand on the shoulders of giants, are you really doing anything? And what LLMs are

03:18:04.520 --> 03:18:09.000
helping you do is they help you stand on the shoulders of giants in your program. There's

03:18:09.000 --> 03:18:13.720
mistakes. They're interesting that you learn from, but I just, it would love to get your

03:18:13.960 --> 03:18:19.880
opinion first high level of what you think about this impact of larger language models when they

03:18:19.880 --> 03:18:26.760
do program synthesis, when they generate code. Yeah. Well, so I don't know where it all goes.

03:18:28.200 --> 03:18:34.120
I'm an optimist and I'm a human optimist. I think that things I've seen are that a lot of the LLMs

03:18:34.120 --> 03:18:39.000
are really good at crushing leak code projects and they can reverse the link list like crazy.

03:18:39.080 --> 03:18:42.760
They can reverse the link list like crazy. Well, it turns out there's a lot of

03:18:43.880 --> 03:18:47.880
instances of that on the internet and it's a pretty stock thing. And so if you want to see

03:18:48.920 --> 03:18:53.400
standard questions answered, LLMs can memorize all the answers and that can be amazing. And

03:18:53.400 --> 03:18:58.440
also they do generalize out from that. And so there's good work on that. But I think that

03:18:59.240 --> 03:19:03.640
in my experience, building things, building something like you talk about mojo, or you talk

03:19:03.640 --> 03:19:08.520
about these things, or you talk about building an applied solution to a problem, it's also about

03:19:08.520 --> 03:19:12.840
working with people. It's about understanding the problem. What is the product that you want to build?

03:19:12.840 --> 03:19:17.000
What are the use case? What are the customers? You can't just go survey all the customers because

03:19:17.000 --> 03:19:22.600
they'll tell you that they want a faster horse. Maybe they need a car. And so a lot of it comes into

03:19:24.200 --> 03:19:27.880
I don't feel like we have to compete with LLMs. I think they'll help automate a ton of the

03:19:27.880 --> 03:19:33.560
mechanical stuff out of the way. And just like I think we all try to scale through delegation and

03:19:33.560 --> 03:19:40.040
things like this, delegating wrote things to an LLM, I think is an extremely valuable approach

03:19:40.040 --> 03:19:45.160
that will help us all scale and be more productive. But I think it's a fascinating companion. But I'd

03:19:45.160 --> 03:19:51.080
say I don't think that that means that we're going to be done with coding. But there's power in it as

03:19:51.080 --> 03:19:59.320
a companion. And from there, I would love to zoom in onto mojo a little bit. Do you think about that?

03:19:59.400 --> 03:20:06.680
Do you think about LLMs generating mojo code and helping sort of like, when you design new

03:20:06.680 --> 03:20:10.920
programming language, it almost seems like, man, it would be nice to sort of

03:20:13.240 --> 03:20:18.760
almost as a way to learn how I'm supposed to use this thing for them to be trained on some of the

03:20:18.760 --> 03:20:26.360
mojo code. So I do lead an AI company. So maybe there will be a mojo LLM at some point. But if

03:20:26.360 --> 03:20:34.120
your question is like, how do we make a language to be suitable for LLMs? I think the cool thing

03:20:34.120 --> 03:20:40.120
about LLMs is you don't have to. And so if you look at what is English or any of these other

03:20:40.120 --> 03:20:44.120
terrible languages that we as humans deal with on a continuous basis, they're never designed for

03:20:44.120 --> 03:20:49.320
machines. And yet, they're the intermediate representation. They're the exchange format

03:20:49.320 --> 03:20:54.760
that we humans use to get stuff done. And so these programming languages, they're an intermediate

03:20:54.760 --> 03:21:00.520
representation between the human and the computer or the human and the compiler, roughly, right?

03:21:00.520 --> 03:21:05.640
And so I think the LLMs will have no problem learning whatever keyword we pick.

03:21:05.640 --> 03:21:09.400
Maybe the phi emoji is going to- Oh, maybe that's going to break it. It doesn't tokenize.

03:21:09.400 --> 03:21:14.520
No, the reverse of that, it will actually enable it. Because one of the issues I could see with

03:21:14.520 --> 03:21:20.360
being a superset of Python is there will be confusion by the gray area. So it will be mixing

03:21:20.360 --> 03:21:26.440
stuff. But- Well, I'm a human optimist. I'm also an LLM optimist. I think that we'll solve that

03:21:26.440 --> 03:21:34.840
problem. But you look at that and you say, okay, well, reducing the rote thing, right? Turns out

03:21:34.840 --> 03:21:39.080
compilers are very particular and they really want things. They really want the indentation to be

03:21:39.080 --> 03:21:43.560
right. They really want the colon to be there on your else or else it'll complain, right? I mean,

03:21:43.560 --> 03:21:49.000
compilers can do better at this, but LLMs can totally help solve that problem. And so I'm very

03:21:49.000 --> 03:21:53.640
happy about the new predictive coding and copilot type features and things like this,

03:21:53.640 --> 03:21:58.040
because I think it'll all just make us more productive. It's still messy and fuzzy and

03:21:58.040 --> 03:22:04.680
uncertain, unpredictable. But is there a future you see given how big of a leap GPT-4 was

03:22:05.480 --> 03:22:13.080
where you start to see something like LLMs inside a compiler or no? I mean, you could do that. Yeah,

03:22:13.080 --> 03:22:17.720
absolutely. I mean, I think that'd be interesting. Is that wise? Well, I mean, it would be very

03:22:17.720 --> 03:22:23.800
expensive. So compilers run fast and they're very efficient and LLMs are currently very expensive.

03:22:23.800 --> 03:22:28.280
There's on-device LLMs and there's other things going on. And so maybe there's an answer there.

03:22:28.840 --> 03:22:34.840
I think that one of the things that I haven't seen enough of is that so LLMs to me are amazing

03:22:34.840 --> 03:22:41.320
when you tap into the creative potential of the hallucinations, right? And so if you're doing

03:22:41.320 --> 03:22:45.960
creative brainstorming or creative writing or things like that, the hallucinations work in

03:22:45.960 --> 03:22:50.600
your favor. If you're writing code that has to be correct because you're going to ship it in

03:22:50.600 --> 03:22:56.040
production, then maybe that's not actually a feature. And so I think that there has been

03:22:56.040 --> 03:23:01.720
research and there has been work on building algebraic reasoning systems and kind of like

03:23:01.720 --> 03:23:06.520
figuring out more things that feel like proofs. And so I think that there could be interesting

03:23:06.520 --> 03:23:11.160
work in terms of building more reliable at scale systems. And that could be interesting.

03:23:11.160 --> 03:23:15.080
But if you've chased that rabbit hole down, the question then becomes, how do you express

03:23:15.080 --> 03:23:19.080
your intent to the machine? And so maybe you want an LLM to provide the spec,

03:23:19.080 --> 03:23:23.720
but you have a different kind of net that then actually implements the code.

03:23:23.720 --> 03:23:30.360
Right. So it's used as documentation and inspiration versus the actual implementation.

03:23:30.360 --> 03:23:31.240
Yeah, potentially.

03:23:33.160 --> 03:23:40.760
Since a successful modular will be the thing that runs, I say so jokingly, our AI overlords,

03:23:40.760 --> 03:23:47.320
but AI systems that are used across, I know it's a cliche term, but internet of things.

03:23:49.080 --> 03:23:52.040
I'll joke and say like, AGI should be written in Mojo.

03:23:52.040 --> 03:23:56.840
Yeah, AGI should be written in Mojo. You're joking, but it's also possible that it's not a joke.

03:23:58.600 --> 03:24:05.320
That a lot of the ideas behind Mojo seems like the natural set of ideas that would enable

03:24:05.400 --> 03:24:13.080
at scale training and inference of AI systems. So I just have to ask you about the big philosophical

03:24:13.080 --> 03:24:18.920
question about human civilization. So folks like Eliezer Yadkovsky are really concerned about

03:24:18.920 --> 03:24:26.520
the threat of AI. Do you think about the good and the bad that can happen

03:24:27.160 --> 03:24:29.560
at scale deployment of AI systems?

03:24:29.560 --> 03:24:33.880
Well, so I've thought a lot about it and there's a lot of different parts to this problem,

03:24:33.880 --> 03:24:39.480
everything from job displacement to Skynet, things like this. And so you can zoom into

03:24:39.480 --> 03:24:47.320
some parts of this problem. I'm not super optimistic about AGI being solved next year.

03:24:48.280 --> 03:24:50.040
I don't think that's going to happen personally.

03:24:50.040 --> 03:24:56.600
So you have a kind of Zen-like calm about, is there's a nervousness because the leap of GBT4

03:24:57.240 --> 03:25:03.960
seems so big. It's like we're almost, there's some kind of transitionary period.

03:25:03.960 --> 03:25:04.520
You're thinking...

03:25:05.800 --> 03:25:11.160
So I mean, there's a couple of things going on there. One is I'm sure GPT-5 and 7 and 19

03:25:11.160 --> 03:25:16.600
will be also huge leaps. They're also getting much more expensive to run. And so there may

03:25:16.600 --> 03:25:21.880
be a limiting function in terms of just expense on the one hand and train. That could be a limiter

03:25:21.880 --> 03:25:27.720
that slows things down. But I think the bigger limiter is outside of like Skynet takes over.

03:25:27.720 --> 03:25:31.320
And I don't spend any time thinking about that because if Skynet takes over and kills us all,

03:25:31.320 --> 03:25:35.320
then I'll be dead. So I don't worry about that. So, you know, I mean, that's just,

03:25:36.280 --> 03:25:40.040
okay, if other things worry about, I'll just focus on. I'll focus and not worry about that one.

03:25:41.240 --> 03:25:47.720
But I think that the other thing I'd say is that AI moves quickly, but humans move slowly and we

03:25:47.720 --> 03:25:54.040
adapt slowly. And so what I expect to happen is just like any technology diffusion, like the

03:25:54.040 --> 03:26:00.360
promise and then the application takes time to roll out. And so I think that I'm not even

03:26:00.360 --> 03:26:05.720
too worried about autonomous cars defining away all the taxi drivers. Remember, autonomy is supposed

03:26:05.720 --> 03:26:12.840
to be solved by 2020. Boy, do I remember. And so like, I think that on the one hand, we can see

03:26:12.840 --> 03:26:18.200
amazing progress, but on the other hand, we can see that, you know, the reality is a little bit

03:26:18.200 --> 03:26:22.520
more complicated and it may take longer to roll out than you might expect. Well, that's in the

03:26:22.520 --> 03:26:29.480
physical space. I do think in the digital space is the stuff that's built on top of LLMs that runs,

03:26:30.680 --> 03:26:35.400
you know, the millions of apps that can be built on top of them. And that could be run on millions

03:26:35.400 --> 03:26:44.040
of devices, millions of types of devices. I just think that the rapid effect it has on human

03:26:44.040 --> 03:26:51.480
civilization could be truly transformative to what we don't even know. Well, and there I think it

03:26:51.480 --> 03:26:59.320
depends on, are you an optimist or a pessimist or a masochist? Just to clarify, optimist about human

03:26:59.320 --> 03:27:05.080
civilization. Me too. And so I look at that as saying, okay, cool, well, AI do, right? And so

03:27:05.080 --> 03:27:09.400
some people say, oh my God, is it going to destroy us all? How do we prevent that? I kind of look at

03:27:09.400 --> 03:27:14.200
it from a, is it going to unlock us all? Right? You talk about coding, is it going to make, so I

03:27:14.200 --> 03:27:18.760
don't have to do all the repetitive stuff. Well, suddenly that's a very optimistic way to look at

03:27:18.760 --> 03:27:24.200
it. And you look at what a lot of, a lot of these technologies have done to improve our lives. And

03:27:24.200 --> 03:27:29.720
I want that to go faster. What do you think the future of programming looks like in the next 10,

03:27:29.800 --> 03:27:39.800
20, 30, 50 years with LLMs and with, with Mojo, with modular, like the vision for devices,

03:27:39.800 --> 03:27:44.120
the hardware to the compilers, to this, to the different stacks of software.

03:27:44.120 --> 03:27:47.720
Yeah. Well, so what I want, I mean, coming, coming back to my arch nemesis, right,

03:27:47.720 --> 03:27:54.040
it's complexity, right? So again, me being the optimist, if we drive down complexity,

03:27:54.040 --> 03:27:57.960
we can make these tools, these technologies, these cool hardware widgets

03:27:57.960 --> 03:28:02.600
accessible to way more people. Right. And so what I'd love to see is more personalized experiences,

03:28:02.600 --> 03:28:08.840
more things, the research getting into production instead of being lost at NeurIPS. Right. And so,

03:28:08.840 --> 03:28:14.360
and like the, the, the, these things that impact people's lives by entering products.

03:28:15.080 --> 03:28:17.960
And so one of the things that I'm a little bit concerned about is right now,

03:28:19.480 --> 03:28:24.280
the big companies are investing huge amounts of money and are driving the top line of AI capability

03:28:24.280 --> 03:28:29.400
for really quickly. But if it means that you have to have a hundred million dollars to train a model

03:28:29.400 --> 03:28:35.080
or more, a hundred billion dollars, right? Well, that's going to make it very concentrated with

03:28:35.080 --> 03:28:39.320
very few people in the world that can actually do this stuff. I would much rather see

03:28:40.600 --> 03:28:45.560
lots of people across the industry be able to participate and use this. Right. And you look

03:28:45.560 --> 03:28:50.120
at this, you know, I mean, a lot of great research has been done in the health world and looking at,

03:28:51.080 --> 03:28:55.880
like detecting pathologies and doing radiology with AI and like doing all these things.

03:28:56.440 --> 03:29:00.280
Well, the problem today is that to deploy and build these systems, you have to be an expert

03:29:00.280 --> 03:29:07.480
in radiology and expert in AI. And if we can break down the barriers so that more people can

03:29:07.480 --> 03:29:13.880
use AI techniques and it's more like programming Python, which roughly everybody can do if they

03:29:13.880 --> 03:29:18.200
want to. Right. Then I think that we'll get a lot more practical application of these techniques

03:29:18.200 --> 03:29:23.640
and a lot more niche-ier, cool, but narrower domains. And I think that's going to be really

03:29:23.640 --> 03:29:29.400
cool. Do you think we'll have more or less programmers in the world than now? Well, so

03:29:29.400 --> 03:29:33.560
I think we'll have more programmers, but they may not consider themselves to be programmers.

03:29:33.560 --> 03:29:37.080
That'd be a different name for it. Right. I mean, do you consider somebody that uses,

03:29:37.080 --> 03:29:42.840
you know, I think that arguably the most popular programming language is Excel. Yeah.

03:29:43.800 --> 03:29:48.920
Right. Yeah. And so do they consider themselves to be programmers? Maybe not. I mean, some of them

03:29:48.920 --> 03:29:57.880
make crazy macros and stuff like that. But what you mentioned, Steve Jobs, it's the bicycle for

03:29:57.880 --> 03:30:03.080
the mind that allows you to go faster. Right. And so I think that as we look forward, right,

03:30:03.080 --> 03:30:07.880
what is AI? I look at it as hopefully a new programming paradigm. It's like object-oriented

03:30:07.880 --> 03:30:11.480
programming. Right. If you want to write a cat detector, you don't use for loops.

03:30:12.200 --> 03:30:16.520
It turns out that's not the right tool for the job. Right. And so right now, unfortunately,

03:30:16.520 --> 03:30:20.920
because I mean, it's not unfortunate, but it's just kind of where things are. AI is this weird,

03:30:20.920 --> 03:30:25.720
different thing that's not integrated into programming languages and normal tool chains.

03:30:25.720 --> 03:30:30.680
And all the technology is really weird and doesn't work right. And you have to babysit it. And

03:30:30.680 --> 03:30:35.000
every time you switch to hardware, it's different. It shouldn't be that way. When you change that,

03:30:35.000 --> 03:30:39.160
when you fix that, suddenly, again, the tools and technologies can be way easier to use.

03:30:39.160 --> 03:30:42.920
You can start using them for many more things. And so that's what I would be excited about.

03:30:43.640 --> 03:30:46.920
What kind of advice could you give to somebody in high school right now or

03:30:46.920 --> 03:30:53.960
maybe early college who's curious about programming and feeling like the world is

03:30:53.960 --> 03:30:58.840
changing really quickly here? Yeah. What kind of stuff to learn? What kind of stuff to work on?

03:30:59.880 --> 03:31:04.520
Should they finish college? Should they go work at a company? Should they build a thing?

03:31:04.520 --> 03:31:09.000
What do you think? Well, so I mean, one of the things I'd say is that you'll be most

03:31:09.000 --> 03:31:14.440
successful if you work on something you're excited by. And so don't get the book and read the book

03:31:15.480 --> 03:31:20.360
cover to cover and study and memorize and recite and flashcard and go build something.

03:31:20.360 --> 03:31:24.520
Like go solve a problem. Go build the thing that you want to exist. Go build an app. Go

03:31:25.240 --> 03:31:29.640
build, train a model, like go build something and actually use it and set a goal for yourself.

03:31:29.640 --> 03:31:34.360
And if you do that, then you'll, you know, there's a success. There's the adrenaline rush.

03:31:34.360 --> 03:31:38.680
There's the achievement. There's the unlock that I think is where, you know, if you keep setting

03:31:38.680 --> 03:31:42.760
goals and you keep doing things and building things, learning by building is really powerful.

03:31:43.960 --> 03:31:47.560
In terms of career advice, I mean, everybody's different. It's very hard to give generalized

03:31:47.560 --> 03:31:53.720
experience, generalized advice. I'll speak as, you know, a compiler nerd. If everybody's going

03:31:53.720 --> 03:31:59.880
left, sometimes it's pretty cool to go right. And so just because everybody's doing a thing,

03:31:59.880 --> 03:32:06.040
it doesn't mean you have to do the same thing and follow the herd. In fact, I think that sometimes

03:32:06.040 --> 03:32:12.040
the most exciting paths for life lead to being curious about things that nobody else actually

03:32:12.040 --> 03:32:17.560
focuses on, right? And it turns out that understanding deeply parts of the problem that

03:32:17.560 --> 03:32:22.600
people want to take for granted makes you extremely valuable and specialized in ways that

03:32:23.480 --> 03:32:28.040
the herd is not. And so again, I mean, there's lots of rooms for specialization, lots of rooms

03:32:28.040 --> 03:32:32.120
for generalists. There's lots of room for different kinds and parts of the problem. But,

03:32:32.760 --> 03:32:36.280
but I think that it's, you know, just because everything, everybody's doing one thing doesn't

03:32:36.280 --> 03:32:42.120
mean you should necessarily do it. And now the herd is using Python. So if you want to be a rebel,

03:32:43.000 --> 03:32:50.200
go check out Mojo and help Chris and the rest of the world fight the arch nemesis of complexity

03:32:50.200 --> 03:32:54.600
because simple is beautiful. There you go. Because you're an incredible person. You've,

03:32:54.600 --> 03:32:59.000
you've been so kind to me ever since we met. You've been extremely supportive. I'm forever

03:32:59.000 --> 03:33:04.520
grateful for that. Thank you for being who you are, for being legit, for being kind, for fighting this

03:33:06.680 --> 03:33:12.120
really interesting problem of how to make AI accessible to a huge number of people,

03:33:12.120 --> 03:33:16.760
huge number of devices. Yeah. Well, so Lex, you're a pretty special person too, right? And so

03:33:17.320 --> 03:33:21.960
I think that, you know, one of the funny things about you is that besides being curious and pretty

03:33:21.960 --> 03:33:26.680
damn smart, you're actually willing to push on things. And you're, I think that you've got

03:33:26.680 --> 03:33:31.160
an agenda to like make the world think, which I think is a pretty good agenda.

03:33:31.160 --> 03:33:35.000
It's a pretty good one. Thank you so much for talking to Chris. Yeah, thanks Lex.

03:33:36.120 --> 03:33:39.880
Thanks for listening to this conversation with Chris Latner. To support this podcast,

03:33:39.880 --> 03:33:44.920
please check out our sponsors in the description. And now let me leave you some words from Isaac

03:33:44.920 --> 03:33:53.880
Asimov. I do not fear computers. I fear the lack of them. Thank you for listening and hope to see you

03:33:53.880 --> 03:33:54.440
next time.

