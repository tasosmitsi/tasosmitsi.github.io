WEBVTT

00:00.000 --> 00:04.720
a radical political movement, of which there will always be a lot in the country,

00:05.680 --> 00:09.680
has managed to do something that a radical movement's not supposed to be able to do in the

00:09.680 --> 00:16.000
U.S., which is they've managed to hijack institutions all across the country and hijack

00:16.000 --> 00:21.600
medical journals and universities and, you know, the ACLU, you know, all the, you know,

00:21.600 --> 00:27.360
activist organizations and nonprofits and many tech companies. And the way I view a liberal

00:27.360 --> 00:32.400
democracy is it is a bunch of these institutions that were that were trial and error crafted over,

00:32.400 --> 00:39.600
you know, hundreds of years. And they all rely on trust, public trust, and a certain kind of

00:39.600 --> 00:45.200
feeling of unity that actually is critical to a liberal democracy's functioning. And what I see

00:45.200 --> 00:51.520
this thing is, is as a parasite on that, that whose goal is, and I'm not saying each, by the way,

00:51.520 --> 00:56.240
each individual in this is, I don't think they're bad people. I think that it's the ideology itself

00:56.240 --> 01:02.160
has the property of its goal is to tear apart the pretty delicate workings of the liberal

01:02.160 --> 01:09.760
democracy and shred the critical lines of trust. The following is a conversation with Tim Urban,

01:09.760 --> 01:15.440
his second time in the podcast. He's the author and illustrator of the amazing blog called Wait,

01:15.440 --> 01:21.520
But Why, and is the author of a new book coming out tomorrow called What's Our Problem,

01:21.520 --> 01:26.480
a self-help book for societies. We talk a lot about this book in this podcast,

01:26.480 --> 01:32.160
but you really do need to get it and experience it for yourself. It is a fearless, insightful,

01:32.160 --> 01:37.120
hilarious, and I think important book in this divisive time that we live in.

01:37.120 --> 01:41.840
The Kindle version, the audiobook, and the web version should be all available on date of

01:41.840 --> 01:49.360
publication. I should also mention that my face might be a bit more beat up than usual. I got

01:49.360 --> 01:55.280
hit in the chin pretty good since I've been getting back into training jiu-jitsu,

01:55.280 --> 02:01.200
a sport I love very much after recovering from an injury. So if you see marks on my face during

02:01.200 --> 02:06.400
these intervals of conversations, you know that my life is in a pretty good place.

02:07.200 --> 02:12.320
This is the Lex Friedman podcast. To support it, please check out our sponsors in the description.

02:12.320 --> 02:15.440
And now, dear friends, here's Tim Urban.

02:15.440 --> 02:22.080
Tim, you wrote an incredible book called What's Our Problem, a self-help book for societies.

02:23.200 --> 02:30.960
In the beginning, you present this view of human history as a thousand-page book,

02:31.840 --> 02:39.040
where each page is 250 years. And it's a brilliant visualization because almost nothing happens

02:39.040 --> 02:45.200
for most of it. So what blows your mind most about that visualization when you just sit back

02:45.200 --> 02:51.040
and think about it? I think it's a boring book. So 950 pages, 95% of the book, hunter-gatherers

02:51.040 --> 02:55.280
kind of doing their thing. I'm sure there's obviously some major cognitive advancements

02:55.280 --> 03:00.880
along the way and language. And I'm sure the bow and arrow comes around at some point. So tiny

03:00.880 --> 03:05.040
things, but it's like, oh, now we have 400 pages until the next thing. But then you get to page 950

03:05.600 --> 03:09.040
and things start moving. Recorded history starts at 976.

03:09.040 --> 03:13.680
Right. So basically, the bottom row is when anything interesting happens. There's a bunch

03:13.680 --> 03:19.280
of agriculture for a while before we know anything about it. And then recorded history starts.

03:19.280 --> 03:27.200
Yeah, 25 pages of actual recorded history. So when we think of prehistoric, we're talking about pages

03:27.200 --> 03:36.480
one through 975 of the book. And then history is page 976 to 1000. If you were reading the book,

03:36.480 --> 03:42.640
it would be like epilogue AD, the last little 10 pages of the book. And we think of AD is super

03:42.640 --> 03:50.080
long, 2000 years, the Roman Empire 2000 years ago. That's so long. Human history has been going on

03:50.080 --> 03:58.800
for over 2000 centuries. It's hard to wrap your head around. And even that's just the end of a

03:58.800 --> 04:07.040
very long road. The 100,000 years before that, it's not like that was that different. So it's

04:07.040 --> 04:13.040
just, there's been people like us that have emotions like us, that have physical sensations

04:13.040 --> 04:23.120
like us for so, so long. And who are they all? And what was their life like? I think we have

04:23.120 --> 04:28.080
no idea what it was like to be them. The thing that's craziest about the people of the far past

04:28.080 --> 04:32.240
is not just that they had different lives, they had different fears, they had different dangers

04:32.240 --> 04:36.240
and different responsibilities, and they lived in tribes and everything, but they didn't know

04:36.240 --> 04:40.720
anything. We just take it for granted that we're born on top of this tower of knowledge.

04:40.720 --> 04:46.960
And from the very beginning, we know that the earth is a ball floating in space. And we know

04:46.960 --> 04:54.640
that we're going to die one day. And we know that we evolved from animals. Those were all like

04:54.640 --> 05:00.080
incredible epiphanies quite recently. And the people a long time ago, they just had no idea

05:00.080 --> 05:04.640
what was going on. And I'm kind of jealous because I feel like it might have been scary to not know

05:04.640 --> 05:08.400
what's going on, but it also I feel like would be, you'd have a sense of awe and wonder all the

05:08.400 --> 05:11.680
time and you don't know what's going to happen next. And once you learn, you're kind of like,

05:11.680 --> 05:16.880
oh, that's like, it's a little grim. But they probably had the same capacity for consciousness

05:17.600 --> 05:23.120
to experience the world, to wander about the world, maybe to construct narratives about the

05:23.120 --> 05:30.720
world and myths and so on. They just had less grounded systematic facts to play with. They

05:30.720 --> 05:36.320
still probably felt the narratives, the myths that constructed as intensely as we do.

05:36.320 --> 05:42.960
Oh yeah. They also fell in love. They also had friends and they had falling outs with friends.

05:42.960 --> 05:46.400
They didn't shower much though. No, they did not smell nice.

05:47.520 --> 05:52.560
Maybe they did. Maybe beauty is in the eye of the beholder. Maybe it's all like relative.

05:53.520 --> 05:58.720
How many people in history have experienced a hot shower? Like almost none. That's like

05:58.880 --> 06:05.600
when we're hot showers invented a hundred years ago, like less. So like George Washington never

06:05.600 --> 06:10.560
had a hot shower. It's like, it's just kind of weird. Like he took cold showers all the time

06:12.400 --> 06:16.880
and again, we just take this for granted, but that's like an unbelievable life experience

06:16.880 --> 06:22.640
to have a rain, a controlled little booth where it rains hot water on your head.

06:23.200 --> 06:25.520
And then you get out and it's not everywhere. It's like contained.

06:25.920 --> 06:30.160
Um, that was like, you know, they, a lot of people probably lived and died with never

06:30.160 --> 06:34.240
experiencing hot water. Maybe they, they had a way to heat water over a fire, but like then it's,

06:34.240 --> 06:40.000
I don't know. It's just like, there's a, there's so many things about our lives now that are

06:40.000 --> 06:44.400
completely just total anomaly. It makes you wonder like, what is the thing that would notice the

06:44.400 --> 06:52.160
most? I mean, the sewer system, like it doesn't smell in cities. What does the sewer system do?

06:52.160 --> 06:55.680
I mean, it gets rid of waste efficiently, et cetera. We don't have to confront it

06:55.680 --> 07:00.000
both with our, with any of our senses. And that's probably wasn't there. I mean,

07:00.000 --> 07:03.760
what else? Plus all the medical stuff associated with. Yeah. I mean, how about the disease?

07:03.760 --> 07:09.040
Yeah. How about the cockroaches and the rats and the, and the disease and the, the plagues and,

07:09.040 --> 07:12.640
you know, and, and then when they got, so they, they caught more diseases, but then when they

07:12.640 --> 07:17.760
caught the disease, they also didn't have treatment for it. So they often would die or they would just

07:17.760 --> 07:23.280
be in a huge amount of pain. They also didn't know what the disease was. They don't know about

07:23.280 --> 07:27.200
microbes. That was this new thing. The idea that these tiny little animals that are causing these

07:27.200 --> 07:32.400
diseases. So what did they think? You know, in the, the bubonic plague, you know, in the black death,

07:32.400 --> 07:37.920
the 1300s, people thought that it was an act of God because, you know, God's angry at us.

07:37.920 --> 07:41.360
Cause why would, you know, why would you not think that if you didn't know what it was?

07:42.400 --> 07:46.640
And so the crazy thing is that these were the same primates. So I do know something about them. I

07:46.640 --> 07:52.480
know in some sense what it's like to be them. Cause I am a human as well. And to know that this

07:52.480 --> 07:58.880
particular primate that I know what it's like to be experienced such different things. It's, and,

07:58.880 --> 08:04.000
and like, this isn't, our life is not the life that this primate has experienced almost ever.

08:04.000 --> 08:09.520
So it's just a, it's just a bit strange. I don't know. I have a sense that we would get

08:09.520 --> 08:15.280
acclimated very quickly. Like if we threw ourselves back a few thousand years ago,

08:15.280 --> 08:19.280
it would be very uncomfortable at first, but the whole hot shower thing, you'll get used to it.

08:19.280 --> 08:19.600
Oh yeah.

08:19.600 --> 08:25.440
After a year, you would not even like miss it. Cause there's a few, I'm trying to remember

08:25.440 --> 08:30.160
which book that talks about hiking that Appalachian trail, but you kind of miss those

08:30.160 --> 08:34.240
hot showers. But I have a sense like after a few months, after a few years.

08:34.240 --> 08:36.560
Well, your skill recalibrates. Yeah.

08:36.560 --> 08:41.200
Yeah. I was saying the other day to a friend that whatever you're used to, you start to think that,

08:41.200 --> 08:45.840
oh, that the people that have more than me are more fortunate. Like it's just sounds incredible.

08:45.840 --> 08:49.760
I would, I would be so happy, but you know, that's not true. Cause you experience what would happen

08:49.760 --> 08:53.680
is you would, you would, you would get these new things or you would, you would get these new

08:53.680 --> 08:57.120
opportunities and then you would get used to it. And then you would, this, the hedonic treadmill,

08:57.120 --> 09:01.280
you'd come back to where you are. And likewise though, cause you think, oh my God, what if I had

09:01.280 --> 09:06.880
to, you know, have this kind of job that I never would want, or I had this kind of marriage that

09:06.880 --> 09:10.720
I never would want. You know what, if you did, you would adjust and you get used to it and you

09:10.720 --> 09:15.680
might not be that much less happy than you are now. So on the other side of the, you being okay,

09:15.680 --> 09:19.840
going back, you know, you, we would survive if we had to go back. Um, you know, we'd have to

09:19.840 --> 09:23.840
learn some skills and, but, but we would buck up and, you know, people have gone to war before

09:23.840 --> 09:27.520
that were in the shopkeepers a year before that they were in the trenches the next year.

09:28.400 --> 09:32.480
But on the other hand, if you brought them here, you know, I always think it'd be so fun to just

09:32.480 --> 09:37.120
bring, forget the hunter gatherers, bring a 1700s person here and tour them around, take them on an

09:37.120 --> 09:40.880
airplane and show them your phone and all the things that can do, show them the internet,

09:40.880 --> 09:46.080
show them the grocery store. Imagine taking them to a whole foods. Likewise, I think they would be

09:46.080 --> 09:51.520
completely awestruck and on their knees crying tears of joy. And then they'd get used to it

09:51.520 --> 09:55.040
and they'd be a complaint about like, you know, you don't have the oranges in stock is like, you

09:55.040 --> 09:59.360
know, and that's, you know, the grocery store is a tough one to get used to. Like when I, when I

09:59.360 --> 10:04.880
first came to this country, the, uh, the abundance of bananas was the thing that struck me the most

10:04.880 --> 10:12.000
or like fruits in general, but food in general, but bananas somehow struck me the most that you

10:12.000 --> 10:17.600
could just eat them as much as you want. That took a long time for me. It probably took several years

10:17.600 --> 10:23.760
to really get acclimated to that. Is that- Why didn't you have bananas?

10:24.400 --> 10:32.240
Uh, the number of banana, fresh bananas, I don't, that wasn't available. Bread, yes. Bananas, no.

10:32.400 --> 10:37.680
Hmm. Yeah. It's like, we don't even know what to have, like, we don't even know the proper levels

10:37.680 --> 10:41.760
of gratitude. You know, walking around the grocery store, I don't know to be like, the bread's nice,

10:41.760 --> 10:45.440
but the bananas are like, we're so lucky. I don't know. I'm like, oh, I could have been the other

10:45.440 --> 10:52.640
way. I have no idea. Well, it's interesting then where we point our gratitude in the West,

10:52.640 --> 10:55.200
in the United States. Probably,

10:58.720 --> 11:05.040
do we point it away from materialist possessions towards, or do we just aspire that, to do that

11:05.040 --> 11:10.000
towards other human beings that we love? Because in the East, in the Soviet Union,

11:10.960 --> 11:17.680
growing up poor, it's having food is the gratitude. Having transportation is gratitude.

11:18.320 --> 11:25.600
Having warmth and shelter is gratitude. And now, but see within that, the deep gratitude is for

11:25.600 --> 11:30.880
other human beings. It's the penguins huddling together for warmth in the cold. I think it's a

11:30.880 --> 11:35.200
person-by-person basis. I mean, I'm sure, yes, of course, in the West, we will, on average,

11:35.200 --> 11:39.280
feel gratitude towards different things, or maybe a different level of gratitude. Maybe we feel less

11:39.280 --> 11:44.480
gratitude than some, than countries that, um, you know, obviously I think the easiest, the person

11:44.480 --> 11:49.360
that's most likely to feel gratitude is going to be someone whose life happens to be one where they

11:49.360 --> 11:53.520
just move up, up, up throughout their life. A lot of people in the greatest generation, you know,

11:53.520 --> 11:58.080
people who were born in the twenties or whatever, and a lot of the boomers too, the story is the

11:58.080 --> 12:02.640
greatest generation grew up dirt poor and they often ended up middle class. And the boomers,

12:02.640 --> 12:07.680
some of them started off middle class and many of them ended up quite wealthy. And I feel like

12:07.680 --> 12:15.520
that life trajectory is naturally going to, um, foster gratitude, right? Um, because you're not

12:15.520 --> 12:19.040
going to take for granted these things because you didn't have them. Um, you know, I didn't go out of

12:19.040 --> 12:23.680
the country really in my childhood very much. Um, you know, like, you know, uh, we, we traveled,

12:23.680 --> 12:28.640
but it was to Virginia to see my grandparents or Wisconsin to see other relatives or, you know,

12:28.640 --> 12:32.720
maybe Florida after going on to the beach. And then I started going out of the country like crazy

12:32.720 --> 12:37.680
in my twenties. Cause I, I really, you know, became my favorite thing. And I feel like because

12:37.680 --> 12:40.800
I, if I had grown up always doing that, it would have been another thing. I'm like, yeah,

12:40.800 --> 12:45.680
that's just something I do. But I still, every time I go to a new country, I'm like, oh my God,

12:45.680 --> 12:48.640
this is so cool. And in another country, this thing I've only seen on the map. I'm like,

12:48.640 --> 12:53.920
I'm there now. And so I feel like it's, it's, it's a lot of times it's a product of what you

12:53.920 --> 13:00.160
didn't have. And then you suddenly had, but I still think it's case by case in that there's a,

13:00.160 --> 13:07.120
there's like a meter in everyone's head, you know, uh, that I think on, on, on, at a, at a 10,

13:07.760 --> 13:12.480
you are, you're experiencing just immense gratitude, right? Which is a euphoric feeling.

13:12.480 --> 13:19.520
It's a great feeling. Um, and it's, um, it's, it makes you happy to savor what you have,

13:19.520 --> 13:24.000
to look down at the mountain of stuff you have that you're standing on, right? To look,

13:24.000 --> 13:29.040
to look down at and say, oh my God, I'm so lucky and I'm so grateful for this and this and this.

13:30.000 --> 13:33.840
Obviously that's a happy exercise. Now, when you move the meter down to six or seven,

13:33.840 --> 13:38.560
maybe you think that sometimes, but you're, you're not always thinking that, um, uh,

13:38.560 --> 13:43.760
cause you're sometimes looking up at this cloud of things that you don't have and the things that

13:43.760 --> 13:47.440
they have, but you don't or the things you wished you had or you thought you were going to have or

13:47.440 --> 13:51.600
whatever. And that's the opposite direction to look, right? And, and that's the, either that's,

13:51.600 --> 13:57.520
that's envy, that's yearning, um, or often it's, it's, it's, if you think about your past, um,

13:57.840 --> 14:02.480
it's grievance, right? And so then you go into a one and you have someone who feels like a

14:02.480 --> 14:07.440
complete victim. They are just a victim of the society, of their, their, their, their siblings

14:07.440 --> 14:13.360
and their parents and their, their loved one. Um, and they are, um, they're wallowing in

14:14.240 --> 14:16.880
everything that's happened wrong to me, everything I should have that I don't,

14:16.880 --> 14:21.760
everything that has gone wrong for me. And so that's a very unhealthy, mentally unhealthy

14:21.760 --> 14:26.320
place to be. Um, anyone can go there, you know, there's an endless list of stuff you can be,

14:26.320 --> 14:30.080
it can be aggrieved about and an endless list of stuff you can have gratitude for.

14:30.080 --> 14:33.920
And so it's, it's, in some ways it's a choice and it's a habit. And maybe it's part of how

14:33.920 --> 14:37.600
we were raised or our natural demeanor, but it's such a good, you are really good at this by the

14:37.600 --> 14:45.040
way. Your Twitter is like, go on. Well, like, uh, like you're, you, you, you are constantly just

14:45.040 --> 14:50.000
saying, man, I'm lucky or like, I'm, I'm so grateful for this. And that's, it's, it's a

14:50.000 --> 14:52.720
good thing to do because you're reminding yourself, but you're also reminding other

14:52.720 --> 14:58.320
people to think that way. And it's like, we are lucky. Um, you know, and, um, and so anyway,

14:58.320 --> 15:01.520
I think that scale can go from one to 10 and I think it's hard to be 10. I think you'd be very

15:01.520 --> 15:06.240
happy if you could be, but I think trying to be above a five and looking down at the things you

15:06.240 --> 15:12.240
have more often than you are looking up at the things you don't or being resentful about the

15:12.240 --> 15:17.440
things that people have wronged you. And well, the interesting thing I think was an open question,

15:18.000 --> 15:22.960
but I suspect that you can control that knob for, for the individual. Like you yourself can

15:22.960 --> 15:27.760
choose. It's like the stoic philosophy. You could choose where you are as a matter of habit. Like

15:27.760 --> 15:33.440
you said, but you can also probably control that on a scale of a family, of a tribe, of a, of a

15:33.440 --> 15:38.240
nation, of a society. I mean, a lot, you can describe a lot of the things that happens in

15:38.240 --> 15:44.480
Nazi Germany and different other parts of history through a sort of societal envy and resentment

15:44.480 --> 15:50.720
that builds up. Maybe certain narratives pick up and then they infiltrate your mind and then

15:50.720 --> 15:55.360
now your knob goes to, from the gratitude for everything, it goes to resentment and envy.

15:56.000 --> 16:01.360
Germany between the two world wars, you know, like, like you said, the Soviet, um,

16:02.320 --> 16:06.560
kind of mentality. Um, so yeah, and then when you're soaking in a culture,

16:06.560 --> 16:12.480
so there's this kind of two factors, right? It's, um, it's, it's what's going on in your own head

16:12.480 --> 16:15.680
and then what's surrounding you and what's surrounding you kind of has concentric circles.

16:15.680 --> 16:20.560
There's your immediate group of people. Cause that group of people, if they're a certain way,

16:20.560 --> 16:23.760
if they feel a lot of gratitude and they talk about it a lot, that kind of insulates you from

16:23.760 --> 16:27.680
the broader culture because you know, the, the, the, the people are going to have the most impact

16:27.680 --> 16:32.320
on you are the ones closest, but often they're all the, all the concentric circles are, are saying

16:32.320 --> 16:35.760
the same thing. The people around you are the feeling the same way that the broader community,

16:35.760 --> 16:41.040
which is feeling the same way as the broader country. Um, and you know, I think this is why

16:41.040 --> 16:46.560
I think American patriotism, you know, nationalism, you know, can be tribal, can be very not,

16:46.560 --> 16:54.080
not a good thing. Patriotism, um, I think is, is a great thing because really what is patriotism?

16:54.080 --> 16:57.440
I mean, it's, if you love your country, you should love your fellow countrymen, you know, to

16:57.440 --> 17:02.400
Patriot, you know, that's a Reagan quote. It's like patriotism is like, I think a feeling of like,

17:02.960 --> 17:10.080
um, unity, um, and, but it also comes along with an implicit kind of concept of gratitude because

17:10.080 --> 17:13.680
it's like, we are so lucky to live in, you know, people, you know, think it's chauvinist to say we

17:13.680 --> 17:17.360
live in the best country in the world. Right. And you know, yes, when Americans say that no one

17:17.360 --> 17:22.080
likes it. Right. But actually it's not a bad thing to think. It's a nice thing to think it thinks

17:22.080 --> 17:26.160
it's a way of saying, I'm so grateful for all the great things of this country gives to me

17:26.160 --> 17:29.040
in this country has done. And, and I think, you know, if you heard the Phillip, you know,

17:29.040 --> 17:31.760
a Filipino person say, you know what, the Philippines is the best country in the world.

17:31.760 --> 17:35.520
No one in America would say that's chauvinist. They'd say awesome. Right. Because when it's

17:35.520 --> 17:40.240
coming from someone, you know, who's not American, it sounds totally fine. Um, but I think,

17:40.240 --> 17:43.920
I think, you know, national pride is actually good. Now, again, that can quickly translate into

17:43.920 --> 17:47.120
xenophobia and nationalism. And so, you know, you have to make sure it doesn't go off that cliff,

17:47.120 --> 17:52.160
but yeah, there's good ways to formulate that. Like you talk about, we'll talk about like high

17:52.160 --> 18:00.000
wrong progressivism, high wrong conservatism. Those are two different ways of, of, uh,

18:00.000 --> 18:04.960
embodying patriotism. So you could talk about maybe loving the tradition that this country

18:04.960 --> 18:10.880
stands for, or you can talk about loving the people, the, uh, that ultimately push progress.

18:10.880 --> 18:16.400
And those are, from an intellectual perspective, a good way to represent, uh, patriotism. We got

18:16.400 --> 18:21.600
to zoom out because this, this graphic is epic. A lot of images in your book are just epic on

18:21.600 --> 18:27.520
their own. It's brilliantly done, but this one has, uh, famous people for each of the cards,

18:29.360 --> 18:34.800
like the best of, uh, for you. By the way, good for them to be the person. Yeah.

18:35.520 --> 18:38.160
It's not that I could have chosen lots of people for each card,

18:38.160 --> 18:42.720
but I think most people would agree, you know, that's a pretty fair choice for each, each page

18:42.720 --> 18:46.320
and to good for them to be, you know, you, you crushed it. If you can be the person for your

18:46.320 --> 18:50.960
whole 250 year page. So, well, I noticed he put Gandhi didn't put Hitler. I mean,

18:51.680 --> 18:56.160
there's a lot of people going to argue with you about that particular last page. True. Yes,

18:56.160 --> 19:00.080
you're right. I could have, I could have put an, I actually, I was thinking about Darwin there too.

19:01.040 --> 19:04.960
Einstein. Yeah, exactly. You really could have put anyone. Do you think about putting yourself

19:04.960 --> 19:08.240
for a second? Yeah, I should have. I should have. That would have been awesome. Uh, I'm sure that

19:08.240 --> 19:11.680
would have endeared the readers to me from right from the beginning of the first page of the book.

19:12.240 --> 19:16.640
Uh, a little bit of a messianic complex going on, but yeah. So the list of people, just so you know,

19:16.640 --> 19:24.160
so these are 250 year chunks, the last one being from 1770 to 2020. And so it goes Gandhi,

19:24.160 --> 19:30.000
Shakespeare, Joan of Arc, Genghis Khan, Charlemagne, Muhammad, Constantine,

19:30.000 --> 19:36.240
Jesus, Cleopatra, Aristotle, Buddha. That's so interesting to think about this very

19:36.240 --> 19:41.920
recent human history. That's 11 pages. So it would be 2750, almost 3000 years.

19:42.640 --> 19:48.000
Just that there's these figures that stand out and then define the course of human history.

19:48.800 --> 19:55.360
It's like the cra- the craziest thing to me is that like Buddha was a dude. He was a guy with like

19:56.240 --> 20:01.920
arms and legs and fingernails that he maybe bit and like he liked certain foods and maybe he got

20:01.920 --> 20:09.040
like, uh, you know, he had like digestive issues sometimes and like he got cuts and they stung and

20:09.040 --> 20:14.560
like he was a guy. Um, and he had hopes and dreams and he probably had a big ego for a while before

20:14.560 --> 20:19.440
he, I guess Buddha totally overcame that one. But like, and it's like, who knows, you know,

20:19.440 --> 20:23.280
you know, what the myth, the mythical figure of Buddha, who knows how similar he was, but the fact

20:23.280 --> 20:29.440
same with Jesus, like this was a good guy. Like to me, it's, he's a primate. What a impact.

20:29.440 --> 20:31.520
He was a cell first and then a baby.

20:31.520 --> 20:33.440
Yeah, he was a fetus at some point.

20:33.440 --> 20:35.520
A dumb baby trying to learn how to walk.

20:35.520 --> 20:37.280
Yeah, like having tantrum.

20:37.280 --> 20:37.600
Yeah.

20:37.600 --> 20:41.200
Um, because he's frustrated because he's in the terrible twos. Jesus was in the terrible twos.

20:41.200 --> 20:43.760
Buddha never had a tantrum. Let's be honest. The myth.

20:44.480 --> 20:46.160
The mother was like, this baby's great.

20:48.480 --> 20:49.360
Figure something out.

20:51.040 --> 20:55.600
Listen, hearing, learning about Genghis Khan, it's incredible to me because it's just like,

20:55.600 --> 21:04.240
this was some, um, Mongolian, you know, herder guy who was taken as a slave and he was like dirt

21:04.240 --> 21:10.560
poor, you know, catching rats is a, you know, young teen with, you know, to feed him and his mom

21:10.560 --> 21:19.360
and his, I think his brother. Um, and it's just like the, the, the odds on when he was born,

21:19.360 --> 21:25.920
he was just one of, you know, probably tens of thousands of random teen boys living in Mongolia

21:26.560 --> 21:31.680
in the 1200s. The odds of that person, any one of them being a household name today that we're

21:31.680 --> 21:37.120
talking about, it's just crazy. Like what had to happen. Um, and it's for that guy to, for that

21:37.120 --> 21:43.920
poor dirt, poor herder to take over the world. I don't know. So history just like continually

21:43.920 --> 21:48.560
blows my mind. Like, you know, and he's the reason you and I are related probably.

21:48.560 --> 21:53.360
Yeah, no. I mean, it's, it's also, that's the other thing is that some of these dudes by

21:54.240 --> 21:58.480
becoming king, by being, having a better army at the right time, you know, William the conqueror

21:58.480 --> 22:02.160
whatever has is in the right place at the right time with the right army, you know, and there's

22:02.160 --> 22:07.040
a weakness at the right moment and he comes over and he exploits it and ends up probably having,

22:07.040 --> 22:12.080
you know, I don't know, thousand children and those children are high up people who might be

22:12.080 --> 22:17.920
have a ton of this species is different now because of him. Like if that is, forget England's

22:17.920 --> 22:23.600
different or, you know, European borders look different, like, like we are like, we look

22:23.600 --> 22:28.880
different because of a small handful of people, you know, when I, sometimes I think I'm like,

22:28.880 --> 22:33.280
oh, you know, this part of the world, I can recognize someone's Greek, you know, someone's

22:33.280 --> 22:36.400
Persian, someone's wherever because, you know, they kind of have certain facial features.

22:36.400 --> 22:39.600
And I'm like, it may have happened. I mean, obviously it's that that's a population,

22:39.600 --> 22:45.760
but it may be that like someone 600 years ago that looked like that really spread their seed.

22:45.760 --> 22:49.840
And that's why the ethnicity looks kind of like that now. Sorry. Anyway.

22:49.840 --> 22:55.920
Yeah. Yeah. Do you think individuals like that can turn the direction of history

22:56.880 --> 23:00.080
or is that an illusion that narrative would tell ourselves?

23:00.800 --> 23:04.160
Well, it's both. I mean, so I said that William the conqueror, right? Or Hitler, right?

23:05.440 --> 23:10.240
It's not that Hitler was born and destined to be great at all, right? I think in a lot of cases,

23:10.240 --> 23:15.040
he's some frustrated artist with a temper who's turning over the table in his studio and hitting

23:15.040 --> 23:22.240
his wife and being kind of a dick and a total nobody, right? I think almost all the times you

23:22.240 --> 23:27.040
could have put Hitler baby on earth. He's a, he's a rando, right? You know, and maybe he's a, you

23:27.040 --> 23:31.040
know, maybe sometimes he becomes a, you know, some kind of, you know, he uses this speaking

23:31.040 --> 23:34.240
ability because that ability was going to be there either way, but maybe he uses it for something

23:34.240 --> 23:41.200
else. But, but that said, I don't also, I think you, but it's not that a world war two was going

23:41.280 --> 23:46.400
to happen either way, right? So it's, it's both. It's that like these circumstances were one way

23:46.400 --> 23:52.160
and this person came along at the right time and those two made a match made in this case hell.

23:52.160 --> 23:58.240
But it makes you wonder, yes, it's a match in hell, but are there other people that could have taken

23:58.240 --> 24:05.120
this place or do these people that stand out? They're the rare spark of that genius, whether

24:05.120 --> 24:12.000
it take us towards evil, towards good, whether those figures singularly define the trajectory

24:12.000 --> 24:17.440
of humanity. You know, what defines the trajectory of humanity in the 21st century, for example,

24:17.440 --> 24:22.480
might be the influence of AI, might be the influence of nuclear war, negative or positive,

24:23.440 --> 24:30.880
not in the case of nuclear war, but the bioengineering, nanotech,

24:33.040 --> 24:38.320
virology, what else is there? Maybe the structure of governments and so on,

24:39.280 --> 24:42.960
maybe the structure of universities. I don't know. There could be singular figures that stand up

24:43.600 --> 24:50.880
and lead the way for human, but I wonder if the society is the thing that manifests that person

24:50.880 --> 24:57.360
or that person really does have a huge impact. I think it's probably a spectrum where there are

24:57.360 --> 25:04.720
some cases when a circumstance was such that something like what happened was going to happen.

25:04.720 --> 25:08.560
If you pluck that person from the earth, I don't know whether the Mongols is a good example or

25:08.560 --> 25:14.480
not, but maybe it could be that if you plucked Genghis Khan as a baby, there was because of the

25:14.480 --> 25:22.320
specific way Chinese civilization was at that time and the specific climate that was causing

25:22.320 --> 25:26.480
a certain kind of pressure on the Mongols and the way they still had their great archers and they

25:26.480 --> 25:31.040
had their horses and they had a lot of the same advantages, so maybe it was waiting to happen,

25:31.040 --> 25:35.600
right? It was going to happen either way and might not have happened to the extent or whatever,

25:35.600 --> 25:39.600
so maybe, or you could go the full other direction and say, actually, this was probably not going to

25:39.600 --> 25:48.320
happen. I think World War II is an example. I think World War II really was the work of,

25:48.320 --> 25:51.200
of course, it relied on all these other circumstances. You had to have the resentment

25:51.200 --> 25:56.160
in Germany. You had to have the Great Depression, but I think if you take Hitler out, I'm pretty

25:56.160 --> 26:01.760
sure World War I, World War II doesn't happen. Well, then it seems easier to answer these

26:01.760 --> 26:05.600
questions when you look at history, even recent history, but let's look at now. Let's look at,

26:05.600 --> 26:10.960
I'm sure we'll talk about social media. So who are the key players in social media? Mark Zuckerberg.

26:12.080 --> 26:18.480
What's the name of the MySpace guy? Tom? Tom, it's just Tom, yeah. There's a meme going around

26:18.480 --> 26:24.240
where MySpace is the perfect social media because no algorithmic involvement, everybody's happy and

26:24.240 --> 26:29.040
positive. Also, Tom did it right. At the time, you were like, oh man, Tom only made a few million

26:29.040 --> 26:35.120
dollars. Sucks to not be Zuck. Tom might be living a nice life right now where he doesn't

26:35.120 --> 26:40.160
have this nightmare that these other people have. Yeah. And he's always smiling in his profile.

26:41.920 --> 26:46.080
And then so there's like Larry Page, so with Google, that's kind of intermingled into that

26:46.080 --> 26:51.920
whole thing, into the development of the internet. Jack Dorsey, now Elon. Who else? I mean, there's

26:51.920 --> 26:56.800
people playing with the evolution of social media. And to me, that seems to be

26:58.720 --> 27:03.680
connected to the development of AI. And it seems like those singular figures

27:03.680 --> 27:08.640
will define the direction of AI development and social media development with social media seeming

27:08.640 --> 27:14.960
to have such a huge impact on our collective intelligence. It does feel in one way like

27:16.160 --> 27:20.800
individuals have an especially big impact right now in that a small number of people are pulling

27:20.800 --> 27:28.240
some big levers. And there can be a little meeting of three people at Facebook and they come in,

27:28.240 --> 27:31.200
they come out of that meeting and make a decision that totally changes the world.

27:32.160 --> 27:39.280
On the other hand, you see a lot of conformity. They all pulled the plug on Trump the same day.

27:41.440 --> 27:45.520
So that suggests that there's some bigger force that is also kind of driving them,

27:46.160 --> 27:52.800
in which case it's less about the individuals. I think what is leadership? To me, leadership

27:53.680 --> 27:59.520
is the ability to move things in a direction that the cultural forces are not already taking

27:59.520 --> 28:04.880
things. A lot of times people seem like a leader because they're just kind of hopping on the

28:04.880 --> 28:08.720
cultural wave and they happen to be the person who gets to the top of it. Now it seems like they're,

28:08.720 --> 28:17.360
but actually the wave was already going. Real leadership is when someone actually changes the

28:17.360 --> 28:26.720
wave, changes the shape of the wave. I think Elon with SpaceX and with Tesla genuinely shaped a

28:26.720 --> 28:32.160
wave. Maybe you could say that EVs were actually going to happen anyway, but there's not much

28:32.160 --> 28:38.400
evidence about at least happening when it did. If we end up on Mars, you can say that Elon was a

28:38.400 --> 28:44.240
genuine leader there. And so there are examples. Zuckerberg definitely has done a lot of leadership

28:44.240 --> 28:53.120
along the way. He's also potentially caught in a storm that is happening and he's one of the

28:53.200 --> 28:59.040
figures in it. So I don't know. And it's possible that he is a big shaper if the metaverse becomes

28:59.040 --> 29:04.560
a reality. If in 30 years we're all living in a virtual world, to many people it seems ridiculous

29:04.560 --> 29:10.080
now that that was a poor investment. Well, he talked about getting, I think it was something

29:10.080 --> 29:15.360
like a billion people with a VR headset in their pocket and by, I think it was 10 years from now

29:15.360 --> 29:21.200
back in 2015. So we're behind that. But he was talking about that. And honestly,

29:21.360 --> 29:26.960
I, this is something I've been wrong about because I went to like one of the Facebook

29:26.960 --> 29:32.400
conferences and tried out all the new Oculus stuff. And I was like, you know, pretty early talking to

29:32.400 --> 29:35.600
some of the major players there because I was going to write a big post about it that then

29:35.600 --> 29:40.880
got swallowed by this book. But I would have been wrong in the post because what I would have said

29:40.880 --> 29:47.280
was that this thing is, when I tried it, I was like, this is, you know, some of them suck. Some

29:47.280 --> 29:51.120
of them make you nauseous and they're just not that, you know, the headsets were big and, you

29:51.120 --> 29:56.000
know, but I was like, the times when this is good, it is, I have this feeling I haven't had. It

29:56.000 --> 29:59.600
reminds me of the feeling I had when I first was five and I went to a friend's house and he had

29:59.600 --> 30:04.080
Nintendo and I, and he gave me the controller and I was looking at the screen and I pressed the

30:04.080 --> 30:10.400
button and Mario jumped. And I said, I said, I can make the something on the screen move.

30:10.400 --> 30:13.760
And the same feeling I had the first time someone showed me how to send an email. It was like really

30:13.760 --> 30:17.200
early. And he's like, you can send this. And I was like, he goes, I can press enter on my computer

30:17.200 --> 30:21.360
and something happens on your computer. Those were obviously, you know, when you have that feeling,

30:21.360 --> 30:25.760
it often means you're, you're witnessing a paradigm shift. And I thought this is one of those things

30:26.800 --> 30:29.680
and I still kind of think it is, but it's kind of weird that it hasn't,

30:30.320 --> 30:33.040
you know, like where, where's the VR revolution? Like,

30:33.760 --> 30:38.160
yeah, I'm surprised because I'm, I'm with you. My first and still instinct is this feels like it

30:38.160 --> 30:42.960
changes everything. VR feels like it changes everything, but it's not changing anything.

30:42.960 --> 30:47.200
Like a dumb part of my brain is genuinely convinced that that's real. And then the smart

30:47.200 --> 30:50.640
part knows it's not, but that's why the dumb part was like, we're not walking off that cliff.

30:50.640 --> 30:54.320
The smart parts, like you're on your rug. It's fine. The dumb part of my brain is like,

30:54.320 --> 30:58.560
I'm not walking off the cliff. So I was like, it's crazy. I feel like it's waiting

30:59.840 --> 31:03.680
for like that revolutionary person who comes in and says, I'm going to create a headset.

31:03.680 --> 31:08.800
Like Steve jobs, iPhone of honestly a little bit of a car Mac type guy, which is why it was really

31:08.800 --> 31:13.280
interesting for him to be involved with Facebook. It's basically how do we create a simple dumb

31:13.280 --> 31:18.240
thing that's a hundred bucks, but actually creates that experience. And then there's going to be some

31:18.240 --> 31:23.360
viral killer app on it. And that's going to be the gateway into a thing that's going to change

31:23.360 --> 31:27.360
everything. I mean, I don't know what exactly was the thing that changed everything with a personal

31:27.360 --> 31:34.960
computer. Does that understood why that maybe graphics, what was the use case?

31:34.960 --> 31:41.520
I mean, exactly. Wasn't, wasn't the, the, the 84 Macintosh, like a moment when it was like,

31:41.520 --> 31:47.200
this is actually something that normal people can and want to use because it was less than $5,000,

31:47.200 --> 31:52.160
I think. And I just think it had some like Steve jobs, user friendliness already to it that other

31:52.160 --> 31:57.840
ones hadn't had. I think windows 95 was a really big deal. The, I remember like, cause I, I'm old

31:57.840 --> 32:01.840
enough to remember the MS DOS when I was like, kind of remembered the command. And then suddenly

32:01.840 --> 32:06.080
this concept of like a window you drag something into or you double click an icon,

32:06.080 --> 32:11.360
which now seems like so obvious to us was like revolutionary because it made it, it made it

32:11.360 --> 32:17.120
intuitive. So, you know, I, I don't know. Yeah. Windows 95 was good. It was crazy. Yeah. I forget

32:17.120 --> 32:23.520
what the big leaps was because those windows 2000 sucked. And then windows XP was good. I moved to

32:23.520 --> 32:31.280
Mac around 2004. So I still just sold to the devil. I see. Well, us, the people still use

32:32.240 --> 32:38.560
windows and Android, the device and the operating system of the people, not you elitist folk with

32:38.560 --> 32:49.920
your books and your what else and success. Okay. You write more technology means better good times,

32:49.920 --> 32:55.600
but it also means bad or bad times. And the scary thing is if the good and bad keep exponentially

32:55.600 --> 33:00.480
growing, it doesn't matter how great the good times become. If the bag gets to a certain level

33:00.480 --> 33:06.400
of bad, it's all over for us. Can you elaborate on this? Why, why is there, why does the bad have

33:07.520 --> 33:12.880
that property that if it's all exponentially getting more powerful, then the bad is going

33:12.880 --> 33:18.080
to win in the end was, is my misinterpreting that? No. So the first thing is I noticed a trend,

33:18.800 --> 33:25.760
which was like the centuries, the good is getting better every century. Like the 20th century

33:25.760 --> 33:31.520
was the best century yet in terms of prosperity, in terms of GDP per capita, in terms of life

33:31.520 --> 33:36.720
expectancy, in terms of poverty and disease and every metric that matters. The 20th century was

33:36.720 --> 33:40.880
incredible. It also had the biggest wars in history, the biggest genocide in history,

33:40.880 --> 33:46.320
the biggest existential threat yet with nuclear weapons, right? You know, the depression was,

33:46.320 --> 33:50.960
you know, probably as big an economic. So it's this interesting thing where the stakes are getting

33:50.960 --> 33:57.360
higher in both directions. And so the question is like, if you get enough good, does that protect

33:57.360 --> 34:02.720
you against the bad, right? The dream, and I do think this is possible too, is the good gets so

34:02.720 --> 34:07.200
good. You know, have you ever read the culture series, the Ian Banks books? Not yet, but I get

34:07.200 --> 34:12.560
criticized on a daily basis by some of the mutual folks we know for not having done so. And I feel

34:12.560 --> 34:16.880
like a lesser man for it. Yes, I need to change this. So that's how I got onto it. And I read six

34:16.880 --> 34:22.000
of the 10 books and they're great. But the thing I love about them is like, it just paints one of

34:22.000 --> 34:30.240
these futuristic societies where the good has gotten so good that the bad is no longer even an

34:30.240 --> 34:38.160
issue. Like basically, and the way that this works is the AI, you know, the AIs are benevolent and

34:38.160 --> 34:42.480
they control everything. And so like there's one random anecdote where they're like, you know,

34:42.480 --> 34:46.400
what happens if you murder someone? Because you're still, you know, there's still people

34:46.400 --> 34:50.880
with rage and jealousy or whatever. So if someone murders someone, first of all, that person's backed

34:50.880 --> 34:55.920
up. So it's like they have to get a new body and it's annoying, but it's like, it's not death.

34:55.920 --> 34:58.480
And secondly, that person, what are they going to do? Put them in jail? No, no, no, they're just

34:58.480 --> 35:02.880
going to send a slap drone around, which is this little like tiny, you know, random drone that just

35:02.880 --> 35:05.760
will float around next to them forever. And by the way, kind of be their servants, like it's kind of

35:05.760 --> 35:09.040
fun to have a slap drone, but it's just making sure that they never do anything. And it's like,

35:09.040 --> 35:13.600
I was like, oh man, it could just be, everyone could be so safe and everything could be so like,

35:13.600 --> 35:17.200
you know, you want a house, you know, the AIs will build your house, there's endless space,

35:17.200 --> 35:21.440
there's endless resources. So I do think that that could be part of our future. That's part of what

35:21.440 --> 35:26.080
excites me is like there is, like today would seem like a utopia to Thomas Jefferson, right?

35:26.080 --> 35:31.760
Thomas Jefferson's world would seem like a utopia to a caveman. There is a future, and by the way,

35:31.760 --> 35:36.400
these are happening faster, these jumps, right? So the thing that would seem like a utopia to us,

35:36.400 --> 35:41.040
we could experience in our own lifetimes, right? Like it's, especially if, you know,

35:41.040 --> 35:47.120
life extension combines with exponential progress, I want to get there. And I think in that part of

35:47.120 --> 35:51.680
what makes it utopia is you don't have to be as scared of the worst bad guy in the world trying

35:51.680 --> 35:57.840
to do the worst damage because we have protection. But that said, I'm not sure how that happens. Like

36:00.320 --> 36:05.120
it's either easier said than done. Nick Bostrom uses the example of if nuclear weapons could be

36:05.120 --> 36:11.520
manufactured by microwaving sand, for example, we'd probably be in the stone age right now,

36:11.520 --> 36:18.320
because 0.001% of people would love to destroy all of humanity, right? Some 16 year old with

36:18.320 --> 36:22.640
huge mental health problems who right now goes and shoots up a school would say, oh, even better,

36:22.640 --> 36:29.280
I'm going to blow up a city. And now suddenly there's copycats, right? And so that's like,

36:30.080 --> 36:39.120
as our technology grows, it's going to be easier for the worst bad guys to do tremendous damage.

36:39.120 --> 36:43.840
And it's easier to destroy than to build. So it takes a tiny, tiny number of these people

36:44.720 --> 36:50.080
with enough power to do bad. So that, to me, I'm like, the stakes are going up because what we have

36:50.080 --> 36:55.600
to lose is this incredible utopia, but also like dystopia is real. It happens. The Romans ended up

36:55.600 --> 37:00.800
in a dystopia they probably earlier thought that was never possible. Like we should not get cocky.

37:01.520 --> 37:08.720
And so to me that trend is the exponential tech is a double edged sword. It's so exciting. I'm

37:08.720 --> 37:13.760
happy to be alive now overall because I'm an optimist and I find it exciting, but it's really

37:13.760 --> 37:19.120
scary. And the dumbest thing we can do is not be scared. The dumbest thing we can do is get cocky

37:19.120 --> 37:22.320
and think, well, my life is always the last couple of generations, everything's been fine.

37:23.280 --> 37:28.720
Stop that. What's your gut? What percentage of trajectories take us towards the,

37:29.440 --> 37:36.720
as you put unimaginably good future versus unimaginably bad future? As an optimist?

37:36.720 --> 37:41.040
It's really hard to know. I mean, one of the things we can do is look at history.

37:41.600 --> 37:47.680
And on one hand, there's a lot of stories. I actually listening to a great podcast right now

37:47.680 --> 37:52.160
called the fall of civilizations. And it's literally every episode is like, you know,

37:52.160 --> 37:56.720
a little like two hour deep dive into some civilizations. Some are really famous like

37:56.720 --> 38:04.560
the Roman empire. Some are more obscure, like the Norse and Greenland, but each one is so

38:04.560 --> 38:11.600
interesting. I mean, there's a lot of civilizations that had their peak. There's always the peak,

38:11.600 --> 38:16.800
right? When they're thriving and they're at their max size and they have their waterways

38:16.800 --> 38:22.640
and they have their, it's civilized and there's representative and it's fair and whatever. Not

38:22.640 --> 38:26.640
always, but the peak is a great, you know, if I could go back in time, you know, it's not that

38:26.640 --> 38:30.000
you don't, you know, the farther you go back, the worse it gets. No, no, no. You want to go back to

38:30.000 --> 38:34.160
a civilization during, I would go to the Roman empire in the year a hundred. Sounds great,

38:34.160 --> 38:37.680
right? You don't want to go to the Roman empire in the year 400. We might be in the peak right

38:37.680 --> 38:42.880
now here, wherever this empire is. Honestly, I think about like the eighties, you know,

38:42.880 --> 38:46.640
the seventies, the eighties. Oh, here we go. The music. No, no, I hate these. So much better.

38:46.640 --> 38:51.360
No, the eighties culture is so annoying. It's just like, when I listen to these things,

38:51.360 --> 38:56.320
I'm thinking, you know, the eighties, the nineties, America, the nineties was popular.

38:56.320 --> 39:00.960
People forget that now. Like Clinton was a superstar around the world. Michael Jordan was

39:00.960 --> 39:06.000
exported internationally. Then basketball was everywhere. Suddenly you had like music,

39:06.000 --> 39:09.760
the sports, whatever. It was a little, probably like the fifties, you know, you're coming out of

39:09.760 --> 39:13.680
the world war and the depression before it. It was like this kind of like everyone was in a good

39:13.680 --> 39:17.920
mood kind of time. You know, it's like a finish a big project and it's Saturday. It was like,

39:17.920 --> 39:22.400
I feel like the fifties was kind of like everyone was having, you know, the, the um,

39:22.400 --> 39:26.560
twenties. I feel like everyone was in good mood randomly. Um, then the thirties, everyone was in

39:26.560 --> 39:31.360
a bad mood. Um, but the nineties, I think we'll look back on it as a time when everyone was in a

39:31.360 --> 39:34.560
good mood. And it was like, you know, again, of course at the time it doesn't feel that way

39:34.560 --> 39:39.520
necessarily, but I look at that, I'm like, maybe that was kind of America's peak. And like,

39:39.520 --> 39:44.480
no, maybe not, but like it hasn't been popular since really worldwide. Um, it's, it's gone in

39:44.480 --> 39:48.320
and out depending on the country, but like, it hasn't reached that level of like America's

39:48.320 --> 39:54.800
awesome around the world and the political, you know, situation's gotten, you know, really ugly.

39:54.800 --> 40:00.960
And, you know, maybe it's social media, maybe who knows, but I, I wonder if it'll ever be as simple

40:01.840 --> 40:07.360
and positive as it was then, like maybe we are in the, in the, you know, it feels a little like

40:07.360 --> 40:11.600
maybe we're in the beginning of the downfall or not. Cause these things don't just, it's not a

40:11.600 --> 40:15.200
perfect smooth hill. It goes up and down and up and down. So maybe we're, there's another big

40:15.200 --> 40:20.880
upcoming. And it's unclear whether public opinion, which is kind of what you're talking to is, uh,

40:20.880 --> 40:25.920
correlated strongly with influence. Cause you could say that even though America has been on a decline

40:25.920 --> 40:32.560
in terms of public opinion, the exporting of technology that America has still, with all the

40:32.560 --> 40:37.520
talk of China has still been needing, leading the way in terms of AI, in terms of social media,

40:37.520 --> 40:42.800
in terms of just basically any software related product chips. Yeah. Chips. So hardware and

40:42.800 --> 40:48.720
software, I mean, America leads the way you could argue that Google and Microsoft and Facebook are

40:48.720 --> 40:53.840
no longer American companies. They're international companies, but they really are still at the,

40:53.840 --> 40:58.880
you know, headquartered in Silicon Valley, broadly speaking. So, uh, and Tesla, of course,

40:58.960 --> 41:03.600
and just all of its, all of the technological innovation still seems to be happening in the

41:04.240 --> 41:13.440
United States. Although culturally and politically, this is not, it's not good. Well,

41:13.440 --> 41:18.720
maybe that could shift at any moment when all the technological development can actually be,

41:19.600 --> 41:24.400
create some positive impact in the world that could shift it with the right leadership and so

41:24.400 --> 41:32.080
on with the right messaging. Yeah. I think, um, I don't feel confident at all about whether,

41:32.080 --> 41:36.400
no, no, I don't mean that. I don't mean, I don't feel confident in my opinion that we may be on

41:36.400 --> 41:40.000
the downswing or that we may be, cause I truly don't know. It's like, I think the people,

41:41.520 --> 41:45.680
these are really big macro stories that are really hard to see when you're inside of them.

41:45.680 --> 41:50.240
It's like, it's like being on a, on a beach and running around, you know, a few miles this way

41:50.240 --> 41:56.240
and trying to suss out the shape of the coastline. Like it's just really hard to see the big picture.

41:56.240 --> 42:00.960
You know, you get caught up in the micro stories, the little tiny ups and downs that are part of

42:00.960 --> 42:06.320
some bigger trend. And also giant paradigm shifts happen quickly nowadays. The internet, you know,

42:06.320 --> 42:10.320
came out of nowhere and suddenly was like, you know, changed everything. So there could be a

42:10.320 --> 42:14.000
changed everything thing on the way it seems like there's a few candidates for it. And like, but,

42:14.000 --> 42:18.880
but I mean, it feels like the stakes are just high, higher than it even was for the Romans,

42:18.880 --> 42:25.040
higher than it was for, because that we were more powerful as a species. We have God-like

42:25.040 --> 42:31.280
powers with technology that other civilizations at their peak didn't have. And so I wonder if

42:31.280 --> 42:38.160
those high stakes and powers will feel laughable to people that live humans, aliens, cyborgs,

42:38.160 --> 42:44.320
whatever lives a hundred years from now that may, maybe, maybe our little, like this feeling of

42:44.320 --> 42:48.480
political and technological turmoil is nothing. Well, that's the big question.

42:49.600 --> 42:54.400
So right now, you know, you know, the 1890s was like a super politically contentious decade in

42:54.400 --> 43:00.400
the U S it was like immense tribalism. Um, and the newspapers were all like lying and telling,

43:00.400 --> 43:04.000
you know, you know, there was a lot of like what we would associate with today's media, the worst

43:04.000 --> 43:08.080
of it. Um, and it was over gold or silver being this, I don't know, it was very, it's something

43:08.080 --> 43:12.880
that I don't understand, but the point is it was a little bit of a blip, right? It happened. It felt,

43:12.880 --> 43:16.800
it must've felt like the end of days at the time. And then now we look and most people don't even

43:16.800 --> 43:21.920
know about that. Uh, versus, you know, again, the Roman empire actually collapsed. And so the

43:21.920 --> 43:27.520
question is just like, is yeah, you know, will in 50 years, will this be like, or like McCarthyism?

43:27.520 --> 43:32.400
Oh, they had like, uh, oh, that was like a crazy few years in America and then it was fine. Um,

43:32.400 --> 43:35.360
or is this the beginning of something really big? And that's what.

43:36.960 --> 43:41.920
Well, I wonder if we can predict, uh, what the big thing is at the beginning. It feels like we're

43:41.920 --> 43:47.280
not, we're just here along for the ride and at the local level and at every level are trying to

43:47.280 --> 43:52.960
do our best. Well, how do we do our best? What's the, that's the one thing I know for sure is that

43:52.960 --> 43:57.680
we need to have our wits about us and do our best and the way that we can do that, you know,

43:57.680 --> 44:05.040
we have to be as wise as possible, right? To proceed forward and wisdom is an emergent property

44:05.040 --> 44:10.000
of discourse. So you're a proponent of wisdom versus stupidity because you can make an, uh,

44:10.000 --> 44:16.160
I can still man the case for stupidity. Do it. I probably can't, but there, there's some,

44:16.960 --> 44:22.640
I think wisdom and you talk about this can come with a false confidence, arrogance. I mean,

44:22.640 --> 44:26.800
you talk about this in the book. That's too easy. That's not wisdom. Then if you're being arrogant,

44:26.800 --> 44:31.600
you're being unwise, unwise. Yeah. I think, I think wisdom is doing what people a hundred years

44:31.600 --> 44:35.680
from now with the hindsight that we don't have would do if they could come back in time and

44:35.680 --> 44:39.280
they knew everything. It's like, how do we figure out how to have hindsight when we actually are

44:39.280 --> 44:44.480
not? What if stupidity is the thing that people from a hundred years from now will see as wise?

44:45.360 --> 44:50.800
I mean, the idiot by Dostoevsky being naive and, uh, trusting everybody. Well, then you get lucky.

44:52.480 --> 44:59.120
Then maybe you get to a good future by stumbling upon it. Um, but ideally you can get there. Like,

44:59.120 --> 45:05.920
I think a lot of the America, the great things about it are a product of the wisdom of previous

45:05.920 --> 45:12.000
Americans. You know, the constitution was a pretty, you know, pretty wise system to set up.

45:12.560 --> 45:17.440
There's not much stupid stumbling around. Well, there is, I mean, with Dostoevsky's, uh,

45:17.440 --> 45:24.240
the idiot Prince Michigan and, uh, brothers Karamazov, there's, uh, uh, Alosha Karamazov,

45:24.240 --> 45:32.000
you err on the side of love and almost like a naive trust in other human beings.

45:32.560 --> 45:35.440
And that turns out to be, at least in my perspective in the longterm,

45:36.400 --> 45:41.360
for the success of the species is actually wisdom. It's a compass. We don't know. It's a

45:41.360 --> 45:47.280
compass when you're in the fog in the fog. It's a compass. Yeah. Love is a compass. Okay. But,

45:47.280 --> 45:50.160
but here's the thing. So I think we should have a compass is nice, but you know what else is nice

45:50.160 --> 45:53.360
is a flashlight in the fog that can help. You can't see that far, but you can see,

45:53.360 --> 45:58.640
oh, you can see four feet ahead instead of one foot. And that to me is discourse. That is open,

45:58.640 --> 46:04.880
vigorous, like discussion in a culture that fosters that is how the species is how the,

46:05.680 --> 46:11.840
the American citizens as a, as a unit can be as wise as possible, can maybe see four feet ahead

46:11.840 --> 46:16.480
instead of one foot ahead. That said, uh, Charles Bukowski said that love is a fog that fades with

46:16.480 --> 46:21.200
the first light of reality. So I don't know how that works out, but I feel like there's

46:21.200 --> 46:27.040
intermixing of metaphors that works. Okay. Uh, you also write that quote as the authors of the story

46:27.040 --> 46:34.400
of us, which is this thousand page book. We have no mentors, no editors, no one to make sure it all

46:34.400 --> 46:40.320
turns out. Okay. It's all in our hands. This scares me, but it's also what gives me hope.

46:40.320 --> 46:46.000
If we can all get just a little wiser together, it may be enough to nudge the story onto a trajectory

46:46.000 --> 46:54.320
that points towards an unimaginably good future. Do you think we can possibly define what a good

46:54.320 --> 47:01.840
future looks like? I mean, this is, uh, the problem was that we ran into with communism

47:02.880 --> 47:10.880
of thinking of utopia, of having a deep confidence about what a utopian world looks like.

47:11.680 --> 47:14.880
Well, it's a deep confidence. That was a deep confidence about the instrumental

47:15.680 --> 47:19.360
way to get there. It was that, you know, I think a lot of us can agree that

47:20.080 --> 47:24.400
if everyone had everything they needed and we didn't have disease or poverty and people could

47:24.400 --> 47:30.480
live as long as they wanted to and choose when to die. And there was no existential major

47:30.480 --> 47:34.640
existential threat because we can draw, I think almost everyone can agree that would be great.

47:34.640 --> 47:40.880
That communism is a potential that that was, they, they said, this is the way to get there. And that

47:40.880 --> 47:46.720
is that that's a different question, you know, so the, the, the unimaginably good future I'm,

47:46.720 --> 47:50.160
I'm picturing, I think a lot of people would picture and I think most people would agree.

47:50.160 --> 47:53.120
Now, not everyone, there's a lot of people out there who would say humans are the scourge on

47:53.120 --> 47:57.520
the earth and we should degrowth or something. But I think a lot of people would agree that,

47:57.520 --> 48:00.960
you know, just again, take Thomas Jefferson, bring him here. He would see it as a utopia for

48:00.960 --> 48:09.680
obvious reasons for the medicine, the food, the transportation, um, just how, uh, the quality

48:09.680 --> 48:14.640
of life and the safety and all of that. So extrapolate that forward for us. Now we're

48:14.640 --> 48:19.440
Thomas Jefferson, you know, what's the equivalent? That's what I'm talking about. And the, and the

48:19.440 --> 48:24.080
big question is, I actually don't, I, I don't try to say, here's the way to get there. Here's the

48:24.080 --> 48:29.600
actual specific way to get there. I try to say, how do we have a flashlight so that we can together

48:29.600 --> 48:33.760
figure it out? Like how do we give ourselves the best chance of figuring out the way to get there?

48:33.760 --> 48:39.120
And I think part of the problem with, with communists, um, and people is ideologues is that

48:39.200 --> 48:44.320
they're, they're, they're way too overconfident that they know the way to get there. And it's,

48:44.320 --> 48:48.720
it becomes a religion to them, this solution. And then you're not, you can't update once you

48:48.720 --> 48:52.720
have a solution as a religion. And so- I felt a little violated when you said

48:52.720 --> 48:59.600
communist and stared deeply into myself. Um, in this book, you've developed a framework

48:59.600 --> 49:04.480
for how to fix everything. Um, it's called the ladder. Can you explain it?

49:04.480 --> 49:07.920
Okay. It's not a framework for how to fix everything. I would never say that.

49:07.920 --> 49:12.560
I'll explain it to Tim urban at some point. Okay. How this humor thing works. The framework

49:12.560 --> 49:19.920
of, uh, how to think about collaboration between humans such that we could fix things.

49:19.920 --> 49:27.040
I think it's a compass. It's like, uh, it's like a, it's a ruler that we can, once we look at it

49:27.040 --> 49:30.480
together and see what it is, we can all say, oh, we want to go to that side of the ruler,

49:30.480 --> 49:35.840
not this side. Um, and so it gives us a direction to go. So what are the parts of the ladder?

49:36.640 --> 49:42.080
So I have these two characters, this orange guy, this primitive mind is, this is our software.

49:42.080 --> 49:50.000
That is the software that was in a 50,000 BC person's head that was specifically optimized

49:50.000 --> 49:53.760
for, to help that person survive in that world and not even, not just not really survive,

49:53.760 --> 50:01.520
but help them pass their genes on in that world. Um, and civilization happened quickly

50:01.600 --> 50:09.520
and brains change slowly. And so that unchanged dude is still running the show in our head. Um,

50:10.080 --> 50:17.440
and I use the example of like Skittles, like, why do we eat Skittles? It's trash. It's obviously bad

50:17.440 --> 50:24.640
for you. And it's because the primitive mind in the world that it was programmed for, there was

50:24.640 --> 50:29.680
no Skittles and it was just fruit. And, you know, and, and if there was a dense, chewy, sweet fruit

50:29.680 --> 50:35.440
like that, it meant you just found like a calorie gold mine, energy, energy, take it, take it, eat

50:35.440 --> 50:40.480
as much as you can, gorge on it. Hopefully you get a little fat. That would be the dream. And now

50:40.480 --> 50:46.000
we're so good with energy for a while. We don't have to stress about it anymore. So today Mars Inc

50:47.200 --> 50:52.480
is clever and says, let's not sell things to people's higher minds. Who's the other character.

50:52.480 --> 50:56.320
Let's sell to people's primitive minds. Primitive minds are dumb and let's trick them into thinking

50:56.320 --> 51:00.880
this is this, this, this thing you should eat and then they'll eat it. Now Mars Inc is a huge

51:00.880 --> 51:04.880
company. Actually just to linger real quick. So you said primitive mind and higher mind. So those

51:04.880 --> 51:10.320
are the two things that make up this bigger mind that it, that is the modern human being. Yeah.

51:10.320 --> 51:13.920
It's like, you know, it's not perfect. Obviously there's a lot of crossover. Um, there's people

51:13.920 --> 51:18.240
who will yell at me for saying there's two minds and you know that, but to me it's still a useful

51:18.880 --> 51:23.520
framework where you have this software that has making decisions based on a world that you're not

51:23.520 --> 51:27.600
in anymore. And then you've got this other character, I call it the higher mind. And it's

51:27.600 --> 51:31.680
the part of you that knows that skills are not good and can override the instinct. And the reason

51:31.680 --> 51:35.680
you don't always eat skills is because the higher mind says, no, no, no, we're not doing that because

51:35.680 --> 51:39.840
that's bad. And I know that right now you can apply that to a lot of things. The higher mind

51:39.840 --> 51:42.640
is the one that knows I shouldn't procrastinate. The primitive mind is the one that wants to

51:42.640 --> 51:46.720
conserve energy and not do anything icky and you know, can't see the future. So he procrastinates

51:46.720 --> 51:54.000
the, you know, you can apply this. No, I in this book apply it to, um, to how we form our beliefs

51:54.000 --> 51:57.040
is one of the ways. And then eventually to politics and political movements. But like,

51:57.760 --> 52:02.720
if you think about what, well, what's the equivalent of the Skittles tug of war in your head

52:02.720 --> 52:10.880
for how do you form your beliefs? Um, and it's that the primitive mind in the world that it was

52:11.760 --> 52:23.680
optimized for, um, it wanted to feel conviction about its beliefs. It wanted to be sure that it

52:23.680 --> 52:28.560
was, um, it wanted to feel conviction and it wanted to agree with the people around there.

52:28.560 --> 52:32.560
Didn't want to stand out. It wanted to, to perfectly agree with the tribe about the tribe's

52:32.560 --> 52:36.240
sacred beliefs. Right. And so there's a big part of us that wants to do that, that, that doesn't

52:36.240 --> 52:40.320
like changing our mind. It feels like it's part of our, the primitive mind identifies with beliefs.

52:40.400 --> 52:45.200
It feels like it's a threat, a physical threat to you, to your primitive mind. When you change your

52:45.200 --> 52:50.160
mind or when someone disagrees with you in a smart way. So there's that huge force in us,

52:50.160 --> 52:54.320
which is confirmation bias. That's where that comes from. It's, it's this, this, this desire

52:54.320 --> 52:59.760
to keep believing what we believe and this desire to also fit in with our beliefs, to believe what

52:59.760 --> 53:05.280
the people around us believe. And that can be fun in some ways. We all like the same sports team and

53:05.280 --> 53:08.960
we're all super into it and we're all going to be biased about that call together. I mean, that

53:08.960 --> 53:13.840
it's not always bad, but it's not a very smart way to be. And it, you're actually,

53:13.840 --> 53:17.920
you're working kind of for those ideas. Those ideas are like your boss and you're working so

53:17.920 --> 53:22.800
hard to keep believing those, those ideas are, you know, a really good paper comes in that you read

53:22.800 --> 53:26.960
that, that, that conflicts with those ideas. And you will do all this work to say that paper

53:26.960 --> 53:34.160
bullshit because you're, you're a faithful employee of those ideas. Now the higher mind to me,

53:34.160 --> 53:38.160
the same party that can override the Skittles can override this and can, and can search for

53:38.160 --> 53:42.960
something that makes a lot more sense, which is truth. Cause what rational being wouldn't want

53:42.960 --> 53:48.720
to know the truth. Who wants to be delusional? And so there's this tug of war because the higher

53:48.720 --> 53:53.360
mind doesn't identify with ideas. Why would you? It's an experiment you're doing and it's a mental

53:53.360 --> 53:57.120
model. And if someone can come over and say, you're wrong, you'd say, where, show me, show me.

53:57.120 --> 54:01.360
And if they point out something that is wrong, you say, oh, thanks. Oh, good. I just got a little

54:01.360 --> 54:04.480
smarter, right? You're not going to identify with the thing. I'll go, you kick it. See if you can

54:04.480 --> 54:08.640
break it. If you can break it, it's not that good. Right? So there's both of these in our heads and

54:08.640 --> 54:12.640
there's this tug of war between them. Uh, and sometimes, you know, if you, if you're telling

54:12.640 --> 54:16.160
me about something with AI, I'm probably going to think with my higher minds. I'm not identified

54:16.160 --> 54:19.920
with it. But if you go and you criticize the ideas in this book, or you criticize my religious

54:19.920 --> 54:23.280
beliefs, you criticize, I might have a harder time because the primitive mind says, no, no, no,

54:23.280 --> 54:28.880
those are our special ideas. And so, yeah, so that's, that's one way to use this ladder is like,

54:28.880 --> 54:32.720
it's a spectrum, you know, at the top, the higher mind is doing all the thinking. And then as you

54:32.720 --> 54:36.800
go down, it becomes more of a tug of war. And at the bottom, the primitive mind is in total control.

54:36.800 --> 54:42.560
And this is distinct as you show from the spectrum of ideas. So this is how you think versus what you

54:42.560 --> 54:48.560
think. And those are distinct, those are different dimensions. We need, we need a vertical axis.

54:48.560 --> 54:52.480
We have all these horizontal axes, left, right, center, or, you know, this opinion all the way

54:52.480 --> 54:57.680
to this opinion. But it's like, what's much more important than where you stand is how you got

54:57.680 --> 55:04.000
there, right? And how you think. So this helps if I can say this person's kind of on the left or on

55:04.000 --> 55:08.720
the right, but they're up high, I think I think in other words, I think they got there using evidence

55:08.720 --> 55:12.160
and reason, and they were willing to change their mind. Now, that means a lot to me what they have

55:12.160 --> 55:16.160
to say. If I think they're just a tribal person, and I can predict all their beliefs from hearing

55:16.160 --> 55:20.320
one, because it's so obvious what political beliefs that person's views are irrelevant to me,

55:20.320 --> 55:26.320
because they're not real, they didn't come from information, they came from a tribe's kind of,

55:27.120 --> 55:31.760
you know, sacred 10 commandments. I really like the comic you have in here about with the boxer.

55:32.640 --> 55:39.680
This is the best boxer in the world. Wow, cool. Who has he beaten? No one. He's never fought anyone.

55:39.680 --> 55:44.240
Then how do you know he's the best boxer in the world? I can just tell. I mean, this connects

55:44.240 --> 55:47.920
with me and I think with a lot of people just because in martial arts, it's especially kind

55:47.920 --> 55:52.560
of true that this is this whole legend about different martial artists and that kind of

55:53.120 --> 55:59.840
would construct like action figures, like, you know, thinking that Steven Seagal is the best

55:59.840 --> 56:03.920
fighter in the world or Chuck Norris. Chuck Norris is actually backed up. He's done really

56:03.920 --> 56:09.120
well in competition, but still the ultimate test for particular for martial arts is what we now

56:09.120 --> 56:13.840
know as mixed martial arts, UFC and so on. And that's the actual scientific testing ground.

56:13.840 --> 56:18.560
It's a meritocracy. Yeah, exactly. I mean, there's within certain rules and you can criticize those

56:18.560 --> 56:22.720
rules like this doesn't actually represent the broader combat that you would think of when you're

56:22.720 --> 56:26.880
thinking about martial arts. But reality is you're actually testing things and that's when you

56:26.880 --> 56:33.040
realize that Aikido and some of these kind of martial arts in their certain implementations

56:33.040 --> 56:39.360
don't work in the way you think they would in the context of fighting. I think this is one of the

56:39.360 --> 56:43.920
places where everyone can agree, which is why it's a really nice comic because then you start to talk

56:44.000 --> 56:51.600
about map this onto ideas that people take personally, it starts becoming a lot more

56:51.600 --> 56:58.240
difficult to basically highlight that we're thinking with not with our higher mind,

56:58.240 --> 57:03.520
but with our primitive mind. Yeah. I mean, if I'm thinking with my higher mind and now here,

57:04.160 --> 57:07.760
you can use different things for an idea as a metaphor. So here the metaphor is a boxer

57:08.000 --> 57:17.040
for one of your conclusions, one of your beliefs. And if all I care about is truth,

57:18.000 --> 57:24.320
in other words, that means all I care about is having a good boxer, I would say, go, yeah, try,

57:24.320 --> 57:28.480
see if this person is good. In other words, I would get into arguments, which is throwing my

57:28.480 --> 57:33.040
boxer out there to fight against other ones. And if I think my argument is good, by the way,

57:33.040 --> 57:39.920
I love boxing. If I think my guy is amazing, Mike Tyson, I'm thinking, oh yeah, bring it on.

57:39.920 --> 57:44.320
Who wants to come see? I bet no one can beat my boxer. I love a good debate in that case.

57:45.440 --> 57:50.800
Now, what would you think about my boxer? If not only was I telling you he was great,

57:50.800 --> 57:54.800
but he's never boxed anyone. But then you said, okay, well, your idea came over to try to punch

57:54.800 --> 58:01.600
him. And I screamed and I said, what are you doing? That's violence. And you're an awful person. And

58:01.600 --> 58:05.040
I don't want to be friends with you anymore because you would think this boxer obviously

58:05.040 --> 58:12.080
sucks. Or at least I think it sucks deep down because why would I be so anti? Anyone, no boxing

58:12.080 --> 58:21.840
allowed. So I call this a ladder, right? If you're in low rung land, whether it's a culture or

58:21.840 --> 58:26.960
whatever, a debate, an argument when someone says, no, that's totally wrong, what you're saying about

58:26.960 --> 58:32.080
that and here's why, or you're actually being totally biased. It sounds like a fight. People

58:32.080 --> 58:36.240
are going to say, oh wow, we got in like a fight. It was really awkward. Are we still friends with

58:36.240 --> 58:40.400
that person? Because that's not a culture of boxing. It's a culture where you don't touch

58:40.400 --> 58:49.600
each other's ideas. That's insensitive. Versus in a high rung culture, it's sport. I mean,

58:49.600 --> 58:54.800
every one of your podcasts, whether you're agreeing or disagreeing, the tone is the same. It's not

58:54.800 --> 58:59.120
like, oh, this got awkward. The tone is identical because you're just playing intellectually either

58:59.120 --> 59:04.400
way because it's a good high rung space. At his best, but people do take stuff personally.

59:05.280 --> 59:09.840
That's actually one of the skills of conversation just as a fan of podcasts is when you sense that

59:09.840 --> 59:16.000
people take a thing personally, you have to like, there's sort of methodologies and little paths

59:16.000 --> 59:21.680
you can take to calm things down. Go around, don't take it as a violation of that. You're trying to

59:21.680 --> 59:26.240
suss out which of their ideas are sacred to them and which ones are, bring it on.

59:27.520 --> 59:30.960
That's the skill of it, I suppose, that sometimes it's the certain wordings

59:32.320 --> 59:36.880
in the way you challenge those ideas that are important. You can challenge them indirectly

59:36.880 --> 59:44.080
and then together, walk together in that way. Because what I've learned is people are used

59:44.960 --> 59:50.800
to their ideas being attacked in a certain way, in a certain tribal way. If you just avoid those,

59:51.440 --> 59:56.640
for example, if you have political discussions and just never mentioned left or right or Republican

59:56.640 --> 01:00:02.960
and Democrat, none of that. Just talk about different ideas and avoid certain kind of triggering

01:00:02.960 --> 01:00:09.440
words. You can actually talk about ideas versus falling into this path that's well established

01:00:09.440 --> 01:00:13.920
through battles that people have previously fought. When you say triggering, I mean, who's

01:00:13.920 --> 01:00:18.800
getting triggered? The primitive mind. What you're saying in this language is, how do you

01:00:18.800 --> 01:00:23.280
have conversations with other people's higher minds, almost like whispering, without waking up

01:00:23.280 --> 01:00:27.680
the primitive mind? The primitive mind is there sleeping, right? As soon as you say something,

01:00:27.680 --> 01:00:30.560
the left primitive mind gets up and says, what? What are you saying about the left? Now,

01:00:32.000 --> 01:00:36.560
everything goes off the rails. What do you make of conspiracy theories under this framework

01:00:36.560 --> 01:00:43.120
of the latter? Here's the thing about conspiracy theories is that once in a while they're true,

01:00:43.120 --> 01:00:46.400
right? Because sometimes there's an actual conspiracy. Actually, humans are pretty good

01:00:46.400 --> 01:00:54.720
at real conspiracies, secret things. I just watched the made-off doc, great new Netflix doc,

01:00:54.720 --> 01:01:06.240
by the way. The question is, how do you create a system that is good at, you put the conspiracy

01:01:06.240 --> 01:01:11.920
theory in and it either goes, eh, or it says, this is interesting, let's keep exploring it.

01:01:11.920 --> 01:01:16.000
How do you do something that it can, how do you assess? Again, I think the high-run culture

01:01:17.360 --> 01:01:23.360
is really good at it because a real conspiracy, what's going to happen is you put it, it's like a

01:01:23.360 --> 01:01:26.480
little machine you put in the middle of the table and everyone starts firing darts at it,

01:01:26.480 --> 01:01:31.200
a bow and arrow or whatever, and everyone starts kicking it and trying to, and almost all conspiracy

01:01:31.200 --> 01:01:36.960
theories, they quickly crumble, right? Because they actually, you know, Trump's election won.

01:01:36.960 --> 01:01:41.120
I actually dug in and I looked at like every claim that he or his team made and it was like,

01:01:42.080 --> 01:01:46.000
all of these, none of these hold up to screw me, none of them. I was open-minded, but none of them

01:01:46.080 --> 01:01:53.040
did. So that was one that as soon as it's open to scrutiny, it crumbles. The only way that conspiracy

01:01:53.040 --> 01:01:59.360
can stick around in a community is if it is a culture where that's being treated as a sacred

01:01:59.360 --> 01:02:03.520
idea that no one should kick or throw a dart at, because if you throw a dart, it's going to break.

01:02:03.520 --> 01:02:10.240
So it's being, it's, and so what you want is a culture where no idea is sacred. Anything can

01:02:10.240 --> 01:02:15.520
get thrown at. And so I think that then what you'll find is that 94 out of 100 conspiracy

01:02:15.520 --> 01:02:19.840
theories come in and they fall down. The other, maybe four of the others come in and there's

01:02:19.840 --> 01:02:23.760
something there, but it's not as extreme as people say. And then maybe one is a huge deal

01:02:23.760 --> 01:02:28.000
and it's actually a real conspiracy. Well, isn't there a lot of gray area and there's a lot of

01:02:28.000 --> 01:02:35.440
mystery? Isn't that where the conspiracy theories seep in? So it's great to hear that you've really

01:02:35.440 --> 01:02:43.120
looked into the Trump election fraud claims, but aren't they resting on a lot of kind of gray area,

01:02:43.120 --> 01:02:49.360
like fog, basically saying that there is dark forces in the shadows that are actually controlling

01:02:49.360 --> 01:02:55.600
everything. I mean, the same thing with maybe you can, there's like safer conspiracy theories,

01:02:55.600 --> 01:03:00.880
less controversial ones, like have we landed on the moon, right? Did the United States ever land

01:03:00.880 --> 01:03:07.120
on the moon? There's, you know, like the reason those conspiracy theories work is you could

01:03:07.120 --> 01:03:12.480
construct, there's incentives and motivation for faking the moon landing. There's a lot of,

01:03:14.800 --> 01:03:21.600
there's very little data supporting the moon landing, like that's very public and kind of

01:03:21.600 --> 01:03:25.280
looks fake, space kind of looks fake. And that would be a big story if it turned out to be fake.

01:03:26.560 --> 01:03:31.680
That would be the argument against it, like are people really as a collective going to hold on

01:03:31.680 --> 01:03:38.640
to a story that big? Yeah, so that, but there's a lot that the reason they work is there's mystery.

01:03:38.640 --> 01:03:42.720
Yeah, there's a great documentary called Behind the Curve about flat earthers. And one of the

01:03:42.720 --> 01:03:48.320
things that you learn about flat earthers is they believe all the conspiracies, not just the flat

01:03:48.320 --> 01:03:53.920
earth. They're convinced the moon landing is fake. They're convinced 9-11 was an American con job.

01:03:55.040 --> 01:04:00.800
They're convinced, you know, that name a conspiracy and they believe it. And so it's so interesting

01:04:00.800 --> 01:04:10.240
is that I think of it as a skepticism spectrum. So on one side, you, it's like a filter in your

01:04:10.240 --> 01:04:15.520
head, a filter in your, in the beliefs section of your brain. On one end of the spectrum,

01:04:15.520 --> 01:04:19.840
you are gullible, perfectly gullible. You believe anything someone says, right? On the other side,

01:04:19.840 --> 01:04:23.680
you're paranoid. You think everyone's lying to you, right? Everything is false. Nothing

01:04:23.680 --> 01:04:28.720
anyone says is true, right? So obviously those aren't good places to be. Now the healthy place,

01:04:28.720 --> 01:04:33.120
I think that the, so I think the healthy place is to be somewhere in the middle.

01:04:33.120 --> 01:04:36.400
And, but also you can learn to trust certain sources and then, you know, you don't have to do

01:04:36.400 --> 01:04:44.160
as much, apply as much skepticism to them. And so here's what, like, when you start having a bias,

01:04:44.160 --> 01:04:49.200
just say you have a political bias, when your side says something, you will find yourself moving

01:04:49.200 --> 01:04:53.440
towards the gullible side of the spectrum. You read an article written that supports your views.

01:04:53.440 --> 01:04:56.240
You move to the gullible side of the spectrum and you just believe it and you don't have any,

01:04:56.240 --> 01:04:59.680
where's that skepticism that you normally have, right? And then you move and then you,

01:04:59.680 --> 01:05:02.800
as soon as it's the other person talking, the other team talking, you move to the

01:05:02.800 --> 01:05:09.440
skeptical, the closer to the, you know, in denial, paranoid side. Now, flat earthers are the extreme.

01:05:09.440 --> 01:05:15.040
They are either at 10 or 1. So it's like, it's so interesting because they're the people who are

01:05:15.040 --> 01:05:18.640
saying, ah, nah, I won't believe you. I'm not gullible. No, everyone else is gullible about

01:05:18.640 --> 01:05:23.040
the moon landing. I won't. And then yet, when there's this evidence like, oh, because you can't

01:05:23.040 --> 01:05:27.920
see Seattle. You can't see the buildings over that horizon and you should, which isn't true.

01:05:27.920 --> 01:05:32.320
You should be, if the earth were round, you wouldn't be able to see them. Therefore,

01:05:32.320 --> 01:05:35.360
so suddenly they become the most gullible person. They hear any theory about the earth flat,

01:05:35.360 --> 01:05:39.680
they believe it. It goes right into their beliefs. So they're actually jumping back and forth between

01:05:39.680 --> 01:05:44.400
refusal to believe anything and believe anything. And so they're the extreme example. But I think

01:05:44.400 --> 01:05:49.040
when it comes to conspiracy theories, the people that get themselves into trouble are the ones who

01:05:49.040 --> 01:05:52.640
they become really gullible when they hear a conspiracy theory that kind of fits with their

01:05:52.640 --> 01:05:56.880
worldview. And they likewise, when there's something that's kind of obviously true and

01:05:56.880 --> 01:06:02.880
it's not a big lie, they will actually, they'll think it is. They just tighten up their kind of

01:06:02.880 --> 01:06:08.720
skepticism filter. And so, yeah, so I think the healthy places to be is where you are not,

01:06:08.720 --> 01:06:11.200
because you also don't want to be the person who says every conspiracy, you hear the word

01:06:11.200 --> 01:06:18.880
conspiracy theory and it sounds like a synonym for like quack job crazy theory, right? So yeah,

01:06:18.880 --> 01:06:23.040
so I think, yeah, I think it's be somewhere in the middle of that spectrum and to learn to fine

01:06:23.040 --> 01:06:26.720
tune it. Which is a tricky place to operate because you kind of have to every time you

01:06:26.720 --> 01:06:33.440
hear a new conspiracy theory, you should approach it with an open mind. And, you know, and also if

01:06:33.440 --> 01:06:38.400
you don't have enough time to investigate, which most people don't kind of still have a humility

01:06:38.400 --> 01:06:44.000
not to make a conclusive statement that that's nonsense. There's a lot of social pressure,

01:06:44.080 --> 01:06:50.720
actually, to immediately laugh off any conspiracy theory if it's done by the bad guys, right?

01:06:50.720 --> 01:06:55.120
You will quickly get mocked and laughed at and not taken seriously. If you give any credence,

01:06:55.120 --> 01:07:00.960
you know, back the lab leak was a good one where it's like, turned out that that was at least

01:07:00.960 --> 01:07:07.680
very credible, if not true. And that was a perfect example of one where when it first came out,

01:07:08.640 --> 01:07:14.240
not only so, so Brett Weinstein talked about it. And then I, in a totally different conversation,

01:07:14.240 --> 01:07:17.520
said something complimentary about him on a totally different subject.

01:07:18.720 --> 01:07:22.720
And people were saying, Tim, you might've gone a little off the deep end. You're like quoting

01:07:22.720 --> 01:07:29.440
someone who is like a lab leak person. So I was getting my reputation dinged for complimenting

01:07:29.440 --> 01:07:34.960
on a different topic, someone whose reputation was totally sullied because they have, you know,

01:07:34.960 --> 01:07:40.000
they questioned an orthodoxy, right? So what does that make me want to do?

01:07:41.040 --> 01:07:44.720
Distance myself from Brett Weinstein. That's the, at least they see incentive. And what does that

01:07:44.720 --> 01:07:48.080
make other people want to do? Don't become the next Brett Weinstein. Don't say it out loud

01:07:48.080 --> 01:07:51.600
because you don't want to become someone that no one wants to compliment anymore, right?

01:07:51.600 --> 01:07:55.360
You can see the social pressure and that's, and of course, when there is a conspiracy,

01:07:55.360 --> 01:08:02.400
that social pressure is its best friend. Because then they see the people from outside

01:08:03.200 --> 01:08:08.000
are seeing that social pressure enact like a Tim Urban becoming more and more and more extreme

01:08:08.000 --> 01:08:10.960
to the other side. And so they're going to take the more and more and more extreme.

01:08:11.600 --> 01:08:19.840
I mean, this, what do you see that the pandemic did, like COVID did to our civilization in that

01:08:19.840 --> 01:08:26.000
regard, in the forces? Why was it so divisive? Do you understand that?

01:08:26.800 --> 01:08:31.520
Yeah. So COVID, you know, I thought might be, you know, we always, you know, the ultimate example

01:08:31.520 --> 01:08:35.600
of a topic that will unite us all as the alien attack. Although honestly, I don't even have that

01:08:35.600 --> 01:08:40.320
much faith then I think there'd be like, some people are super like, you know, pro alien and

01:08:40.320 --> 01:08:44.560
some people are anti alien. But anyway. I was actually trying to interrupt because I was talking

01:08:44.560 --> 01:08:53.520
to a few astronomers and they're the first folks that made me kind of sad in that if we

01:08:53.520 --> 01:08:58.880
discover life on Mars, for example, that there's going to be potentially a division over that too,

01:08:58.880 --> 01:09:01.120
whereas half the people will not believe that's real.

01:09:01.760 --> 01:09:12.080
Well, because we live in a current society where the political divide has subsumed everything.

01:09:12.080 --> 01:09:17.840
And that's not always like that. It goes into stages like that. We're in a really bad one

01:09:17.840 --> 01:09:22.560
where it's actually in the book, I call it like a vortex, like a, like a, like a,

01:09:22.560 --> 01:09:28.560
almost like a whirlpool that pulls everything into it. It pulls, it pulls. And so normally

01:09:28.560 --> 01:09:32.640
you'd say, okay, you know, immigration naturally going to be contentious. That's always political,

01:09:32.640 --> 01:09:39.440
right? But like COVID seemed like, oh, that's one of those that will unite us all. Let's fight this

01:09:40.480 --> 01:09:45.600
not human virus thing. Like obvious is no, no one's sensitive. No one's like getting hurt.

01:09:45.600 --> 01:09:49.280
When we insult the virus, like let's all be, we have this threat, this common threat. That's a

01:09:49.280 --> 01:09:55.920
threat to everyone of every nationality in every country, every ethnicity. And what it didn't do

01:09:55.920 --> 01:10:01.280
that at all. The whirlpool was too powerful. So it pulled COVID in and suddenly masks.

01:10:02.080 --> 01:10:06.320
If you're on the left, you like them. If you're on the right, you hate them. And suddenly lockdowns.

01:10:06.320 --> 01:10:10.800
If you're on the left, you like them. And on the right, you hate them. And vaccines, this is people

01:10:10.800 --> 01:10:18.320
forget this. When, when they, Trump first started talking about the vaccine, Biden, Harris, Cuomo,

01:10:18.320 --> 01:10:22.560
they're all saying, I'm not taking that vaccine. Not from this CDC. Because it was too rushed or

01:10:22.560 --> 01:10:26.640
something like that. No, but because I'm not trusting anything that Trump says. Trump wants

01:10:26.640 --> 01:10:32.400
me to take it. I'm not taking it. I'm not taking it from this CDC. So this was Trump, Trump was

01:10:32.400 --> 01:10:35.760
almost out of office. But at the time, if that, if Trump had been, it would have been, I'm pretty

01:10:35.760 --> 01:10:40.800
sure it would have stayed. Right likes vaccines. The left doesn't like vaccines. Instead the

01:10:40.800 --> 01:10:46.000
president switched and all those people are suddenly saying, they were actually specifically

01:10:46.000 --> 01:10:50.320
saying that if you, you know, that, that, that like, if you're saying the CDC is not trustworthy,

01:10:50.320 --> 01:10:54.400
that's misinformation, which is exactly what they were saying about the other CDC. And they

01:10:54.400 --> 01:10:58.400
were saying it because they genuinely didn't trust Trump, which is fair. But now when other

01:10:58.400 --> 01:11:03.040
people don't trust the Biden CDC, suddenly it's this kind of misinformation that needs to be

01:11:03.040 --> 01:11:07.680
censored. So it was a sad moment because it was a couple of months at the very, even a week or so,

01:11:07.680 --> 01:11:12.320
I mean, a month or so at the very beginning when it felt like a lot of our other squabbles were

01:11:12.320 --> 01:11:16.320
kind of like, Oh, I feel like they're kind of irrelevant right now. And then very quickly,

01:11:16.320 --> 01:11:21.520
the whirlpool sucked it in. And, and, and in a way where I think it damaged the reputation of

01:11:21.520 --> 01:11:25.040
these, a lot of the, the trust in a lot of these institutions for the long run.

01:11:25.040 --> 01:11:29.840
But there's also an individual psychological impact. It's like a vicious negative feedback

01:11:29.840 --> 01:11:34.560
cycle where they were deeply affected on an emotional level and people just were not their

01:11:34.560 --> 01:11:40.000
best selves. That's definitely true. Yeah. I mean, talk about the primitive mind. I mean,

01:11:40.800 --> 01:11:46.160
one thing that we've been dealing with for our whole human history is pathogens. Yeah. And it's

01:11:46.240 --> 01:11:50.880
emotional, right? It brings out, you know, there's really interesting studies where like,

01:11:51.920 --> 01:12:01.520
if they study the phenomena of disgust, which is one of these like, you know, smiling is universal.

01:12:01.520 --> 01:12:06.240
You don't have to ever translate a smile, right? Certain, you know, throwing your hands up when

01:12:06.240 --> 01:12:11.680
your sports team wins is universal because it's part of our coding. And so is disgust to kind of

01:12:11.680 --> 01:12:15.440
make this like, you know, face where you wrinkle up your nose and you kind of put out your tongue

01:12:15.440 --> 01:12:20.560
and maybe even gag that's to expel, expel, whatever, because it's, it's the reaction when

01:12:20.560 --> 01:12:26.640
something is potentially a pathogen that might harm us, right? Feces, vomit, whatever. But they

01:12:26.640 --> 01:12:34.240
did this interesting study where people who in two groups, the control group, you know, was shown

01:12:34.240 --> 01:12:38.480
images of, and I might be getting two studies mixed up, but they were showing, they were showing

01:12:38.480 --> 01:12:42.160
images of like car crashes and like disturbing, but not disgusting. And the other one was shown

01:12:42.160 --> 01:12:46.240
like, you know, like, you know, rotting things and just things that were disgusting. And then

01:12:46.240 --> 01:12:49.840
they were asked about immigration. These were Canadians. And the group that was, had the

01:12:49.840 --> 01:12:56.560
disgust feeling going, pulsing through their body was way more likely to prefer like immigrants from

01:12:56.560 --> 01:13:02.320
white countries. And the group that was, had been shown car accidents, they were, they still

01:13:02.320 --> 01:13:07.200
prefer the groups from white countries, but much less so. And so what does that mean? It's because

01:13:07.280 --> 01:13:13.360
the disgust impulse makes us scared of, you know, sexual practices that are foreign, of ethnicities

01:13:13.360 --> 01:13:18.000
that are not look, they don't look like us, of, it's still xenophobia. So it's ugly. It's really

01:13:18.000 --> 01:13:24.320
ugly stuff. This is of course also how, you know, the Nazi propaganda with cockroaches and, or it

01:13:24.320 --> 01:13:30.320
was, Rwandan was cockroaches, you know, the Nazis was rats and, you know, it's specifically, it's a

01:13:30.320 --> 01:13:37.360
dehumanizing emotion. So anyway, we were, we were, we were, we were talking about COVID, but I think

01:13:37.360 --> 01:13:41.920
it does, it taps deep into like the human psyche. And it's, I don't think it brings out our, I think

01:13:41.920 --> 01:13:48.320
like you said, I think it brings out an ugly side in us. You describe an idea lab as being opposite

01:13:48.320 --> 01:13:53.520
of echo chambers. So we know what echo chambers are. And you said like, just basically no good

01:13:53.520 --> 01:13:59.040
term for the opposite of an echo chamber. So what's an idea lab? Yeah. Well, first of all,

01:13:59.040 --> 01:14:02.880
both of these, I think we think of an echo chamber as like a group maybe, or even a place,

01:14:02.880 --> 01:14:08.640
but it's, it's a culture. It's an intellectual culture. And this goes along with the high rung,

01:14:08.640 --> 01:14:12.240
so high rung and low rung thinking is individual. So I was talking about what's going on in your

01:14:12.240 --> 01:14:19.760
head, but this is very connected to the social scene around us. And so groups will do high rung

01:14:19.760 --> 01:14:26.640
and low rung thinking together. Basically it's, so an echo chamber to me is, is a collaborative

01:14:26.640 --> 01:14:33.680
low rung thinking. It is, it's a culture where the cool, it's based around a sacred set of ideas.

01:14:34.240 --> 01:14:39.280
And it's the coolest thing you can do in an echo chamber culture is talk about how great

01:14:39.280 --> 01:14:45.920
the sacred ideas are and how bad and evil and stupid and wrong the people are who have the

01:14:45.920 --> 01:14:51.920
other views. And this, and, and, and, and it's, it's quite boring. You know, it's quite boring

01:14:52.800 --> 01:14:57.680
it's very hard to learn. And changing your mind is not cool in an echo chamber culture.

01:14:57.680 --> 01:15:04.480
It makes you seem wishy washy. It makes you seem like, you know, like you're waffling and

01:15:04.480 --> 01:15:09.040
you're flip-flopping or whatever. Showing conviction about the sacred ideas in echo

01:15:09.040 --> 01:15:13.360
chamber culture is awesome. If you're just like, you know, obviously this makes you seem smart

01:15:13.360 --> 01:15:17.280
while being, you know, humble makes you seem dumb. So now flip all of those things on their heads.

01:15:17.280 --> 01:15:20.480
And you have an, you have the opposite, which is idea lab culture, which is collaborative,

01:15:20.480 --> 01:15:24.640
high rung thinking. It's collaborative truth-finding. But it's also just,

01:15:24.640 --> 01:15:31.680
it's just a totally different vibe. It's, it's a place where arguing is a fun thing. It's not,

01:15:31.680 --> 01:15:36.320
no one's getting offended. And, and criticizing like the thing everyone believes is actually,

01:15:36.320 --> 01:15:40.080
it makes you seem like interesting. Like, oh, really? Why, why do you think we're all wrong?

01:15:40.080 --> 01:15:45.040
And expressing too much conviction makes people lose trust in you. Doesn't make you seem smart.

01:15:45.040 --> 01:15:47.360
It makes you seem stupid. If you don't really know what you're talking about,

01:15:47.360 --> 01:15:52.400
but you're acting like you do. I really like this diagram of where on the x-axis agreement,

01:15:52.400 --> 01:15:58.080
the y-axis is decency. That's in an idea lab and echo chamber. There's only one axis. It's

01:15:59.120 --> 01:16:04.720
asshole to non-asshole. Right. It's a really important thing to understand about the

01:16:04.720 --> 01:16:10.240
difference between you call it decency here about assholishness and disagreement.

01:16:10.240 --> 01:16:15.360
So my college friends, we love to argue, right? And, and no one thought anyone was an asshole for,

01:16:15.360 --> 01:16:18.720
it was just for sport. Sometimes we'd realize we're not even disagreeing on something. And that

01:16:18.720 --> 01:16:22.240
would be disappointing and be like, oh, I think we agree. And it was kind of like sad. It was like,

01:16:22.240 --> 01:16:29.040
oh, well, there goes the fun. And one of the members of this group has this, she brought her

01:16:29.040 --> 01:16:35.520
new boyfriend to one of our like hangouts. And there was like a heated, heated debate, you know,

01:16:35.520 --> 01:16:40.160
just, just, just one of our typical things. And afterwards, you know, the next day he said like,

01:16:40.160 --> 01:16:43.440
is everything okay? And she was like, what do you mean? And he said like, after the fight,

01:16:43.440 --> 01:16:46.640
and she was like, what fight? And he was like, you know, the fight last night. And she was like,

01:16:46.640 --> 01:16:50.960
and she had to, then she was like, you mean like the arguing? And he was like, yeah. And she,

01:16:50.960 --> 01:16:55.920
and so that's someone who is not used to idea lab culture coming into it. And seeing it is like,

01:16:55.920 --> 01:17:00.320
that was like, this is like, are they still friends? Right. And idea lab is nice for the

01:17:00.320 --> 01:17:05.360
people in them because you're, it, it, individuals thrive. You don't want to just conform. That does,

01:17:05.360 --> 01:17:08.560
it makes you seem boring in an idea, but you want to be yourself. You want to challenge things. You

01:17:08.560 --> 01:17:12.640
want to have a unique brain. So that's great. And, and, and you also have people criticizing

01:17:12.640 --> 01:17:16.960
your ideas, which makes you smarter. It doesn't always feel good, but you, you become more correct

01:17:16.960 --> 01:17:21.280
and smarter. An echo chamber is, is the opposite where it's not good for the people in it. And it

01:17:21.280 --> 01:17:27.600
doesn't, you're learning skills, atrophy. And, and I think it's boring, but the thing is they also

01:17:27.600 --> 01:17:34.640
have emergent properties. So the emergent property of an idea lab is like super intelligence, just

01:17:34.640 --> 01:17:40.000
you and me alone, just the two of us. If we're working together on something, but we're being

01:17:40.000 --> 01:17:44.160
really, um, grown up about it, we're, we're disagreeing. We're not, you know, no one's

01:17:44.160 --> 01:17:48.000
sensitive about anything. We're going to each find flaws in the other one's arguments that,

01:17:48.000 --> 01:17:52.480
that you wouldn't have found on your own. And we're going to have epiphany, double the epiphanies.

01:17:52.480 --> 01:17:57.440
Right. So it's almost like the two of us together is like as smart as 1.5 is like 50% smarter than

01:17:57.440 --> 01:18:03.120
either of us alone. Right. So you have this 1.5 intelligent kind of joint being now we've made

01:18:03.120 --> 01:18:06.800
now bring the third person in fourth person. And right. You see it starts to scale up. This is why

01:18:06.800 --> 01:18:13.360
science institutions can discover the relativity and quantum mechanics and these things that no

01:18:13.360 --> 01:18:17.840
individual human, you know, was going to come up with without a ton of collaboration because

01:18:17.840 --> 01:18:23.360
it's this giant idea lab. So it has an emergent property of super intelligence and echo chamber

01:18:23.360 --> 01:18:29.440
is the opposite where it has the emergent property of stupidity. I mean, it has the

01:18:29.440 --> 01:18:33.760
emergent property of a bunch of people all, you know, you know, paying field, you know,

01:18:33.760 --> 01:18:40.880
fealty to this set of sacred ideas. And so you lose this magical thing about language and humans,

01:18:40.880 --> 01:18:44.160
which is collaborative intelligence. You lose it. It disappears.

01:18:44.960 --> 01:18:50.320
But there is that access of decency, which is really interesting because you kind of paint

01:18:50.320 --> 01:18:57.840
this picture of you and your friends arguing really harshly, but underlying that is a basic

01:18:57.840 --> 01:19:05.360
camaraderie, respect. There's all kinds of mechanisms we humans have constructed to

01:19:05.360 --> 01:19:10.080
communicate like mutual respect or maybe communicate the you're here for the idea

01:19:10.080 --> 01:19:13.920
lab version of this. Totally. It doesn't, you don't take it. You don't get personal,

01:19:14.720 --> 01:19:18.480
right? You're not getting personal. You're not, you're not taking things personally.

01:19:20.320 --> 01:19:24.800
People are respected in an idea lab and ideas are disrespected. And there's a way,

01:19:24.800 --> 01:19:29.520
ways to signal that. So like for with friends, you've already done the signaling,

01:19:29.520 --> 01:19:33.600
you've already established a relationship. The interesting thing is online. I think you have

01:19:33.600 --> 01:19:39.760
to do some of that work. I mean, to me, the sort of steel manning the other side or no,

01:19:40.560 --> 01:19:45.280
having empathy and hearing out, being able to basically repeat the argument the other person

01:19:45.280 --> 01:19:50.000
is making before you and showing like respect to that argument. I could see how you could think

01:19:50.000 --> 01:19:55.520
that before you make a counter argument, there's just a bunch of ways to communicate that you're

01:19:55.520 --> 01:20:04.720
here not to do kind of, what is it, low rung, you know, shit talking, mockery, derision,

01:20:04.720 --> 01:20:09.520
but are actually here ultimately to discover the truth in the space of ideas and the tension of

01:20:09.520 --> 01:20:17.120
those ideas. And I think it's, I think that's a skill that we're all learning as a civilization

01:20:17.120 --> 01:20:21.600
of how to do that kind of communication effectively. I think disagreement as I'm

01:20:21.600 --> 01:20:26.480
learning on the internet, it's actually a really tricky skill, like high effort,

01:20:26.480 --> 01:20:31.680
high decency disagreement. I got to listen to, there's a really good debate podcast,

01:20:32.720 --> 01:20:38.240
Intelligence Squared. And like they can go pretty hard in the paint. Classic idea lab.

01:20:39.040 --> 01:20:43.920
Exactly. But like, how do we map that to social media? When people like will say,

01:20:44.240 --> 01:20:49.840
um, we'll say, well, like Lex or anybody, you're not, you hate disagreement. You,

01:20:49.840 --> 01:20:55.360
you want to censor disagreement. No. Um, I love Intelligence Squared type of disagreement. That's

01:20:55.360 --> 01:21:01.440
fun. Or you want to reduce asshole. And for me personally, I don't want to reduce asshole. If,

01:21:01.440 --> 01:21:06.400
you know, I kind of like asshole or it's like fun in many ways, but the problem is when the asshole

01:21:06.400 --> 01:21:13.120
shows up to the party, they make it less fun for the, for the party that's there for the idea lab

01:21:13.120 --> 01:21:17.040
and the other people, especially the quiet voices at the back of the room, they leave.

01:21:17.040 --> 01:21:22.480
And so all you're left is, was, was with assholes. Well, that Twitter political Twitter to me is one

01:21:22.480 --> 01:21:29.760
of those parties. It's a big party where a few assholes have really sent a lot of the quiet

01:21:30.640 --> 01:21:36.720
thinkers away. Yeah. Um, and, and so, so if you think about this graph again,

01:21:37.680 --> 01:21:45.920
what the, what, what some place like Twitter, um, a great way to get followers is to be an asshole

01:21:45.920 --> 01:21:50.640
with a certain, you know, pumping a certain ideology. You'll get a huge amount of followers

01:21:50.640 --> 01:21:54.160
and for those followers and the followers you're going to get, the people who would let you know,

01:21:54.160 --> 01:21:59.680
not the people who like you are probably going to be people who are really thinking with their

01:21:59.680 --> 01:22:04.160
primitive mind because they're seeing your, your being, your being an asshole, but because you

01:22:04.240 --> 01:22:07.840
agree with them, they love you and they think they don't see any problem with how you're being.

01:22:07.840 --> 01:22:10.720
Yeah. They don't see the asshole. This is a fascinating thing. Because look,

01:22:10.720 --> 01:22:15.280
because look at the thing on the right agreement and decency are the same. So if you're in that

01:22:15.280 --> 01:22:19.280
mindset, bigger, the asshole, the better. If you're agreeing with me, you're my man. I love what

01:22:19.280 --> 01:22:24.000
you're saying. Yes. Show them. Right. And the algorithm helps those people does those people

01:22:24.000 --> 01:22:30.000
do great on the algorithm. There's a fascinating dynamic that happens. Uh, cause I have currently

01:22:30.000 --> 01:22:34.880
hired somebody that looks at my social media and they block people because the assholes will

01:22:34.880 --> 01:22:39.360
roll in. They're not actually there to have a interesting disagreement, which I love.

01:22:40.080 --> 01:22:43.840
They're there to do kind of mockery. And then when they get blocked,

01:22:45.200 --> 01:22:50.800
they then celebrate that to their echo chamber. Like, look at this, I got them or whatever.

01:22:50.800 --> 01:22:55.120
Or they'll say some annoying thing like, oh, so it's, so he talks about, he likes, you know,

01:22:55.120 --> 01:22:59.440
if I, if I'd done this, they'll say he, oh, he says he likes idea labs, but he actually wants

01:22:59.440 --> 01:23:04.800
to create an echo chamber. But I'm like, Nope, you're an asshole. I'm not, I'm not, I look at

01:23:04.800 --> 01:23:09.360
the other 50 people on this thread that disagreed with me respectfully. They're not blocked. Yep.

01:23:09.360 --> 01:23:13.200
Exactly. You know, and so they see it as some kind of hypocrisy because again, they only see the

01:23:13.200 --> 01:23:18.080
thing on the right and they're not understanding that there's two axes or that I see it as two

01:23:18.080 --> 01:23:22.400
axes. And so you, you seem petty in that moment, but it's like, no, no, no, you're, this is very

01:23:22.400 --> 01:23:28.000
specific. What I'm doing. You're actually killing the conversation. I, I, and generally I give all

01:23:28.000 --> 01:23:33.760
those folks a pass and just send them love telepathically. But yes, like it's getting

01:23:33.760 --> 01:23:39.040
rid of assholes in the conversation is the way you allow for the disagreement. You do a lot of

01:23:39.040 --> 01:23:44.480
like when I think when like primitive mindedness comes at you, at least on Twitter, I don't know

01:23:44.480 --> 01:23:49.680
what you're feeling internally in that moment, but you do a lot of like, I'm going to meet that with

01:23:49.680 --> 01:23:55.040
my higher mind and you come out and you'll be like, and you'll be like, thanks for all the criticism.

01:23:55.040 --> 01:24:01.680
I love you. And that's the, that, that, that's actually a web, an amazing response because it

01:24:01.680 --> 01:24:08.320
just, it, what it does is it, it, it, that it, it unrials up that person's primitive mind and

01:24:08.320 --> 01:24:11.600
actually wakes up their higher mind who says, oh, okay, you know, this guy's not so bad. And

01:24:11.600 --> 01:24:17.840
suddenly like civility comes back. So it's a very powerful, hopefully long-term, but the thing is

01:24:17.840 --> 01:24:24.000
they do seem to drive away high quality disagreement. Cause like, cause it takes

01:24:24.000 --> 01:24:30.320
so much effort to disagree in a high quality way. I've noticed this in my blog. Like my,

01:24:30.320 --> 01:24:34.480
one of the things I pride myself on is like my comment section is awesome. Like there's,

01:24:34.480 --> 01:24:40.640
there's, there's every, everyone's being respectful. No one's afraid to disagree with me and tell them

01:24:40.640 --> 01:24:44.800
and say, you know, tear my post apart, but in a totally respectful way where the underlying

01:24:44.800 --> 01:24:49.360
thing is like, I'm here cause I like this guy and his writing and people disagree with each other

01:24:49.360 --> 01:24:52.720
and they get in these long interest and it's interesting and I read it and I'm learning.

01:24:52.720 --> 01:24:56.320
And then I, you know, a couple of posts, especially the ones I've written about politics.

01:24:56.320 --> 01:25:00.160
It's not like it seems like any other comment section, people are being nasty to me. They're

01:25:00.160 --> 01:25:06.000
being nasty to each other. And then I looked down one of them and I realized like almost all of this

01:25:06.000 --> 01:25:10.480
is the work of like three people. That's who you need to block. Those people need to be blocked.

01:25:10.480 --> 01:25:16.080
You're not being thin skinned. You're not being petty doing it. You're actually protecting an idea

01:25:16.080 --> 01:25:19.760
lab because what, what people would really aggressive people like that do is they'll turn

01:25:19.760 --> 01:25:23.360
it into their own echo chamber because now everyone is scared to kind of disagree with

01:25:23.360 --> 01:25:27.120
them because it's unpleasant. And so people who will chime in or the people who agree with them

01:25:27.120 --> 01:25:31.840
and suddenly like they've taken over the space. And I kind of believe that those people on a

01:25:31.840 --> 01:25:35.840
different day could actually do high effort disagreement. It's just that they're in a,

01:25:35.840 --> 01:25:39.760
in a, in a certain kind of mood. And a lot of us, just like you said, with a primitive mind

01:25:39.760 --> 01:25:46.640
could get into that mood. And it's, I believe it's actually the job of the technology, the platform

01:25:46.640 --> 01:25:52.400
to incentivize those folks to be like, are you sure this is the best you can do? Like if you

01:25:52.400 --> 01:25:58.320
really want to talk shit about this idea, like do better. Like, yeah. And then we need to create

01:25:58.320 --> 01:26:04.160
incentives where you get likes for high effort disagreement. Cause currently you get likes for

01:26:04.160 --> 01:26:12.640
like, uh, something that's slightly funny and is a little bit like mockery. Like, um, yeah, basically

01:26:12.640 --> 01:26:18.720
signals to some kind of echo chamber that this person is a horrible person is a hypocrite is

01:26:18.720 --> 01:26:24.160
evil, whatever that, that feels like it's solvable with technology. Cause I think in our private

01:26:24.160 --> 01:26:29.040
lives, none of us want that. I wonder if it's making me think that I want to like, because a

01:26:29.040 --> 01:26:34.960
much easier way for me to do it just for my, my world would be to say something like, you know,

01:26:35.520 --> 01:26:39.520
here's this axis, this high, this is, this is part of what I, part of what I like about the

01:26:39.520 --> 01:26:43.440
ladder is it's a language that we can use. It's like specifically what we're talking about is

01:26:44.960 --> 01:26:49.120
high rung disagreement, good, low rung disagreement, bad. Right. And so, so it

01:26:49.120 --> 01:26:52.560
gives us like a language for that. And so what I would say is I would, you know, my, you know,

01:26:52.560 --> 01:26:57.520
I would have my readers, you know, understand this axis. And then I would specifically say something

01:26:57.520 --> 01:27:05.280
like, please do the, the, do the, do it, but why a favor and up vote, regardless of what they're

01:27:05.280 --> 01:27:09.280
saying horizontally, right? Regardless of what their actual view is, up vote, high rungness.

01:27:10.000 --> 01:27:14.480
They can be tearing me apart. They can be saying great. They can be praising me, whatever

01:27:15.600 --> 01:27:20.080
upward, high rungness and down vote, low rungness. And if enough people are doing that,

01:27:20.080 --> 01:27:24.560
suddenly there's all this incentive to try to say, no, I need to calm my emotion down here and not

01:27:24.560 --> 01:27:27.600
be personal because I'm going to get voted into oblivion by these people.

01:27:28.240 --> 01:27:33.920
I think a lot of people would be very good at that. They, they, and they not are only,

01:27:33.920 --> 01:27:38.640
would they be good at that? They would want that, that task of saying, I know I completely

01:27:38.640 --> 01:27:44.480
disagree with this person, but this was a high effort, high rung disagreement.

01:27:44.480 --> 01:27:47.280
It gets everyone thinking about that other axis too. You're not just looking at where do

01:27:47.280 --> 01:27:50.320
you stand horizontally? You're saying, well, how did you get there? And how are you, you know,

01:27:51.600 --> 01:27:55.760
are you treating ideas like machines or are you treating them like little babies?

01:27:55.760 --> 01:28:00.720
And there should be some kind of labeling on personal attacks versus idea disagreement.

01:28:00.720 --> 01:28:04.560
Sometimes people like throw in both a little bit. That's like, all right, no,

01:28:04.560 --> 01:28:07.840
there should be a disincentive at personal attacks versus idea attacks.

01:28:07.840 --> 01:28:13.040
Well, you can also, one metric is a respectful disagreement. If I see,

01:28:13.040 --> 01:28:17.840
just say someone else's Twitter and I see, you know, you put out a thought and I see someone say,

01:28:17.840 --> 01:28:22.880
you know, you know, someone say, you know, I don't see it that way. Here's,

01:28:22.880 --> 01:28:27.200
here's where I think you went wrong. And they're just explaining. I'm thinking that if Lex Reed is

01:28:27.200 --> 01:28:30.800
that he's going to be interested. He's going to, he's going to want to post more stuff, right?

01:28:30.800 --> 01:28:36.080
Cause he's going to like that. If I see someone being like, um, um, wow, this really shows the

01:28:36.080 --> 01:28:40.240
kind of person that you become or shows up. I'm thinking that person is making Lex want to be on

01:28:40.240 --> 01:28:44.320
Twitter less. It's making him it's. And so what's that doing? What that person's actually doing is

01:28:44.320 --> 01:28:47.680
they're putting, is they're actually shut their chilling discussion. Cause they're making it

01:28:47.680 --> 01:28:52.080
unpleasant to, they're making it scary to say what you think. And the first person isn't at all. The

01:28:52.080 --> 01:28:55.920
first person is making you want to say more stuff. So, and those are both disagreed. Those are people

01:28:55.920 --> 01:29:02.000
who both disagree with you. Exactly. Exactly. I want to, it's a great disagreement with friends

01:29:02.000 --> 01:29:09.680
in meat space is like you're, they disagree with you. They could be even yelling at you.

01:29:10.800 --> 01:29:14.800
Honestly, they could even have some shit talk where it's like personal attacks. It is still

01:29:14.800 --> 01:29:18.880
feels good. Cause you know them well and you know that that shit talk. Cause like, yeah,

01:29:18.880 --> 01:29:23.440
friends shit talk all the time playing a, playing a sport or a game. And again, it's, it's, it's

01:29:23.440 --> 01:29:28.160
because they know each other well enough to know that this is fun. We're having fun. And obviously

01:29:28.160 --> 01:29:32.800
I love you. Like, you know, and, and that's, that's important online. It's a lot harder.

01:29:32.800 --> 01:29:37.360
Yeah. The, that obviously I love you that underlies a lot of human interaction.

01:29:37.360 --> 01:29:42.400
Right. Seems to be easily lost online. I've seen some people on Twitter and elsewhere just behave

01:29:42.400 --> 01:29:47.680
their worst. Yeah. And it's like, I know that's not who you are. Like, why are you, I actually,

01:29:47.680 --> 01:29:53.360
you know, I know he's this human. I know someone personally who is one of the best people. Yeah.

01:29:53.920 --> 01:29:59.360
It's just, I love this guy. Like one of the best, like fun, funny, like nicest dudes.

01:30:00.640 --> 01:30:05.200
And he, if you would, if you looked at his Twitter only, you would think he's a culture

01:30:05.200 --> 01:30:12.400
warrior, an awful culture warrior and you know, you know, biased and just stoking anger.

01:30:13.360 --> 01:30:16.880
And, and, and it comes out of a good place. And I'm not going to give any other info about,

01:30:16.880 --> 01:30:19.440
you know, specific, but like- I think you're describing a lot of people.

01:30:19.440 --> 01:30:22.480
It comes out of a good place because he really cares about what he, you know, it comes up,

01:30:22.480 --> 01:30:25.840
but it's just, I can't square the two. It's so, and that's it. You have to,

01:30:25.840 --> 01:30:28.720
once you know someone like that, you can realize, okay, apply that to everyone.

01:30:28.720 --> 01:30:32.960
Cause a lot of these people are lovely people and it's just bring, even just, you know, back in the,

01:30:32.960 --> 01:30:38.720
before social media, you ever had a friend who like was just like, they had this like

01:30:38.720 --> 01:30:43.200
dickishness on text or email that they didn't have in person. You're like, wow, like email you is

01:30:43.200 --> 01:30:47.520
like kind of a dick. And it's like, it just, certain people have a different persona behind the screen.

01:30:48.160 --> 01:30:52.960
It has, for me personally, has become a bit of a meme that Lex blocks with love,

01:30:53.760 --> 01:30:58.800
but there is a degree to that where this is, I don't see people on social media as representing

01:30:58.800 --> 01:31:02.960
who they really are. I really do have love for them. I really do think positive thoughts of them

01:31:02.960 --> 01:31:08.000
throughout the entirety of the experience. I see this as some weird side effect of

01:31:08.000 --> 01:31:15.120
online communication. And so it's like, to me, blocking is not some kind of a derisive act

01:31:15.120 --> 01:31:19.840
towards that individual. It's just like saying, well, a lot of times what's happened is they have

01:31:19.840 --> 01:31:27.120
slipped into a very common delusion that dehumanizes others. So that doesn't mean they're a bad person.

01:31:27.120 --> 01:31:33.040
We all can do it, but they're dehumanizing you or whoever they're being nasty to because they,

01:31:33.040 --> 01:31:36.320
in a way they would never do in person because in a person they're reminded that's a person.

01:31:37.200 --> 01:31:40.960
Remember I said the dumb part of my brain when I'm doing VR, like won't step off the cliff,

01:31:40.960 --> 01:31:44.640
but the smart part of my brain knows I'm just on the rug. That dumb part of our brain

01:31:45.600 --> 01:31:49.200
is really dumb in a lot of ways. It's the part of your brain where you can

01:31:50.000 --> 01:31:53.920
set the clock five minutes fast to help you not be late. The smart part of your brain knows

01:31:53.920 --> 01:31:58.640
you did that, but the dumb part will fall for it. That same dumb part of your brain can forget that

01:31:58.640 --> 01:32:05.200
the person behind that screen, behind that handle is a human that has feelings. And that doesn't

01:32:05.200 --> 01:32:09.120
mean they're a bad person for forgetting that because it's possible. Well, this really

01:32:09.120 --> 01:32:15.200
interesting idea, and I wonder if it's true that you're right, is that both primitive mindedness

01:32:15.200 --> 01:32:21.600
and high mindedness tend to be contagious. I hope you're right that it's possible to make

01:32:21.600 --> 01:32:29.120
both contagious because our sort of popular intuition is only one of them. The primitive

01:32:29.120 --> 01:32:34.080
mindedness is contagious as exhibited by social media. To compliment you again, don't you think

01:32:34.080 --> 01:32:41.680
that your Twitter to me is like, I was just looking down and I mean, it's just high mindedness.

01:32:41.680 --> 01:32:46.080
It's just high mindedness down, down, down, down, down. It's gratitude, it's optimism,

01:32:46.080 --> 01:32:50.800
it's love, it's forgiveness. It's all these things that are the opposite of grievance and victimhood

01:32:50.800 --> 01:32:58.320
and resentment and pessimism, right? And there's, I think, a reason that a lot of people follow you

01:32:58.400 --> 01:33:02.160
because it is contagious. It makes other people feel those feelings.

01:33:02.160 --> 01:33:09.520
I don't know. I've been recently, over the past few months, attacked quite a lot and it's fascinating

01:33:09.520 --> 01:33:15.040
to watch because it's over things that I think I probably have done stupid things, but I'm being

01:33:15.040 --> 01:33:20.960
attacked for things that are totally not worthy of attack. I got attacked for a book list.

01:33:22.000 --> 01:33:24.560
I saw that, by the way. I thought it was great.

01:33:24.880 --> 01:33:32.880
You can always kind of find ways to, I guess the assumption is this person surely is a fraud

01:33:33.600 --> 01:33:38.240
or some other explanation. He sure has dead bodies in the basement he's hiding or something like this

01:33:38.800 --> 01:33:43.040
and then I'm going to construct a narrative around that and mock and attack that. I don't know how

01:33:43.040 --> 01:33:47.840
that works, but there is, there does, and I think you write this in the book, there seems to be a

01:33:47.840 --> 01:33:51.920
gravity pulling people towards the primitive mind.

01:33:51.920 --> 01:33:58.640
Well, when it comes to anything political, right? Religious, certain things are bottom heavy,

01:33:58.640 --> 01:34:04.480
you know, for our psyche. They have a magnet that pulls our psyches downwards on the

01:34:04.480 --> 01:34:09.120
ladder and why? Why does politics pull our psyches down on the ladder? Because

01:34:09.920 --> 01:34:14.560
it, for the tens of thousand years that we were evolving,

01:34:16.720 --> 01:34:22.720
you know, during human history, it was life or death. Politics was life or death and so

01:34:24.240 --> 01:34:31.280
there's actually an amazing study where it's like they challenged like 20 different beliefs

01:34:31.280 --> 01:34:36.480
of a person and different parts of the person's brain, and they had an MRI going,

01:34:36.480 --> 01:34:40.320
different parts of the person's brain lit up when non-political beliefs were challenged versus

01:34:40.320 --> 01:34:44.720
political beliefs were challenged. When political beliefs were challenged, when non-political

01:34:44.720 --> 01:34:51.360
beliefs were challenged, the like the rational, like the prefrontal cortex type areas were lit

01:34:51.360 --> 01:34:55.520
up. When the political beliefs were challenged, and then I'm getting over my head here, but it's

01:34:55.520 --> 01:34:58.960
like the parts of your brain, the default mode network, the parts of your brain associated with

01:35:00.080 --> 01:35:06.240
introspection and like your own identity were lit up and they were much more likely to change

01:35:06.240 --> 01:35:11.200
their mind on all the beliefs, the non-political beliefs. When that default mode network part of

01:35:11.200 --> 01:35:17.040
your brain lit up, you were going to, if anything, get more firm in those beliefs when you had them

01:35:17.040 --> 01:35:24.240
challenged. So politics is one of those topics that just literally, literally lights up different

01:35:24.240 --> 01:35:28.320
part of our brain. Again, I think we come back to primitive mind, higher mind here. It's like,

01:35:28.960 --> 01:35:32.880
it gets our higher, this is one of the things our primitive mind comes programmed

01:35:33.440 --> 01:35:38.960
to care a ton about. And so there, it's going to be very hard for us to stay rational and calm and,

01:35:38.960 --> 01:35:41.920
and looking for truth because we have all this gravity to it.

01:35:41.920 --> 01:35:45.280
Well, it's weird because politics, like what is politics? Like to talk about,

01:35:45.280 --> 01:35:49.680
it's a bunch of different issues. And each individual issue, if we really talk about-

01:35:49.680 --> 01:35:52.640
And tax policy, like why are we being emotional about this?

01:35:52.640 --> 01:35:57.680
I don't think we're actually that, I mean, yeah, we're emotional about something else.

01:35:57.760 --> 01:36:02.960
Yeah, I think what we're emotional about is this, my side, the side I've identified with

01:36:02.960 --> 01:36:09.360
is in power and making the decisions and your side is out of power. And if your side's in power,

01:36:09.360 --> 01:36:14.080
that's really scary for me because that goes back to, you know, the idea of who is making,

01:36:14.080 --> 01:36:17.600
who's, who's pulling the strings in this tribe, right? Who's in, who's the chief?

01:36:17.600 --> 01:36:23.280
Is it your family's patriarch or is it mine? You know, you might not have food if we don't

01:36:23.280 --> 01:36:28.800
win this, you know, kind of whatever, you know, chief election. So I think that it's not about

01:36:28.800 --> 01:36:32.800
the tax policy or anything like that. And then, and then it gets tied to this like broader,

01:36:32.800 --> 01:36:37.440
I think a lot of our tribalism has really coalesced around this. We don't have that

01:36:37.440 --> 01:36:42.160
much religious tribalism in the US, right? The Protestants and the Catholics hate each other.

01:36:42.160 --> 01:36:46.960
We don't have that really, right? And honestly, you say, people like to say we have racial

01:36:46.960 --> 01:36:52.640
tribalism and everything, but a white, you know, a white, even a kind of a racist white

01:36:52.640 --> 01:36:58.720
conservative guy, I think takes the black conservative over the woke white person

01:36:58.720 --> 01:37:01.360
any day of the week right now. So that's the strongest source of division.

01:37:01.360 --> 01:37:06.000
It tells me that, I think politics is way stronger tribalism right now. I think that,

01:37:06.000 --> 01:37:11.760
that, that white racist guys, you know, loves the black conservative guy compared to the

01:37:11.760 --> 01:37:15.440
white woke guy, right? There's no, so, so, so to me, I think not, again, not that racial

01:37:15.440 --> 01:37:20.240
tribalism isn't a thing. Of course it's always a thing, but like political tribalism is the

01:37:20.240 --> 01:37:25.680
number one right now. So race is almost a topic for the political division versus the actual

01:37:25.680 --> 01:37:30.880
sort of element of the tribe. It's a political football. It's, yeah. So there, there's a,

01:37:30.880 --> 01:37:37.280
I mean, this is dark because, so this is a book about human civilization. This is a book about

01:37:37.840 --> 01:37:41.200
human nature, but it's also a book of politics about politics.

01:37:41.600 --> 01:37:50.960
Um, it is just the way you listed out in the book, it's kind of dark how we just fall into these

01:37:52.000 --> 01:37:58.160
left and right checklists. So if you're on the left, it's maintained where we weighed

01:37:59.600 --> 01:38:05.280
universal healthcare, good mainstream media, fine guns, kill people, us as a racist country,

01:38:05.280 --> 01:38:10.000
protect immigrants, tax cuts, bad climate change, awful raise minimum wage. And on the right is the

01:38:10.000 --> 01:38:16.320
flip of that. Reverse where we weighed universal healthcare, bad mainstream media, bad people kill

01:38:16.320 --> 01:38:21.600
people, not guns kill people. US was a racist country, protect borders, tax cuts, good climate

01:38:21.600 --> 01:38:27.200
change, overblown, don't raise minimum wage. I mean, it has, you almost don't have to think

01:38:27.200 --> 01:38:31.520
about any of this. It's like literally. So when you say it's a book about politics, it's interesting

01:38:31.520 --> 01:38:36.400
because it's a book about the vertical axis. Right. It's specifically not a book about the

01:38:36.400 --> 01:38:39.680
horizontal axis in that I'm not talking, I don't actually talk about any of these issues.

01:38:40.240 --> 01:38:44.320
I don't put out an opinion on them. Um, those are all horizontal, right?

01:38:45.120 --> 01:38:48.960
But when you, so my, and rather than argue, you know, having, you know, another book about

01:38:48.960 --> 01:38:54.880
those issues, about right versus left, I wanted to do a book about this other axis. And so on

01:38:54.880 --> 01:39:02.240
this axis, the reason I had this checklist is that this is a low part of the low rung politics

01:39:02.240 --> 01:39:08.320
world, right? Low rung politics is a checklist and that checklist evolves, right? Like Russia

01:39:08.320 --> 01:39:12.640
suddenly is like popular with the right as opposed to, you know, it used to be, you know, in the 60s,

01:39:12.640 --> 01:39:16.560
the left was the one defending Stalin. Like, so they'll switch. It doesn't even matter. The

01:39:16.560 --> 01:39:20.560
substance doesn't matter. It's that this is the approved checklist of the capital P party. And

01:39:20.560 --> 01:39:26.960
this is what everyone believes. That's a low rung thing. The high rungs, this is not what it's like

01:39:26.960 --> 01:39:30.720
high rung politics. You, you tell me your one view on this. I have no idea what you think about

01:39:30.720 --> 01:39:36.080
anything else, right? And you're going to say, I don't know about a lot of stuff because inherently

01:39:36.080 --> 01:39:38.960
you're not going to have that strong an opinion because you don't have that much info. These are

01:39:38.960 --> 01:39:43.040
complex things. So there's a lot of, I don't know. And people are all over the place.

01:39:43.760 --> 01:39:48.240
It's the, when it's, you know, you're in, you know, you're talking to someone who has been subsumed

01:39:48.240 --> 01:39:53.600
with low rung politics when, if they tell you their opinion on any one of these issues, you

01:39:53.600 --> 01:39:56.720
could just, you know, you could just rattle off their opinion on every single other one.

01:39:56.720 --> 01:40:00.560
And if, and if in three years it becomes fashionable to, to have this new view,

01:40:00.560 --> 01:40:05.040
they're going to have it. That's, you're not thinking that's echo, that's echo chamber culture.

01:40:05.040 --> 01:40:11.760
And I've been using kind of a shorthand of centrist to describe this kind of a high rung

01:40:11.760 --> 01:40:17.280
thinking, but people tend to, I mean, it's, it seems to be difficult to be a centrist or whatever,

01:40:17.280 --> 01:40:23.120
a high rung thinker. It's like it, people want to label you as a person who's too cowardly to

01:40:23.120 --> 01:40:28.800
take a stance, somehow, as opposed to asking, saying, I don't know, is a first statement.

01:40:28.800 --> 01:40:33.760
Well, the problem with centrist is that would mean that in each of these, tax cuts bag,

01:40:33.760 --> 01:40:38.000
tax cuts good. It means that you are saying, I am in, I think we should have some tax cuts,

01:40:38.000 --> 01:40:41.760
but not that many. You might not think that. You might actually come do some research and say,

01:40:41.760 --> 01:40:47.040
actually, I think tax cuts are really important. That doesn't mean, oh, I'm not a centrist anymore.

01:40:47.040 --> 01:40:51.200
I guess I'm a far, you know, no, no, no, that's why we need the second axis. So what you're

01:40:51.200 --> 01:40:54.640
trying to be when you say centrist is high rung, which means you might be all over the place

01:40:54.640 --> 01:40:58.320
horizontally. You might agree with the far left on this thing, the far right on this thing. You

01:40:58.320 --> 01:41:03.600
might agree with the centrists on this thing, but, but calling yourself a centrist actually like is

01:41:03.600 --> 01:41:08.400
putting yourself in a prison on the horizontal axis. And, and it's saying that, you know,

01:41:08.400 --> 01:41:12.720
I, I, whatever the, on the, on the different topics, I'm right in between the two policy wise.

01:41:12.720 --> 01:41:17.200
That's not where you are. So yeah, that's what we, we're badly missing this other axis.

01:41:17.200 --> 01:41:24.400
Yeah. I mean, I, I still do think it's like, for me, I am a centrist when you project it down

01:41:24.400 --> 01:41:30.640
to the horizontal, but the point is you're missing so much data by not considering the vertical

01:41:30.640 --> 01:41:35.200
because like on average, maybe it falls somewhere in the middle, but in reality,

01:41:35.200 --> 01:41:40.000
there's just a lot of nuance issue to issue that involves just thinking and uncertainty and

01:41:40.000 --> 01:41:46.560
changing in the, given the context of the current geopolitics and economics and just

01:41:46.560 --> 01:41:50.400
always considering, always questioning, always evolving your views, all of that.

01:41:50.400 --> 01:41:53.600
Not just, not just about like, oh, I think we should be in the center on this,

01:41:53.600 --> 01:41:57.760
but another way to be in the center is if there's some phenomenon happening,

01:41:57.760 --> 01:42:02.240
you know, there's always a terrorist attack, you know, and one side wants to say, this has

01:42:02.240 --> 01:42:06.000
nothing to do with Islam. And the other one, the other side wants to say, this is radical Islam,

01:42:06.000 --> 01:42:12.160
right? What's in between those is saying this is complicated and nuanced and we have to learn

01:42:12.160 --> 01:42:16.320
more. And it probably has something to do with Islam and something to do with the economic

01:42:16.320 --> 01:42:21.840
circumstances and something to do with, you know, geopolitics. So in the case like that,

01:42:21.840 --> 01:42:25.600
you actually do get really a nuanced when you go to the extremes and all of that nuance,

01:42:25.600 --> 01:42:29.120
which is where all the truth usually is, is going to be in the middle. So yeah.

01:42:29.120 --> 01:42:33.120
But there is a truth to the fact that if you take that nuance on those issues,

01:42:33.200 --> 01:42:37.520
like war in Ukraine, COVID, you're going to be attacked by both sides.

01:42:37.520 --> 01:42:43.680
Yes. People who have, who are really strongly on one side or the other, hate centrist people.

01:42:43.680 --> 01:42:48.320
I've gotten this myself and you know, this, the, the slur that I've had thrown at me is I'm an

01:42:48.320 --> 01:42:52.800
enlightened centrist in a very mocking way. So what are they actually saying? What does

01:42:52.800 --> 01:42:56.640
enlightened centrist mean? It means someone who is, you know, Steven Pinker or Jonathan

01:42:56.640 --> 01:43:02.800
Haidt gets accused of is, you know, that they're highfalutin, you know, intellectual world and they

01:43:02.800 --> 01:43:07.440
don't actually have any, they don't actually take a side. They don't actually get their hands dirty

01:43:07.440 --> 01:43:12.320
and they can be superior to both sides without actually taking a stand, right? So I see the

01:43:12.320 --> 01:43:19.600
argument and I disagree with it because I firmly believe that the hardcore tribes, they think

01:43:19.600 --> 01:43:22.400
they're taking a stand and they're out in the streets and they're pushing for something. I

01:43:22.400 --> 01:43:25.840
think what they're doing is they're just driving the whole country downwards. And I think they're,

01:43:25.840 --> 01:43:29.920
they're hurting all the causes they care about. And so it's not that, it's not that, you know,

01:43:29.920 --> 01:43:33.120
it's not that we need everyone to be sitting there, you know, refusing to take a side. It's

01:43:33.120 --> 01:43:38.560
that you can be far left and far right, but be upper left and upper right. If we talk about the,

01:43:38.560 --> 01:43:44.080
you use the word liberal a lot in the book to mean something that we don't in modern

01:43:44.080 --> 01:43:49.040
political discourse mean. So it's this higher philosophical view. And then you use the words

01:43:49.040 --> 01:43:55.120
progressive to mean the left and conservative to mean the right. Can you describe the concept of

01:43:55.120 --> 01:44:03.360
liberal games and power games? So the power games is, is what I call the like, basically just the

01:44:03.360 --> 01:44:10.240
laws of nature as the, when laws of nature are the laws of the land, that's the power game. So

01:44:10.240 --> 01:44:16.080
animals, watch any David Attenborough special. And when the little lizard is running away from the,

01:44:16.960 --> 01:44:21.520
the, you know, the bigger animal or whatever. And I use an example of a bunny and a bear. I don't

01:44:21.520 --> 01:44:24.720
even know if bears eat bunnies. They probably don't, but pretend bears eat bunnies, right? So

01:44:24.720 --> 01:44:30.160
it's like in the power games, the bear is chasing the bunny. There's no fairness. There's no, okay.

01:44:30.160 --> 01:44:34.160
Well, what's right, but you know, what, what, what, what, what's legal? No, no, no. If the bear is fast

01:44:34.160 --> 01:44:40.000
enough, it can eat the bunny. If the bunny is, can get away, it can stay living. And so that's it.

01:44:40.000 --> 01:44:45.600
That's the only rule. Now humans have spent a lot of time in essentially that environment. So when

01:44:45.600 --> 01:44:50.880
you have a totalitarian dictatorship, it's, and so what's the rule of the power games? It's everyone

01:44:50.880 --> 01:44:54.880
can do whatever they want if they have the power to do so. It's just a game of power. So the,

01:44:54.880 --> 01:44:58.400
if the bunny gets away, the bunny actually has more power than the bear in that situation.

01:44:58.400 --> 01:45:03.840
Right. And likewise, the totalitarian dictatorship, there's no rules. A dictator can do whatever

01:45:03.840 --> 01:45:08.400
they want. They can, they can, they can torture, they can, you know, flatten a rebellion with a lot

01:45:08.400 --> 01:45:12.880
of murder because they have the power to do so. What are you going to do? Right. And that's,

01:45:12.880 --> 01:45:15.920
that's kind of the state of nature. That's our natural way. You know, that would, you know,

01:45:16.000 --> 01:45:20.480
when you look at the mafia, watch a mafia movie, you know, there's, we do a lot of, we have,

01:45:20.480 --> 01:45:27.600
we have it in us. We all have, we all can snap into power games mode when it becomes all about,

01:45:28.240 --> 01:45:34.640
you know, just, just actual raw power. Now the liberal games is, is, you know, something that

01:45:34.640 --> 01:45:38.800
civilizations for thousands of years have been working on. It's not invented by America or

01:45:38.800 --> 01:45:44.480
modern times, but America's kind of was like the latest crack at it yet, which is this idea.

01:45:44.480 --> 01:45:48.480
Instead of everyone can do what they want if they have the power to do so, it's everyone can do

01:45:48.480 --> 01:45:52.160
what they want as long as it doesn't harm anyone else. Now that's really complicated. How do you

01:45:52.160 --> 01:45:57.280
define harm? And, and the idea is that everyone has their, a list of rights, which are protected

01:45:57.280 --> 01:46:02.560
by the government. And then they have their inalienable rights and they're, they're protected,

01:46:02.560 --> 01:46:07.920
you know, those are protected, uh, uh, again, by, you know, um, from, from an invasion by other

01:46:07.920 --> 01:46:12.720
people. And so you have this kind of fragile balance. And so the idea with the liberal games

01:46:12.720 --> 01:46:18.480
is you, that there are laws, but it's not totalitarian. They will build very clear,

01:46:18.480 --> 01:46:23.040
strict laws, kind of around the edges of what you can and can't do. And then everything else,

01:46:23.040 --> 01:46:28.480
freedom. So unlike a totalitarian dictatorship, actually it's, it's very loose. You can, there's

01:46:28.480 --> 01:46:32.560
a lot of things can happen and it's kind of up to the people, but there are still laws that protect

01:46:32.560 --> 01:46:36.560
the very basic and alienable rights and stuff like that. So it's this much looser thing. Now

01:46:36.560 --> 01:46:44.720
the vulnerability there is that it, so, so, so the, the benefits of it are obvious, right? Freedom

01:46:44.720 --> 01:46:49.040
is great. It seems like it's the most fair. They, you know, that, that equality of opportunity

01:46:49.040 --> 01:46:56.080
seemed like the most fair thing and, um, and, you know, equality before the law, you know, due

01:46:56.080 --> 01:47:00.960
process and all of this stuff. So it seems fair to the founders of the U S and other enlightenment

01:47:00.960 --> 01:47:06.320
thinkers. And it also is a great way to manifest productivity, right? You know, you have, um, you

01:47:06.320 --> 01:47:10.640
have Adam Smith saying it's not from the benevolence of the butcher or the baker that we get our dinner,

01:47:10.640 --> 01:47:14.640
but from their own, from their own self-interest. So you have, you can harness kind of selfishness

01:47:14.640 --> 01:47:20.560
for, for progress, but, um, it has a vulnerability, which is that because the laws, it's like the

01:47:20.560 --> 01:47:26.560
totalitarian laws, they don't have an excess of laws for no reason. They want to control everything

01:47:26.560 --> 01:47:30.720
and the U S, you know, in the U S we say, they're not going to do that. And so the second,

01:47:30.720 --> 01:47:35.600
it's almost two puzzle pieces. You have the laws and then you've got a liberal culture. Liberal

01:47:35.600 --> 01:47:41.840
laws have to be married to liberal culture, kind of a defense of liberal spirit in order to truly

01:47:41.840 --> 01:47:47.040
have the liberal games going on. And so that's vulnerable because free speech, you can have

01:47:47.600 --> 01:47:52.560
the first amendment. That's the, the laws part. But if, if you're in a culture where anyone who,

01:47:53.360 --> 01:47:58.800
you know, speaks out against orthodoxy is going to be shunned from the community,

01:47:58.800 --> 01:48:02.240
well, you're lacking the second piece of the puzzle there. You're lacking liberal culture.

01:48:02.240 --> 01:48:06.880
And so therefore you, um, you might as well be in it. You might as well not even have the first

01:48:06.880 --> 01:48:11.360
amendment. And there's a lot of examples like that where the culture has to do its part for

01:48:11.360 --> 01:48:16.480
the true liberal games to be enjoyed. So it's just much more complicated, much more nuanced

01:48:16.480 --> 01:48:23.840
than the power games. It's kind of, it, it's kind of a set of basic laws that then are coupled

01:48:23.840 --> 01:48:31.520
with a basic spirit to create this very awesome and human environment. That's also very vulnerable.

01:48:32.160 --> 01:48:37.520
So what do you mean the culture has to play along? So for something like a freedom of speech to work,

01:48:38.400 --> 01:48:43.040
there has to be a basic, what decency that if all people are perfectly good,

01:48:43.680 --> 01:48:49.280
then perfect freedom without any restrictions is great. It's where the human nature starts

01:48:49.280 --> 01:48:54.320
getting a little iffy. We start being cruel to each other. We start being, uh, greedy and,

01:48:54.320 --> 01:49:00.640
uh, desiring of harm and also the narcissist and sociopaths and psychopaths in society,

01:49:00.640 --> 01:49:04.480
all of that. That's when you start to have to inject some limitations on that freedom.

01:49:05.280 --> 01:49:11.040
Yeah. I mean, if, if, um, so that what the government basically says is we're going to

01:49:11.040 --> 01:49:15.680
let everyone be mostly free. Um, but no one, no one is going to be free to

01:49:16.880 --> 01:49:23.120
physically harm other people or to steal their property. Right. Um, and so we're, we're also,

01:49:23.120 --> 01:49:28.160
we're all agreeing to sacrifice that, you know, that, that 20% of our freedom. And then in return,

01:49:28.160 --> 01:49:35.200
all of us in theory can be 80% free. And that's kind of the, the bargain. Um, but now that's a

01:49:35.200 --> 01:49:40.560
lot of freedom to leave people with. And a lot of people choose, it's like, you're so free in the

01:49:40.560 --> 01:49:43.920
U S you're actually free to be unfree. If you choose, that's kind of what an echo chamber is

01:49:43.920 --> 01:49:50.160
to me. It's, you know, um, you can, you can choose to kind of be friends with people who,

01:49:52.320 --> 01:50:01.520
uh, essentially make it, make it so uncomfortable to speak your mind that it's no actual effective

01:50:01.520 --> 01:50:05.920
difference for you than if you lived in a country, if, if you can't, you know, criticize

01:50:05.920 --> 01:50:11.520
Christianity in a certain community, that you have a first amendment. So you're not going to

01:50:11.520 --> 01:50:18.080
get arrested by the government for criticizing Christianity. But if you, but if you have this,

01:50:18.080 --> 01:50:23.680
if the social penalties are so extreme that it's just never worth it, you might as well be in a

01:50:23.680 --> 01:50:30.560
country that imprisons people for criticizing Christianity. And so that same thing goes for,

01:50:30.560 --> 01:50:34.880
for wokeness, right? This is what people get, you know, uh, you know, cancel culture and stuff. So

01:50:35.200 --> 01:50:40.880
the reason these things are bad is because they're actually, they're depriving Americans

01:50:41.440 --> 01:50:47.520
of the beauty of the freedom of the liberal games by, you know, imposing a social culture

01:50:47.520 --> 01:50:52.560
that is very power games. It's basically a power games culture comes in and you might as well be

01:50:52.560 --> 01:50:58.880
in the power games now. And so liberal, if you live in a liberal democracy, it's, it's you,

01:50:58.880 --> 01:51:06.720
there will be, always be challenges to a liberal culture, lowercase L liberal. There'll always be

01:51:06.720 --> 01:51:10.720
challenges to a liberal culture from people who are much more interested in playing the power

01:51:10.720 --> 01:51:15.760
games. And, and, and, and there has to be kind of an immune system that stands up to that culture

01:51:15.760 --> 01:51:20.480
and says, that's not how we do things here in America. Actually, we don't ex communicate

01:51:20.480 --> 01:51:25.040
people for not having the right religious beliefs or not rent, you know, we don't disinvite a speaker

01:51:25.040 --> 01:51:29.680
from campus for having the wrong political beliefs. Uh, and if it doesn't stand up for itself,

01:51:29.680 --> 01:51:35.760
it's, it's, it's like the immune system of the country failing and power games rushes in.

01:51:37.760 --> 01:51:45.280
So, uh, before chapter four in your book, uh, and the chapters that will surely result in you being

01:51:45.280 --> 01:51:51.440
burned at the stake, you write quote, we'll start our pitchfork tour in this chapter by taking a

01:51:51.440 --> 01:51:55.680
brief trip through the history of the Republican party. Then in the following chapters, we'll take

01:51:55.680 --> 01:52:02.640
a Tim's career tanking deep dive into America's social justice movement as you started to talk

01:52:02.640 --> 01:52:08.960
about. Okay. So let's go. Uh, what's the history of the Republican party? I'm looking at this

01:52:08.960 --> 01:52:14.800
through my vertical ladder. I'm saying what is this, this familiar story of the Republicans from

01:52:14.800 --> 01:52:20.160
the sixties to today, what does it look like through the vertical lens? Right. Does it look

01:52:20.160 --> 01:52:23.840
different? And, and, and is there, is there an interesting story here that's been kind of hidden

01:52:23.840 --> 01:52:27.840
because we're always looking at the horizontal. Now, the horizontal story, you'll hear people

01:52:27.840 --> 01:52:31.680
talk about it and it's, they'll say something like the Republicans have moved farther and farther to

01:52:31.680 --> 01:52:41.120
the right. And, um, and to me that, that's not really true. Like it was Trump more right-wing

01:52:41.120 --> 01:52:45.600
than Reagan. I don't think so. I think he's left less. Actual policy. Yeah. Yeah. So it's,

01:52:45.600 --> 01:52:48.960
so we're using this again, it's just like you're calling yourself centrist when it's not exactly

01:52:48.960 --> 01:52:53.840
what you mean, even though it also is. Yeah. So I, again, this, I was like, okay, look,

01:52:53.840 --> 01:52:57.200
this vertical lens helps with other things. Let's, let's apply it to the Republicans. And here,

01:52:57.200 --> 01:53:04.320
here's what I saw is I looked at the sixties and I saw an interesting story, which I don't think

01:53:04.320 --> 01:53:08.800
that, you know, not everyone's familiar with like what happened in the early sixties, but

01:53:09.600 --> 01:53:16.240
in 1960, the Republican party was very, it was a plurality. You had progressives like genuine,

01:53:16.400 --> 01:53:21.840
Rockefeller, you know, pretty progressive people, um, all the way to, you know, then you had the,

01:53:21.840 --> 01:53:27.760
you know, moderates like Eisenhower and Dewey. And then you go all the way to the farther right,

01:53:27.760 --> 01:53:32.880
you had Goldwater and you know, what you might call, I call them the fundamentalists. Um,

01:53:34.400 --> 01:53:40.880
and so it's this interesting plurality, right? Something we don't have today. And what happened

01:53:40.880 --> 01:53:47.920
was the, the Goldwater contingent, which was the underdog. They were small, right? The Eisenhower

01:53:47.920 --> 01:53:53.440
was the president, uh, had just been the president and was, it seemed like the moderates were, you

01:53:53.440 --> 01:53:56.400
know, that was the, that's the, he said, you have to be close to the center of the chessboard. That's

01:53:56.400 --> 01:54:00.320
right. That's, that's how you maintain power. These people were very far from the center of the

01:54:00.320 --> 01:54:06.000
chessboard, but they ended up basically have like a hostile takeover. They conquered their own party

01:54:06.080 --> 01:54:12.880
and they did it by breaking all of the kind of unwritten rules and norms. So they did things

01:54:12.880 --> 01:54:16.400
like they first started with like the college Republicans, which was like this feeder group

01:54:16.400 --> 01:54:20.560
that turned in, you know, a lot of the politicians started there and they, they, they went to the

01:54:20.560 --> 01:54:26.560
election and they wouldn't let the, the current president, the incumbent speak and they were

01:54:26.560 --> 01:54:30.000
throwing chairs and they were fistfights. And eventually people gave up and they just sat there

01:54:30.000 --> 01:54:33.840
and they sat in the chair talking for, you know, their, their candidate until everyone eventually

01:54:33.840 --> 01:54:39.440
left and then they declared victory. So basically they, they, they, they, they came in, there was a,

01:54:39.440 --> 01:54:43.760
there was a certain set of rules, agreed upon rules, and they came in playing the power games

01:54:43.760 --> 01:54:49.120
saying, well, actually, if we do this, you won't have the power, you know, we have the power to,

01:54:49.120 --> 01:54:53.920
to take it if we just break all the rules. Right. And so they did and they won and that became a

01:54:53.920 --> 01:54:57.840
hugely influential thing, which then they, then they conquered California through again, these,

01:54:57.840 --> 01:55:02.000
these people were taken aback. These, you know, these, these, these proper Republican candidates

01:55:02.000 --> 01:55:05.360
were appalled by the kind of like, you know, the insults that were being hurled at them and

01:55:05.360 --> 01:55:09.840
the intimidation and the bullying. And eventually they ended up in the national convention, which

01:55:09.840 --> 01:55:14.400
was called like the right wing Woodstock. It was like, you know, the Republican national convention

01:55:14.400 --> 01:55:18.720
in 64 was just, they, again, there was jeering and they wouldn't let their moderates or the

01:55:18.720 --> 01:55:23.120
progressives even speak. And there was racism, you know, you know, Jackie Robinson was there

01:55:23.120 --> 01:55:26.640
and he was a proud Republican. And he said that like, he feels like he was a Jew in Hitler's

01:55:26.640 --> 01:55:30.240
Germany with the way that blacks were being treated there. And it was nasty. And, but what

01:55:30.240 --> 01:55:36.800
do they do? They had, they had fiery, you know, plurality enough to win. And they won. They ended

01:55:36.800 --> 01:55:40.640
up getting crushed in the general election and they kind of faded away. But to me, I was like,

01:55:40.640 --> 01:55:45.360
what, that was an interesting story. I see it as, I have this character in the book called the Golem,

01:55:45.360 --> 01:55:49.920
which is a big, kind of a big, dumb, powerful monster. That's the, you know, the emergent

01:55:49.920 --> 01:55:54.000
property of like a political echo chamber is like this big giant. It's stupid, but it's powerful

01:55:54.000 --> 01:55:59.840
and scary. And to me, I was like, a Golem rose up, conquered the party for a second,

01:55:59.840 --> 01:56:07.120
knocked it on its ass and then, and then faded away. And to me, when I looked at the Trump

01:56:07.120 --> 01:56:11.600
revolution and a lot, and not just Trump, the last 20 years, I see that same lower right,

01:56:12.240 --> 01:56:20.080
that lower right monster kind of making another charge for it, but this time succeeding and really

01:56:20.080 --> 01:56:25.600
taking over the party for a long period of time. I see the same story, which is the power games

01:56:25.600 --> 01:56:31.360
are being played in a situation when it had always been, the government relies on all these unwritten

01:56:31.360 --> 01:56:36.560
rules and norms to function. But for example, you have in 2016, Merrick Garland gets,

01:56:36.560 --> 01:56:44.400
gets nominated by Obama and the unwritten norm says that when the president nominates a justice,

01:56:44.400 --> 01:56:47.760
then you pass them through unless there's some egregious thing. That's what has happened.

01:56:47.760 --> 01:56:51.120
But they said, actually, this is the last year of his presidency and the people should choose. I

01:56:51.120 --> 01:56:56.480
don't think we should set a new precedent where the president can't nominate people, nominate a

01:56:56.480 --> 01:57:01.040
Supreme Court justice in the last year. So they passed it through and it ends up being Gorsuch.

01:57:01.680 --> 01:57:06.720
And so they lose that seat. Now, three years later, it's Trump's last year and it's another

01:57:06.720 --> 01:57:12.880
election year and Ginsburg dies. And what did they say? They say, oh, let's keep our precedent. They

01:57:12.880 --> 01:57:17.920
said, no, oh, actually, we changed our mind. We're going to nominate Amy Barrett. So to me,

01:57:17.920 --> 01:57:21.680
that is classic power games, right? That there's, there's no actual rule. And what you're doing is

01:57:21.680 --> 01:57:25.040
they had the, they did technically have the power to block the nomination then. And then they

01:57:25.040 --> 01:57:27.360
technically had the power to put someone in and they, and they're pretending there's some

01:57:27.360 --> 01:57:32.800
principle to it, but they're just extra. They're going for the short-term edge at the expense of

01:57:32.800 --> 01:57:37.440
what is like the workings of the system in the long run. And then one of the Democrats have to

01:57:37.440 --> 01:57:41.920
do in that situation, because both parties have been doing this is they either can lose now all

01:57:41.920 --> 01:57:45.680
the time or they start playing the power games too. And now you have a prisoner's dilemma where

01:57:45.680 --> 01:57:51.600
it's like both are end up doing this thing and everyone ends up worse off the debt ceiling,

01:57:51.600 --> 01:57:55.680
all these power plays that are being made with these holding the country hostage, this is power

01:57:55.680 --> 01:57:59.520
games. And to me, that's what Goldwater was doing in the sixties, but it was a healthier time in a

01:57:59.520 --> 01:58:05.520
way because there was this plurality within the parties, reduced some of the national tribalism

01:58:05.520 --> 01:58:09.200
and that there wasn't as much of an appeal to that. But today it's just like, do whatever you

01:58:09.200 --> 01:58:14.160
have to do to beat the enemies. And so I'm seeing a rise in power games. And I talk about the

01:58:14.160 --> 01:58:16.960
Republicans because they did a lot of these things first. They have been a little bit more

01:58:16.960 --> 01:58:22.000
egregious, but both parties have been doing it over the last 20, 30 years. Can you place blame

01:58:22.000 --> 01:58:29.840
or maybe there's a different term for it at the subsystems of this? So is it the media? Is it the

01:58:29.840 --> 01:58:38.560
politicians like in the Senate and in Congress? Is it Trump? So the leadership is it, or maybe

01:58:38.560 --> 01:58:45.760
it's us human beings, maybe social media versus mainstream media. Is there a sense of where,

01:58:46.400 --> 01:58:49.840
what is the cause of what is the symptom? It's very complex. So Ezra Klein is a great book,

01:58:49.840 --> 01:58:53.760
Why We're Polarized, where he talks about a lot of this. And there's some of these are,

01:58:54.560 --> 01:58:58.800
it's really no one's fault. First of all, it's the environment has changed in a bunch of ways

01:58:58.800 --> 01:59:02.160
you just mentioned. And what happens when you take human nature, which is a constant and you

01:59:02.160 --> 01:59:07.120
put it into an environment, behavior comes out. The environment is the independent variable. When

01:59:07.120 --> 01:59:12.000
that changes, the dependent variable, the behavior changes with it, right? And so the

01:59:12.000 --> 01:59:19.040
environment has changed in a lot of ways. So one major one is it used to for a long time, actually,

01:59:19.040 --> 01:59:25.920
the first it was the Republicans and then the Democrats just had a stranglehold on Congress.

01:59:25.920 --> 01:59:32.080
There was no, it was not even competitive. The Democrats for 40 years had the majority. And so

01:59:32.080 --> 01:59:38.480
therefore it actually is a decent environment to compromise it because now we can both,

01:59:38.480 --> 01:59:42.000
you know, what you want is Congress people thinking about their home district and, you know,

01:59:42.720 --> 01:59:46.160
voting yes on a national policy because we're going to get a good deal on it back at home.

01:59:46.160 --> 01:59:52.240
That's actually healthy as opposed to voting in lockstep together because this is what the

01:59:52.240 --> 01:59:57.200
red party is doing, regardless of what's good for my home district. You know, an example is Obamacare.

01:59:57.200 --> 02:00:00.560
You know, there were certain Republican districts that would have actually officially been

02:00:01.200 --> 02:00:06.160
benefited by Obamacare, but every Republican voted against it. So, and part of the reason is

02:00:06.160 --> 02:00:11.040
because there's no longer this obvious majority. Every few years it switches. It's a 50-50 thing.

02:00:11.680 --> 02:00:16.560
And that's, you know, partially because it's become so, we've been so subsumed with this one

02:00:16.560 --> 02:00:23.440
national divide of left versus right that people are not, people are whoever, you know, they're

02:00:23.440 --> 02:00:27.840
voting for the same party for president all the way down the ticket now. And so you have this just

02:00:27.840 --> 02:00:32.720
kind of 50-50 color war and that's awful for compromise. So there's like 10 of these things,

02:00:32.720 --> 02:00:38.160
you know, that have redistricting, but also it is social media. It is, you know, I call it hyper

02:00:38.160 --> 02:00:41.840
charged tribalism. We've, you know, in the sixties you had kind of distributed tribalism. You had

02:00:41.840 --> 02:00:46.320
some people that are worked up about the USSR, right? They're national. That's what they care

02:00:46.320 --> 02:00:51.120
about. US versus foreign. You had some people that were saying left versus right, like they had today,

02:00:51.120 --> 02:00:55.200
and then other people that were saying that they were fighting within the party. But today you

02:00:55.200 --> 02:01:00.560
don't have that. You have ideological realignment. So you kind of got rid of a lot of the in-party

02:01:00.560 --> 02:01:05.200
fighting. And then there hasn't been that big of a foreign threat, nothing like the USSR for a long

02:01:05.200 --> 02:01:09.680
time. So you kind of lost that. And what's left is just this left versus right thing. And so that's

02:01:09.680 --> 02:01:16.800
kind of this hypercharged whirlpool that subsumes everything. And so, yeah, it's, I mean, people

02:01:16.800 --> 02:01:21.280
point to Newt Gingrich, you know, and people like there's certain characters that enacted policies

02:01:21.280 --> 02:01:26.080
that stoked this kind of thing. But I think this is a much bigger kind of environmental shift.

02:01:26.080 --> 02:01:29.600
Well, that's going back to our questions about the role of individuals in human history.

02:01:30.160 --> 02:01:34.320
So the interesting, one of the many interesting questions here is about Trump.

02:01:34.320 --> 02:01:40.240
Is he a symptom or a cause? Because he seems to be from the public narrative, such a significant

02:01:41.360 --> 02:01:45.600
catalyst for some of the things we're seeing. This goes back to what we were talking about earlier,

02:01:45.600 --> 02:01:50.560
right? Like, is it the person or is it the times? I think he's a perfect example of it's a both

02:01:50.560 --> 02:01:54.720
situation. I don't think, I don't think if you pluck Trump out of this situation, I don't think

02:01:54.720 --> 02:02:00.880
Trump was inevitable. But I think we were very vulnerable to a demagogue. And if you hadn't been,

02:02:00.880 --> 02:02:08.080
Trump would have had no chance. And so why were we vulnerable to a demagogue is because you have

02:02:08.080 --> 02:02:14.000
these, well, I mean, I think it's specifically on the right. If you actually look at the stats,

02:02:14.000 --> 02:02:17.920
it's pretty bad. Like the people who, because it's not just who voted for Trump, a lot of people

02:02:17.920 --> 02:02:22.800
just vote for the red, right? What's interesting is who voted for Obama against Romney and then

02:02:22.800 --> 02:02:29.280
voted for Trump? Who, you know, these are not racists, right? These are not hardcore Republicans.

02:02:29.280 --> 02:02:34.880
They voted for Obama. And where did the switch come from? Places that had economic despair,

02:02:34.880 --> 02:02:40.000
where bridges were not working well. That's a signifier, you know, where paints chipping

02:02:40.000 --> 02:02:44.320
in the schools, you know, these little things like this. So I think that, you know, you had this,

02:02:45.200 --> 02:02:48.560
a lot of these kind of rural towns, you have true despair. And then you also have,

02:02:50.080 --> 02:02:55.920
the number one indicator of voting for Trump was distrust in media. And the media has become much

02:02:55.920 --> 02:03:02.720
less trustworthy, you know? And so you have all these ingredients that actually make us very

02:03:02.720 --> 02:03:06.800
vulnerable to a demagogue. And a demagogue is someone who takes advantage, right? There's

02:03:06.800 --> 02:03:12.400
someone who comes in and says, I can pull the right strings and push all the right emotional

02:03:12.400 --> 02:03:17.840
buttons right now and get myself power by taking advantage of the circumstances. And that is what

02:03:17.840 --> 02:03:24.640
Trump totally did. It makes me wonder how easy it is for somebody who's a charismatic leader

02:03:24.640 --> 02:03:31.840
to capitalize on cultural resentment when there's economic hardship to channel that.

02:03:32.480 --> 02:03:38.080
So John Height wrote a great article about like, basically, truth is in an all-time low right now.

02:03:38.480 --> 02:03:44.800
The media is not penalized for lying, right? MSNBC, Fox News, these are not penalized for

02:03:44.800 --> 02:03:50.560
being inaccurate. They're penalized if they stray from the orthodoxy. On social media,

02:03:50.560 --> 02:03:57.120
it's not the truest tweets that go viral, right? And so Trump understood that better than anyone,

02:03:57.120 --> 02:04:01.600
right? He took advantage of it. He was living in the current world when everyone else was stuck

02:04:01.600 --> 02:04:08.960
in the past. And he saw that and he just lied. He, everything he said, you know, it doesn't,

02:04:08.960 --> 02:04:13.280
the truth was not relevant at all, right? It's just truly, it's not relevant to him when what

02:04:13.280 --> 02:04:17.920
he's talking about. He doesn't care. And he knew that neither do a subset of the country.

02:04:17.920 --> 02:04:21.440
I was thinking about this, just reading articles by journalists,

02:04:22.880 --> 02:04:28.160
especially when you're not a famous journalist in yourself, but you're more like in your

02:04:29.040 --> 02:04:32.640
Times journalist. So the big famous thing is the institution you're part of.

02:04:34.160 --> 02:04:39.520
You can just lie because you're not going to get punished for it. You're going to be rewarded for

02:04:39.520 --> 02:04:46.000
the popularity of an article. So if you write 10 articles, there's a huge incentive to just

02:04:46.000 --> 02:04:50.160
make stuff up. You got to get clicks. To get clicks. That's the first and foremost. And like,

02:04:50.160 --> 02:04:54.960
culturally, people will attack that article to say it's dishonest. Like one half the country

02:04:54.960 --> 02:04:59.120
will attack that article for saying it's dishonest, but they'll kind of forget the,

02:05:00.080 --> 02:05:05.280
you will not have a reputational hit. There won't be a memory like this person made up a lot of

02:05:05.280 --> 02:05:10.720
stuff in the past. No, they'll take one article at a time and they'll attach the reputation hits

02:05:10.720 --> 02:05:15.440
will be to New York Times, the institution. And so for the individual journalists, there's a huge

02:05:15.440 --> 02:05:22.560
incentive to make stuff up. Totally. And it's scary because it's almost like you can't survive

02:05:22.560 --> 02:05:26.320
if you're just an old school, honest journalist who really works hard and tries to get it right

02:05:26.320 --> 02:05:31.280
and does it with nuance. What you can be is you can be a big time substacker or big time

02:05:31.280 --> 02:05:37.120
podcaster. A lot of people do have a reputation for accuracy and rigor and they have huge audiences.

02:05:37.680 --> 02:05:47.840
But if you're working in a big company right now, especially, I think that many of the big media

02:05:47.840 --> 02:05:52.480
brands are very much controlled by the left. But I will say that the ones that are controlled by

02:05:52.480 --> 02:05:57.120
the right are even more egregious, not just in terms of accuracy, but also in terms of,

02:05:57.120 --> 02:06:02.720
you know, the New York Times for all of its criticisms, they have a handful of,

02:06:04.720 --> 02:06:10.720
here and there, they put out a pretty, you know, an article that strays from the, you know,

02:06:10.720 --> 02:06:15.280
Barry Weiss wrote there for a long time. And then you've got, they wrote an article criticizing

02:06:15.280 --> 02:06:19.920
free speech on campus stuff, you know, recently. And they have, you know, they have a couple very,

02:06:19.920 --> 02:06:25.920
you know, left progressive friendly conservatives, but they have conservatives that are writing the

02:06:25.920 --> 02:06:31.120
op-eds. Fox News, you know, you're not seeing thoughtful, a bright bar, you're not seeing

02:06:31.120 --> 02:06:36.320
thoughtful progressives writing there, right? There's some degree to which the New York Times,

02:06:37.200 --> 02:06:45.280
I think, still incentivizes and values the vertical, the high effort. So you're allowed to

02:06:45.280 --> 02:06:51.680
have a conservative opinion if you do a really damn good job. Like if it's a very thorough,

02:06:51.680 --> 02:06:56.160
in-depth kind of- And if you kind of pander to the progressive

02:06:56.160 --> 02:07:00.640
senses in all the right ways. You know, I always joke that, you know, Ted, they always have a

02:07:00.640 --> 02:07:04.160
couple, you know, token conservatives, but they get on stage and they're basically like,

02:07:04.160 --> 02:07:09.440
so totally you're all, you know, the progressivisms are, it's right about all of this, but maybe,

02:07:10.000 --> 02:07:13.920
maybe, you know, libertarianism isn't all about, you know, it's just, so there is an element,

02:07:13.920 --> 02:07:19.840
but you know what? It's something. It's better than being a total tribal. I think you can see

02:07:19.840 --> 02:07:23.280
the New York Times tug of war, the internal tug of war. You can see it, because then they also

02:07:23.280 --> 02:07:26.800
have these awful instances, you know, or like, you know, the firing of James Bennett, which is

02:07:26.800 --> 02:07:33.760
this whole other story, but like they have, yeah, you can see it going both ways, but in the 60s,

02:07:33.760 --> 02:07:38.480
what did you have? You had ABC, NBC, CBS, you know, the 70s, you know, you had these three

02:07:38.480 --> 02:07:42.000
news channels and they weren't always right, and they definitely sometimes spun a narrative

02:07:42.000 --> 02:07:47.440
together maybe about the Vietnam or whatever, but they, if one of them was just lying,

02:07:47.440 --> 02:07:50.960
they'd be embarrassed for it. They would be penalized. They'd be dinged and they'd be known

02:07:50.960 --> 02:07:54.080
as this is the trash one. And that would be terrible for their ratings because they weren't

02:07:54.080 --> 02:07:57.600
just catering to half the country. They're catering, they all are catering to the whole country. So

02:07:57.600 --> 02:08:04.640
both on the axis of accuracy and on the axis of neutrality, they had to, you know, try to stay

02:08:04.640 --> 02:08:11.040
somewhere in the reasonable range and that's just gone. One of the things I'm really curious about

02:08:11.040 --> 02:08:17.280
is I think your book is incredible. I'm very curious to see how it's written about by the press

02:08:18.080 --> 02:08:22.800
because I could see click, I could myself write with the help of Jackie Petey, of course,

02:08:22.800 --> 02:08:28.800
clickbait articles in either direction. Yeah. It's easy to imagine. Your whole book is beautifully

02:08:28.800 --> 02:08:33.280
written for clickbait articles. Yeah. If any journalists out there need help, I can, I can

02:08:33.280 --> 02:08:40.160
help. Yeah. I can write out the most atrocious criticisms. Yeah. I'm, I'm, I'm, I'm, I'm ready.

02:08:40.160 --> 02:08:49.840
I'm braced. Yeah. So speaking of which, you write about social justice. You write about two kinds

02:08:49.840 --> 02:08:57.760
of social justice, liberal social justice and SJF, social justice fundamentalism. What are those?

02:08:58.560 --> 02:09:03.040
Yeah. So like the term wokeness is so loaded with baggage. It's kind of like mocking and derogatory

02:09:03.360 --> 02:09:08.560
I was trying not to do that in this book. If it's the term loaded with baggage, you're already kind

02:09:08.560 --> 02:09:18.160
of, you're, you're, you're from, from the first minute you're already behind. So to me, it, it,

02:09:18.160 --> 02:09:23.280
also when people say wokeness is bad, social justice is bad, they're throwing the baby out

02:09:23.280 --> 02:09:29.440
with the bathwater because the, the, you know, the proudest tradition in the US is liberal

02:09:29.440 --> 02:09:36.080
social justice. And what I mean by that, again, liberal meaning with lowercase L it is, it is

02:09:36.080 --> 02:09:40.560
intertwined with liberalism. So Martin Luther King classic example, his, I have a dream speech. He

02:09:40.560 --> 02:09:49.680
says stuff like this country, you know, is, you know, has made a promise to all of its citizens

02:09:49.680 --> 02:09:56.000
and it has broken that promise to its black citizens, right? In other words, liberalism,

02:09:56.000 --> 02:10:01.120
the constitution, the core ideals, those are great. We're not living up to them. We're failing

02:10:01.120 --> 02:10:07.200
on some of them. So civil disobedience, the goal of it wasn't to, to hurt liberalism is to

02:10:07.200 --> 02:10:12.720
specifically break the laws that were already violating that were the laws that were a violation

02:10:12.720 --> 02:10:18.240
of liberalism to expose that this is illiberal, that the constitution should not have people

02:10:18.240 --> 02:10:23.360
of different skin color sitting in different parts of the bus. And so it was, it was kind of a,

02:10:23.440 --> 02:10:26.880
it was really patriotic, you know, the civil rights movement who was saying, this is a beautiful,

02:10:26.880 --> 02:10:31.280
you know, we have a, we have a liberalism is this beautiful thing and we need to do better at it.

02:10:31.280 --> 02:10:36.560
So I call it liberal social justice. And it used the tools of liberalism to try to,

02:10:38.720 --> 02:10:44.800
to try to improve the flaws and that were going on. So free speech, you know, Mario Savio in the

02:10:44.800 --> 02:10:50.080
sixties was the, you know, he's a leftist and what would the leftist doing in the sixties on

02:10:50.080 --> 02:10:55.840
Berkeley campus? You know, they were saying we need more free speech because that's what social

02:10:55.840 --> 02:10:59.120
liberal social justice was fighting for. But you can also go back to the twenties, women's suffrage.

02:10:59.120 --> 02:11:04.080
I mean, so the, you know, the emancipation, the, the, the thing that America obviously has all of

02:11:04.080 --> 02:11:08.240
its, these, these are, these are all ugly things that it had to get out of, but it got out of them,

02:11:08.240 --> 02:11:12.240
you know, one by one and it's still getting out of them. That's what's cool about America

02:11:12.240 --> 02:11:17.040
and liberal social justice basically is the practice of saying, where are we not being

02:11:17.040 --> 02:11:23.840
perfect liberals? And now let's fix that. So that's the idea of liberalism that permeates

02:11:23.840 --> 02:11:29.200
the history in the United States, but then there's interplay. You have so many good images in this

02:11:29.200 --> 02:11:35.440
book, but one of them is highlighting the interplay of different ideas over the past, let's say a

02:11:35.440 --> 02:11:42.480
hundred years. So liberalism is on one side. There's that thread. There's Marxism on the other. And

02:11:42.480 --> 02:11:49.920
there's postmodernism. How do those interplay together? So it's interesting because Marxism

02:11:50.960 --> 02:11:55.280
is and all of its various descendants, obviously there's a lot of things that are rooted in

02:11:55.280 --> 02:12:00.720
Marxism that aren't, you know, the same thing as what Karl Marx preached, but what do they all

02:12:00.720 --> 02:12:12.240
have in common? They think liberalism is bad, right? They actually think that, that the opposite

02:12:12.240 --> 02:12:17.200
of what Martin Luther King and other people in the civil rights and other movements,

02:12:17.200 --> 02:12:20.720
they think the opposite. They think, he thinks, you know, liberalism is good. We need to preserve

02:12:20.720 --> 02:12:26.560
it. They said liberalism is the problem. These other problems with racism and inequality that

02:12:26.560 --> 02:12:32.160
we're seeing, those are inevitable results of liberalism. Liberalism is a rigged game

02:12:32.160 --> 02:12:36.560
and it's just the power games in disguise. There is no liberal games. It's just the power games

02:12:36.560 --> 02:12:41.120
in disguise. And there's the upper people that oppressed the lower people and they convinced

02:12:41.120 --> 02:12:44.960
the lower people, it's all about false consciousness. They convinced the lower people

02:12:44.960 --> 02:12:49.120
that everything is fair and now the lower people vote against their own interests and they work

02:12:49.120 --> 02:12:53.200
to preserve the system that's oppressing them. And what do we need to do? We need to actually,

02:12:53.200 --> 02:12:59.120
there's much more revolutionary, we need to overthrow liberalism, right? So people think is,

02:12:59.120 --> 02:13:04.400
oh, you know, like what we call a wokeness is just, you know, a normal social justice activist

02:13:04.400 --> 02:13:08.720
activism, but it's like more extreme, right? It's this, no, no, it's the polar opposite,

02:13:08.720 --> 02:13:15.040
polar opposite. And so now that's the Marxist threat. Now, postmodernism is kind of, you know,

02:13:15.040 --> 02:13:18.960
this term that is super controversial and I don't think anyone calls themselves a postmodernist,

02:13:18.960 --> 02:13:23.360
so take all of this with a grain of salt in terms of the term, but what's the definition of radical?

02:13:23.360 --> 02:13:31.920
The definition of radical to me is how deep you want change to happen at. So a liberal progressive

02:13:32.720 --> 02:13:37.520
and a conservative progressive will disagree about policies. The liberal progressive wants to,

02:13:37.520 --> 02:13:41.440
you know, change a lot of policies and change, change, change, right?

02:13:41.440 --> 02:13:45.440
And the conservative is more wants to keep things the way they are. But they're both

02:13:45.440 --> 02:13:51.760
conservative when it comes to liberalism. Beneath it, the liberal kind of foundation of the country,

02:13:51.760 --> 02:13:56.240
they both want to, they both are become conservatives about that. The Marxist is

02:13:56.240 --> 02:14:01.440
more radical because they want to go one notch deeper and actually overthrow that foundation.

02:14:01.440 --> 02:14:07.200
Now, what's below, what's below liberalism is kind of the core tenets of modernity.

02:14:08.160 --> 02:14:12.880
This idea of reason and the notion that there is an objective truth and

02:14:15.200 --> 02:14:19.360
science as the scientific method, right? These things are actually beneath and even the Marxist,

02:14:19.360 --> 02:14:23.120
if you look at the Frankfurt School, you know, these, these, these, these post Marxist thinkers

02:14:23.120 --> 02:14:28.880
and, and Marx himself, they were not anti-science. They believed in that bottom bottom foundation.

02:14:28.880 --> 02:14:32.000
They were, they were, they were, they were actually wanted to preserve modernity, but they

02:14:32.000 --> 02:14:36.080
wanted to get rid of liberalism on top of it. The post modernist is even more radical because

02:14:36.080 --> 02:14:40.320
they want to actually go down to the bottom level and overthrow. They think science itself

02:14:40.320 --> 02:14:45.680
is a tool of oppression. They think it's a tool where oppression kind of flows through,

02:14:45.680 --> 02:14:50.640
you know, they think that the white Western world has invented these concepts like, you know,

02:14:50.640 --> 02:14:54.160
they claim that there's an objective truth and that there's, you know, reason and science.

02:14:54.160 --> 02:14:57.600
And they think all of that is just one meta-narrative and right. And it, and it,

02:14:57.600 --> 02:15:00.720
and it goes a long way to serve the interests of the powerful.

02:15:00.720 --> 02:15:05.680
So in the sense that it's almost caricatured, but that is to the core,

02:15:05.680 --> 02:15:10.560
their belief that math could be racist, for example, not the, not the education of math,

02:15:10.560 --> 02:15:17.040
but literally math, the notion in math, that there's a right answer and a wrong answer

02:15:17.040 --> 02:15:21.680
that they believe is a meta-narrative that serves white supremacy or in, in, in the,

02:15:21.680 --> 02:15:26.880
the post modernist might've said it serves just the powerful or the wealthy. But to,

02:15:26.880 --> 02:15:32.240
so what social justice fundamentalism is, is you take the Marxist thread that has been going on

02:15:32.960 --> 02:15:38.400
in lots of countries and has, and the, whoever the upper and lower is, that's what they all have in

02:15:38.400 --> 02:15:43.280
common, but the upper and lower, you know, and for, for Marx was the ruling class and the oppressed

02:15:43.280 --> 02:15:50.560
class, it was economic. And then, but you come here and, and, and the economic class doesn't,

02:15:50.560 --> 02:15:53.760
you know, doesn't resonate as much here as it did maybe in some of those other places,

02:15:53.760 --> 02:15:59.600
but what does resonate here in the sixties and seventies is race and gender and these kind of

02:15:59.600 --> 02:16:04.880
social justice disagreements. And so what social justice fundamentalism is, is this basically this,

02:16:04.880 --> 02:16:13.760
this tried and true framework of Marx, you know, this Marxist framework kind of with a new skin on

02:16:13.760 --> 02:16:18.720
it, which is American social justice, and then made even more radical with the infusion of

02:16:18.720 --> 02:16:23.200
postmodernism where, you know, not just as liberalism bad, but actually the sign, you know,

02:16:23.200 --> 02:16:28.560
that, like you said, math can be racist. So it's this kind of like philosophical Frankenstein,

02:16:28.560 --> 02:16:33.840
this like stitched together of these, it, and has, and so again, it's called, you know, they,

02:16:33.840 --> 02:16:37.680
they wear the same uniform as the liberal social justice. They say social justice, right? You know,

02:16:37.680 --> 02:16:43.360
racial equality, but it has nothing to do with liberal social justice. It is directly opposed

02:16:43.360 --> 02:16:48.960
to liberal social justice. This is fascinating. The evolution of ideas. If we ignore the harm

02:16:48.960 --> 02:16:54.800
done by it, it's fascinating how humans get together and evolve these ideas. So as you show

02:16:54.800 --> 02:17:00.000
Marxism is the idea that society is a zero sum. I mean, I guess the zero sum is a really important

02:17:00.000 --> 02:17:04.960
thing here. Uh, zero sum struggle between the ruling class and the working class with power

02:17:04.960 --> 02:17:12.240
being exerted through politics and economics. Then you add critical theory, Marxism 2.0 on top of

02:17:12.240 --> 02:17:17.600
that. And you add to politics and economics, you add culture and institutions. And then on top of

02:17:17.600 --> 02:17:22.400
that for postmodernism, you add science, you have morality, basically anything else you can think

02:17:22.400 --> 02:17:26.240
of. It's a stitched together Frankenstein. And if you notice, and which is not necessarily bad,

02:17:26.240 --> 02:17:30.800
but in this case, I think it's actually violating the Marxist tradition by being anti-science and,

02:17:30.800 --> 02:17:35.120
and, and, and, you know, and it's violating the postmodernism because what postmodernists were,

02:17:35.120 --> 02:17:39.840
they were radical skeptics, not just, they were radical skeptics, not just of the way things were,

02:17:39.840 --> 02:17:44.800
but of their own beliefs. They, they, and what, and social justice fundamentalism is suddenly is

02:17:44.800 --> 02:17:50.720
not at all, uh, self, self-critical. It says that we have the answers, which is the opposite of what

02:17:50.720 --> 02:17:54.400
postmodernists would ever say this. No, you just have another meta narrative. So, and it's also

02:17:54.400 --> 02:17:57.760
violating, of course, the tradition of like liberal social justice in a million ways because it's,

02:17:57.760 --> 02:18:01.120
it's anti-liberal. Um, and so this Frankenstein comes together. Meanwhile,

02:18:02.080 --> 02:18:07.840
liberal social justice doesn't have a Frankenstein. It's very clear. It's very, it's a crisp ideology

02:18:07.840 --> 02:18:12.240
that says we need, we, they're trying to make, we trying to get to a more perfect union. They're

02:18:12.240 --> 02:18:18.640
trying to, to, to, to keep the promises made in the constitution. And that's what it's trying to

02:18:18.640 --> 02:18:23.520
do. And so it's, it's much simpler in a lot of ways. So you, you write that my big problem with

02:18:23.520 --> 02:18:28.800
social justice fundamentalism isn't the ideology itself. It's what its scholars and activists

02:18:28.800 --> 02:18:34.960
started to do sometimes around 2013 when they began to wield a cudgel that's not supposed to

02:18:34.960 --> 02:18:39.840
have any place in the country like the US. So it's the actions, not the ideas.

02:18:39.840 --> 02:18:47.520
Well, I don't like the ideology. I think it's a low rung ideology. I think it's morally inconsistent

02:18:47.520 --> 02:18:53.280
based on, you know, it's, it's flip flops on, on its morals, depending on the group. I think it's

02:18:53.280 --> 02:18:59.680
echo chambery. I think it's, um, I think it's, it's, it's full of inaccuracies and kind of

02:18:59.680 --> 02:19:03.840
can't stand up to debate. So I think it's a low, but, but there's a ton of low rung ideologies.

02:19:03.840 --> 02:19:07.120
I don't like, I don't like a lot of religious doctrines. I don't like a lot of political

02:19:07.120 --> 02:19:13.840
doctrines, right? The US is a place inherently that is a mishmash of a ton of ideologies. And

02:19:13.840 --> 02:19:17.680
I'm not going to like two thirds of them at any given time. So my problem, the reason I'm writing

02:19:17.680 --> 02:19:21.440
about this is not cause I'm like, by the way, this ideology is not something I like. That's not

02:19:21.440 --> 02:19:27.600
interesting. The reason that it must be written about right now, this particular ideology is

02:19:27.600 --> 02:19:33.920
because it's not playing nicely with others. What, what, what, if you want to be a hardcore,

02:19:33.920 --> 02:19:40.000
you know, evangelical Christian go in the US says live and let live. Not only are you allowed to

02:19:40.000 --> 02:19:44.160
have an echo chamber of some kind, you're, it's actively protected here, live and let live.

02:19:44.160 --> 02:19:48.400
They can do what they want. You do what you want. Now, if the evangelical Christian started saying,

02:19:48.400 --> 02:19:53.600
by the way, anyone who says anything that conflicts with even evangelical Christianity

02:19:53.600 --> 02:19:58.480
is going to be severely socially punished. And they have the cultural power to do so,

02:19:58.480 --> 02:20:02.240
which they don't in this case, they might like to, but they don't have the power,

02:20:02.240 --> 02:20:06.000
but they're able to get anyone fired who they want. And they're able to actually

02:20:06.000 --> 02:20:10.560
change the curriculum in all of these schools and to, to, to suddenly not conflict with no more

02:20:10.560 --> 02:20:15.360
evolution in the, in the textbooks because they don't want it. Now I would write a book about why

02:20:15.360 --> 02:20:21.040
about evangelical Christianity, because that's what every liberal, regardless of what you think

02:20:21.040 --> 02:20:26.080
of the actual horizontal beliefs, it doesn't matter what they believe when, when they start

02:20:26.080 --> 02:20:32.640
violating live and let live and shutting down other area, other segments of society.

02:20:32.640 --> 02:20:36.720
And in kind of, it's almost like a, you know, not to, you know, it's not the best analogy,

02:20:36.720 --> 02:20:41.280
but like, it's like a, an echo chamber is like a benign tumor. And what you, what you have to

02:20:41.280 --> 02:20:46.400
watch out for is a tumor that starts to metastasize, starts to forcefully spread and damage the tissue

02:20:46.400 --> 02:20:51.600
around it. And that's what this particular ideology has been doing.

02:20:51.600 --> 02:21:00.960
Do you worry about it, you know, as an existential threat to liberalism in the West,

02:21:00.960 --> 02:21:10.160
in the United States, is it a problem or is it the biggest problem that's threatening all of human

02:21:10.160 --> 02:21:16.160
civilization? I would never, I would not say it's the biggest problem. It might be, I wouldn't,

02:21:16.160 --> 02:21:19.840
if someone, if it turns out in 50 years, someone says, actually it was, I wouldn't be shocked,

02:21:20.560 --> 02:21:23.840
but I also, I would, I wouldn't bet on that because there's a lot of problems.

02:21:24.400 --> 02:21:29.360
I'm a little sorry to interrupt. It is popular to say that kind of thing though.

02:21:30.000 --> 02:21:36.320
And it's less popular to say the same thing about AI or nuclear weapons, which worries me

02:21:36.320 --> 02:21:41.920
that I'm more worried about nuclear weapons even still than I am about wokeism.

02:21:41.920 --> 02:21:46.560
So I've gotten, I've had probably a thousand arguments about this. That's one nice thing about

02:21:46.560 --> 02:21:51.120
spending six years procrastinating on getting a book done is you end up test battle testing

02:21:51.120 --> 02:21:55.600
your ideas a million times. So I've heard this one a lot, right? Which is there's kind of three

02:21:55.600 --> 02:22:02.560
groups of former Obama voters. One is super woke now. Another one is super anti-woke now.

02:22:02.560 --> 02:22:07.120
And the third is what you just said, which is sure, wokeness is over the top, right?

02:22:07.760 --> 02:22:11.520
They're not, you're not woke, but I think that the anti-woke people are

02:22:12.080 --> 02:22:14.880
totally lost their mind and it's just not that big a deal, right?

02:22:15.760 --> 02:22:23.200
Now here's why I disagree with that because it's not, it's not wokeness itself. It's that

02:22:24.400 --> 02:22:29.760
a radical political movement of which there will always be a lot in the country

02:22:30.720 --> 02:22:35.040
has managed to do something that a radical movement is not supposed to be able to do in the US,

02:22:35.680 --> 02:22:44.160
which is they've managed to hijack institutions all across the country and hijack

02:22:46.000 --> 02:22:51.440
medical journals and universities and, you know, the ACLU, you know, saying all the,

02:22:51.440 --> 02:22:58.640
you know, activist organizations and nonprofits and certain NGOs. Yeah. And many, and many tech

02:22:58.640 --> 02:23:04.080
companies. And what, so it's not that I think this thing is so bad. It's a little, like we said with

02:23:04.080 --> 02:23:08.400
Trump, it's that what I'm, what the reason Trump scares me is not because Trump's so bad. It's

02:23:08.400 --> 02:23:14.720
that because it shows, it's, it reveals that we were vulnerable to a demagogue candidate.

02:23:14.720 --> 02:23:18.400
And what wokeness reveals to me is that we are currently, and until something changes,

02:23:18.400 --> 02:23:28.720
will continue to be vulnerable to a, a bully, a bully movement and a forcefully expansionist

02:23:28.720 --> 02:23:37.520
movement that wants to actually destroy the workings in their liberal gears and tear them

02:23:37.520 --> 02:23:43.120
apart. And so here's the way I view a liberal democracy is it is a bunch of these institutions

02:23:43.120 --> 02:23:49.760
that were trial and error crafted over, you know, hundreds of years. And they all rely on trust,

02:23:49.760 --> 02:23:55.280
public trust, and a certain kind of feeling of unity that actually is critical to a liberal

02:23:55.360 --> 02:24:02.800
democracy's functioning. And what I see this thing is, is as a parasite on that, that whose goal is,

02:24:02.800 --> 02:24:06.320
and I'm not saying each, by the way, each individual in this is, I don't think they're bad

02:24:06.320 --> 02:24:13.280
people. I think that it's, it's the ideology itself has the property of its goal is to tear apart the

02:24:13.280 --> 02:24:17.520
pretty delicate workings of the liberal democracy and shred the critical lines of trust.

02:24:18.400 --> 02:24:23.120
And so you talk about AI and you talk about all these other big problems, nuclear, right?

02:24:23.120 --> 02:24:26.880
The reason I stop, I like writing about that stuff a lot more than I like writing about politics.

02:24:26.880 --> 02:24:32.240
This wasn't a fun topic for me is because I realized that like all of those things,

02:24:32.240 --> 02:24:35.520
if they were going to have a good future with those things and they're actually threats,

02:24:35.520 --> 02:24:38.400
like I said, we need to have our wits about us and we need the, the liberal,

02:24:39.040 --> 02:24:43.840
you know, gears and, and, and levers working. We need the liberal machine working. And so

02:24:43.840 --> 02:24:46.880
if something's threatening to undermine that, it affects everything else.

02:24:47.840 --> 02:24:53.920
We need to have our scientific mind about us, about these fun foundational ideas. But I guess

02:24:53.920 --> 02:25:01.760
my sense of hope comes from observing the immune system respond to wokeism. There seems to be a

02:25:01.760 --> 02:25:08.160
pro liberalism immune system. And not only that, so like there's intellectuals, there's people that

02:25:08.160 --> 02:25:15.760
are willing to do the fight. You talk about courage, being courageous, and there is a hunger for that,

02:25:16.320 --> 02:25:22.000
such that those ideas can become viral and they take over. So I just don't see a mechanism by

02:25:22.000 --> 02:25:30.080
which wokeism accelerates, like exponentially and takes over, like it's expand. It feels like as it

02:25:30.080 --> 02:25:38.000
expands, the immune system responds. The immune system of the, of liberalism, of basically a

02:25:38.000 --> 02:25:43.680
country, at least in the United States, that still ultimately at the core of the individual values,

02:25:43.680 --> 02:25:47.360
the freedom of speech, just freedoms in general, the freedom of an individual,

02:25:47.920 --> 02:25:55.440
but that's the battle. So to me, it is like a virus and an immune system. Yeah. And I totally

02:25:55.440 --> 02:25:59.280
agree. I see the same story happening and I, you know, I'm sitting here rooting for the immune

02:25:59.280 --> 02:26:05.360
system. Are you still worried? Well, here's the thing. So a liberal democracy is always going to

02:26:05.360 --> 02:26:12.400
be vulnerable to a movement like this, right? And there will be more because it's not a totalitarian

02:26:12.400 --> 02:26:16.880
dictatorship because if you can socially pressure people to not say what they're thinking,

02:26:16.880 --> 02:26:21.680
you can suddenly start to just take over, right? You can break the liberalism of the liberal

02:26:21.680 --> 02:26:25.920
democracy quite easily. And suddenly a lot of things are illiberal. On the other hand,

02:26:27.600 --> 02:26:32.800
the same vulnerability, the same system that's vulnerable to that also is hard to truly conquer

02:26:33.840 --> 02:26:38.880
because now the Maoists, right? Similar kind of vibe. They were saying that science is evil

02:26:39.440 --> 02:26:43.920
and that the intellectuals are, you know, it's all this big conspiracy,

02:26:45.600 --> 02:26:51.920
but they could murder you. And they had the hard cudgel in their hand,

02:26:52.720 --> 02:27:00.800
right? And the hard cudgel is scary and you can conquer a country with the hard cudgel,

02:27:00.800 --> 02:27:05.600
but you can't use that in the U.S. So what they have is a soft cudgel, which can have the same

02:27:05.600 --> 02:27:11.040
effect initially. You can scare people into shutting up. You can't maybe imprison them

02:27:11.040 --> 02:27:14.960
and murder them, but if you can socially ostracize them and get them fired, that basically is going

02:27:14.960 --> 02:27:19.680
to have the same effect. So the soft cudgel can have the same effect for a while, but the thing is

02:27:20.720 --> 02:27:28.240
it's a little bit of a house of cards because it relies on fear. And as soon as that fear goes away,

02:27:29.120 --> 02:27:35.360
the whole thing falls apart, right? The soft cudgel requires people to be so scared

02:27:35.360 --> 02:27:39.760
of getting canceled or getting whatever. And as soon as some people start, you know, Toby Lutka of

02:27:39.760 --> 02:27:43.280
Shopify, I always like think about, you know, he just said, you know what, I'm not scared of

02:27:43.280 --> 02:27:47.680
this soft cudgel and spoke up and said, we're not political at this company and we're not a family.

02:27:47.680 --> 02:27:51.600
We're a team and we're going to do this. And you know what, like they're thriving. He will be on

02:27:51.600 --> 02:27:57.600
this podcast. He seems like a fascinating human. He's amazing. He spoke up. He's one of the smartest

02:27:57.600 --> 02:28:03.360
and like kindest dudes, but he's also, he has courage at a time when it's hard. But here's the

02:28:03.360 --> 02:28:07.920
thing is that it's different than that. You need so much less courage against a soft cudgel than

02:28:07.920 --> 02:28:14.560
you do the Iranians throwing their hijabs into the fire. Those people's courage just, just blows

02:28:14.560 --> 02:28:20.080
away any courage we have here. Cause they might get executed. That's the thing is that you can

02:28:20.080 --> 02:28:31.440
actually have courage right now. And it's so don't worry about it. Oh man. The irony of that. And

02:28:31.440 --> 02:28:35.360
you talk about the two things to fight this. There's two things, awareness and courage.

02:28:36.400 --> 02:28:45.040
What's the awareness piece? The awareness piece is, is, is under first, just no understanding the

02:28:45.040 --> 02:28:50.400
stakes. Like getting our heads out of the sand and being like technology is blowing up exponentially

02:28:50.400 --> 02:28:55.280
where our society's trust is devolving. Like we're kind of falling apart in some important

02:28:55.280 --> 02:29:00.560
ways. We're losing our grip on some stability at the worst time. That's the first point,

02:29:00.560 --> 02:29:04.720
just the big picture. And then also awareness of, I think this vertical axis or whatever your

02:29:04.720 --> 02:29:10.800
version of it is, this concept of how do I really form my beliefs? Where do they actually come from?

02:29:10.800 --> 02:29:14.640
Where do, you know, did they, are they someone else's beliefs? Am I following a checklist?

02:29:17.040 --> 02:29:22.080
How about my values? You know, I used to identify with the blue party or the red party,

02:29:22.080 --> 02:29:25.760
but now they've changed. And I suddenly am okay with that. Is that because my values

02:29:25.760 --> 02:29:30.400
changed with it or am I actually anchored to the party, not to any principle?

02:29:30.400 --> 02:29:36.400
Asking yourself these questions. Asking your, you know, looking for where do I feel disgusted

02:29:36.400 --> 02:29:40.400
by fellow human beings? You know, that maybe I'm, I'm being a crazy tribal person without

02:29:40.400 --> 02:29:44.160
realizing it. How about the people around me? Am I being bullied by some echo chamber

02:29:44.160 --> 02:29:49.280
without realizing it? Am I the bully somewhere? Right. So that's the first, just, just, just,

02:29:49.280 --> 02:29:55.680
I think just to kind of do a self audit. And, and, and, um, and I think that like,

02:29:56.480 --> 02:30:00.560
just, just some awareness like that, it's just a self audit about these things can, can go a long

02:30:00.560 --> 02:30:06.640
way. But if you don't, if you, if you keep it to yourself, it's almost useless because if it doesn't,

02:30:06.640 --> 02:30:11.920
if you don't have, without, you know, awareness without courage does very little. So courage is

02:30:11.920 --> 02:30:16.000
when you take that awareness and you actually export it out into the world and it starts

02:30:16.000 --> 02:30:20.640
affecting other people. And so courage can happen on multiple levels. It can happen by,

02:30:20.640 --> 02:30:24.640
first of all, just stop saying stuff you don't believe. If you're being pressured by a kind of

02:30:24.640 --> 02:30:30.320
a ideology or a movement to say stuff that you don't actually believe, just stop, just, just,

02:30:30.320 --> 02:30:33.920
just stay in your ground and don't say anything. That's, that's courage. That's one first step.

02:30:34.880 --> 02:30:40.400
Start speaking out in small groups. Start, you know, actually speaking your mind, see what happens.

02:30:40.400 --> 02:30:44.240
The sky doesn't usually fall. Actually, people usually respect you for it. Like, you know, and

02:30:44.560 --> 02:30:49.360
not every group, but like you'd be surprised. And then eventually, you know, maybe start speaking

02:30:49.360 --> 02:30:53.200
out in bigger groups, start going public, you know, go public with it. But you don't need

02:30:53.200 --> 02:30:57.200
everyone doing this. Look, some people will lose their jobs for it. I'm not talking to those people.

02:30:57.200 --> 02:31:02.160
Most people won't lose their jobs, but they have the same fear as if they would. Right. And it's

02:31:02.160 --> 02:31:06.400
like, what are you going to get criticized? Or you can get a bunch of people, you know, angry

02:31:06.400 --> 02:31:11.200
Twitter people will, will criticize you. Like it, yeah, it's not pleasant, but actually that's

02:31:11.200 --> 02:31:16.480
a little bit like our primitive minds fear that really back when it was programmed,

02:31:17.040 --> 02:31:20.880
that kind of ostracism or criticism will get, leave you out of the tribe and you'll die.

02:31:20.880 --> 02:31:24.480
Today, it's kind of a delusional fear. It's not actually that scary.

02:31:24.480 --> 02:31:27.760
And the people who have realized that can exercise incredible leadership right now.

02:31:28.400 --> 02:31:35.360
So you have a really interesting description of censorship, self-censorship also,

02:31:36.080 --> 02:31:42.960
as you've been talking about, who's King Mustache and this gap, I think, I hope you write even more,

02:31:42.960 --> 02:31:46.000
even more than you've written in the book about these ideas because it's so strong.

02:31:46.800 --> 02:31:54.400
This censorship gaps that are created between the dormant thought pile and the kind of

02:31:54.400 --> 02:31:58.480
thing under the speech curve. Yeah. So first of all, so I like to think of,

02:31:59.360 --> 02:32:04.560
I think it's a useful tool is this thing called the thought pile, which is if you have a,

02:32:04.560 --> 02:32:08.800
on any given issue, you have a horizontal spectrum and just say I could take your brain

02:32:08.800 --> 02:32:14.560
out of your head and I put it on the thought pile right where you happen to believe about that issue.

02:32:14.560 --> 02:32:18.400
Now I did that for everyone in the community or in a society and you're going to end up with a big

02:32:18.400 --> 02:32:22.560
mushy pile that I think will often just form a bell curve. If it's really politicized, it might

02:32:22.560 --> 02:32:26.640
form like a camel with two humps because it's like concentrated here, but for a typical issue,

02:32:26.640 --> 02:32:30.080
it'll just form, you know, a fear of AI. You're going to have a bell curve, right? You know,

02:32:30.080 --> 02:32:35.200
things like this. That's the thought pile. Now the second thing is a line that I call

02:32:35.200 --> 02:32:39.760
the speech curve, which is what people are saying. So the speech curve is high when not just a lot

02:32:39.760 --> 02:32:43.360
of people are saying it, but it's being said from the biggest platforms, being said in the,

02:32:43.360 --> 02:32:47.760
you know, on the, you know, in the New York Times and it's being said by the president on,

02:32:47.760 --> 02:32:50.640
you know, in the state of the union, you know, those things are the top of the speech curve.

02:32:51.280 --> 02:32:55.040
Now, and then, you know, and then when the speech curves lower, it means it's being said either

02:32:55.040 --> 02:32:59.120
whispered in small groups or it's just not very many people are talking about it. Now a healthy,

02:33:00.080 --> 02:33:02.960
when a free speech democracy is healthy on a certain topic,

02:33:04.160 --> 02:33:07.840
you've got the speech curve sitting right on top of the thought pile. They mirror each other,

02:33:07.840 --> 02:33:11.280
which is naturally what would happen. More people think something is going to be said

02:33:11.280 --> 02:33:16.800
more often and from higher platforms. What censorship does and that censorship can be

02:33:16.800 --> 02:33:21.600
from the government. So I use the tale of King Mustache and King Mustache, he's a little tiny

02:33:21.600 --> 02:33:26.640
tyrant and he's very sensitive and people are making fun of his mustache and they're saying

02:33:26.640 --> 02:33:30.880
he's not a good king and he does not like that. So what does he do? He enacts a policy and he says,

02:33:31.680 --> 02:33:37.760
anyone who has heard criticizing me or my mustache or my rule will be put to death.

02:33:39.120 --> 02:33:44.960
And immediately at the town, because his father was a very liberal, it was always free speech in

02:33:44.960 --> 02:33:49.360
his kingdom. But now King Mustache has taken over and he's saying this is a new rules now.

02:33:49.360 --> 02:33:51.760
And so a few people yell out and they say, that's not how we do things here.

02:33:52.640 --> 02:33:58.640
And that moment is what I call a moment of truth. Did the king's guards stand with the principles

02:33:58.640 --> 02:34:02.240
of the kingdom and say, yeah, King Mustache, that's not what we do. In which case he would

02:34:02.240 --> 02:34:06.240
kind of have to, he's not that he can do. Or are they going to execute? So in this case,

02:34:06.240 --> 02:34:10.320
it's as if he laid down an electric fence over a part of this thought pile and said, no one's

02:34:10.320 --> 02:34:14.160
allowed to speak over here. The speech curve, maybe people will think these things, but the

02:34:14.160 --> 02:34:19.600
speech curve cannot go over here. But the electric fence wasn't actually electrified until the king's

02:34:19.600 --> 02:34:24.960
guards in a moment of truth get scared and say, okay, and they hang the five people who spoke out.

02:34:24.960 --> 02:34:30.880
So in that moment, that fence just became electric. And now no one criticizes King Mustache

02:34:30.880 --> 02:34:34.800
anymore. So I use this as an allegory. Now, of course he has a hard cudgel because he can

02:34:34.800 --> 02:34:39.840
execute people. But now when we look at the US, what you're seeing right now is a lot of pressure,

02:34:40.560 --> 02:34:44.640
which is very similar. An electric fence is being laid down saying no one can criticize these ideas.

02:34:45.280 --> 02:34:49.360
And if you do, you won't be executed, you'll be canceled. You'll be fired.

02:34:50.080 --> 02:34:55.120
Now, is that fence electrified from there? No, they don't work at the company, they can't fire you.

02:34:55.760 --> 02:35:00.320
But they can start a Twitter mob when someone violates that speech curve, when someone violates

02:35:00.320 --> 02:35:07.520
that speech rule. And then the leadership at the company has the moment of truth. And what the

02:35:07.520 --> 02:35:13.440
leaders should do is stand up for their company's values, which is almost always in favor of the

02:35:13.440 --> 02:35:16.400
employee and say, look, even if they made a mistake, they make people make mistakes, we're

02:35:16.400 --> 02:35:19.120
not going to fire them. Or maybe that person actually said something that's reasonable and

02:35:19.120 --> 02:35:23.200
we should discuss it. But either way, we're not going to fire them. And if they said no,

02:35:23.200 --> 02:35:27.680
what happens is the Twitter mob actually doesn't have, they can't execute you. They go away and

02:35:27.680 --> 02:35:31.600
the fence has proven to have no electricity. The problem with the past few years is what's

02:35:31.600 --> 02:35:36.000
happened again and again, is the leader gets scared and they get scared of the Twitter mob

02:35:36.000 --> 02:35:41.120
when they fire them. Boom, that fence has electricity. And now actually, if you cross that,

02:35:42.160 --> 02:35:48.560
it's not just a threat. You'll be out of a job. It's really bad. You'll have a huge

02:35:48.560 --> 02:35:52.400
penalty. You might not be able to feed your kids. So that's an electric fence that goes up. Now,

02:35:52.400 --> 02:35:56.080
what happens when an electric fence goes up and it's proven to actually be electrified?

02:35:56.080 --> 02:36:01.200
The speech curve morphs into a totally different position. And now these new people say, instead

02:36:01.200 --> 02:36:05.520
of having the kind of marketplace of ideas that turns into a kind of a natural bell curve,

02:36:05.520 --> 02:36:10.080
they say, no, no, no, these ideas are okay to say, not just okay. You'll be socially rewarded

02:36:10.080 --> 02:36:13.280
and these ones don't. That's the rules of their own echo chamber that they're now applying to

02:36:13.280 --> 02:36:17.520
everyone and it's working. And so the speech curve distorts. And so you end up with now,

02:36:17.520 --> 02:36:21.920
instead of one region, which is a region of kind of active communal thinking, what people are

02:36:21.920 --> 02:36:26.560
thinking and saying, you now have three regions. You have a little active communal thinking,

02:36:26.560 --> 02:36:30.720
but mostly you now have this dormant thought pile, which is all these, these opinions that

02:36:30.720 --> 02:36:33.360
suddenly everyone's scared to say out loud. Everyone's thinking, but they're scared to

02:36:33.360 --> 02:36:36.560
say it out loud. Everyone's thinking, but no one's saying. And then you have this other region,

02:36:36.560 --> 02:36:44.000
which is this, the approved ideas of this now cultural kind of dictator. And those are being

02:36:44.000 --> 02:36:47.760
spoken from the largest platforms and they're being repeated by the president and they're being

02:36:47.760 --> 02:36:53.040
repeated all over the place, you know, even though people don't believe it. And that's this

02:36:53.040 --> 02:36:57.920
distortion. And what happens is the society becomes really stupid because active communal

02:36:57.920 --> 02:37:01.600
thinking is the region where we can actually think together and now no one can think together. And

02:37:02.480 --> 02:37:07.200
it gets siloed into small private conversations. It's really powerful what you said about

02:37:07.200 --> 02:37:12.640
institutions and so on. It's not trivial to, from a leadership position to be like, no, we

02:37:12.800 --> 02:37:18.960
defend the employee or defend the, yeah, the employee, the person with us on our, like,

02:37:18.960 --> 02:37:26.240
cause we don't, there's, cause there's no actual ground to the, any kind of violation we're hearing

02:37:26.240 --> 02:37:31.440
about. So the mob, they resist the mob. It's ultimately to the leader, I guess, of a particular

02:37:31.440 --> 02:37:35.920
institution or a particular company. And it's difficult. Oh yeah, no, no, it's not, I don't,

02:37:35.920 --> 02:37:40.720
if it were easy, it wouldn't, there wouldn't be all of these failings. And by the way, this is,

02:37:40.720 --> 02:37:44.960
that's the immune system failing. That's the liberal immune system of that company failing,

02:37:44.960 --> 02:37:49.520
but also then it's an example, which means that a lot of other, you know, it's failing kind of to

02:37:49.520 --> 02:37:53.840
the country. It's not easy. Of course it's not because why, because we have primitive minds that

02:37:53.840 --> 02:37:58.400
are wired to care so much about what people think of us. And even if we're not going to, you know,

02:37:58.400 --> 02:38:01.360
first of all, we're scared that it's going to start a, cause there's, you know, what, you know,

02:38:01.360 --> 02:38:05.840
what, what do mobs do? They don't just say, I'm going to criticize you. I'm going to criticize

02:38:05.840 --> 02:38:10.480
anyone who still buys your product. I'm going to criticize anyone who goes on your podcast.

02:38:10.480 --> 02:38:16.000
So it's not just you. It's now suddenly, if, if, if, if, if Lex becomes tarnished enough.

02:38:16.000 --> 02:38:19.280
Now I go on the podcast and people are saying, oh, I'm not buying his book. He went on Lex Friedman.

02:38:19.280 --> 02:38:23.360
No, no thanks. Right. And now I get by there. It's a call. I call it a smear web. Like you've

02:38:23.360 --> 02:38:27.120
been smeared and it's so we're in such a, you know, bad time that it's smear travels to me.

02:38:27.120 --> 02:38:30.000
And now, meanwhile, someone who buys my book and tries to share it. Someone said, you're buying

02:38:30.000 --> 02:38:33.760
that guy's book. He, you know, he goes on Lex Freeman. You see how this happens. Right. So that

02:38:33.760 --> 02:38:39.200
hasn't happened in this case, but that, so we are so wired and a, that is kind of bad, right? Like

02:38:39.200 --> 02:38:44.240
that is actually like bad for you, but, but we're wired to care about it so much because it meant

02:38:44.240 --> 02:38:51.280
life or death back in the day. Yeah. Yeah. And luckily in this case, we're both probably can

02:38:51.280 --> 02:38:55.520
smear each other in this conversation. This is wonderful. I smear you all the time. Given,

02:38:55.520 --> 02:39:03.680
given the nature of your book. What do you think about freedom of speech as a term and as an idea

02:39:03.680 --> 02:39:08.800
as a way to resist the mechanism, this mechanism of a dormant thought pile and artificially

02:39:08.800 --> 02:39:14.080
generated speech, this ideal of the freedom of speech and protecting speech and celebrating

02:39:14.080 --> 02:39:19.440
speech. Yeah. Well, so this is, this is kind of the point I was talking about earlier about

02:39:21.120 --> 02:39:28.160
King Mustache made a rule against for he's created official. Can I just, I just love the,

02:39:28.160 --> 02:39:31.680
one of the amazing things about your book as you get later and later in the book,

02:39:31.680 --> 02:39:35.840
you cover more and more difficult issues as a way to illustrate the importance of the vertical

02:39:35.840 --> 02:39:44.880
perspective. But there's something about using hilarious drawings throughout that make it much

02:39:44.880 --> 02:39:49.680
more fun. And it takes you away from the personal somehow. And you start thinking in the space of

02:39:49.680 --> 02:39:54.640
ideas versus like outside of the tribal type of thinking. So it's, it's a really brilliant,

02:39:54.640 --> 02:39:58.720
I mean, I would advise for any way to do con when they write controversial books,

02:39:58.720 --> 02:40:02.800
to have hilarious drawings. It's true. Like put the silly stick figure in your thing and it,

02:40:02.800 --> 02:40:06.480
it lightens, it does, it lightens the mood. It gets people's guard down a little bit, you know,

02:40:06.480 --> 02:40:11.520
and it works. It reminds people that like, we're all friends here, right? Like we're, you know,

02:40:11.520 --> 02:40:15.360
let's like laugh, you know, laugh at ourselves, laugh at the, laugh at the fact that we're like

02:40:15.360 --> 02:40:19.520
in a culture war a little bit and now we can talk about it, right? As opposed to like getting

02:40:19.520 --> 02:40:24.480
religious about it. But, but basically like King Mustache had no first amendment. He said we,

02:40:25.440 --> 02:40:28.960
the government is censoring, right? Which is very common around the world, right? Government

02:40:28.960 --> 02:40:33.040
censor all them. The U.S., you know, again, there's some, you can argue there's some

02:40:33.040 --> 02:40:37.360
controversial things recently, but basically the U.S., the first amendment isn't the problem,

02:40:38.160 --> 02:40:44.480
right? No one is being arrested for saying the wrong thing, but this graph is still happening.

02:40:44.480 --> 02:40:52.640
And so, so freedom of speech, when people, what people like to say is if someone's complaining

02:40:52.640 --> 02:40:56.400
about a cancel culture and saying, you know, this is, this is, you know, an empty free speech,

02:40:57.120 --> 02:41:00.400
people like to point out, no, it's not. The government's not arresting you for anything.

02:41:00.400 --> 02:41:05.680
This is called like, you know, the free market, buddy. Like this is called, you know, you're,

02:41:05.680 --> 02:41:09.360
you're putting your ideas out and you're getting criticized and your precious marketplace of ideas,

02:41:09.360 --> 02:41:14.000
there it is, right? You know, I've gotten this a lot and this is not making a critical distinction

02:41:14.000 --> 02:41:22.240
between cancel culture and criticism culture. Criticism culture is a little bit of this kind

02:41:22.240 --> 02:41:31.600
of high wrong idea lab stuff we talked about. Criticism culture attacks the idea and encourages

02:41:31.600 --> 02:41:37.040
further discussion, right? It enlivens discussion. It makes everyone smarter.

02:41:38.240 --> 02:41:42.720
Cancel culture attacks the person. Very different. Can't, criticism culture says,

02:41:42.720 --> 02:41:46.800
here's why this idea is so bad. Let me tell you. Cancel culture says, here's why this person is

02:41:46.800 --> 02:41:52.000
bad and no one should talk to them and they should be fired. And what does that do? It doesn't enliven

02:41:52.000 --> 02:41:55.680
the discussion. It makes everyone scared to talk and it's, it's the opposite. It shuts down

02:41:55.680 --> 02:41:59.840
discussion. So you still have your first amendment, but first amendment plus cancel culture equals,

02:41:59.840 --> 02:42:03.920
you might as well being king must, you might as well have government censorship, right?

02:42:04.560 --> 02:42:09.200
First amendment plus criticism culture. Great. Now you have this vibrant marketplace of ideas.

02:42:09.200 --> 02:42:16.400
So there's a very clear difference. And so when, when people criticize the cancel culture and then

02:42:16.400 --> 02:42:20.160
someone says, oh, see, you're so sensitive. Now you look, you're doing the cancel culture yourself.

02:42:20.160 --> 02:42:22.800
You're trying to punish this person for critics. It's like, no, no, no, no, no.

02:42:23.840 --> 02:42:28.560
Every good liberal and I, and I mean that in the lower case, which is that anyone who believes in

02:42:28.560 --> 02:42:32.880
liberal democracies, regardless of what they believe should stand up and say no to cancel

02:42:32.880 --> 02:42:38.240
culture and say, this is not okay, regardless of what the actual topic is. And that makes them a

02:42:38.240 --> 02:42:42.720
good liberal versus if they're trying to cancel someone who's just criticizing, they're doing

02:42:42.720 --> 02:42:46.240
the opposite. Now they're shutting. So it's the opposite thing, but it's very easy to get confused.

02:42:46.240 --> 02:42:50.640
You can see people take advantage of the, and sometimes they just don't know it themselves.

02:42:51.280 --> 02:42:56.240
The lines here can be very confusing. The wording can be very confusing. And without that wording,

02:42:56.240 --> 02:43:01.200
suddenly it looks like someone who's criticizing cancel culture is canceling, but they're not.

02:43:02.080 --> 02:43:10.640
You apply this thinking to universities in particular. There's a great, yet another great

02:43:10.640 --> 02:43:17.040
image on the trade-off between knowledge and conviction. And it's what's commonly,

02:43:17.040 --> 02:43:21.040
actually you can maybe explain to me the difference, but it's often referred to as

02:43:21.040 --> 02:43:25.760
the Dunning-Kruger effect where you, when you first learn of a thing, you have an extremely

02:43:26.880 --> 02:43:31.600
high confidence about self-estimation of how well you understand that thing.

02:43:31.600 --> 02:43:34.000
You actually say that Dunning-Kruger means something else.

02:43:34.000 --> 02:43:37.440
So yeah, it's everyone, when I post this, everyone's like Dunning-Kruger and it's,

02:43:37.920 --> 02:43:41.360
what everyone thinks Dunning-Kruger is. Dunning-Kruger is a little different. It's,

02:43:41.360 --> 02:43:46.480
it's you have a diagonal line like this one, right? Which is the place you are. It's the,

02:43:46.480 --> 02:43:50.560
I call it like the humility tightrope, but the humility sweet spot. It's exactly the right level

02:43:50.560 --> 02:43:54.080
of humility based on what you know. If you're below it, you're insecure. You actually have too

02:43:54.080 --> 02:43:56.960
much humility. You don't have enough confidence because you know more than you're giving yourself

02:43:56.960 --> 02:44:01.920
credit for. And when you're above the line, you're in the arrogant zone, right? You need a dose of

02:44:01.920 --> 02:44:05.280
humility, right? You think you know more than you do. So we all want to stay on that tightrope.

02:44:05.280 --> 02:44:10.320
And Dunning-Kruger is basically a straight line that's just a, has a lower slope. So you start

02:44:10.320 --> 02:44:18.240
off, you still are, you still are getting more confident as you go along, but you start off

02:44:18.240 --> 02:44:23.120
above that line. And as you learn more, you end up below the line later. So, but anyway-

02:44:23.120 --> 02:44:24.560
So this wavy thing-

02:44:24.560 --> 02:44:28.560
This wavy thing is, is, is, is a different phenomenon and it's, it's related, but-

02:44:29.200 --> 02:44:36.240
This idea, so for people just listening, there's a child's hill, pretty damn sure you know a whole

02:44:36.240 --> 02:44:40.720
lot and feeling great about it. That's in the beginning. And then there's an insecure canyon,

02:44:40.720 --> 02:44:45.920
you crash down, acknowledging that you don't know that much. And then there's a growth mountain-

02:44:46.640 --> 02:44:47.760
Grown-up mountain.

02:44:47.760 --> 02:44:54.240
Grown-up mountain, where after you feel ashamed and embarrassed about not knowing that much,

02:44:54.240 --> 02:44:59.360
you begin to realize that knowing how little you know is the first step in becoming someone

02:44:59.360 --> 02:45:04.480
who actually knows stuff. And that's the, the grown-up mountain. And you climb and climb and

02:45:04.480 --> 02:45:11.120
climb. You're saying that in universities, we're pinning people at the top of the child's hill.

02:45:11.120 --> 02:45:16.160
So, so for me, this is a very, you know, I think of myself with this because I went to college,

02:45:16.160 --> 02:45:22.000
like a lot of 18 year olds, and I was very cocky. I just thought I knew a lot, you know,

02:45:22.000 --> 02:45:26.080
and when it came to politics, I was like bright blue, just because I grew up in a

02:45:26.080 --> 02:45:29.120
bright blue suburb. And I wasn't thinking that hard about it. And I thought that,

02:45:29.120 --> 02:45:33.760
you know, and what I did when I went to college is met a lot of smart conservatives and a lot of

02:45:33.760 --> 02:45:38.240
smart progressives. But I've met a lot of people who weren't just going down a checklist, and they

02:45:38.240 --> 02:45:43.360
knew stuff. And when I, and it's suddenly I realized that like, a lot of these views I have

02:45:43.360 --> 02:45:49.280
are not based on knowledge. They're based on other people's conviction. Everyone else thinks

02:45:49.280 --> 02:45:55.520
that's true. So now I think it's, well, I'm actually like, I'm transferring someone else's

02:45:55.520 --> 02:45:58.400
conviction to me. And who knows why they have conviction? They might have conviction because

02:45:58.400 --> 02:46:05.200
they're transferring from someone else. And I'm a smart dude, I thought. Why am I like

02:46:05.840 --> 02:46:12.560
giving away my own independent, you know, learning abilities here and just adopting

02:46:12.560 --> 02:46:15.760
other views? So anyway, it was this humbling experience. And it wasn't just about politics,

02:46:15.760 --> 02:46:20.880
by the way. It was that I had strong views about a lot of stuff. And I just, I got lucky,

02:46:20.880 --> 02:46:25.680
or not lucky, I sought out, you know, the kind of people I sought out were the type that loved to

02:46:25.680 --> 02:46:31.360
disagree. And they were, man, they knew stuff. And so you're quickly in, you know, in again,

02:46:31.360 --> 02:46:35.280
Idealab culture, it was an Idealab. And also, I also went to, I started getting in the habit.

02:46:35.280 --> 02:46:38.880
I started loving listening to people who disagreed with me because it was so exhilarating listening

02:46:38.880 --> 02:46:42.880
to a smart person. When I thought there was no credence to this other argument, right?

02:46:43.840 --> 02:46:48.560
The, this side of this debate is obviously wrong. I wanted to see an intelligence squared on that

02:46:48.560 --> 02:46:52.880
debate. I wanted to go see, I actually got into intelligence squared in college. I wanted to see

02:46:53.520 --> 02:46:57.760
a smart person who disagrees with me talk. It became so fascinating to me, right? It was

02:46:57.760 --> 02:47:01.920
the most interesting thing. That was a new thing. I didn't think I liked that. And so what did that

02:47:01.920 --> 02:47:07.200
do? That, that shoved me down the humble tumble here, number three. It shoved me down where I

02:47:07.200 --> 02:47:10.720
started to, and then I, and then I went the other way, where I realized that I had been, a lot of

02:47:10.720 --> 02:47:16.160
my identity had been based on this faux feeling of knowledge, this idea that I thought I knew

02:47:16.160 --> 02:47:20.720
everything. Now that I don't have that, I was like, I felt really like dumb and I felt really

02:47:20.720 --> 02:47:24.240
almost like embarrassed of what I knew. And so that's where I call this insecure canyon.

02:47:24.240 --> 02:47:27.040
I think it's sometimes when you're so used to thinking, you know, everything, and then you

02:47:27.040 --> 02:47:31.600
realize you don't, it's like, it's, and then you start to realize that actually really awesome

02:47:31.600 --> 02:47:36.320
thinkers, they, they, they, they don't judge me for this. They totally respect if I say, I don't

02:47:36.320 --> 02:47:38.800
know anything about this and say, oh, cool. You should read this and this and this. They don't

02:47:38.800 --> 02:47:43.680
say, you don't know anything. They don't say that. Right. And so, and not that I'm, by the way,

02:47:43.680 --> 02:47:47.680
this is not to say I'm now on grownup mountain and you should all join me. I often find myself

02:47:47.680 --> 02:47:52.640
drifting up with like a helium balloon. Oh, I think I read about the new thing and suddenly I

02:47:52.640 --> 02:47:57.200
think I have, I think I, you know, I read three things about, you know, a new AI thing and I'm

02:47:57.200 --> 02:48:02.000
like, I'll go do a talk on this. I'm like, no, I won't. I don't, I just, I'm going to just be

02:48:02.000 --> 02:48:06.080
spouting out the opinion of the person I just read. So I have to remind myself, but it's useful.

02:48:06.160 --> 02:48:12.880
Now the reason my problem with colleges today is that it's, I was a graduate in 2004. This is a

02:48:12.880 --> 02:48:19.440
recent change is that all of those speakers I went who disagreed with me, a lot of them were

02:48:19.440 --> 02:48:24.640
conservative. So many of those speakers would not be allowed on campuses today. And so many of the

02:48:24.640 --> 02:48:29.600
discussions I had were in big groups or classrooms. And this is still, you know, this was a liberal

02:48:29.600 --> 02:48:36.320
campus. So many of those disagreements, they're not happening today. And I've

02:48:36.320 --> 02:48:40.400
interviewed a ton of college students. It's chilly. It is, you know, people keep to themselves.

02:48:40.960 --> 02:48:46.000
So what's happening is not only are people losing that push off Child's Hill, which was so

02:48:46.000 --> 02:48:50.800
valuable to me, so valuable to me as a thinker, it kind of started my life as a better thinker.

02:48:51.360 --> 02:48:55.440
They're losing that, but actually what college, a lot of the college classes and the vibe in

02:48:55.440 --> 02:49:00.160
colleges, a lot of what I was saying that there is one right set of views and it's this kind of,

02:49:00.160 --> 02:49:06.880
you know, woke ideology. And it's right. And anyone who disagrees with it is bad. And don't

02:49:06.880 --> 02:49:12.240
speak up, you know, unless you're going to agree with it. It's teaching people that Child's Hill's,

02:49:12.240 --> 02:49:16.800
you know, it's nailing people's feet to Child's Hill. It's teaching people that these are right,

02:49:16.800 --> 02:49:21.200
this user right. And like, you don't have any, you're nothing to, you should feel a complete

02:49:21.200 --> 02:49:28.560
conviction about them. Yeah. How do we fix it? Is it part of the administration? Is it part of

02:49:28.560 --> 02:49:34.480
the culture? Is it part of the, is it part like actually instilling in the individual, like 18

02:49:34.480 --> 02:49:40.480
year olds, the idea that this is the beautiful way to live is to embrace the disagreement and

02:49:40.480 --> 02:49:45.280
the growth from that? It's awareness and courage. It's the same thing. So first of all, just get,

02:49:45.520 --> 02:49:52.160
awareness is people need to see what's happening here. That kids are getting losing the, they're

02:49:52.160 --> 02:49:58.160
not going to college and becoming better, tougher, more robust thinkers. They're actually going to

02:49:58.160 --> 02:50:01.760
college and becoming zealots. They're getting taught to be zealots. And the, and the website

02:50:01.760 --> 02:50:06.320
still advertises, you know, wide variety of, you know, the website is a bait and switch.

02:50:06.320 --> 02:50:10.240
You list all the universities at Harvard. It's a bait and switch. It's, it's still saying here,

02:50:10.240 --> 02:50:13.920
you're coming here for a wide intellectual, basically they're advertising, this is an idea

02:50:13.920 --> 02:50:17.200
lab and you get there and it's like, actually it's an echo chamber that you're paying money for.

02:50:17.200 --> 02:50:23.360
So if people realize that they start to get mad, hopefully. And then courage, I mean, starts,

02:50:23.360 --> 02:50:27.520
you know, yes, brave students. There's been some very brave students who have started, you know,

02:50:28.080 --> 02:50:31.360
big think clubs and stuff like that, where it's like, we're going to have, you know,

02:50:32.160 --> 02:50:37.440
present both sides of a debate here. And that, that takes courage, but also courage and leadership.

02:50:38.560 --> 02:50:42.880
Like the, it's, it's like, if you look at these colleges, it's specifically the leaders

02:50:43.920 --> 02:50:50.160
who show strength, who get, who get the best results. Remember the, the cudgel is soft.

02:50:50.160 --> 02:50:55.200
So if a leader of one of these places says, you know, the, the, the college presidents who have

02:50:55.200 --> 02:51:00.640
shown some strength, they actually don't get as much trouble. It's the ones who pander, the ones who

02:51:03.760 --> 02:51:10.000
in that, you know, in that moment of truth, they, they, they shrink away. Then they get a lot more

02:51:10.000 --> 02:51:17.120
trouble. The mob smells blood. For the listener, the podcast favorite Liv Burry just entered and

02:51:17.120 --> 02:51:22.720
your friend just entered the room. Do you mind if she joins us? Please. I think there's a story

02:51:22.720 --> 02:51:28.480
she has about you. So Liv, you mentioned something that there's a funny story about,

02:51:28.480 --> 02:51:32.000
we haven't talked at all about the actual process of writing the book.

02:51:32.640 --> 02:51:39.280
Is, is there, you guys made a bet of some kind? Yeah. Is this a true story? Is this a completely

02:51:39.280 --> 02:51:47.360
false fabric? No, no, it's true. Liv is, she's mean. I didn't, I did not know mean Liv. She's like,

02:51:47.360 --> 02:51:51.280
she's like a bully. She's like scary. I have to have that, have that screenshot. So Liv was

02:51:51.280 --> 02:51:56.240
FaceTiming me and she was like, she was like being intimidating. I took a screenshot and I made it my

02:51:56.240 --> 02:52:00.240
phone background. So every time I opened it, I was like, ah. So to give the background of this,

02:52:00.240 --> 02:52:05.120
it's because if you hadn't noticed, Tim started writing this book, how many years ago? Six?

02:52:05.120 --> 02:52:10.480
2016, mid 2016. Right. As sort of a response to like the Trump stuff.

02:52:10.480 --> 02:52:14.000
And not even, yeah, it was just supposed to be a mini post. I was like, oh, I'm so like,

02:52:14.880 --> 02:52:18.320
I was like, I'm looking at all these like future tech things. And I feel this like uneasiness,

02:52:18.320 --> 02:52:21.920
like, ah, we're going to like mess up all these things. Why? There's like some cloud over our

02:52:21.920 --> 02:52:25.920
society. Let me just write a mini post. And I opened it up to WordPress to write a one day

02:52:25.920 --> 02:52:32.800
little essay. And things went. On politics. It was going to be on like this feeling I had that,

02:52:33.120 --> 02:52:39.920
like this feeling I had that we were, our tech was just growing and growing and we were becoming

02:52:39.920 --> 02:52:43.360
less wise. What's up? What's up with that? And I just wanted to write like just like a little,

02:52:43.360 --> 02:52:46.880
like a little thousand word essay on like something I think we should pay attention to. And that was

02:52:46.880 --> 02:52:52.640
the beginning of this six year nightmare. Did you anticipate the blog post would take a long while?

02:52:54.800 --> 02:52:58.800
I don't remember the process fully in terms of, I remember you saying, oh, I'm actually writing,

02:52:59.120 --> 02:53:03.600
it's turning into a bigger thing. And I was like, because the more we talked about it,

02:53:03.600 --> 02:53:08.400
I was like, oh, this goes deep. Because I didn't really understand the full scope of the situation

02:53:08.400 --> 02:53:13.120
like nowhere near. And you sort of explained it. I was like, okay, yeah, I see that. And then the

02:53:13.120 --> 02:53:16.800
more we dug into it, the sort of the deeper and deeper and deeper it went. But no, I did not

02:53:16.800 --> 02:53:21.120
anticipate it would be six years. Let's put it that way. And when was your TED talk on

02:53:21.120 --> 02:53:27.440
procrastination? So that was, that was March of 2016. And I started this book three months later,

02:53:28.000 --> 02:53:33.440
to the biggest procrastination hole that I've ever fallen into. Oh, wow. The irony isn't lost on me.

02:53:33.440 --> 02:53:39.120
I mean, it's like, it's, I just like, I like how much credit I have as for that TED talk. I'm like,

02:53:39.120 --> 02:53:45.120
I am legit procrastinator. That is not, I'm not just saying it. Like, it wasn't just because I

02:53:45.120 --> 02:53:48.400
mean, you did, you know, you did intend it to start out as a blog post, but then you're like,

02:53:48.400 --> 02:53:52.800
actually, this needs to be multiple. Actually, let's make it into a full series. You know what,

02:53:52.880 --> 02:53:58.080
I'll turn it into a book. And then that's why. And what also would live witnessed a few times,

02:53:58.080 --> 02:54:04.240
and my wife has witnessed like 30 of these, is like these, these 180 epiphanies, where I'll be

02:54:04.240 --> 02:54:09.280
like, I'll like, I'll have a moment when I'm, and I don't know what, you know, sometimes it's that

02:54:09.280 --> 02:54:13.280
there's a really good idea. Sometimes it's like, I'm just dreading having to finish this the way it

02:54:13.280 --> 02:54:16.560
is. And so this epiphanies where it's like, you know what, I need to start over from the beginning

02:54:16.560 --> 02:54:22.160
and just make this like a short, like 20 little blog post list, and then I'll do that. And then

02:54:22.160 --> 02:54:27.200
I'll say, no, no, no, I have like a new epiphany. And it's these, and yeah, it's kind of like the

02:54:27.200 --> 02:54:32.960
crazy person a little bit. But anyway, can I tell the story of the bed? All right. So things came

02:54:32.960 --> 02:54:39.520
to a head when we were in, we were all on vacation in Dominican Republic, Tim and his wife, me and

02:54:39.520 --> 02:54:46.240
Igor. And we were in the ocean. And I remember you'd been in the ocean for like an hour just

02:54:46.240 --> 02:54:50.880
bobbing in there becoming it. And we got talking and we were talking about the book. And

02:54:52.640 --> 02:54:57.840
you know, you were expressing just like this, you know, just the horror of the situation,

02:54:57.840 --> 02:55:02.480
basically, or like, look, I just, I'm so close, but there's still this and then there's this and

02:55:04.400 --> 02:55:10.560
an idea popped into my head, which is that, you know, poker players often, we will set ourselves

02:55:10.560 --> 02:55:15.680
like negative bets, you know, like, essentially, if we don't get a job done, then we have to

02:55:16.240 --> 02:55:19.760
do something we really don't want to do. So instead of having a carrot, like a really,

02:55:19.760 --> 02:55:23.280
really big stick. So I had the idea to ask Tim, okay,

02:55:26.000 --> 02:55:33.040
what is the worst either organization or individual that you if you had to, you know,

02:55:33.040 --> 02:55:37.280
that you would loathe to give a large sum of money to? And he thought about it for a little

02:55:37.280 --> 02:55:43.360
while. And he gave his answer. And I was like, All right, what's your net worth? He said his

02:55:43.360 --> 02:55:48.640
net worth. All right, 10% of your net worth to that thing. If you don't get the draft because,

02:55:48.960 --> 02:55:53.440
sorry, but just before that I asked him, how long like if you had a gun to your head or to

02:55:53.440 --> 02:55:58.320
your wife's head, and you had to get the booked into a state where you could like send off an

02:55:58.320 --> 02:56:04.000
edit to the draft to your editor, how long he's like, Oh, I guess like I could get it like 95%

02:56:04.000 --> 02:56:09.840
good in a month. I was like, Okay, great. And one month's time, if you do not have that edit handed

02:56:09.840 --> 02:56:16.960
in, really scary, 10% of your net worth is going to this thing that you really, really think is

02:56:16.960 --> 02:56:23.840
terrible. But you're forgetting the kicker. The kicker was that because, you know, procrastinators,

02:56:23.840 --> 02:56:30.640
they self defeat. That's what they do. And then Liz says, I'm gonna sweeten the deal. And I am

02:56:30.640 --> 02:56:39.520
going to basically match you. And I'm going to put in I'm going to send this like a huge amount

02:56:39.520 --> 02:56:44.240
of my own money there if you don't do it. So and I can't that's, that would be really bad.

02:56:44.240 --> 02:56:46.560
Not only are you screwing yourself, you're screwing a friend.

02:56:46.560 --> 02:56:52.640
And she and she was like, and as your friend, because I'm your friend, I will send it. I will

02:56:52.640 --> 02:57:02.960
send the money. I mean, like, that, you know, like, tyranny. Yeah. And I got the drafting.

02:57:02.960 --> 02:57:08.560
Yeah, I got the drafting. I know. I was going to test it. Like, actually, it was it was funny,

02:57:08.560 --> 02:57:11.520
because it was it was like supposed to be by the summer solstice or whatever it was, it was like a

02:57:11.520 --> 02:57:18.480
certain date. And I got it in at four and I got no I got it in at 4am, like the next morning,

02:57:18.480 --> 02:57:22.720
but then and and and they were both like, that's doesn't count. I'm like, it does. It's still for

02:57:22.720 --> 02:57:26.720
me. It's the same day still. It's okay. How fucked in the head you have to be. Yeah,

02:57:26.720 --> 02:57:32.720
so like literally technically pass the deadline by four hours. I for an obscene amount of money

02:57:32.720 --> 02:57:38.800
to a thing you loathe. That's how bad his sickness because I knew the hard hard deadline I knew that

02:57:38.800 --> 02:57:42.640
there was no way she was going to actually send that money because it was 4am. So I knew I actually

02:57:42.640 --> 02:57:46.320
had the whole night. So yeah, I should actually punish you and just I should send I should send

02:57:46.320 --> 02:57:55.040
like a nominal amount to that thing. No, thanks. No. But is there some micro like lessons from that

02:57:55.040 --> 02:57:59.200
from how to avoid procrastination writing a book that you've learned? Yes. Well, I've learned a lot

02:57:59.200 --> 02:58:03.200
of things. I mean, like, first, don't take don't write like a dissertation about like proving some

02:58:03.200 --> 02:58:09.600
grand theory of society because that's really procrastinating. Like I would have been an awful

02:58:09.600 --> 02:58:13.200
PhD student for that reason. So and so like, I'm going to do another book and it's going to be like

02:58:13.200 --> 02:58:17.760
a bunch of short chapters that are one offs because that's like, it just doesn't feed into your book

02:58:17.760 --> 02:58:21.680
is like a giant like framework. There is grand theories all through your book. I know and I

02:58:21.680 --> 02:58:25.520
learned not to do that again. I did it once. I don't want to do it again. Oh, with the book.

02:58:25.520 --> 02:58:30.480
Yeah, I learned book is a giant mistake. Yes. Don't do another one. It looks like some people

02:58:30.480 --> 02:58:35.600
should it's just not for me. I just did it. I know and it almost killed me. Okay, so that's

02:58:35.600 --> 02:58:41.040
the first one. But secondly, yeah, like, basically, there's two ways to fix procrastination. One is

02:58:41.040 --> 02:58:44.800
you fix it's like a picture you have a boat that's leaking and it's not working very well. You can

02:58:44.800 --> 02:58:49.440
fix it in two ways. You can get your hammer and nails out and your boards and actually fix the boat.

02:58:50.320 --> 02:58:55.120
Or you can duct tape it for now to get yourself across the river, but it's not actually fixed.

02:58:55.120 --> 02:59:01.600
So ideally, down the road, I have repaired whatever kind of bizarre mental illness that

02:59:01.600 --> 02:59:06.560
I have that makes me procrastinate in a very like I just don't self defeat in this way anymore.

02:59:06.560 --> 02:59:11.760
But in the meantime, I can duct tape the boat by bringing what I call the panic monster into

02:59:11.760 --> 02:59:16.720
the situation via things like this and this scary person and having external pressure

02:59:16.720 --> 02:59:22.960
to have external pressure of some kind is critical for me. It's yes, I don't have the

02:59:22.960 --> 02:59:27.520
muscle to do the work I need to do without external pressure. By the way, Liv, is there

02:59:27.520 --> 02:59:33.600
a possible future where you write a book? And meanwhile, by the way, huge procrastinator.

02:59:33.600 --> 02:59:38.080
That's the funny thing about this. Yeah. Yeah, I mean, how long did your last video take? Oh,

02:59:38.080 --> 02:59:42.960
my God. Is there advice that you give to live how to get the videos done faster? Well, it would be

02:59:42.960 --> 02:59:46.480
the same exact thing. We actually I can give good procrastination advice. Panic monster.

02:59:47.360 --> 02:59:51.680
Yeah, well, we should do it together. It should be like we have this day. But you know, it's,

02:59:52.320 --> 02:59:55.760
it's we should actually just do another bet. I have to have my script done by this time.

02:59:55.760 --> 03:00:01.920
Yes. I got to get the third part out because then you'll actually do it. And and and it's not the

03:00:01.920 --> 03:00:05.840
thing is the time. And it's like if you if you could take three weeks on a video and instead you

03:00:05.840 --> 03:00:11.280
take 10 weeks, it's not like, oh, well, I've also I'm having more fun in those 10 weeks.

03:00:11.280 --> 03:00:15.920
The whole 10 weeks are bad, bad. So you're just you're just having a bad time and you're getting

03:00:15.920 --> 03:00:19.120
less work done and less work out. And it's not like you're enjoying your personal life. It's

03:00:19.120 --> 03:00:23.600
bad for you for your relationships. It's bad for your your own. But you keep doing it anyway.

03:00:24.160 --> 03:00:29.040
Yeah. Well, why do people why do people have troubles keeping a diet? Right? Yeah.

03:00:29.040 --> 03:00:34.880
Primitive mind. Why'd you point at me instead? That's offensive. What's your procrastination

03:00:34.880 --> 03:00:40.880
weakness? Do you have one? Everything, everything, everything, everything, preparing for a

03:00:40.880 --> 03:00:45.680
conversation. I had your book, amazing book. I really enjoyed it. I started reading it.

03:00:46.400 --> 03:00:51.840
I was like, this is awesome. It's so awesome that I'm going to save it when I'm behind the

03:00:51.840 --> 03:00:57.040
computer and can take notes like good notes. Of course, that resulted in like last minute

03:00:57.040 --> 03:01:01.600
everything, everything, everything I'm doing in my life. Not everyone's like that. You know,

03:01:01.600 --> 03:01:04.560
people self-defeat in different ways. Some people don't have this particular problem.

03:01:04.560 --> 03:01:08.320
Adam Grant is that he calls himself a procrastinator where he gets an assignment.

03:01:08.960 --> 03:01:13.440
He will go home and do it until it's done and handed it, which is also not necessarily good.

03:01:14.400 --> 03:01:19.280
You're rushing it either way, but it's better. But some people have the opposite thing where

03:01:22.400 --> 03:01:26.800
the looming deadline makes them so anxious that they go and fix it. The procrastinator,

03:01:26.800 --> 03:01:30.640
I think, has a similar anxiety, but they resolve it in a totally different way.

03:01:30.640 --> 03:01:32.640
Well, they don't solve it. They just live with the anxiety.

03:01:32.640 --> 03:01:37.360
Right. Right. They just live with the anxiety. Now, I think there's an even bigger group of people.

03:01:37.360 --> 03:01:41.040
So there's these people, the Adam Grants, there's people like me, and then there's people who have

03:01:41.040 --> 03:01:45.040
a healthy relationship with deadlines, but they're still part of a bigger group of people that

03:01:45.040 --> 03:01:54.400
actually, they need a deadline there to do something. So they actually, they still are

03:01:54.400 --> 03:01:59.520
motivated by a deadline. And as soon as you have all the things in life that don't have a deadline,

03:01:59.520 --> 03:02:03.440
like working out and like working on that album you wanted to write, they don't do anything either.

03:02:03.440 --> 03:02:06.800
So there's actually like, that's why procrastination is a much bigger problem than people realize,

03:02:06.800 --> 03:02:10.080
because it's not just the funny last second people. It's anyone who

03:02:11.040 --> 03:02:13.280
actually can't get things done that don't have a deadline.

03:02:14.480 --> 03:02:20.160
You dedicate your book, quote, to Tandis, who never planned on being married to someone who

03:02:20.160 --> 03:02:25.440
would spend six years talking about his book on politics, but here we are. What's the secret

03:02:25.440 --> 03:02:29.440
to a successful relationship with a procrastinator? That's maybe for both of you.

03:02:30.560 --> 03:02:34.160
Well, I think the first most important thing.

03:02:34.160 --> 03:02:36.880
You already started with a political answer, I can tell. Okay, go ahead.

03:02:36.880 --> 03:02:40.560
No. The first and most important thing is because people who don't procrastinate,

03:02:41.360 --> 03:02:45.920
if you don't, it's like, you will, people, their instinct is to judge it as like,

03:02:47.360 --> 03:02:50.640
let's say either just think they're just being like a loser or they're taking it,

03:02:50.640 --> 03:02:55.120
they'll take it personally, you know, and instead to see this as like, this is a,

03:02:56.720 --> 03:03:02.960
some form of addiction or some form of ailment. You know, they're not just being a dick, right?

03:03:03.280 --> 03:03:09.040
They have a problem and so some compassion, but then also maybe finding that line where you can,

03:03:09.040 --> 03:03:13.760
you know, maybe apply some tough love, some middle ground. On the other hand, you might say that,

03:03:13.760 --> 03:03:17.840
you know, you don't want the significant other relationship where it's like, they're the one

03:03:17.840 --> 03:03:21.520
nagging you. Maybe that's, you don't want them even being part of that. And I think maybe it's,

03:03:21.520 --> 03:03:25.120
you know, better to have a live, do it instead. Right. Having someone who can like create the

03:03:25.120 --> 03:03:30.240
infrastructure where they aren't the direct stick. You need a bit of carrot and stick, right? Maybe

03:03:30.240 --> 03:03:35.040
they can be the person who keeps reminding them of the carrot and then they set up a friend group

03:03:35.040 --> 03:03:40.080
to be the stick. And then that keeps your relationship. Yeah. In a good place, stick,

03:03:40.080 --> 03:03:44.720
like looming in the background. That's your friend group. Okay. At the beginning of the

03:03:44.720 --> 03:03:50.160
conversation, we talked about how all of human history can be presented as a thousand page book.

03:03:50.960 --> 03:03:55.440
Uh, what are you excited about for the one thousandth?

03:03:56.960 --> 03:04:02.800
How do you say that first page? Uh, so the next 250 years, what do you, what do you,

03:04:02.800 --> 03:04:09.920
what are you most excited about? I'm most excited about, um, have you read the fable of the dragon?

03:04:10.640 --> 03:04:17.120
Okay. Well, it's an allegory for death and it's, you know, Nick Bostrom and he talks about the,

03:04:17.120 --> 03:04:22.960
he compares death to a dragon that eats 60 million people or whatever the number is every year. And

03:04:22.960 --> 03:04:26.880
you just, every year we shepherd those people up and they feed them to the dragon and that there's

03:04:26.880 --> 03:04:31.440
a Stockholm syndrome when we say that's just a lot of man and that's what we have to do. And anyone

03:04:31.440 --> 03:04:36.320
who says maybe we should try to beat the dragon, they get called vain and narcissistic. Um, but

03:04:36.320 --> 03:04:40.960
someone who tries to, someone who goes, does chemo, no one calls them vain or narcissistic. They say

03:04:40.960 --> 03:04:44.080
they're, they're, you know, good, good for you, right? You're a hero. You're, you're, you're

03:04:44.080 --> 03:04:47.760
fighting, fighting the good fight. So I think there's some disconnect here. And I think that

03:04:47.760 --> 03:04:53.360
if we can get out of that Stockholm syndrome and realize that death is just the machine,

03:04:53.360 --> 03:05:00.640
the human physical machine failing and that there's no law of nature that says you can't

03:05:00.640 --> 03:05:06.960
with enough technology, um, uh, repair the machine and keep it going until no one, I don't think

03:05:06.960 --> 03:05:11.520
anyone wants to live forever. People think they do. No one does, but until people are ready.

03:05:11.520 --> 03:05:17.520
And I think when we hit a world where we can, we have enough tech that we can continue to keep the

03:05:17.520 --> 03:05:21.920
human machine alive until the person says, I'm done, I'm ready. I think we will look back and

03:05:21.920 --> 03:05:26.160
we will think that anything before that time, that'll be the real ADBC. You know, we'll look

03:05:26.160 --> 03:05:32.000
back at BC before the big advancement and it'll seem so sad and so heartbreaking, barbaric. And

03:05:32.000 --> 03:05:36.800
people will say, I can't believe that humans like us had to live with that when they lost loved ones

03:05:36.800 --> 03:05:41.760
and they, they died before they were ready. I think that's the ultimate achievement, but we need

03:05:41.760 --> 03:05:49.200
to stop criticizing and smearing people who you talk about it. So you think that's actually doable

03:05:49.200 --> 03:05:56.160
in the next 250 years? Yes. A lot happens in 250 years, especially when technology really

03:05:56.160 --> 03:06:02.240
exponentially. Yeah. And you think humans will be around versus AI complete takes over where

03:06:02.320 --> 03:06:06.640
mortality means something. I mean, look, the optimist in me and maybe the stupid kind of

03:06:06.640 --> 03:06:11.600
2023 person in me says, yeah, of course we'll make it. We'll figure it out. But you know,

03:06:12.400 --> 03:06:18.640
I mean, we are going into, you know, I have a friend who knows as much about the future

03:06:18.640 --> 03:06:23.520
as anyone I know. I mean, he's really, he's a big investor and you know, future tech, and he's

03:06:23.520 --> 03:06:26.560
really on the pulse with things. And he just says the future is going to be weird. That's what he

03:06:26.560 --> 03:06:30.800
says. Future is going to be weird. And it's going to be weird. Don't look at the last few decades of

03:06:30.800 --> 03:06:33.520
your life and apply that for it and say, that's just what life is like. No, no, no, it's going to

03:06:33.520 --> 03:06:38.880
be weird and different. Well, some of my favorite things in this world, they're weird. And speaking

03:06:38.880 --> 03:06:43.520
of which, it's good to have this conversation. It's good to have you as friends. This was an

03:06:43.520 --> 03:06:48.640
incredible one. Thanks for coming back and thanks for talking with me a bunch more times. This was

03:06:48.640 --> 03:06:53.360
awesome. Thank you, Lex. Thank you. Thanks for listening to this conversation with Tim Urban.

03:06:53.360 --> 03:06:58.160
To support this podcast, please check out our sponsors in the description. And now let me

03:06:58.160 --> 03:07:04.080
leave you with some words from Winston Churchill. When there's no enemy within, the enemies outside

03:07:04.640 --> 03:07:09.360
cannot hurt you. Thank you for listening and hope to see you next time.

