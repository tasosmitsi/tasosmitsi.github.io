WEBVTT

00:00.000 --> 00:04.200
The great lie we tell ourselves is that people who are evil are not like us. They're a class apart.

00:04.200 --> 00:08.000
Everybody in history who has sinned is a person who's very different from me.

00:08.000 --> 00:13.300
Robert George, the philosopher over at Princeton, he's fond of doing a sort of thought experiment in his classes

00:13.300 --> 00:17.600
where he asks people to raise their hand if they had lived in Alabama in 1861.

00:17.600 --> 00:19.400
How many of you would be abolitionists?

00:19.400 --> 00:22.500
And everybody raises their hand. He says, of course, that's not true.

00:22.500 --> 00:24.000
Of course, that's not true.

00:24.000 --> 00:29.300
The best protection against evil is recognizing that it lies in every human heart

00:29.300 --> 00:32.800
and the possibility that it takes you over.

00:32.800 --> 00:38.500
Do you ever sit back, you know, in the quiet of your mind and think, am I participating in evil?

00:41.100 --> 00:46.100
The following is a conversation with Ben Shapiro, a conservative political commentator,

00:46.100 --> 00:52.300
host of The Ben Shapiro Show, co-founder of The Daily Wire and author of several books,

00:52.300 --> 00:58.900
including The Authoritarian Moment, The Right Side of History, and Facts Don't Care About Your Feelings.

00:59.700 --> 01:05.100
Whatever your political leanings, I humbly ask that you try to put those aside

01:05.100 --> 01:11.400
and listen with an open mind, trying to give the most charitable interpretation of the words we say.

01:11.400 --> 01:14.700
This is true in general for this podcast,

01:14.700 --> 01:23.000
whether the guest is Ben Shapiro or Alexandria Ocasio-Cortez, Donald Trump or Barack Obama.

01:23.000 --> 01:28.700
I will talk to everyone from every side, from the far left to the far right,

01:28.700 --> 01:35.000
from presidents to prisoners, from artists to scientists, from the powerful to the powerless,

01:35.000 --> 01:44.400
because we are all human, all capable of good and evil, all with fascinating stories and ideas to explore.

01:44.400 --> 01:51.100
I seek only to understand, and in so doing, hopefully add a bit of love to the world.

01:51.100 --> 01:53.000
This is the Lex Freeman Podcast.

01:53.000 --> 01:56.500
To support it, please check out our sponsors in the description.

01:56.500 --> 02:00.400
And now, dear friends, here's Ben Shapiro.

02:01.400 --> 02:02.900
Let's start with a difficult topic.

02:04.100 --> 02:09.300
What do you think about the comments made by Yeh, formerly known as Kanye West, about Jewish people?

02:09.800 --> 02:14.700
They're awful and anti-Semitic, and they seem to get worse over time.

02:14.700 --> 02:18.300
They started off with the bizarre DEATHCON 3 tweet,

02:18.300 --> 02:26.300
and then they went into even more stereotypical garbage about Jews and Jews being sexual manipulators.

02:26.300 --> 02:31.600
I think that was the Pete Davidson, Kim Kardashian stuff, and then Jews running all of the media,

02:31.600 --> 02:34.900
Jews being in charge of the financial sector, Jewish people.

02:34.900 --> 02:39.300
I mean, there's no, I mean, I called it on my show, there's Sherma Nazism, and it is.

02:39.300 --> 02:43.400
I mean, it's like right from Protocols of the Elters of Zion type stuff.

02:43.400 --> 02:46.900
Do you think those words come from pain? Where do they come from?

02:46.900 --> 02:49.100
And you know, it's always hard to try and read somebody's mind.

02:49.100 --> 02:53.800
What he looks like to me, just having experience in my own family with people who are bipolar,

02:53.800 --> 02:55.700
is he seems like a bipolar personality.

02:55.700 --> 03:00.300
He seems like somebody who is in the middle of a manic episode,

03:00.300 --> 03:05.600
and when you're manic, you tend to say a lot of things that you shouldn't say,

03:05.600 --> 03:08.800
and you tend to believe that they're the most brilliant things ever said.

03:08.800 --> 03:15.500
The Washington Post, an entire piece speculating about how bipolarism played into the kind of stuff that Ye was saying,

03:15.500 --> 03:20.100
and it's hard for me to think that it's not playing into it,

03:20.100 --> 03:27.400
especially because even if he is an anti-Semite, and I have no reason to suspect he's not, given all of his comments,

03:27.400 --> 03:30.800
if he had an ounce of common sense, he would stop at a certain point,

03:30.800 --> 03:37.100
and bipolarism tends to drive you well past the point where common sense applies.

03:37.100 --> 03:39.800
So, I mean, I would imagine it's coming from that.

03:39.800 --> 03:48.700
I mean, from his comments, I would also imagine that he's doing the logical mistake that a lot of anti-Semites or racists or bigots do,

03:48.700 --> 03:54.400
which is, somebody hurt me, that person is a Jew, therefore all Jews are bad.

03:54.400 --> 04:01.000
And that jump from a person did something to me I don't like, who's a member of a particular race or class,

04:01.000 --> 04:03.600
and therefore everybody of that race or class is bad.

04:03.600 --> 04:07.600
I mean, that's textbook bigotry, and that's pretty obviously what Ye is engaging in here.

04:07.600 --> 04:09.300
So, jumping from the individual to the group.

04:09.300 --> 04:11.800
That's the way he's been expressing it, right? He keeps talking about his Jewish agents.

04:11.800 --> 04:14.800
And I watched your interview with him, and you kept saying, so just name the agents, right?

04:14.800 --> 04:17.600
Just name the people who are screwing you.

04:17.700 --> 04:22.800
And he wouldn't do it. Instead, he just kept going back to the general, the group, the Jews in general.

04:22.800 --> 04:25.100
I mean, that's textbook bigotry.

04:25.100 --> 04:30.700
And if we're put in any other context, he would probably recognize it as such.

04:30.700 --> 04:35.500
To the degree as words fuel hate in the world, what's the way to reverse that process?

04:35.500 --> 04:37.900
What's the way to alleviate the hate?

04:37.900 --> 04:45.200
I mean, when it comes to alleviating the kind of stuff that he's saying, obviously debunking it,

04:45.200 --> 04:48.600
making clear that what he's saying is garbage.

04:48.600 --> 04:56.600
But the reality is that I think that for most people who are in any way engaged with these issues,

04:56.600 --> 05:00.000
I don't think they're being convinced to be anti-Semitic by Ye.

05:00.000 --> 05:04.600
I mean, I think there's a group of people who may be swayed that anti-Semitism is acceptable

05:04.600 --> 05:10.600
because Ye is saying what he's saying, and he's saying so very loudly, and he's saying it over and over.

05:10.600 --> 05:16.100
But I think that, for example, there are these signs that are popping up in Los Angeles saying Ye is right.

05:16.100 --> 05:20.600
Well, that group's been out there posting anti-Semitic signs on the freeways for years.

05:20.600 --> 05:23.900
And there are groups like that posting anti-Semitic signs where I live in Florida.

05:23.900 --> 05:26.400
They've been doing that for years, well before Ye was saying this sort of stuff.

05:26.400 --> 05:29.800
It's just like the latest opportunity to kind of jump on that particular bandwagon.

05:29.800 --> 05:34.600
But listen, I think that people do have a moral duty to call that stuff out.

05:34.700 --> 05:45.400
So there is a degree to which it normalizes that kind of idea that Jews control the media, Jews control X institution.

05:45.400 --> 05:56.500
Is there a way to talk about a high representation of a group like Jewish people in a certain institution

05:56.500 --> 06:02.200
like the media or Hollywood and so on without it being a hateful conversation?

06:02.200 --> 06:11.400
Of course, a higher than statistically represented in the population percentage of Hollywood agents are probably Jewish.

06:11.400 --> 06:13.800
A higher percentage of lawyers generally are probably Jewish.

06:13.800 --> 06:16.500
A high percentage of accountants are probably Jewish.

06:16.500 --> 06:19.600
Also, a higher percentage of engineers are probably Asian.

06:19.600 --> 06:22.700
Like the statistical truths are statistical truths.

06:22.700 --> 06:29.500
It doesn't necessarily mean anything about the nature of the people who are being talked about.

06:29.500 --> 06:36.900
There are a myriad of reasons why people might be disproportionately in one arena or another ranging from the cultural to sometimes the genetic.

06:36.900 --> 06:44.900
I mean, there are certain areas of the world where people are better long distance runners because of their genetic adaptations in those particular areas of the world.

06:44.900 --> 06:47.000
That's not racist. That's just fact.

06:47.000 --> 06:58.400
What starts to get racist is when you are attributing a bad characteristic to an entire population based on the notion that some members of that population are doing bad things.

06:58.400 --> 07:00.100
Yeah, there's a jump between.

07:00.100 --> 07:11.200
It's also possible that record label owners as a group have a kind of culture that Fs over artists, doesn't treat artists fairly.

07:11.200 --> 07:19.000
And it's also possible that there's a high representation of Jews in the group of people that own record labels.

07:19.000 --> 07:27.800
But it's that small but a very big leap that people take from the group that own record labels to all Jews.

07:27.800 --> 07:36.600
For sure. And I think that one of the other issues also is that anti-Semitism is fascinating because it breaks down into so many different parts.

07:36.600 --> 07:44.300
Meaning that if you look at sort of different types of anti-Semitism, if you're a racist against black people, it's typically because you're racist based on the color of their skin.

07:44.300 --> 07:49.400
If you're racist against the Jews, you're anti-Semitic, then there are actually a few different ways that breaks down.

07:49.400 --> 07:54.400
You have anti-Semitism in terms of ethnicity, which is like Nazi-esque anti-Semitism.

07:54.400 --> 08:01.600
You have Jewish parentage, you have a Jewish grandparent, therefore your blood is corrupt and you are inherently going to have bad properties.

08:01.600 --> 08:09.500
Then there's sort of old school religious anti-Semitism, which is that the Jews are the killers of Christ or the Jews are the sons of pigs and monkeys.

08:09.500 --> 08:13.200
And therefore, Judaism is bad and therefore Jews are bad.

08:13.200 --> 08:20.600
And the way that you get out of that anti-Semitism, historically speaking, is mass conversion, which most anti-Semitism for a couple thousand years actually was not ethnic.

08:20.600 --> 08:23.200
It was much more rooted in this sort of stuff.

08:23.200 --> 08:28.800
If a Jew converted out of the faith, then the anti-Semitism was, quote unquote, alleviated.

08:28.800 --> 08:39.000
And then there's a sort of bizarre anti-Semitism that's political anti-Semitism, and that is members of a group that I don't like are disproportionately Jewish.

08:39.000 --> 08:46.700
Therefore, all Jews are members of this group or are predominantly represented in this group.

08:46.700 --> 08:54.500
So you'll see Nazis saying the communists are Jews, you'll see communists saying the Nazis are Jews, or you'll see communists saying that the capitalists, rather, are Jews.

08:54.500 --> 08:56.900
And so that's the weird thing about anti-Semitism.

08:56.900 --> 08:58.600
It's kind of like the Jews behind every corner.

08:58.600 --> 09:00.200
It's basically a big conspiracy theory.

09:00.200 --> 09:12.600
Unlike a lot of other forms of racism, which are not really conspiracy theory, anti-Semitism tends to be a conspiracy theory about the levers of power being controlled by a shadowy cadre of people who are getting together behind closed doors to control things.

09:12.600 --> 09:24.000
Yeah, the most absurd illustration of anti-Semitism, just like you said, is Stalin versus Hitler over Poland, that every bad guy was a Jew.

09:24.000 --> 09:41.500
It was like, so every enemy, there's a lot of different enemy groups, intellectuals, political and so on, military, and behind any movement that is considered the enemy for the Nazis and any movement that's considered the enemy for the Soviet army are the Jews.

09:41.500 --> 09:48.000
What does the fact that Hitler took power teach you about human nature?

09:48.000 --> 09:52.900
When you look back at the history of the 20th century, what do you learn from that time?

09:52.900 --> 09:55.100
I mean, there are a bunch of lessons to Hitler taking power.

09:55.100 --> 10:03.500
The first thing I think people ought to recognize about Hitler taking power is that the power had been centralized in the government before Hitler took it.

10:03.500 --> 10:08.300
So if you actually look at the history of Nazi Germany, the Weimar Republic had effectively collapsed.

10:08.300 --> 10:16.800
The power had been centralized in the chancellery and really under Hindenburg for a couple of years before that.

10:16.800 --> 10:21.600
And so it was only a matter of time until someone who was bad grabbed the power.

10:21.600 --> 10:34.500
And so the struggle between the Reds and the Browns in pre-Nazi Germany led to this kind of up spiraling of radical sentiment that allowed Hitler in through the front door, not through the back door.

10:34.500 --> 10:35.500
He was elected.

10:35.500 --> 10:37.600
So you think communists could have also taken power?

10:37.600 --> 10:39.300
I mean, there's no question communists could have taken power.

10:39.300 --> 10:41.900
They were a serious force in pre-Nazi Germany.

10:41.900 --> 10:46.800
Do you think there was an underlying current that would have led to an atrocity if the communists had taken power?

10:46.800 --> 10:48.000
It wouldn't have been quite the same atrocity.

10:48.000 --> 10:53.500
But obviously, the communists in Soviet Russia at exactly this time were committing the halatomar.

10:53.500 --> 10:57.500
So there were very few good guys in terms of good parties.

10:57.500 --> 11:05.500
The moderate parties were being dragged by the radicals into alliance with them to prevent the worst case scenario from the other guy.

11:05.600 --> 11:13.700
So if you look at, I'm sort of fascinated by the history of this period because it really does speak to how does a democracy break down?

11:13.700 --> 11:16.200
I mean, in the 20s, Weimar Republic was a very liberal democracy.

11:16.200 --> 11:21.200
How does a liberal democracy break down into complete fascism and then into genocide?

11:21.200 --> 11:30.300
And there's a character who was very prominent in the history of that time named Franz von Papen, who was actually the second to last chancellor of the republic before Hitler.

11:30.300 --> 11:32.800
So he was the chancellor and then he handed over to Schleicher.

11:32.900 --> 11:37.400
And then he ended up Schleicher ended up collapsing and that ended up handing power over to Hitler.

11:37.400 --> 11:41.200
It was Papen who had stumped for Hitler to become chancellor.

11:41.200 --> 11:44.500
Papen was a was a Catholic Democrat.

11:44.500 --> 11:48.800
He didn't like Hitler. He thought that Hitler was a radical and a nut job.

11:48.800 --> 12:00.800
But he also thought that Hitler being a buffoon, as he saw it, was going to essentially be usable by the right forces in order to get the in order to prevent the communists from taking power.

12:00.800 --> 12:08.700
Maybe in order to restore some sort of legitimacy to the regime because he was popular in order for Papen to retain power himself.

12:08.700 --> 12:12.800
And then immediately after Hitler taking power, Hitler basically kills all of Papen's friends.

12:12.800 --> 12:15.500
Papen out of quote unquote loyalty stays on.

12:15.500 --> 12:18.100
He ends up helping the Anschluss in Austria.

12:18.100 --> 12:22.000
Now, all this stuff is really interesting, mainly because what it speaks to is the great lie.

12:22.000 --> 12:24.600
We tell ourselves that people who are evil are not like us.

12:24.600 --> 12:29.800
They're they're a class apart. People who do evil things, people who support evil people, people they're not like us.

12:29.900 --> 12:31.300
And that's an easy call.

12:31.300 --> 12:36.300
Everybody everybody in history who has sinned is a person who's very different from me.

12:36.300 --> 12:43.000
Robert George, the philosopher over at Princeton, he's he's fond of doing a sort of thought experiment in his classes where he asks people to raise their hand.

12:43.000 --> 12:47.500
If they had lived in Alabama in 1861, how many of you would be abolitionists?

12:47.500 --> 12:50.600
And everybody raises their hand. He says, of course, that's not true.

12:50.600 --> 12:52.200
Of course, that's not true.

12:52.300 --> 13:01.100
The best protection against evil is recognizing that it lies in every human heart and the possibility that it takes you over.

13:01.100 --> 13:05.000
And so you have to be very cautious in how you approach these issues.

13:05.000 --> 13:13.600
And the back and forth of politics, the sort of bipolarity of politics that or the polarization in politics might be a better way to put it, you know,

13:13.700 --> 13:27.200
makes it very easy to kind of fall into the Rockham Sockham robots that eventually could theoretically allow you to support somebody who's truly frightening and hideous in order to stop somebody who you think is more frightening and hideous.

13:27.200 --> 13:31.400
You see this kind of language, by the way, now predominating almost all over the Western world, right?

13:31.400 --> 13:33.400
My political enemy is an enemy of democracy.

13:33.400 --> 13:35.100
My political enemy is going to end the Republic.

13:35.100 --> 13:39.100
My political enemy is going to be the person who destroys the country we live in.

13:39.100 --> 13:44.100
And so that person has to be stopped by any means necessary.

13:44.100 --> 13:46.900
And that's that's dangerous stuff.

13:46.900 --> 13:49.300
So the communists had to be stopped in Nazi Germany.

13:49.300 --> 13:51.100
And so they're the devil.

13:51.100 --> 13:58.500
And so any useful buffoon, as long as they're effective against the communists, would do.

13:58.500 --> 14:04.100
Do you ever wonder because the people that are participating in evil may not understand that they're doing evil.

14:04.100 --> 14:10.100
Do you ever sit back, you know, in the quiet of your mind and think, am I participating in evil?

14:10.100 --> 14:25.100
I mean, so my business partner and I, one of our favorite memes is from there's a British comedy show that name escapes me of these two guys who are members of the SS and they're dressed in the SS uniforms and the black uniforms that the skulls on them.

14:25.100 --> 14:31.300
And they're saying to each other, one says to the other guy, you notice like the British, the symbol is something is something nice.

14:31.300 --> 14:33.100
And it's like an it's like an eagle.

14:33.100 --> 14:34.700
But it's a skull and crossbones.

14:34.700 --> 14:39.900
You see that the Americans, you see that their blue uniforms are very nice and pretty as a jet black.

14:39.900 --> 14:41.200
Are we the baddies?

14:41.200 --> 14:43.300
And, you know, that's it.

14:43.300 --> 14:47.400
And the truth is, we look back at the Nazis and we say, well, of course, they were the baddies.

14:47.400 --> 14:48.400
They wore black uniforms.

14:48.400 --> 14:50.400
They had jackboots and they had this and that.

14:50.400 --> 14:52.500
And, of course, they were the bad guys.

14:52.500 --> 14:55.500
But evil rarely presents its face so clearly.

14:55.500 --> 14:59.600
So, yeah, I mean, I think you have to constantly be thinking along those lines.

14:59.600 --> 15:02.400
And hopefully you try to avoid it.

15:02.400 --> 15:04.500
You can only do the best that a human being can do.

15:04.500 --> 15:07.600
But, yeah, I mean, the answer is yes.

15:07.600 --> 15:15.400
I would say that I spend an inordinate amount of time reflecting on whether I'm doing the right thing.

15:15.400 --> 15:16.700
And I may not always do the right thing.

15:16.700 --> 15:19.200
I'm sure a lot of people think that I'm doing the wrong thing on a daily basis.

15:19.200 --> 15:27.000
But it's definitely a question that has to enter your mind as a historically aware and hopefully morally decent person.

15:27.100 --> 15:34.900
Do you think you're mentally strong enough if you realize that you're on the wrong side of history to switch sides?

15:34.900 --> 15:37.500
Very few people in history seem to be strong enough to do that.

15:37.500 --> 15:41.000
I mean, I think that the answer I hope would be yes.

15:41.000 --> 15:44.000
You never know until the time comes and you have to do it.

15:44.000 --> 15:51.400
I will say that having heterodox opinions in a wide variety of areas is something that I have done before.

15:51.400 --> 16:00.400
I'm the only person I've ever heard of in public life who actually has a list on their website of all the dumb, stupid things I've ever said.

16:00.400 --> 16:07.600
So I go through and I either say this is why I still believe this or this is why what I said was terrible and stupid.

16:07.600 --> 16:09.600
And I'm sure that list will get a lot longer.

16:09.600 --> 16:13.000
Yeah, look forward to new additions to that list.

16:13.000 --> 16:15.100
It actually is a super, super long list.

16:15.100 --> 16:16.000
People should check it out.

16:16.000 --> 16:18.900
And it's quite honest and raw.

16:18.900 --> 16:33.600
What do you think about, it's interesting to ask you given how pro-life you are about Ye's comments about comparing the Holocaust to 900,000 abortions in the United States a year.

16:33.600 --> 16:35.800
So I'll take this from two angles.

16:35.800 --> 16:44.000
As a pro-life person, I actually didn't find it offensive because if you believe, as I do, that unborn and pre-born lives deserve protection,

16:44.100 --> 16:53.300
then the slaughter of just under a million of them every year for the last almost 50 years is a historic tragedy on par with a Holocaust.

16:53.300 --> 16:59.200
From the outside perspective, I get why people would say there's a difference in how people view the pre-born as to how people view,

16:59.200 --> 17:01.200
say, a seven-year-old who's being killed in the Holocaust,

17:01.200 --> 17:11.200
like the visceral power and evil of the Nazis shoving full-grown human beings and small children into gas chambers can't be compared to a person who,

17:11.200 --> 17:16.200
even from pro-life perspective, may not fully understand the consequences of their own decisions or from a pro-choice perspective,

17:16.200 --> 17:20.800
fully understands the consequences, but just doesn't think that that person is a person, that that's actually different.

17:20.800 --> 17:23.000
So I understand both sides of it.

17:23.000 --> 17:28.900
I wasn't offended by Ye's comments in that way, though, because if you're a pro-life human being,

17:28.900 --> 17:36.800
then you do think that what's happening is a great tragedy on scale that involves the dehumanization of an entire class of people, the pre-born.

17:36.800 --> 17:39.200
So the philosophically, you understand the comparison.

17:39.200 --> 17:39.900
I do.

17:39.900 --> 17:41.400
Sure.

17:41.400 --> 17:46.100
So in his comments, in the jumping from the individual to the group,

17:46.100 --> 17:51.900
I'd like to ask you, you're one of the most effective people in the world at attacking the left.

17:51.900 --> 17:56.000
And sometimes they can slip into attacking the group.

17:56.000 --> 18:05.200
Do you worry that that's the same kind of oversimplification that Ye's doing about Jewish people that you can sometimes do with the left as a group?

18:05.200 --> 18:09.000
So when I speak about the left, I'm speaking about a philosophy.

18:09.000 --> 18:16.900
I'm not really speaking about individual human beings as the leftists, like group, and then try to name who the members of this individual group are.

18:16.900 --> 18:19.800
I also make a distinction between the left and liberals.

18:19.800 --> 18:25.800
There are a lot of people who are liberal who disagree with me on taxes, disagree with me on foreign policy, disagree with me on a lot of things.

18:25.800 --> 18:29.300
The people who I'm talking about generally, and I talk about the left in the United States,

18:29.300 --> 18:36.800
are people who believe that alternative points of view ought to be silenced because they are damaging and harmful simply based on the disagreement.

18:36.800 --> 18:38.400
So that's one distinction.

18:38.400 --> 18:44.000
The second distinction, again, is when I talk about the right versus the left, typically I'm talking about a battle of competing philosophies.

18:44.000 --> 18:47.200
And so I'm not speaking about typically...

18:47.200 --> 18:48.000
It would be hard to...

18:48.000 --> 18:51.300
If you put a person in front of me and said, is this person of the left or of the right?

18:51.300 --> 18:57.800
Having just met them, I wouldn't be able to label them in the same way that if you met somebody in the name of Greenstein, you'd immediately got you.

18:57.800 --> 19:00.100
I mean, a black person is a black person.

19:00.100 --> 19:05.100
And the adherence to a philosophy makes you a member of a group.

19:05.100 --> 19:11.300
If I think the philosophy is bad, that doesn't necessarily mean that you as a person are bad, but it does mean that I think your philosophy is bad.

19:11.300 --> 19:20.900
Yeah, so the grouping is based on the philosophy versus something like a race, like the color of your skin or race, as in the case of the Jewish people.

19:20.900 --> 19:22.600
So it's a different thing.

19:22.600 --> 19:29.700
You can be a little bit more nonchalant and careless in attacking a group because it's ultimately attacking a set of ideas.

19:29.700 --> 19:32.700
Well, I mean, it's really nonchalant in attacking the set of ideas.

19:32.700 --> 19:34.500
And I don't know that nonchalant would be the way I'd put it.

19:34.500 --> 19:37.800
I tried to be exact when you're, you know, you don't always hit.

19:37.800 --> 19:41.900
But, you know, if I say that I oppose the communists, right?

19:41.900 --> 19:47.200
And then presumably I'm speaking of people who believe in the communist philosophy.

19:47.200 --> 19:49.100
Now, the question is whether I'm mislabeling, right?

19:49.100 --> 19:52.500
Whether I'm taking someone who's not actually a communist and then shoving them in that group of communists, right?

19:52.500 --> 19:53.900
That would be inaccurate.

19:53.900 --> 19:58.800
The dangerous thing is it expands the group as opposed to you talking about the philosophy.

19:58.800 --> 20:03.600
You're throwing everybody who's ever said, I'm curious about communism.

20:03.600 --> 20:06.700
I'm curious about socialism because there's like a gradient.

20:06.700 --> 20:10.100
You know, it's like to throw something at you.

20:10.100 --> 20:13.000
I think Joe Biden said, MAGA Republicans, right?

20:13.000 --> 20:14.200
Right.

20:14.200 --> 20:22.500
You know, I think that's a very careless statement because the thing you jump to immediately is like all Republicans for Trump,

20:22.500 --> 20:28.700
versus I think in the charitable interpretation, that means a set of ideas.

20:28.800 --> 20:35.900
My actually problem with the MAGA Republicans line from Biden is that he went on in the speech that he made in front of Independence Hall

20:35.900 --> 20:41.800
to actually trying to find what it meant to be a MAGA Republican who was a threat to the Republic was the kind of language that he was using.

20:41.800 --> 20:45.700
And later on in the speech, he actually suggested, well, you know, there are moderate Republicans

20:45.700 --> 20:48.800
and the moderate Republicans are people who agree with me on like the Inflation Reduction Act.

20:48.800 --> 20:54.400
It's like, well, that can't be the dividing line between a MAGA Republican and a moderate.

20:54.500 --> 21:00.800
Like a moderate Republican, somebody who agrees with you, you got to name me like a Republican who disagrees with you fairly strenuously,

21:00.800 --> 21:03.300
but is not in this group of threats to the Republic.

21:03.300 --> 21:08.100
You make that distinction, we can have a fair discussion about whether the idea of election denial, for example,

21:08.100 --> 21:11.000
makes somebody a threat to institutions.

21:11.000 --> 21:15.100
That's a conversation that we can have and then we'll have to discuss how much power they have,

21:15.100 --> 21:17.900
what the actual perspective is, delve into it.

21:17.900 --> 21:22.600
But, you know, I think that he was being over broad and sort of labeling all of his political enemies under one rubric.

21:22.600 --> 21:25.100
Now, again, in politics, this stuff sort of happens all the time.

21:25.100 --> 21:29.300
I'm not going to plead clean hands here because I'm sure that I've been inexact.

21:29.300 --> 21:34.500
But somebody, what would be good in that particular situation is for somebody to sort of read me back the quote

21:34.500 --> 21:36.400
and I'll let you know where I've been inaccurate.

21:36.400 --> 21:37.200
I'll try to do that.

21:37.200 --> 21:44.800
And also you don't shy away from humor and occasional trolling and mockery and all that kind of stuff for the fun, for the chaos, all that kind of stuff.

21:44.800 --> 21:52.100
I mean, I try not to do trollery for trollery's sake, but, you know, if the show is not entertaining and not fun, people aren't going to listen.

21:52.100 --> 21:58.000
And so, you know, if you can't have fun with politics, the truth about politics is we all take it very seriously because it has some serious ramifications.

21:58.000 --> 22:00.500
Politics is veep. It is not house of cards.

22:00.500 --> 22:08.700
The general rule of politics is that everyone is a moron unless proven otherwise, that virtually everything is done out of stupidity rather than malice.

22:08.700 --> 22:12.000
And that if you actually watch politics as a comedy, you'll have a lot more fun.

22:12.000 --> 22:18.800
And so the difficulty for me is I take politics seriously, but also I have the ability to sort of flip the switch and suddenly it all becomes incredibly funny

22:18.800 --> 22:20.600
because it really is.

22:20.600 --> 22:31.200
Like if you just watch it from a pure entertainment perspective and you put aside the fact that it affects hundreds of millions of people, then watching, you know, President Trump being president.

22:31.200 --> 22:38.600
I mean, he's one of the funniest humans who's ever lived watching Kamala Harris be Kamala Harris and talking about how much she loves Venn diagrams or electric buses.

22:38.600 --> 22:39.900
I mean, that's funny stuff.

22:39.900 --> 22:43.500
So if I can't make fun of that, then my job becomes pretty morose pretty quickly.

22:43.500 --> 22:56.900
Yeah, it's funny to figure out what is the perfect balance between seeing the humor and the absurdity of the game of it versus taking it seriously enough because it does affect hundreds of millions of people.

22:56.900 --> 22:58.600
It's a weird balance to strike.

22:58.600 --> 23:03.100
It's like I am afraid with the Internet that everything becomes a joke.

23:03.100 --> 23:04.500
I totally agree with this.

23:04.500 --> 23:11.300
I will say this. I try to make less jokes about the ideas and more jokes about the people in the same way that I make jokes about myself.

23:11.500 --> 23:14.000
I'm pretty self-effacing in terms of my humor.

23:14.000 --> 23:16.800
I would say at least half the jokes on my show are about me.

23:16.800 --> 23:24.200
When I'm reading ads for Tommy John and they're talking about their no wedgie guarantee, I'll say things like, you know, that would help me in high school because it would have.

23:24.200 --> 23:25.800
I mean, just factually speaking.

23:25.800 --> 23:31.100
So, you know, if I can speak that way about myself, I feel like everybody else can take it as well.

23:31.100 --> 23:32.600
Difficult question.

23:32.600 --> 23:36.200
In 2017, there was a mosque shooting in Quebec City.

23:36.200 --> 23:39.100
Six people died, five others seriously injured.

23:39.100 --> 23:46.600
The 27 year old gunman consumed a lot of content online and checked Twitter accounts a lot of a lot of people.

23:46.600 --> 23:49.900
But one of the people he checked quite a lot of is you.

23:49.900 --> 23:53.100
Ninety three times in the month leading up to the shooting.

23:53.100 --> 24:02.600
If you could talk to that young man, what would you tell him and maybe other young men listening to this that have hate in their heart in that same way?

24:02.600 --> 24:03.500
What would you tell him?

24:03.500 --> 24:05.400
You're getting it wrong.

24:05.500 --> 24:11.900
If anything that I or anyone else in mainstream politics says drives you to violence, you're getting it wrong.

24:11.900 --> 24:13.300
You're getting it wrong.

24:13.300 --> 24:18.300
Now, again, when it comes to stuff like this, I have a hard and fast rule that I've applied evenly across the spectrum.

24:18.300 --> 24:25.800
And that is I never blame people's politics for other people committing acts of violence unless they're actively advocating violence.

24:25.800 --> 24:30.900
So when a fan of Bernie Sanders shoots up a congressional baseball game, that is not Bernie Sanders' fault.

24:30.900 --> 24:31.800
I may not like his rhetoric.

24:31.800 --> 24:32.800
I may disagree with him on everything.

24:32.800 --> 24:41.000
Bernie Sanders did not tell somebody to go shoot up a congressional baseball game when a nutcase in San Francisco goes and hits Paul Pelosi with a hammer.

24:41.000 --> 24:43.700
I'm not going to blame Kevin McCarthy, the House Speaker, for that.

24:43.700 --> 24:49.400
When somebody threatens Brett Kavanaugh, I'm not going to I'm not going to suggest that that was Joe Biden's fault because it's not Joe Biden's fault.

24:49.400 --> 24:51.400
I mean, we can play this game all day long.

24:51.400 --> 25:01.000
And I find that the people who are most intensely focused on playing this game are people who tend to oppose the politics of the person as opposed to actually believing sincerely

25:01.000 --> 25:05.700
that this is driven somebody into the arms of the god of violence.

25:05.700 --> 25:09.700
But, you know, I I have four point seven million Twitter followers.

25:09.700 --> 25:11.800
I have eight million Facebook followers.

25:11.800 --> 25:13.700
I have five million YouTube followers.

25:13.700 --> 25:18.000
I would imagine that some of them are people who are violent.

25:18.000 --> 25:22.000
I would imagine that some of them are people who do evil things or want to do evil things.

25:22.100 --> 25:31.100
And I wish that there were a one that we could wave that would prevent those people from deliberately or mistakenly misinterpreting things as a call of violence.

25:31.100 --> 25:34.800
It's it's just a negative byproduct of the fact that you can reach a lot of people.

25:34.800 --> 25:45.700
And so, you know, if somebody could point me to the comment that that I suppose, quote unquote, drove somebody to go and literally murder human beings, then I would appreciate it.

25:46.200 --> 26:01.200
So I could talk about the comment, but I don't mainly because I just think that if we remove agency from individuals and we if we blame broad scale political rhetoric for every act of violence,

26:01.200 --> 26:07.200
we're not going to the people who are going to pay the price are actually the general population because free speech will go away.

26:07.200 --> 26:13.900
If the idea is that things that we say could drive somebody who is unbalanced to go do something evil.

26:13.900 --> 26:18.400
The necessary byproduct is hate is that is that speech is a form of hate.

26:18.400 --> 26:19.800
Hate is a form of violence.

26:19.800 --> 26:20.900
Speech is a form of violence.

26:20.900 --> 26:22.600
Speech needs to be curbed.

26:22.600 --> 26:25.900
And that to me is deeply disturbing.

26:25.900 --> 26:33.500
So definitely he that man, the twenty seven year old man is the only one responsible for the evil he did.

26:33.500 --> 26:38.300
But what if he and others like him are not not cases?

26:38.300 --> 26:40.900
What if they're people with pain?

26:40.900 --> 26:42.800
With anger in their heart?

26:42.800 --> 26:44.400
What would you say to them?

26:44.400 --> 26:51.000
You are exceptionally influential and other people like you that speak passionately about ideas.

26:51.000 --> 26:55.700
What do you think is your opportunity to alleviate the hate in their heart?

26:55.700 --> 27:00.200
If we're speaking about people who are mentally ill and people who are just misguided,

27:00.200 --> 27:04.200
I'd say to him the thing I said to every other young man in the country,

27:04.200 --> 27:17.000
You need to find meaning and purpose in forming connections that actually matter in a belief system that actually promotes general prosperity and promotes helping other people.

27:17.000 --> 27:27.700
And this is why the message that I most commonly say to young men is it's time for you to grow up, mature, get a job, get married, have a family, take care of the people around you, become a useful part of your community.

27:27.700 --> 27:36.900
I've never at any point in my entire career suggested violence as a resort to political issues.

27:36.900 --> 27:40.300
And the whole point of having a political conversation is that it's a conversation.

27:40.300 --> 27:45.600
If I didn't think that it were worth trying to convince people of my point of view, I wouldn't do what I do for a living.

27:45.600 --> 27:47.200
So violence doesn't solve anything.

27:47.200 --> 27:49.700
No, it doesn't.

27:49.700 --> 27:55.300
As if this wasn't already a difficult conversation.

27:55.300 --> 27:58.900
Let me ask about Ilhan Omar.

27:58.900 --> 28:03.800
You've called out her criticism of Israel policies as anti-Semitic.

28:03.800 --> 28:12.400
Is there a difference between criticizing a race of people like the Jews and criticizing the policies of a nation like Israel?

28:12.400 --> 28:13.600
Of course, of course.

28:13.600 --> 28:15.900
I criticize the policies of Israel on a fairly regular basis.

28:15.900 --> 28:18.400
I would assume from a different angle than Ilhan Omar does.

28:18.400 --> 28:22.500
But yeah, I mean, I criticize the policies of a wide variety of states.

28:22.500 --> 28:28.300
And to take an example, I mean, I've criticized Israel's policy in giving control of the Temple Mount to the Islamic walk,

28:28.300 --> 28:31.900
which effectively prevents anybody except for Muslims from praying up there.

28:31.900 --> 28:34.200
I've also criticized the Israeli government for their COVID crackdown.

28:34.200 --> 28:37.700
I mean, you can criticize the policies of any government, but that's not what Ilhan Omar does.

28:37.700 --> 28:40.300
Ilhan Omar doesn't actually believe that there should be a state of Israel.

28:40.300 --> 28:48.300
She believes that Zionism is racism and that the existence of a Jewish state in Israel is in and of itself the great sin.

28:48.300 --> 28:52.000
That is a statement she would make about no other people in no other land.

28:52.000 --> 28:54.100
She would not say that the French don't deserve a state for the French.

28:54.100 --> 28:57.400
She wouldn't say that the Somalis wouldn't deserve a state in Somalia.

28:57.400 --> 29:00.600
She wouldn't say that the Germans don't deserve a state in Germany.

29:00.600 --> 29:06.000
She wouldn't say for the 50 plus Islamic states that exist across the world that they don't deserve states of their own.

29:06.000 --> 29:09.500
It is only the Jewish state that has fallen under her significant scrutiny.

29:09.500 --> 29:17.200
And she also promulgates lies about one specific state in the form of suggesting, for example, that Israel is an apartheid state,

29:17.200 --> 29:22.000
which it is most eminently not considering that the last unity government in Israel included an Arab party,

29:22.000 --> 29:25.600
that there are Arabs who sit on the Israeli Supreme Court and all the rest.

29:25.600 --> 29:29.800
And then beyond that, obviously, she's engaged in some of the same sort of anti-Semitic tropes that you heard from Yeh, right?

29:29.800 --> 29:34.700
The stuff about it's all about the Benjamins, that American support for Israel is all about the Benjamins.

29:34.700 --> 29:38.200
And she's had to be chided by members of her own party about this sort of stuff before.

29:38.200 --> 29:41.200
Can you empathize with the plight of Palestinian people?

29:41.200 --> 29:42.200
Absolutely.

29:42.200 --> 29:47.700
I mean, I, you know, some of the uglier things that I've ever said in my career are things that I said very early on when I was 17, 18, 19.

29:47.700 --> 29:50.200
I started writing a syndicated comment when I was 17, I'm now 38.

29:50.200 --> 29:53.200
So virtually all the dumb things, I don't say virtually all, many of the dumb things,

29:53.200 --> 29:58.900
the plurality of the dumb things that I've said came from the ages of, I would say, 17 to maybe 23.

29:58.900 --> 30:02.200
And they are rooted, again, in sloppy thinking.

30:02.200 --> 30:07.600
I feel terrible for people who have lived under the thumb and currently live under the thumb of Hamas,

30:07.600 --> 30:15.100
which is an actual terrorist group, or the Palestinian Authority, which is a corrupt oligarchy that steals money from its people and leaves them in misery,

30:15.100 --> 30:18.100
or Islamic Jihad, which is an actual terrorist group.

30:18.100 --> 30:27.100
And the basic rule for the region, in my view, is if these groups were willing to make peace with Israel, they would have a state literally tomorrow.

30:27.100 --> 30:29.600
And if they are not, then there will be no peace.

30:29.600 --> 30:36.600
And it really is that simple. If Israel, the formula that's typically used has become a bit of a bumper sticker, but it happens to be factually correct.

30:36.600 --> 30:39.100
If the Palestinians put down their guns tomorrow, there would be a state.

30:39.100 --> 30:41.600
If the Israelis put down their guns, there would be no Israel.

30:44.600 --> 30:47.100
You get attacked a lot on the internet.

30:47.100 --> 30:48.600
Oh, yeah.

30:48.600 --> 30:51.600
I got to ask you about your own psychology.

30:52.600 --> 30:55.600
How do you not let that break you mentally?

30:55.600 --> 31:01.600
And how do you avoid letting that lead to a resentment of the groups that attack you?

31:01.600 --> 31:04.600
I mean, so there are a few sort of practical things that I've done.

31:04.600 --> 31:09.600
So for example, I would say that four years ago, Twitter was all consuming.

31:09.600 --> 31:12.100
Twitter is an ego machine, especially the notifications button.

31:12.100 --> 31:15.100
The notifications button is just people talking about you all the time.

31:15.100 --> 31:17.100
And the normal human tendency is, wow, people talking about me.

31:17.100 --> 31:20.100
I got to see what they're saying about me, which is a recipe for insanity.

31:20.100 --> 31:23.600
So my wife actually said, Twitter is making your life miserable.

31:23.600 --> 31:25.600
You need to take it off your phone. So Twitter is not on my phone.

31:25.600 --> 31:33.600
If I want to log onto Twitter, I have to go onto my computer and I have to make the conscious decision to go onto Twitter and then take a look at what's going on.

31:33.600 --> 31:35.600
I could just imagine you like there's a computer in the basement.

31:35.600 --> 31:39.600
You descend into the Czech Twitter in the darkness.

31:39.600 --> 31:46.600
If you look at when I actually tweet, it's generally like in the run up to recording my show or when I'm prepping for my show later in the afternoon, for example.

31:46.600 --> 31:50.600
That doesn't affect you negatively mentally, like put you in a bad mental space?

31:50.600 --> 31:53.600
Not particularly if it's restricted to sort of what's being watched.

31:53.600 --> 32:02.600
Now, I will say that I think the most important thing is you have to surround yourself with a group of people who are who you trust enough to make serious critiques of you when you're doing something.

32:02.600 --> 32:09.600
But also, you know that they have your best interests at heart because the Internet is filled with people who don't have your best interests at heart and who hate your gods.

32:09.600 --> 32:12.600
And so you can't really take those critiques seriously or it does wreck you.

32:12.600 --> 32:15.600
And the world is also filled with sycophants, right?

32:15.600 --> 32:20.600
Then the more successful you become, there are a lot of people who will tell you you're always doing the right thing.

32:20.600 --> 32:22.600
I'm very lucky. I got married when I was 24.

32:22.600 --> 32:26.600
My wife was 20, so she's known me long before I was famous or wealthy or anything.

32:26.600 --> 32:29.600
And so she's a good sounding board.

32:29.600 --> 32:34.600
I have a family that's willing to that's willing to call me out on my bullshit as you talk to you about.

32:34.600 --> 32:37.600
I have friends who are able to do that.

32:37.600 --> 32:42.600
I try to have open lines of communications with people who I believe have my best interests at heart.

32:42.600 --> 32:48.600
But one of the sort of conditions of being friends is that when you see me do something wrong, I'd like for you to let me know that so I can correct it.

32:48.600 --> 32:50.600
I don't want to leave bad impressions out there.

32:50.600 --> 32:58.600
The sad thing about the Internet, just looking at the critiques you get, I see very few critiques from people that actually want you to succeed, want you to grow.

32:58.600 --> 33:04.600
I mean, they're not sophisticated. They're just, I don't know, they're cruel.

33:04.600 --> 33:08.600
It's not the actual critiques. It's just cruelty.

33:08.600 --> 33:10.600
And that's most of Twitter.

33:10.600 --> 33:14.600
Twitter is a place to smack and be smacked.

33:14.600 --> 33:20.600
Anybody who uses Twitter for an intellectual conversation, I think, is engaging in category error.

33:20.600 --> 33:23.600
I use it to spread love. I think it's impossible.

33:23.600 --> 33:26.600
You're the only one. It's you and no one else, my friend.

33:26.600 --> 33:29.600
On that topic, what do you think about Elon buying Twitter?

33:29.600 --> 33:33.600
What do you like? What are you hopeful on that front?

33:33.600 --> 33:36.600
What would you like to see Twitter improve?

33:36.600 --> 33:39.600
So I'm very hopeful about Elon buying Twitter.

33:39.600 --> 33:45.600
I mean, I think that Elon is significantly more transparent than what has taken place up till now.

33:45.600 --> 33:51.600
He seems committed to the idea that he's going to broaden the Overton window to allow for conversations that simply were banned before.

33:51.600 --> 33:57.600
Everything ranging from efficacy of masks with regard to COVID to whether men can become women and all the rest.

33:57.600 --> 34:02.600
A lot of things that would get you banned on Twitter before without any sort of real explanation.

34:02.600 --> 34:11.600
It seems like he's dedicated to at least explaining what the standards are going to be and being broader in allowing a variety of perspectives on the outlet, which I think is wonderful.

34:11.600 --> 34:13.600
I think that's also why people are freaking out.

34:13.600 --> 34:19.600
I think the kind of wailing and gnashing of teeth and wearing of sackcloth and ash by so many members of the legacy media.

34:19.600 --> 34:28.600
I think a lot of that is because Twitter essentially was an oligarchy in which certain perspectives were allowed and certain perspectives just were not.

34:28.600 --> 34:35.600
And that was part of a broader social media, reimposed oligarchy in the aftermath of 2017.

34:35.600 --> 34:45.600
So in order to really understand, I think, what it means for Elon to take over Twitter, I think that we have to take a look at sort of the history of media in the United States in two minutes or less.

34:46.600 --> 34:57.600
The United States, the media for most of its existence up until about 1990, at least from about 1930s until the 1990s, virtually all media was three major television networks, a couple major newspapers and the wire services.

34:57.600 --> 35:04.600
Everybody had a local newspaper, the wire services that basically did all the foreign policy and all the national policy, McClatchy, Reuters, AP, AFB, et cetera.

35:04.600 --> 35:09.600
So that monopoly or oligopoly existed until the rise of the Internet.

35:09.600 --> 35:14.600
There were sort of pokes at it and talk radio and Fox News, but there certainly was not this plethora of sources.

35:14.600 --> 35:18.600
Then the Internet explodes and all of a sudden you can get news everywhere.

35:18.600 --> 35:28.600
And the way that people are accessing that news is you're, I believe, significantly younger than I am, but we used to do this thing called bookmarking, where you would bookmark a series of websites and then you would visit them every morning.

35:28.600 --> 35:32.600
And then social media came up.

35:32.600 --> 35:33.600
Was this on AOL?

35:33.600 --> 35:34.600
Yeah, exactly.

35:34.600 --> 35:39.600
You had the dial-up and it was actually a can connected to a string and you would actually just go...

35:40.600 --> 35:48.600
And then there came a point where social media arose and social media was sort of a boon for everybody because you no longer had to bookmark anything.

35:48.600 --> 35:53.600
You just followed your favorite accounts and all of them would pop up and you follow everything on Facebook and it would all pop up and it was all centralized.

35:53.600 --> 35:57.600
And for a while everybody was super happy because this was the brand new wave of the future.

35:57.600 --> 35:58.600
It made everything super easy.

35:58.600 --> 36:03.600
Suddenly outlets like mine were able to see new eyeballs because it was all centralized in one place.

36:03.600 --> 36:05.600
You didn't have to do it through Google optimization.

36:05.600 --> 36:09.600
You could now just put it on Facebook and so many eyeballs were on Facebook, you'd get more traffic.

36:09.600 --> 36:13.600
And everybody seemed pretty happy with this arrangement until precisely the moment Donald Trump became president.

36:13.600 --> 36:30.600
At that point, then the sort of pre-existing supposition of a lot of the powers that be, which was Democrats are going to continue winning from here on out so we can sort of use these social media platforms as ways to push our information and still allow for there to be other information out there.

36:30.600 --> 36:36.600
The immediate response was we need to reestablish this siphoning of information.

36:36.600 --> 36:39.600
It was misinformation and disinformation that won Donald Trump the election.

36:39.600 --> 36:43.600
We need to pressure the social media companies to start cracking down on misinformation and disinformation.

36:43.600 --> 36:46.600
And actually see this in the historical record.

36:46.600 --> 36:50.600
You can see how Jack Dorsey's talk about free speech shifted from about 2015 to about 2018.

36:50.600 --> 36:55.600
You can see Mark Zuckerberg gave a speech at Georgetown in 2018 in which he talked about free speech and its value.

36:55.600 --> 37:01.600
And by 2019, he was going in front of Congress talking about how he was responsible for the stuff that was on Facebook, which is not true.

37:01.600 --> 37:03.600
He's not responsible for the stuff on Facebook, right?

37:03.600 --> 37:06.600
It's a platform. Is AT&T responsible for the stuff you say on your phone?

37:06.600 --> 37:07.600
The answer is typically no.

37:07.600 --> 37:16.600
So when that happened, because all the eyeballs had now been centralized in these social media sites, they were able to suddenly control what you could see and what you could not see.

37:16.600 --> 37:24.600
And the most obvious example was obviously leading up to 2020, the election, the killing of the Hunter Biden story is a great example of this.

37:24.600 --> 37:30.600
And so Elon coming in and taking over one of the social media services and saying, I'm not playing by your rules, right?

37:30.600 --> 37:36.600
There's not going to be this sort of group of people in the halls of power who are going to decide what we can see.

37:36.600 --> 37:38.600
And here instead, I'm going to let a thousand flowers bloom.

37:38.600 --> 37:41.600
There'll be limits, but it's going to be on more case by case basis.

37:41.600 --> 37:50.600
We're going to allow perspectives that are mainstream, but maybe not mainstream in the halls of academia or in the halls of media.

37:50.600 --> 37:51.600
Let those let those be said.

37:51.600 --> 37:53.600
I think it's a really good thing.

37:53.600 --> 38:03.600
Now that comes with some responsibilities on Elon's personal part, which would be to be, for example, I think more responsible and dissemination of information himself sometimes, right?

38:03.600 --> 38:10.600
Like he got himself in trouble the other day for tweeting out that that story about Paul Pelosi that was speculative and untrue.

38:10.600 --> 38:13.600
And I think I don't think what he did is horrific.

38:13.600 --> 38:15.600
He deleted it when he found out that it was false.

38:15.600 --> 38:17.600
But and that's actually a free speech working, right?

38:17.600 --> 38:18.600
He said something wrong.

38:18.600 --> 38:19.600
People ripped into him.

38:19.600 --> 38:20.600
He realized he was wrong.

38:20.600 --> 38:27.600
He deleted it, which seems to be a better solution than preemptively banning content, which only raises more questions than it than it actually stops.

38:27.600 --> 38:34.600
With that said, as the face of responsible free speech, you know, and that's sort of what he's pitching at Twitter.

38:34.600 --> 38:38.600
He I think should should enact that himself and be a little more careful in the stuff that he tweets out.

38:38.600 --> 38:40.600
Well, that's a tricky balance.

38:40.600 --> 38:48.600
The reason a lot of people are freaking out is because one, he's putting his thumb on the scale by saying he is more likely to vote Republican.

38:48.600 --> 38:57.600
He's showing himself to be center right and sort of just having a political opinion versus being this amorphous thing that doesn't have a political opinion.

38:57.600 --> 39:08.600
I think if I were to guess, I haven't talked to him about it, but if I were to guess he's sending a kind of signal that's important for the Twitter, the company itself, because if we're being honest, most of the employees are left leaning.

39:08.600 --> 39:26.600
So you have to kind of send a signal that like a resisting mechanism to say, like, since most of the employees are left, it's good for for you to be more right to balance out the way the actual engineering is done to say we're not going to do any kind of activism.

39:27.600 --> 39:33.600
If I were to guess, that's kind of the effective aspect of that of that mechanism.

39:33.600 --> 39:47.600
And the other one by posting the Pelosi thing is probably to expand the Overton window, like saying we can play, we can post stuff, we can post conspiracy theories, and then through discourse figure out what is and isn't true.

39:47.600 --> 39:53.600
Yeah, again, like I say, I mean, I think that that is a better mechanism in action than what it was before.

39:53.600 --> 40:00.600
I just think it gave people who hate his guts the opening to kind of slap him for no reason, but I can see the strategy of it for sure.

40:00.600 --> 40:13.600
And I think that the general idea that he's kind of pushing right where the company had pushed left before, I think that there is actually unilateral polarization right now in politics, at least with regard to social media,

40:13.600 --> 40:21.600
in which one side basically says the solution to disinformation is to shut down free speech from the other side.

40:21.600 --> 40:36.600
And the other side is basically like people like me are saying the solution to disinformation is to let a thousand like I'd rather have people on the left also being able to put out stuff that I disagree with than for there to be anybody who's sort of in charge of these social media platforms and using them as editorial sites.

40:37.600 --> 40:40.600
I mean, I'm not criticizing MSNBC for not putting on right-wing opinions.

40:40.600 --> 40:42.600
I mean, that's fine. I run a conservative site.

40:42.600 --> 40:47.600
We're not going to put up left-wing opinions on a wide variety of issues because we are a conservative site.

40:47.600 --> 40:50.600
But if you pitch yourself as a platform, that's a different thing.

40:50.600 --> 40:58.600
If you pitch yourself as the town square, as Elon likes to call it, then I think Elon has a better idea of that than many of the former employees did,

40:58.600 --> 41:08.600
especially now that we have that report from The Intercept suggesting that there are people from Twitter working with DHS to monitor quote unquote disinformation and being rather vague about what disinformation meant.

41:08.600 --> 41:21.600
Yeah, I don't think activism has a place in what is fundamentally an engineering company that's building a platform like the people inside the company should not be putting a thumb on the scale of what is and isn't allowed.

41:21.600 --> 41:25.600
You should create a mechanism for the for the people to decide what is and isn't allowed.

41:25.600 --> 41:32.600
Do you think Trump should have been removed from Twitter? Should his account be restored?

41:32.600 --> 41:37.600
His account should be restored. And this is coming from somebody who really dislikes an enormous number of Donald Trump's tweets.

41:37.600 --> 41:42.600
Again, he's a very important political personage.

41:42.600 --> 41:48.600
Even if he weren't, I don't think that he should be banned from Twitter or Facebook in coordinated fashion.

41:48.600 --> 41:53.600
By the way, I hold that opinion about people who I think are far worse than Donald Trump.

41:53.600 --> 41:58.600
Everyone knows I'm not an Alex Jones guy. I don't like Alex Jones. I think Alex Jones.

41:58.600 --> 42:00.600
Oh, Alex should be back on Twitter.

42:00.600 --> 42:07.600
I do, actually, because I think that there are plenty of people who are willing to say that what he's saying is wrong.

42:07.600 --> 42:18.600
And I'm not a big fan of this idea that that because people I disagree with and people who have personally targeted me, by the way, I mean, Alex Jones, this has been has said some some things about me personally that I'm not real fond of.

42:19.600 --> 42:24.600
Well, we're not besties. Now, it turns out, yeah, all I've said is I don't really enjoy a show.

42:24.600 --> 42:29.600
He said some other stuff about the Antichrist and such, but that's a bit of a different thing, I suppose.

42:29.600 --> 42:33.600
Even so, I'm just not a big fan of this idea.

42:33.600 --> 42:42.600
I've defended people who have really gone after me on a personal level, have targeted me, that the town square is online.

42:42.600 --> 42:45.600
Banning people from the town square is unpersoning them.

42:45.600 --> 42:51.600
Unless you violated a criminal statute, you should not be unpersoned in American society as a general rule.

42:51.600 --> 42:57.600
That doesn't mean that companies that are not platforms don't have the ability to respond to you.

42:57.600 --> 43:03.600
I think Adidas is right to terminate its contract with Kanye, for example, with Ye.

43:03.600 --> 43:07.600
You know, that's but Twitter ain't Adidas.

43:08.600 --> 43:19.600
So the way your stance on free speech to the degree it's possible to achieve on a platform like Twitter is you fight bad speech with more speech, with better speech.

43:19.600 --> 43:35.600
And that's so if Alex Jones and Trump is allowed back on in the coming months and years leading up to the 2024 election, you think that's going to make for a better world in the long term?

43:35.600 --> 43:43.600
I think that on the principle that people should be allowed to do this and the alternative being a group of thought bosses telling us what we can and cannot see, yes.

43:43.600 --> 43:47.600
Do I think in the short term it's going to mean a lot of things that I don't like very much? Sure.

43:47.600 --> 43:50.600
I mean, that's the cost of doing business.

43:50.600 --> 43:55.600
I think that one of the costs of freedom is people doing things that I don't particularly like.

43:55.600 --> 44:01.600
And I would prefer the freedom with all the stuff I don't like than not the freedom.

44:01.600 --> 44:03.600
Let me linger on the love a little bit.

44:03.600 --> 44:15.600
You and a lot of people are pretty snarky on Twitter, sometimes to the point of mockery, derision, even a bit of, if I were to say, bad faith in the kind of mockery.

44:15.600 --> 44:20.600
And you see it as a war, like I disagree with both you and Elon on this.

44:20.600 --> 44:25.600
Elon sees Twitter as a war zone or at least saw it that way in the past.

44:25.600 --> 44:32.600
Have you ever considered being nicer on Twitter as a voice that a lot of people look up to?

44:32.600 --> 44:39.600
That if Ben Shapiro becomes a little bit more about love that's going to inspire a lot of people or no?

44:39.600 --> 44:41.600
Is it just too fun for you?

44:41.600 --> 44:43.600
The answer is yes. Sure, it's occurred to me.

44:43.600 --> 44:47.600
Let's put it this way. There are a lot of tweets that actually don't go out that I delete.

44:47.600 --> 44:52.600
I will say that Twitter's new function, that 30-second function is a friend of mine.

44:52.600 --> 44:55.600
Every so often I'll tweet something and I'll think about it a second time.

44:55.600 --> 44:57.600
Do I need to say this? Probably not.

44:57.600 --> 45:05.600
Can you make a book published after you pass away of all the tweets that you didn't send?

45:05.600 --> 45:09.600
I don't know. My kids are still going to be around, I hope, so that's the legacy.

45:09.600 --> 45:12.600
But yeah, I mean, sure. The answer is yes.

45:12.600 --> 45:15.600
And this is a good piece of what we would call in Orthodox Judaism, mussur.

45:15.600 --> 45:17.600
This is like he's giving you a mussur schmooze right now.

45:17.600 --> 45:20.600
This is like the kind of be a better person stuff.

45:20.600 --> 45:22.600
I agree with you. I agree with you.

45:22.600 --> 45:26.600
And yeah, I will say that Twitter is sometimes too much fun.

45:26.600 --> 45:34.600
I try to be at least, if not even-handed, then equal opportunity in my derision.

45:34.600 --> 45:40.600
I remember that during the 2016 primaries I used to post rather snarky tweets

45:40.600 --> 45:43.600
about virtually all of the candidates, Republican and Democrat.

45:43.600 --> 45:47.600
And every so often I'll still do some of that.

45:47.600 --> 45:50.600
I do think actually the amount of snark on my Twitter feed has gone down fairly significantly.

45:50.600 --> 45:53.600
I think if you go back a couple of years, it was probably a little more snarky.

45:53.600 --> 45:57.600
Today I'm trying to use it a little bit more in terms of strategy to get out information.

45:57.600 --> 46:03.600
Now, that doesn't mean I'm not going to make jokes about, for example, Joe Biden.

46:03.600 --> 46:06.600
I will make jokes about Joe Biden. He's the president of the United States.

46:06.600 --> 46:08.600
Nobody else will mock him.

46:08.600 --> 46:11.600
So the entire comedic establishment has decided they actually work for him.

46:11.600 --> 46:16.600
So the president of the United States, no matter who they are, get the snark?

46:16.600 --> 46:20.600
Yes. And President Trump, I think, is fairly aware that he got the snark from me as well.

46:20.600 --> 46:22.600
When it comes to snarking the president, I'm not going to stop that.

46:22.600 --> 46:24.600
I think the president deserves to be snarked.

46:24.600 --> 46:26.600
So you're not afraid of attacking Trump?

46:26.600 --> 46:29.600
No. I mean, I've done it before.

46:29.600 --> 46:37.600
Can you say what your favorite and least favorite things are about President Trump and President Biden, one at a time?

46:37.600 --> 46:43.600
So maybe one thing that you can say is super positive about Trump and one thing super negative about Trump.

46:43.600 --> 46:49.600
Okay. So the super positive thing about Trump is that because he has no preconceived views that are establishmentarian,

46:49.600 --> 46:53.600
he's sometimes willing to go out of the box and do things that haven't been tried before.

46:53.600 --> 46:55.600
And sometimes that works.

46:55.600 --> 47:00.600
I mean, the best example being the entire foreign policy establishment telling him that he couldn't get a Middle Eastern deal done

47:00.600 --> 47:03.600
unless he centered the Palestinian-Israeli conflict.

47:03.600 --> 47:08.600
And instead, he just went right around that and ended up cutting a bunch of peace deals in the Middle East or moving the embassy in Jerusalem.

47:08.600 --> 47:12.600
Sometimes he does stuff and it's really out of the box and it actually works.

47:12.600 --> 47:15.600
And that's kind of awesome in politics and neat to see.

47:15.600 --> 47:25.600
The downside of Trump is that he has no capacity to use any sort of  there's no filter between brain and mouth.

47:25.600 --> 47:28.600
Well, whatever happens in his brain is the thing that comes out of his mouth.

47:28.600 --> 47:32.600
I know a lot of people find that charming and wonderful and it is very funny.

47:32.600 --> 47:39.600
But I don't think that it is a particularly excellent personal quality in a person who has as much responsibility as President Trump has.

47:39.600 --> 47:43.600
I think he says a lot of damaging and bad things on Twitter.

47:43.600 --> 47:49.600
I think that he seems consumed in some ways by his own grievances,

47:49.600 --> 47:52.600
which is why you've seen him focusing in on Election 2020 so much.

47:52.600 --> 47:54.600
And I think that that is very negative about President Trump.

47:54.600 --> 47:58.600
So I'm very grateful to President Trump as a conservative for many of the things that he did.

47:58.600 --> 48:02.600
I think that a lot of his personality issues are pretty severe.

48:02.600 --> 48:05.600
What about Joe Biden?

48:05.600 --> 48:08.600
So I think that the thing that I like most about Joe Biden 

48:08.600 --> 48:09.600
Yes.

48:09.600 --> 48:13.600
I will say that Biden  two things.

48:13.600 --> 48:20.600
One, Biden seems to be a very good father by all available evidence, right?

48:20.600 --> 48:25.600
There are a lot of people who are put out, you know, kind of tape of him talking to Hunter and Hunter's having trouble with drugs or whatever.

48:25.600 --> 48:30.600
And I keep listening to that tape and thinking he seems like a really good dad.

48:30.600 --> 48:35.600
Like, the stuff that he's saying to his son is stuff that, God forbid, if that were happening with my kid, I'd be saying to my kid.

48:35.600 --> 48:37.600
And so, you know, you can't help but feel for the guy.

48:37.600 --> 48:45.600
He's had an incredibly difficult go of it with his first wife and the death of members of his family and then bowdying.

48:45.600 --> 48:51.600
I mean, like, that kind of stuff obviously is deeply sympathetic, and he seems like a deeply sympathetic father.

48:51.600 --> 48:56.600
As far as his politics, he seems like a slap on the back kind of guy.

48:56.600 --> 48:58.600
And I don't mind that.

48:58.600 --> 48:59.600
I think that's nice so far as it goes.

48:59.600 --> 49:04.600
It's sort of an old school politics where things are done with handshake and personal relationships.

49:04.600 --> 49:07.600
The thing I don't like about him is I think sometimes that's really not genuine.

49:07.600 --> 49:16.600
I think that sometimes, you know, I think that's his personal tendency, but I think sometimes he allows the prevailing winds of his party to carry him to incredibly radical places.

49:16.600 --> 49:22.600
And then he just doubles down on the radicalism in some pretty disingenuous ways.

49:22.600 --> 49:29.600
And there I would cite the Independence Day speech or the Independence Hall speech, which I thought was truly one of the worst speeches I've seen a president give.

49:29.600 --> 49:31.600
So you don't think he's trying to be a unifier in general?

49:31.600 --> 49:32.600
Not at all.

49:32.600 --> 49:34.600
I mean, that's what he was elected to do.

49:34.600 --> 49:37.600
He was elected to do two things, not be alive and be a unifier.

49:37.600 --> 49:38.600
Those were the two things.

49:38.600 --> 49:41.600
And when I say not be alive, I don't mean like physically dead.

49:41.600 --> 49:43.600
This is where the snark comes in.

49:43.600 --> 49:48.600
But what I do mean is that he was elected to not be particularly activist.

49:49.600 --> 49:51.600
Basically, the mandate was don't be Trump.

49:51.600 --> 49:52.600
Be sane.

49:52.600 --> 49:53.600
Don't be Trump.

49:53.600 --> 49:54.600
Calm everything down.

49:54.600 --> 49:55.600
And instead, he got in.

49:55.600 --> 49:57.600
He's like, what if we spend seven trillion dollars?

49:57.600 --> 50:00.600
What if we what if we pull out of Afghanistan without any sort of plan?

50:00.600 --> 50:03.600
What if I start labeling all of my political enemies, enemies of the republic?

50:03.600 --> 50:12.600
What if I start bringing Dylan Mulvaney to the White House and talking about how it is a moral sin to prevent the general mutilation of minors?

50:12.600 --> 50:14.600
I mean, like this kind of stuff is very radical stuff.

50:14.600 --> 50:22.600
And this is not a president who has pursued a unifying agenda, which is why his approval rating sank from 60 percent when he entered office to low 40s or high 30s today.

50:22.600 --> 50:25.600
Unlike President Trump, who never had a high approval rating.

50:25.600 --> 50:27.600
Trump came into office and he had like a 45 percent approval rating.

50:27.600 --> 50:33.600
And when he left office, he had about a 43 percent approval rating and bounced around between 45 and 37 pretty much his entire presidency.

50:33.600 --> 50:37.600
Biden went from being a very popular guy coming in to a very unpopular guy right now.

50:37.600 --> 50:40.600
And if you're Joe Biden, you should be looking in the mirror and wondering exactly why.

50:41.600 --> 50:46.600
Do you think that pulling out from Afghanistan could be flipped as a pro for Biden in terms of he actually did it?

50:46.600 --> 50:48.600
I think it's going to be almost impossible.

50:48.600 --> 50:54.600
I think the American people are incredibly inconsistent about their own views on foreign policy.

50:54.600 --> 50:59.600
In other words, we like to be isolationist until it comes time for us to be defeated and humiliated.

50:59.600 --> 51:02.600
When that happens, we tend not to like it very much.

51:02.600 --> 51:05.600
You mentioned Biden being a good father.

51:05.600 --> 51:14.600
Can you make the case for and against the Hunter Biden laptop story for it being a big deal and against it being a big deal?

51:14.600 --> 51:17.600
Sure. So the case for it being a big deal is basically twofold.

51:17.600 --> 51:30.600
One is that it is clearly relevant if the president's son is running around to foreign countries picking up bags of cash because his last name is Biden while his father is vice president of the United States.

51:30.600 --> 51:37.600
And it raises questions as to influence peddling for either the vice president or the former vice president using political connections.

51:37.600 --> 51:43.600
Did he make any money? Who was the big guy? Right. All these open questions that obviously implicates the questions to be asked.

51:43.600 --> 51:50.600
And then the secondary reason that the story is big is actually because the reaction of the story, the banning of the story is in and of itself a major story.

51:50.600 --> 51:56.600
If there's if there's any story that implicates a presidential candidate in the last month of an election and there is a media blackout,

51:57.600 --> 52:03.600
including a social media blackout, that obviously raises some very serious questions about informational flow and dissemination in the United States.

52:03.600 --> 52:09.600
So no matter how big of a deal the story is, it is a big deal that there's a censorship of any relevant story.

52:09.600 --> 52:13.600
There's a coordinated collusive blackout. Yeah, that's that's a that's a serious and major problem.

52:13.600 --> 52:16.600
So those are the two reasons why it would be a big story.

52:16.600 --> 52:32.600
The two reasons, a reason why it would not be a big story, perhaps is if it turns out and we don't really know this yet, but let's say that that Hunter Biden was basically off on his own doing what he was doing, being a derelict or drug addict or acting badly.

52:32.600 --> 52:35.600
And his dad had nothing to do with it. And Joe was telling the truth.

52:35.600 --> 52:38.600
And he really knew. But the problem is, we never actually got those questions answered.

52:38.600 --> 52:44.600
So if it turned out to be a nothing of a story, the nice thing about stories that turn out to be nothing is that after they turn out to be nothing, they're nothing.

52:44.600 --> 52:51.600
The biggest problem with this story is that it wasn't allowed to take the normal life cycle of a story, which is original story breaks.

52:51.600 --> 52:54.600
Follow on questions are asked. Follow on questions are answered.

52:54.600 --> 52:57.600
Story is either now a big story or it's nothing.

52:57.600 --> 53:04.600
When the life cycle of a story is cut off right at the very beginning, right when it's born, then that allows you to speculate in any direction you want.

53:04.600 --> 53:09.600
You can speculate. It means nothing. It's nonsense. It's Russian. It's a Russian laptop.

53:10.600 --> 53:15.600
Or on the other hand, this means that Joe Biden was personally calling Hunter and telling him to pick up a sack of cash over in Beijing.

53:15.600 --> 53:17.600
And then he became president and he's influence peddling.

53:17.600 --> 53:20.600
So this is why it's important to allow these stories to go forward.

53:20.600 --> 53:24.600
So this is why actually the bigger story for the moment is not the laptop.

53:24.600 --> 53:27.600
It's the reaction to the laptop because it cut off that life cycle of the story.

53:27.600 --> 53:32.600
And then, you know, at some point I would assume that there will be some follow on questions that are actually answered.

53:32.600 --> 53:36.600
I mean, the House is pledging, if it goes Republican, to investigate all of this.

53:36.600 --> 53:43.600
Again, I wouldn't be supremely surprised if it turns out that there was no direct involvement of Joe in this sort of stuff.

53:43.600 --> 53:46.600
Because it turns out, as I said before, that all of politics is Veep.

53:46.600 --> 53:55.600
And this is always the story with half the scandals that you see is that everybody assumes that there's some sort of deep and abiding, clever plan that some politician is implementing it.

53:55.600 --> 53:58.600
And then you look at it and it turns out, no, it's just something dumb, right?

53:58.600 --> 54:03.600
This is sort of a perfect example of this, you know, President Trump with the classified documents in Mar-a-Lago.

54:03.600 --> 54:05.600
So people on the left, like, it's probably nuclear codes.

54:05.600 --> 54:08.600
Probably he's taking secret documents and selling them to the Russians or the Chinese.

54:08.600 --> 54:13.600
And the real, most obvious explanation is Trump looked at the papers and he said, I like these papers.

54:13.600 --> 54:15.600
And then he just decided to keep them, right?

54:15.600 --> 54:18.600
And then people came to him and said, Mr. President, you're not allowed to keep those papers.

54:18.600 --> 54:20.600
He said, who are those people? I don't care about what they have to say.

54:20.600 --> 54:22.600
I'm putting them in the other room, in a box.

54:22.600 --> 54:27.600
Like, it is highly likely that that is what happened.

54:27.600 --> 54:31.600
And it's very disappointing to people, I think, when they realize the human brain.

54:31.600 --> 54:34.600
I mean, you know this better than I do, but the human brain is built to find patterns, right?

54:34.600 --> 54:36.600
It's what we like to do. We like to find plans and patterns.

54:36.600 --> 54:41.600
Because this is how we survived in the wild, is you found a plan, you found a pattern, you cracked the code of the universe.

54:41.600 --> 54:47.600
When it comes to politics, the conspiracy theories that we see so often, it's largely because we're seeing inexplicable events.

54:47.600 --> 54:49.600
Unless you just assume everyone's a moron.

54:49.600 --> 54:52.600
If you assume that there's a lot of stupidity going on, everything becomes quickly explicable.

54:52.600 --> 54:58.600
If you assume that there must be some rationale behind it, you have to come up with increasingly convoluted conspiracy theories

54:58.600 --> 55:01.600
to explain just why people are acting the way that they're acting.

55:01.600 --> 55:11.600
And I find that, I won't say 100% of the time, but 94% of the time, the conspiracy theory turns out just to be people being dumb.

55:11.600 --> 55:14.600
And then other people reacting in dumb ways to the original people being dumb.

55:14.600 --> 55:27.600
But it's also, to me, in that same way, very possible, very likely that Hunter Biden getting money in Ukraine, I guess, for consulting and all that kind of stuff, is a nothing burger.

55:27.600 --> 55:34.600
He's qualified, he's getting money as he should, there's a lot of influence peddling in general that's not corrupt.

55:34.600 --> 55:41.600
I think the most obvious explanation there, probably, is that he was fake influence peddling, meaning he went to Ukraine, and he's like, guess what, my dad's Joe.

55:41.600 --> 55:47.600
And they're like, well, you don't have any qualifications in oil and natural gas, and you don't really have a great resume, but your dad is Joe.

55:47.600 --> 55:51.600
And then that was kind of the end of it. They gave him a bag of cash, hoping he would do something. He never did anything.

55:51.600 --> 55:55.600
I think you're making it sound worse than it is. I think that, in general, consulting is done in that way.

55:56.600 --> 55:57.600
I agree with you.

55:57.600 --> 56:05.600
It's not like he is some rare case, and this is an illustration of corruption. If you can criticize consulting, which I would.

56:05.600 --> 56:06.600
That's fair.

56:06.600 --> 56:14.600
Which they're basically not providing. You look at a resume and who's who. If you went to Harvard, I can criticize the same thing.

56:14.600 --> 56:24.600
If you have Harvard on your resume, you're more likely to be hired as a consultant. Maybe there's a network there of people that you know, and you hire them in that same way.

56:24.600 --> 56:28.600
If your last name is Biden, there's a lot of last names that sound pretty good.

56:28.600 --> 56:29.600
For sure, for sure.

56:29.600 --> 56:35.600
And Biden admitted that much, by the way, right? In an open interview, he was like, if your last name weren't Biden, would you have got that job?

56:35.600 --> 56:38.600
And he's like, probably not. And you're right.

56:38.600 --> 56:39.600
I agree with you.

56:39.600 --> 56:48.600
It's not like he's getting a ridiculous amount of money. He was getting like a pretty standard consulting kind of money, which also would criticize because they get a ridiculous amount of money.

56:48.600 --> 56:57.600
But I sort of even to push back on the life cycle or to steal man the side that was concerned about the Hunter Biden laptop story.

56:57.600 --> 57:08.600
I don't know if there is a natural life cycle of a story because there's something about the virality of the Internet that we can't predict that a story can just take hold.

57:08.600 --> 57:20.600
And the conspiracy around it builds, especially around politics, where the interpretation, some popular sexy interpretation of a story that might not be connected to reality at all will become viral.

57:20.600 --> 57:35.600
And that from Facebook's perspective is probably what they're worried about is a organized misinformation campaign that makes up a sexy story or sexy interpretation of the of the vague story that we have.

57:35.600 --> 57:38.600
And that has an influence on the populace.

57:38.600 --> 57:41.600
I mean, I think that's true. But I think the question becomes who's the great adjudicator there, right?

57:41.600 --> 57:49.600
Who adjudicates when the story ought to be allowed to go through even a bad life cycle or allowed to go viral as opposed to not.

57:49.600 --> 57:52.600
Now, it's one thing if you want to say, OK, we can spot the Russian accounts that are actually promoting this stuff.

57:52.600 --> 57:54.600
They belong to the Russian government. Got to shut that down.

57:54.600 --> 58:02.600
I think everybody agrees. This is actually one of the slides that's happened linguistically that I really object to is the slide between disinformation and misinformation.

58:03.600 --> 58:07.600
You notice there is this evolution in 2017. There's a lot of talk about disinformation is Russian disinformation.

58:07.600 --> 58:12.600
The Russians were putting out deliberately false information or to skew election results was the accusation.

58:12.600 --> 58:19.600
And then people started using disinformation or misinformation and misinformation is either mistaken information or information that is quote unquote out of context.

58:19.600 --> 58:23.600
That becomes very subjective very quickly as to what out of context means.

58:23.600 --> 58:27.600
And it doesn't necessarily have to be from a foreign source. It can be from a domestic source, right?

58:27.600 --> 58:29.600
Could be somebody misinterpreting something here.

58:29.600 --> 58:35.600
It could be somebody interpreting something correctly, but PolitiFact thinks that it's out of context and that sort of stuff gets very murky very quickly.

58:35.600 --> 58:46.600
And so I'm deeply uncomfortable with the idea that Facebook and Zuckerberg was on with Rogan and talking about how the FBI had basically set look out for Russian interference in the election.

58:46.600 --> 58:50.600
And then all of these people were out there saying that the laptop was Russian disinformation.

58:50.600 --> 58:55.600
So he basically shut it down. That sort of stuff is frightening, especially because it wasn't Russian disinformation.

58:55.600 --> 58:56.600
I mean, the laptop was real.

58:56.600 --> 59:04.600
And so the fact that you have people who seem to let's put this way, it seems as though maybe this is wrong.

59:04.600 --> 59:11.600
It seems as though when a story gets killed preemptively like this, it is almost universally a story that negatively affects one side of the political aisle.

59:11.600 --> 59:20.600
I can't remember the last time there was a story on the right that was disinformation or misinformation where social media stepped in and they went, we cannot have this.

59:20.600 --> 59:21.600
This cannot be distributed.

59:21.600 --> 59:24.600
We're going to all colludes that this information is not distributed.

59:24.600 --> 59:27.600
Maybe in response to the story being proved false, it gets taken down.

59:27.600 --> 59:31.600
But what made the Hunter Biden thing so amazing is that it wasn't really in response to anything.

59:31.600 --> 59:32.600
It was like the story got posted.

59:32.600 --> 59:37.600
There were no actual doubts expressed as to the verified falsity of the story.

59:37.600 --> 59:40.600
It was just supposition that it had to be false and everybody jumped in.

59:40.600 --> 59:45.600
So I think that confirmed a lot of the conspiracy theories people had about about social media and how it works.

59:45.600 --> 59:46.600
Yeah.

59:46.600 --> 59:56.600
So if the reason you want to slow down the viral spread of a thing is at all grounded in partisanship, that's a problem.

59:56.600 --> 59:59.600
Like you should be very honest with yourself and ask yourself that question.

59:59.600 --> 01:00:06.600
Is it because I'm on the left or on the right that I want to slow this down versus is it hate?

01:00:07.600 --> 01:00:09.600
Bipartisan hate speech.

01:00:09.600 --> 01:00:10.600
Right.

01:00:10.600 --> 01:00:13.600
So it's really tricky.

01:00:13.600 --> 01:00:18.600
But like you, I'm very uncomfortable in general with any kind of slowing down, with any kind of censorship.

01:00:18.600 --> 01:00:33.600
But if there is something like a conspiracy theory that spreads hate, that becomes viral, I still lean to let that conspiracy theory spread because the alternative is dangerous, more dangerous.

01:00:33.600 --> 01:00:35.600
It's sort of like the ring of power, right?

01:00:35.600 --> 01:00:38.600
Everybody wants the ring because with the ring you can stop the bad guys from going forward.

01:00:38.600 --> 01:00:43.600
But it turns out that the ring gives you enormous power and that power can be used in the wrong ways, too.

01:00:43.600 --> 01:00:48.600
You had the Daily Wire, which I'm a member of.

01:00:48.600 --> 01:00:50.600
I appreciate that.

01:00:50.600 --> 01:00:51.600
Thank you.

01:00:51.600 --> 01:00:52.600
I recommend everybody sign up.

01:00:52.600 --> 01:00:56.600
It should be part of your regular diet, whether you're on the left and the right, the far left or the far right.

01:00:56.600 --> 01:00:58.600
Everybody should be part of your regular diet.

01:00:58.600 --> 01:01:03.600
Okay, that said, do you worry about the audience capture aspect of it?

01:01:03.600 --> 01:01:10.600
Because it is a platform for conservatives and you have a powerful voice on there.

01:01:10.600 --> 01:01:22.600
It might be difficult for you to go against the talking points or against the stream of ideas that is usually connected to conservative thought.

01:01:22.600 --> 01:01:24.600
Do you worry about that?

01:01:24.600 --> 01:01:30.600
I mean, the audience would obviously be upset with me and would have a right to be upset with me if I suddenly flipped all of my positions on a dime.

01:01:30.600 --> 01:01:38.600
I have enough faith in my audience that I can say things that I think are true and that may disagree with the audience on a fairly regular basis, I would say.

01:01:38.600 --> 01:01:44.600
But they understand that on the deeper principle, we're on the same side of the aisle, at least I hope that much, from the audience.

01:01:44.600 --> 01:01:52.600
It's also why we provide a number of different views on the platform, many of which I disagree with but are sort of within the generalized range of conservative thought.

01:01:52.600 --> 01:01:56.600
It's something I do have to think about every day though, yeah.

01:01:56.600 --> 01:02:03.600
I mean, you have to think about like, am I saying this because I'm afraid of taking off my audience or am I saying this because I actually believe this?

01:02:03.600 --> 01:02:08.600
And that's a delicate dance a little bit. You have to be sort of honest with yourself.

01:02:08.600 --> 01:02:18.600
Yeah, somebody like Sam Harris is pretty good at this, at saying the most outrageous thing that he knows.

01:02:18.600 --> 01:02:23.600
He almost leans into it. He knows will piss off a lot of his audience.

01:02:23.600 --> 01:02:35.600
Sometimes you almost have to test the system. It's like if you feel you almost exaggerate your feelings just to make sure to send a signal to the audience that you're not captured by them.

01:02:35.600 --> 01:02:45.600
So speaking of people you disagree with, what is your favorite thing about Candice Owens and what is one thing you disagree with her on?

01:02:45.600 --> 01:02:49.600
Well, my favorite thing about Candice is that she will say things that nobody else will say.

01:02:49.600 --> 01:02:53.600
My least favorite thing about Candice is that she will say things that nobody else will say.

01:02:53.600 --> 01:02:59.600
Listen, she says things that are audacious and I think need to be said sometimes.

01:02:59.600 --> 01:03:06.600
Sometimes I think that she is morally wrong. I think the way she responded to Kanye, I've said this clearly, was dead wrong and morally wrong.

01:03:06.600 --> 01:03:07.600
What was her response?

01:03:07.600 --> 01:03:16.600
Her original response was that she proffered confusion of what Ye was actually talking about and then she was defending her friend.

01:03:16.600 --> 01:03:22.600
I wish that the way that she had responded was by saying he's my friend and also he said something bad and anti-Semitic.

01:03:22.600 --> 01:03:25.600
I wish that she had said that.

01:03:25.600 --> 01:03:26.600
Right away.

01:03:26.600 --> 01:03:27.600
Right away.

01:03:27.600 --> 01:03:31.600
Yeah, I think you can also, this is an interesting human thing.

01:03:31.600 --> 01:03:37.600
You can be friends with people that you disagree with and you can be friends with people that actually say hateful stuff.

01:03:37.600 --> 01:03:43.600
And one of the ways to help alleviate hate is being friends with people that say hateful things.

01:03:43.600 --> 01:03:49.600
Yeah, and then calling them out on a personal level when they do say wrong or hateful things.

01:03:49.600 --> 01:03:52.600
Yeah, form a place of love and respect and privately.

01:03:52.600 --> 01:03:54.600
Privately is also a big thing, right?

01:03:54.600 --> 01:04:06.600
The public demand for denunciation from friends to friends is difficult and I certainly have compassion for Candace, given the fact that she's so close with Ye.

01:04:06.600 --> 01:04:11.600
Yeah, it breaks my heart sometimes, the public fights between friends and broken friendships.

01:04:11.600 --> 01:04:16.600
I've seen quite a few friendships publicly break over COVID.

01:04:16.600 --> 01:04:25.600
COVID made people behave their worst in many cases, which breaks my heart a little bit.

01:04:25.600 --> 01:04:34.600
Because the human connection is a prerequisite for effective debate and discussion and battles over ideas.

01:04:34.600 --> 01:04:40.600
Has there been any argument from the opposite political aisle that has made you change your mind about something?

01:04:40.600 --> 01:04:43.600
If you look back.

01:04:44.600 --> 01:04:49.600
So, I will say that the...

01:04:49.600 --> 01:04:55.600
I'm thinking it through because I think that my views probably on foreign policy morphed somewhat.

01:04:55.600 --> 01:04:58.600
I would say that I was much more interventionist when I was younger.

01:04:58.600 --> 01:05:00.600
I'm significantly less interventionist now.

01:05:00.600 --> 01:05:02.600
Are you giving a sample?

01:05:02.600 --> 01:05:04.600
Sure, I was a big backer of the Iraq War.

01:05:04.600 --> 01:05:09.600
I think now in retrospect, I might not be a backer of the Iraq War if the same situation arose again.

01:05:10.600 --> 01:05:18.600
Based on the amount of evidence that had been presented or based on the sort of willingness of the American public to go it.

01:05:18.600 --> 01:05:23.600
If you're going to get involved in a war, you have to know what the end point looks like and you have to know what the American people really are willing to bear.

01:05:23.600 --> 01:05:27.600
The American people are not willing to bear open-ended occupations.

01:05:27.600 --> 01:05:31.600
And so knowing that, you have to consider that going in.

01:05:31.600 --> 01:05:38.600
So on foreign policy, I've become a lot more of a Henry Kissinger realist in some ways.

01:05:38.600 --> 01:05:46.600
When it comes to social policy, I would say that I'm fairly strong where I was.

01:05:46.600 --> 01:05:52.600
I may have become slightly convinced actually by more of the conservative side of the aisle on things like drug legalization.

01:05:52.600 --> 01:05:57.600
I think when I was younger, I was much more pro-drug legalization than I am now, at least on the local level.

01:05:57.600 --> 01:06:04.600
On a federal level, I think the federal government can't really do much other than close the borders with regard to fentanyl trafficking, for example.

01:06:04.600 --> 01:06:08.600
But when it comes to how drugs were in local communities, you can see how drugs were in local communities pretty easily.

01:06:08.600 --> 01:06:12.600
Which is weird because I saw you smoke a joint right before this conversation.

01:06:12.600 --> 01:06:14.600
It's my biggest thing. I mean, I try to keep that secret.

01:06:14.600 --> 01:06:18.600
All right. Well, that's interesting about intervention.

01:06:18.600 --> 01:06:24.600
Can you comment about the war in Ukraine? So for me, it's a deeply personal thing.

01:06:24.600 --> 01:06:28.600
But I think you're able to look at it from a geopolitics perspective.

01:06:28.600 --> 01:06:33.600
What is the role of the United States in this conflict, before the conflict, during the conflict?

01:06:33.600 --> 01:06:37.600
And right now in helping achieve peace?

01:06:37.600 --> 01:06:43.600
I think before the conflict, the big problem is that the West took almost the worst possible view,

01:06:43.600 --> 01:06:48.600
which was encourage Ukraine to keep trying to join NATO and the EU, but don't let them in.

01:06:48.600 --> 01:06:54.600
And so what that does is it achieves the purpose of getting Russia really, really, really ticked off and feeling threatened,

01:06:54.600 --> 01:06:59.600
but also does not give any of the protections of NATO or the EU to Ukraine.

01:06:59.600 --> 01:07:04.600
I mean, you know, Michael Olensky is on film when he was a comedy actor making that exact joke, right?

01:07:04.600 --> 01:07:07.600
He has Merkel on the other line and she's like, oh, welcome to NATO.

01:07:07.600 --> 01:07:10.600
And he's like, great. And she's like, wait, is this Ukraine on the line?

01:07:10.600 --> 01:07:15.600
Oops. But so, you know, that sort of policy is sort of nonsensical.

01:07:15.600 --> 01:07:18.600
If you're going to offer alliance to somebody, offer alliance to them.

01:07:18.600 --> 01:07:20.600
And if you're going to guarantee their security, guarantee their security.

01:07:20.600 --> 01:07:25.600
And the West failed signally to do that. So that was mistakes in the run up to the war.

01:07:25.600 --> 01:07:35.600
Once the war began, then the responsibility of the West began and became to give Ukraine as much material as is necessary to repel the invasion.

01:07:35.600 --> 01:07:40.600
And the West did really well with that. I think we were late on the ball in the United States.

01:07:40.600 --> 01:07:43.600
It seemed like Europe led the way a little bit more than the United States did there.

01:07:43.600 --> 01:07:51.600
But in terms of effectuating American interests in the region, which being an American is what I'm chiefly concerned about.

01:07:51.600 --> 01:07:55.600
The American interests were several fold. One is preserve borders.

01:07:55.600 --> 01:08:03.600
Two is degrade the Russian aggressive military because Russia's military has been aggressive and they are geopolitical rival of the United States.

01:08:03.600 --> 01:08:09.600
Three, recalibrate the European balance with China. Europe was sort of balancing with Russia and China.

01:08:09.600 --> 01:08:16.600
And then because of the war, they sort of rebalanced away from China and Russia, which is a real geostrategic opportunity for the United States.

01:08:16.600 --> 01:08:20.600
It seemed like most of those goals have already been achieved at this point for the United States.

01:08:20.600 --> 01:08:24.600
And so then the question becomes, what's the off ramp here and what is the thing you're trying to prevent?

01:08:24.600 --> 01:08:29.600
So what's the best opportunity? What's the best case scenario? What's the worst case scenario? And then what's realistic?

01:08:29.600 --> 01:08:34.600
So best case scenario is Ukraine forces Russia entirely out of Ukraine, including Luhansk and Crimea.

01:08:34.600 --> 01:08:39.600
That's the best case scenario. Virtually no one thinks that's accomplishable, including the United States.

01:08:39.600 --> 01:08:45.600
The White House has basically said as much. It's still cool to imagine, particularly Crimea, the Russians being forced out of Crimea.

01:08:45.600 --> 01:08:50.600
The Ukrainians have been successful in pushing the Russians out of certain parts of Luhansk and Donetsk,

01:08:50.600 --> 01:08:55.600
but the idea that they're going to be able to push the entire Russian army completely back to the Russian borders,

01:08:55.600 --> 01:09:00.600
that would be at best a very, very long and difficult slog in the middle of a collapsing Ukrainian economy,

01:09:00.600 --> 01:09:04.600
which is a point that Zelensky has made. It's like, it's not enough for you guys to give us military aid.

01:09:04.600 --> 01:09:08.600
We're in the middle of a war. We're going to need economic aid as well. So it's a pretty open ended and strong commitment.

01:09:08.600 --> 01:09:15.600
Can I take a small tangent on that and your best case scenario? If that does militarily happen, including Crimea,

01:09:15.600 --> 01:09:26.600
do you think there's a world in which Vladimir Putin would be able to convince the Russian people that this was a good conclusion to the war?

01:09:26.600 --> 01:09:30.600
Right. So the problem is that the best case scenario might also be the worst case scenario,

01:09:30.600 --> 01:09:35.600
meaning that there are a couple of scenarios that are sort of the worst case scenario, and this is sort of the puzzlement of the situation.

01:09:35.600 --> 01:09:40.600
One is that Putin feels so boxed in, so unable to go back to his own people and say,

01:09:40.600 --> 01:09:46.600
we just wasted tens of thousands of lives here for no reason that he unleashed a tactical nuclear weapon on the battlefield.

01:09:46.600 --> 01:09:53.600
Nobody knows what happens after that. So we put NATO planes in the air to take out Russian assets. Do Russians start shooting down planes?

01:09:53.600 --> 01:10:00.600
Does Russia then threaten to escalate even further by attacking an actual NATO civilian center or even Ukrainian civilian center with nuclear weapons?

01:10:00.600 --> 01:10:04.600
Where it goes from there, nobody knows because nuclear weapons haven't been used since 1945.

01:10:04.600 --> 01:10:11.600
So that is a worst case scenario. It's an unpredictable scenario that could devolve into really, really significant problems.

01:10:11.600 --> 01:10:16.600
The other worst case scenario, could be a best case scenario, could be a worse, we just don't know, is Putin falls.

01:10:16.600 --> 01:10:23.600
What happens after that? Who takes over for Putin? Is that person more moderate than Putin? Is that person a liberalizer?

01:10:23.600 --> 01:10:32.600
It probably won't be Navalny. If he's going to be ousted, it'll probably be somebody who's a top member of Putin's brass right now and has capacity to control the military.

01:10:32.600 --> 01:10:37.600
Or it's possible the entire regime breaks down. What you end up with is Syria in Russia, right?

01:10:37.600 --> 01:10:43.600
Where you just have an entirely out of control region with no centralizing power, which is also a disaster area.

01:10:43.600 --> 01:10:54.600
And so in the nature of risk mitigation, in sort of an attempt at risk mitigation, what actually should be happening right now is some off ramp has to be offered to Putin.

01:10:54.600 --> 01:10:58.600
The off ramp likely is going to be him maintaining Crimea and parts of Luhansk and Donetsk.

01:10:58.600 --> 01:11:11.600
It's probably going to be a commitment by Ukraine not to join NATO formally, but a guarantee by the West to defend Ukraine in case of an invasion of its borders again by Russia, like an actual treaty obligation.

01:11:11.600 --> 01:11:16.600
Not like the BS treaty obligation when Ukraine gave up its nuclear weapons in the 90s.

01:11:16.600 --> 01:11:20.600
And that is likely how this is going to have to go.

01:11:21.600 --> 01:11:25.600
The problem is that requires political courage, not from Zelensky.

01:11:25.600 --> 01:11:36.600
It requires courage from probably Biden because Zelensky is not in a political position where he can go back to his own people who have made unbelievable sacrifices on behalf of their nation and freedom and say to them, guys, now I'm calling it quits.

01:11:36.600 --> 01:11:39.600
We're going to have to give them Luhansk and Donetsk and give Putin an off ramp.

01:11:39.600 --> 01:11:44.600
I don't think that's an acceptable answer to most Ukrainians at this point in time from the polling data and from the available data we have on the ground.

01:11:44.600 --> 01:11:52.600
It's going to actually take Biden biting the bullet and being the bad guy and saying to Zelensky, listen, we've made a commitment of material aid.

01:11:52.600 --> 01:11:56.600
We were offering you all these things, including essentially a defense pact.

01:11:56.600 --> 01:11:58.600
We're offering you all this stuff.

01:11:58.600 --> 01:12:03.600
But if you don't come to the table, then we're going to have to start weaning you like there will have to be a stick there.

01:12:03.600 --> 01:12:04.600
It can't just be a carrot.

01:12:04.600 --> 01:12:10.600
And so that will allow Zelensky, if Biden were to do that, would allow Zelensky to blame Biden for the solution everybody knows has to happen.

01:12:11.600 --> 01:12:15.600
Zelensky can go back to his own people and he can say, listen, this is the way it has to go.

01:12:15.600 --> 01:12:18.600
I don't want it to go this way, but it's not my I'm signing other people's checks.

01:12:18.600 --> 01:12:21.600
Right. I mean, like this is it's not my money.

01:12:21.600 --> 01:12:27.600
And Biden would take the hit because he wouldn't then be able to blame Ukraine for whatever happens next, which has been the easy road off.

01:12:27.600 --> 01:12:32.600
I think for a lot of politicians in the West is for them to just say, well, this is up to the Ukrainians to decide.

01:12:32.600 --> 01:12:33.600
It's up to the Ukrainians to decide.

01:12:33.600 --> 01:12:36.600
Well, is it totally up to the Ukrainians to decide?

01:12:36.600 --> 01:12:40.600
Because it seems like the West is signing an awful lot of checks and all of Europe is going to freeze this winter.

01:12:40.600 --> 01:12:44.600
So this is the importance of great leadership, by the way.

01:12:44.600 --> 01:12:47.600
That's why the people we elect is very important.

01:12:47.600 --> 01:12:59.600
Do you think do you think there's power to just one on one conversation or Biden sits down with Zelensky and Biden sits down with Putin almost in person?

01:12:59.600 --> 01:13:15.600
Because I maybe I'm romanticizing the notion, but having done these podcasts in person, I think there's something fundamentally different than through a remote call and also like a distant kind of recorded political type speak versus like man to man.

01:13:15.600 --> 01:13:22.600
So I'm deeply afraid that Putin outplays people in the one on one scenarios because he's done it to multiple presidents already.

01:13:23.600 --> 01:13:32.600
He gets in one on one scenarios with Bush, with Obama, with Trump, with Biden, and he seems to be a very canny operator and a very sort of hard nosed operator in those situations.

01:13:32.600 --> 01:13:40.600
I think that if you were going to do something like that, like an actual political face to face summit, what you would need is for Biden to first have a conversation with Zelensky where Zelensky knows what's going on.

01:13:40.600 --> 01:13:42.600
So he's aware.

01:13:42.600 --> 01:13:48.600
And then Biden walks in and he says to Putin on camera, here's the offer.

01:13:48.600 --> 01:13:49.600
Let's get it together.

01:13:49.600 --> 01:13:51.600
Let's make peace.

01:13:51.600 --> 01:13:57.600
You get to keep this stuff and then let Putin respond how Putin is going to respond.

01:13:57.600 --> 01:14:03.600
But the big problem for Putin, I think, and the problem with public facing fora, maybe it's a private meeting.

01:14:03.600 --> 01:14:05.600
If it's a private meeting, maybe that's the best thing.

01:14:05.600 --> 01:14:08.600
If it's a public facing forum, I think it's a problem because Putin's afraid of being humiliated at this point.

01:14:09.600 --> 01:14:27.600
If it's a private meeting, then sure, except that, again, I wonder whether when it comes to a person as canny as Putin and to a politician that I really don't think is a particularly sophisticated player in Joe Biden.

01:14:27.600 --> 01:14:29.600
And again, this is not unique to Biden.

01:14:29.600 --> 01:14:35.600
I think that most of our presidents for the last 30, 40 years have not been particularly sophisticated players.

01:14:35.600 --> 01:14:38.600
I think that that's a risky scenario.

01:14:38.600 --> 01:14:45.600
Yeah, I still believe in the power of that because otherwise, I don't know.

01:14:45.600 --> 01:14:54.600
I don't think stuff on paper and political speak will solve these kinds of problems because from Zelensky's perspective, nothing but complete victory will do.

01:14:54.600 --> 01:14:55.600
Right.

01:14:55.600 --> 01:15:00.600
As a nation, his people sacrificed way too much and they're all in.

01:15:00.600 --> 01:15:03.600
And if you look at, because I traveled to Ukraine, I spent time there.

01:15:03.600 --> 01:15:06.600
I'll be going back there, hopefully also going back to Russia.

01:15:06.600 --> 01:15:11.600
Just speaking to Ukrainians, they're all in.

01:15:11.600 --> 01:15:13.600
They're all in.

01:15:13.600 --> 01:15:14.600
Yeah.

01:15:14.600 --> 01:15:15.600
Nothing but complete victory.

01:15:15.600 --> 01:15:16.600
Yep, that's right.

01:15:16.600 --> 01:15:30.600
And so for that, the only way to achieve peace is through like honest human to human conversation, giving both people a way to off ramp, to walk away victorious.

01:15:30.600 --> 01:15:45.600
And some of that requires speaking honestly as a human being, but also for America to, actually not even America, honestly, just the president be able to eat their own ego a bit and be the punching bag.

01:15:45.600 --> 01:15:53.600
Just enough for both presidents to be able to walk away and say, listen, we got the American president to come to us.

01:15:53.600 --> 01:15:58.600
And I think that makes the president look strong, not weak.

01:15:58.600 --> 01:15:59.600
I mean, I agree with you.

01:15:59.600 --> 01:16:06.600
I think it would also require some people on the right, people like me, if it's Joe Biden, to say if Biden does that, I see what he's doing and it's the right move.

01:16:06.600 --> 01:16:16.600
I think one of the things that he's afraid of, to steel man him, I think one of the things he's afraid of is he goes and he makes that sort of deal and the right says you just cowered in front of Russia, you just gave away Ukraine, whatever it is.

01:16:16.600 --> 01:16:24.600
But it's going to require some people on the right to say that that move is the right move and then hold by it if Biden actually performs that move.

01:16:24.600 --> 01:16:27.600
You're exceptionally good at debate.

01:16:27.600 --> 01:16:31.600
You wrote how the debate leftist destroyed them.

01:16:31.600 --> 01:16:43.600
You're kind of known for this kind of stuff, just exceptionally skilled at conversation and debate and getting to the facts of the matter and using logic to get to the conclusion in the debate.

01:16:43.600 --> 01:16:56.600
Do you ever worry that this power, talk about the ring, this power you were given has corrupted you and your ability to see what's like to pursue the truth.

01:16:56.600 --> 01:16:57.600
Versus just winning debates.

01:16:57.600 --> 01:16:58.600
I hope not.

01:16:58.600 --> 01:17:12.600
I mean, so I think one of the things that's kind of funny about the branding versus the reality is that most of the things that get characterized as destroying in debates with facts and logic, most of those things are basically me having a conversation with somebody on a college campus.

01:17:12.600 --> 01:17:18.600
It actually isn't like a formal debate where we sit there and we critique each other's positions or it's not me insulting anybody.

01:17:18.600 --> 01:17:23.600
A lot of the clips that have gone very viral is me making an argument and then they're not being like an amazing counter argument.

01:17:23.600 --> 01:17:24.600
Thank you.

01:17:24.600 --> 01:17:27.600
Many of the debates that I've held have been extremely cordial.

01:17:27.600 --> 01:17:28.600
Let's take the latest example.

01:17:28.600 --> 01:17:30.600
About a year ago, I debated Anna Kasparian from Young Turks.

01:17:30.600 --> 01:17:31.600
It was very cordial.

01:17:31.600 --> 01:17:33.600
It was very nice, right?

01:17:33.600 --> 01:17:36.600
That's sort of the way that I like to debate.

01:17:36.600 --> 01:17:43.600
My rule when it comes to debate and or discussion is that my opponent actually gets to pick the mode in which we work.

01:17:43.600 --> 01:17:49.600
So if it's going to be a debate of ideas and we're just going to discuss and critique and clarify, then we can do that.

01:17:49.600 --> 01:18:02.600
If somebody comes loaded for bear, then I will respond in kind because one of the big problems I think in sort of the debate slash discussion sphere is very often misdiagnosis of what exactly is going on.

01:18:02.600 --> 01:18:05.600
People who think that a discussion is a debate and vice versa.

01:18:05.600 --> 01:18:08.600
And that can be a real problem.

01:18:08.600 --> 01:18:16.600
And there are people who will treat what ought to be a discussion as, for example, an exercise in performance art.

01:18:16.600 --> 01:18:21.600
And so what that is is mugging or trolling or saying trolly things in order to just get to that.

01:18:21.600 --> 01:18:23.600
That's something I actually don't do during debate.

01:18:23.600 --> 01:18:26.600
I mean, if you actually watch me talk to people, I don't actually do the trolling thing.

01:18:26.600 --> 01:18:29.600
The trolling thing is almost solely relegated to Twitter and me making jokes on my show.

01:18:29.600 --> 01:18:34.600
When it comes to actually debating people, that sounds actually a lot like what we're doing right now.

01:18:34.600 --> 01:18:38.600
It's just the person maybe taking just an obverse position to mind.

01:18:38.600 --> 01:18:40.600
And so that's fine.

01:18:40.600 --> 01:18:44.600
Usually half of the debate or discussion is me just asking for clarification of terms.

01:18:44.600 --> 01:18:49.600
Like, what exactly do you mean by this so I can drill down on where the actual disagreement may lie?

01:18:49.600 --> 01:18:52.600
Because some of the time people think they're disagreeing and they're actually not disagreeing.

01:18:52.600 --> 01:18:57.600
When I'm talking with Anna Kasparian and she's talking about how corporate and government have too much power together,

01:18:57.600 --> 01:18:58.600
I'm like, well, you sound like a tea party.

01:18:58.600 --> 01:19:00.600
You and I are on the same page about that.

01:19:00.600 --> 01:19:03.600
That sort of stuff does tend to happen a lot in discussion.

01:19:03.600 --> 01:19:06.600
I think that when discussion gets termed debate, it's a problem.

01:19:06.600 --> 01:19:10.600
When debate gets termed discussion, it's even more problematic because debate is a different thing.

01:19:10.600 --> 01:19:13.600
And I find that your debate and your conversation is often good faith.

01:19:13.600 --> 01:19:15.600
You're able to steal man the other side.

01:19:15.600 --> 01:19:17.600
You're able to actually you're actually listening.

01:19:17.600 --> 01:19:18.600
You're considering the other side.

01:19:18.600 --> 01:19:22.600
The times when I see that, you know, Ben Shapiro destroys leftist.

01:19:22.600 --> 01:19:37.600
It's usually just like you said, the other side is doing the trolling because they've I mean, the people that do criticize you for that interaction is the people that usually get destroyed are like 20 years old.

01:19:37.600 --> 01:19:45.600
And they're usually not sophisticated in any kind of degree in terms of being able to use logic and reason and facts and so on.

01:19:45.600 --> 01:19:46.600
And that's that's totally fine, by the way.

01:19:46.600 --> 01:19:52.600
I mean, if people want to criticize me for speaking on college campuses where a lot of political conversation happens, both right and left, that's fine.

01:19:52.600 --> 01:19:55.600
I mean, I've had lots of conversations with people on the other side of the aisle, too.

01:19:55.600 --> 01:19:57.600
I mean, right. I've done podcasts with Sam Harris.

01:19:57.600 --> 01:20:01.600
We've talked about atheism or I've done debates with Anna Kasparian or I've talked to them.

01:20:01.600 --> 01:20:05.600
I've done debate with Chank Weger or I've I've had conversations with lots of people on the other side of the aisle.

01:20:05.600 --> 01:20:09.600
In fact, I believe I'm the only person on the right who recommends that people listen to shows on the other side of the aisle.

01:20:09.600 --> 01:20:13.600
Right. I mean, I say on my show on a fairly regular basis that people should listen to Pods of America.

01:20:13.600 --> 01:20:16.600
Now, no one on Pods of America will ever say that somebody should listen to my show.

01:20:16.600 --> 01:20:19.600
That is verboten. That is not something that can be had.

01:20:19.600 --> 01:20:21.600
It's one of the strangenesses of our politics.

01:20:21.600 --> 01:20:27.600
It's what I've called the happy birthday problem, which is I have a lot of friends who are of the left and are publicly of the left.

01:20:27.600 --> 01:20:29.600
And on my birthday, they'll send you a text message.

01:20:29.600 --> 01:20:34.600
Happy birthday, but they will never tweet happy birthday, lest they be acknowledging that you were born of woman.

01:20:34.600 --> 01:20:36.600
And this can't be allowed.

01:20:36.600 --> 01:20:41.600
So on the Sunday special, I've had a bevy of people who are on the other side of the aisle.

01:20:41.600 --> 01:20:49.600
A lot of them ranging from people in Hollywood like Jason Blum to Larry Wilmore to Sam to just a lot of people on the left.

01:20:49.600 --> 01:20:55.600
I think we're in the near future probably going to do a Sunday special with Rokana up in California, the California congressperson.

01:20:55.600 --> 01:20:56.600
Very nice guy. I had him on the show.

01:20:56.600 --> 01:20:59.600
That kind of stuff is fun and interesting.

01:20:59.600 --> 01:21:05.600
But I think that the easy way out for a clip that people don't like is to either immediately clip the clip.

01:21:05.600 --> 01:21:11.600
I'll take a two-minute clip and clip it down to 15 seconds where somebody insults me and then that goes viral, which is welcome to the Internet.

01:21:11.600 --> 01:21:16.600
Or to say, well, you're only debating colleges. You're only talking to 20.

01:21:16.600 --> 01:21:19.600
I mean, I talk to a lot more people than that. That's just not the stuff you're watching.

01:21:19.600 --> 01:21:29.600
You lost your cool in an interview with BBC's Andrew and Neil, and you're really honest about it after, which was kind of refreshing and enjoyable.

01:21:29.600 --> 01:21:34.600
As the Internet said, they've never seen anyone lose an interview.

01:21:34.600 --> 01:21:41.600
So to me, honestly, it was like seeing Floyd Mayweather Jr. or somebody like knocked down.

01:21:41.600 --> 01:21:44.600
What was it? Can you take me through that experience?

01:21:44.600 --> 01:21:46.600
Here's that day. That day is I have a book release.

01:21:46.600 --> 01:21:51.600
Didn't get a lot of sleep the night before, and this is the last interview of the day, and it's an interview with BBC.

01:21:51.600 --> 01:21:54.600
I don't know anything about BBC. I don't watch BBC. I don't know any of the hosts.

01:21:54.600 --> 01:22:03.600
So we get on the interview, and it's supposed to be about the book, and the host, Andrew, Neil, doesn't ask virtually a single question about the book.

01:22:03.600 --> 01:22:06.600
He just starts reading me bad old tweets, which I hate.

01:22:06.600 --> 01:22:13.600
I mean, it's annoying and it's stupid, and it's the worst form of interview when somebody just reads you bad old tweets, especially when I've acknowledged bad old tweets before.

01:22:13.600 --> 01:22:17.600
And so I'm going through the list with him, and this interview was solidly 20 minutes.

01:22:17.600 --> 01:22:24.600
I mean, it was a long interview, and I make a couple of particularly annoyed mistakes in the interview.

01:22:24.600 --> 01:22:28.600
So annoyed mistake number one is the ego play, right?

01:22:28.600 --> 01:22:32.600
So there's a point in the middle of the interview where I say, like, I don't even know who you are, which was true.

01:22:32.600 --> 01:22:36.600
I didn't know who he was. It turns out he's a very famous person in Britain, and so you can't make that ego play.

01:22:36.600 --> 01:22:38.600
But even if he's not famous, that's not...

01:22:38.600 --> 01:22:40.600
It's a dumb thing to do, and it's an ass thing to do.

01:22:40.600 --> 01:22:45.600
So saying that was more just kind of peak and silliness.

01:22:45.600 --> 01:22:47.600
And so that was mistake number one.

01:22:47.600 --> 01:22:50.600
I enjoyed watching that. It was like, oh, Ben is human.

01:22:50.600 --> 01:22:54.600
Glad somebody enjoyed it. So there's that.

01:22:54.600 --> 01:22:58.600
And then the other mistake was that I just don't watch enough British TV.

01:22:58.600 --> 01:23:02.600
So the way that interviews are done there are much more adversarial than American TV.

01:23:02.600 --> 01:23:06.600
In American TV, if somebody is adversarial with you, you assume that they're a member of the other side.

01:23:06.600 --> 01:23:07.600
That's typically how it is.

01:23:07.600 --> 01:23:12.600
And so I'm critiquing some of his questions at the beginning, and I thought that the critique of some of his questions is actually fair.

01:23:12.600 --> 01:23:17.600
He was asking me about abortion, and I thought he was asking it from a way of framing the question that wasn't accurate.

01:23:17.600 --> 01:23:20.600
And so I assumed that he was on the left because, again, I'd never heard of him.

01:23:20.600 --> 01:23:25.600
And so, you know, I mischaracterized him, and I apologize later for mischaracterizing him.

01:23:25.600 --> 01:23:28.600
We finally go through the interview. It's 20 minutes.

01:23:28.600 --> 01:23:30.600
He just keeps going with the bad old tweets.

01:23:30.600 --> 01:23:33.600
And finally, I got up and I took off the microphone and walked out.

01:23:33.600 --> 01:23:35.600
And immediately, I knew it was a mistake.

01:23:35.600 --> 01:23:38.600
Like within 30 seconds of the end of the interview, I knew it was a mistake.

01:23:38.600 --> 01:23:45.600
And that's why even before the interview came out, I believe I corrected the record that Andrew Neil is not on the left.

01:23:45.600 --> 01:23:47.600
That's a mistake by me.

01:23:47.600 --> 01:23:51.600
And then, you know, took the hit for a bad interview.

01:23:51.600 --> 01:23:57.600
And so as far as, you know, what I wish I had done differently, I wish I had known who he was, I wish I had done my research,

01:23:57.600 --> 01:24:02.600
I wish that I had treated it as though there was a possibility that it was going to be more adversarial than it was.

01:24:02.600 --> 01:24:07.600
I think I was incautious about the interview because it was pitched as it's just another book interview.

01:24:07.600 --> 01:24:10.600
And it wasn't just another book interview. It was treated much more adversarial than that.

01:24:10.600 --> 01:24:12.600
So I wish that that's on me.

01:24:12.600 --> 01:24:17.600
I got to research the people who are talking to me and watch their shows and learn about that.

01:24:17.600 --> 01:24:25.600
And then obviously, you know, the kind of gut level appeal to ego or arrogance like that, that's a bad luck and shouldn't have done that.

01:24:25.600 --> 01:24:27.600
And losing your cool is always a bad luck.

01:24:27.600 --> 01:24:35.600
So the fact that that sort of became somewhat viral and stood out just shows that it happens so rarely to you.

01:24:35.600 --> 01:24:46.600
So just to look at like the day in the life of Ben Shapiro, you speak a lot very eloquently about difficult topics.

01:24:46.600 --> 01:24:48.600
What goes into the research, the mental part?

01:24:48.600 --> 01:24:54.600
And you always look pretty like energetic and you're not exhausted by the burden,

01:24:54.600 --> 01:24:59.600
the heaviness of the topics you're covering day after day after day after day.

01:24:59.600 --> 01:25:05.600
So what goes through the preparation mentally, diet wise, anything like that?

01:25:05.600 --> 01:25:06.600
When do you wake up?

01:25:06.600 --> 01:25:08.600
OK, so I wake up when my kids wake me up.

01:25:08.600 --> 01:25:11.600
Usually that's my baby daughter who's two and a half.

01:25:11.600 --> 01:25:15.600
We are on the monitor usually about 6.15, 6.20 a.m.

01:25:15.600 --> 01:25:17.600
So I get up, my wife sleeps in a little bit.

01:25:17.600 --> 01:25:22.600
I go get the baby and then my son gets up and then my oldest daughter gets up.

01:25:22.600 --> 01:25:23.600
I have eight, six and two.

01:25:23.600 --> 01:25:25.600
The boy's the middle child.

01:25:25.600 --> 01:25:27.600
Is that both the source of stress and happiness?

01:25:27.600 --> 01:25:29.600
Oh my God, it's the height of both, right?

01:25:29.600 --> 01:25:31.600
I mean, it's the source of the greatest happiness.

01:25:31.600 --> 01:25:35.600
So the way that I characterize it is this when it comes to sort of kids in life.

01:25:35.600 --> 01:25:38.600
So when you're single, your boundaries of happiness and unhappiness,

01:25:38.600 --> 01:25:41.600
you can be a zero in terms of happiness, you can be like a 10 in terms of happiness.

01:25:41.600 --> 01:25:43.600
Then you get married and it goes up to like a 20 and a negative 20

01:25:43.600 --> 01:25:48.600
because your happiest stuff is with your wife and then the most unhappy stuff is when something happens to your spouse.

01:25:48.600 --> 01:25:49.600
It's the worst thing in the entire world.

01:25:49.600 --> 01:25:51.600
Then you have kids and all limits are removed.

01:25:51.600 --> 01:25:54.600
So the best things that have ever happened to me are things where I'm watching my kids

01:25:54.600 --> 01:25:57.600
and they're playing together and they're being wonderful and sweet and cute and I love them so much.

01:25:57.600 --> 01:26:02.600
And the worst things are when my son is screaming at me for no reason because he's being insane

01:26:02.600 --> 01:26:04.600
and I have to deal with that.

01:26:04.600 --> 01:26:07.600
Or something bad happens to my daughter at school or something like that.

01:26:07.600 --> 01:26:08.600
That stuff is really bad.

01:26:08.600 --> 01:26:10.600
So yes, the source of my greatest happiness, the source of my greatest stress.

01:26:10.600 --> 01:26:12.600
So they get me up at about 6.15 in the morning.

01:26:12.600 --> 01:26:13.600
I feed them breakfast.

01:26:13.600 --> 01:26:16.600
I'm kind of scrolling the news while I'm making them eggs.

01:26:16.600 --> 01:26:21.600
And just updating myself on anything that may have happened overnight.

01:26:21.600 --> 01:26:26.600
I go into the office, put on the makeup and the wardrobe or whatever.

01:26:26.600 --> 01:26:29.600
And then I sit down and do the show.

01:26:29.600 --> 01:26:33.600
A lot of the prep is actually done the night before because the news cycle doesn't change all that much

01:26:33.600 --> 01:26:37.600
between kind of late at night and in the morning so I can supplement in the morning.

01:26:37.600 --> 01:26:39.600
So I do the show.

01:26:39.600 --> 01:26:43.600
So a lot of the preparation, like thinking through what are the big issues in the world is done the night before.

01:26:43.600 --> 01:26:44.600
Yeah.

01:26:44.600 --> 01:26:46.600
And that's reading pretty much all the legacy media.

01:26:46.600 --> 01:26:50.600
So I rip on legacy media a lot but that's because a lot of what they do is really good

01:26:50.600 --> 01:26:51.600
and a lot of what they do is really bad.

01:26:51.600 --> 01:26:53.600
I cover a lot of legacy media.

01:26:53.600 --> 01:26:58.600
So that's probably covering Wall Street Journal, New York Times, Washington Post, Boston Globe, Daily Mail.

01:26:58.600 --> 01:27:00.600
And then I'll look over at some of the alternative media.

01:27:00.600 --> 01:27:01.600
I'll look at my own website, Daily Wire.

01:27:01.600 --> 01:27:02.600
I'll look at Breitbart.

01:27:02.600 --> 01:27:03.600
I'll look at The Blaze.

01:27:03.600 --> 01:27:05.600
I'll look at maybe The Intercept.

01:27:05.600 --> 01:27:08.600
I'll look at a bunch of different sources.

01:27:08.600 --> 01:27:11.600
And then I will look at different clips online.

01:27:11.600 --> 01:27:13.600
So MediaEye comes in handy here.

01:27:13.600 --> 01:27:15.600
Grabian comes in handy here.

01:27:15.600 --> 01:27:18.600
That sort of stuff because my show relies very heavily on being able to play people

01:27:18.600 --> 01:27:20.600
so you can hear them in their own words.

01:27:20.600 --> 01:27:22.600
And so that's sort of the MediaEye.

01:27:22.600 --> 01:27:23.600
So I sit down.

01:27:23.600 --> 01:27:25.600
I do the show.

01:27:25.600 --> 01:27:32.600
And then once I'm done with the show, I usually have between now it's like 11, 15 in the morning maybe

01:27:32.600 --> 01:27:33.600
because sometimes I'll pre-record the show.

01:27:33.600 --> 01:27:35.600
So it's 11, 15 in the morning.

01:27:35.600 --> 01:27:37.600
I'll go home.

01:27:37.600 --> 01:27:39.600
And if my wife's available, I'll grab lunch with her.

01:27:39.600 --> 01:27:42.600
If not, then I will go and work out.

01:27:42.600 --> 01:27:46.600
I try to work out like five times a week with the trainer, something like that.

01:27:46.600 --> 01:27:49.600
And then I will...

01:27:49.600 --> 01:27:50.600
Just regular gym stuff?

01:27:50.600 --> 01:27:52.600
Just going to the gym?

01:27:52.600 --> 01:27:57.600
Yeah, weights and plyometrics and some CrossFit kind of stuff.

01:27:57.600 --> 01:28:02.600
Yeah, I mean beneath this mild exterior lies a hulking monster.

01:28:02.600 --> 01:28:05.600
And so I'll do that.

01:28:05.600 --> 01:28:10.600
Then I will do reading and writing.

01:28:10.600 --> 01:28:13.600
So I'm usually working on a book at any given time.

01:28:13.600 --> 01:28:15.600
Do you shut off the rest of the world?

01:28:15.600 --> 01:28:16.600
Yes.

01:28:16.600 --> 01:28:18.600
So I put some music in my ears, usually Brahms or Bach.

01:28:18.600 --> 01:28:20.600
Sometimes Beethoven or Mozart.

01:28:20.600 --> 01:28:21.600
It's those four.

01:28:21.600 --> 01:28:22.600
Those are on rotation.

01:28:22.600 --> 01:28:23.600
No rap?

01:28:23.600 --> 01:28:24.600
No rap.

01:28:24.600 --> 01:28:25.600
No rap.

01:28:25.600 --> 01:28:28.600
Despite my extraordinary rendition of WAP, I am not in fact a rap fan.

01:28:28.600 --> 01:28:31.600
Do you still hate WAP, the song?

01:28:31.600 --> 01:28:35.600
I will say I do not think that it is the peak of Western civilized art.

01:28:35.600 --> 01:28:40.600
I don't think that 100 years from now people will be gluing their faces to a WAP and protest at the environment.

01:28:40.600 --> 01:28:43.600
But Brahms and the rest will be still around?

01:28:43.600 --> 01:28:44.600
Yes.

01:28:44.600 --> 01:28:47.600
I would assume if people still have a functioning prefrontal cortex and any sort of taste.

01:28:47.600 --> 01:28:50.600
Strong words from Ben Shapiro.

01:28:50.600 --> 01:28:53.600
All right, so you got some classical music in your ears and you're focusing.

01:28:53.600 --> 01:28:55.600
Are you at the computer when you're writing?

01:28:55.600 --> 01:28:57.600
Yeah, I'm at the computer.

01:28:57.600 --> 01:29:01.600
Usually we have a kind of a room that has some sun coming in, so it's nice in there.

01:29:01.600 --> 01:29:04.600
Or I'll go up to a library that we just completed for me.

01:29:04.600 --> 01:29:06.600
So I'll go up there and I'll write and read.

01:29:06.600 --> 01:29:07.600
Like with physical books?

01:29:07.600 --> 01:29:09.600
Yeah, I love physical books.

01:29:09.600 --> 01:29:12.600
Because I keep Sabbath, I don't use Kindle.

01:29:12.600 --> 01:29:16.600
Because when I'm reading a book and it hits Sabbath, I have to turn off the Kindle.

01:29:16.600 --> 01:29:19.600
So that means that I have tons and tons and tons of physical books.

01:29:19.600 --> 01:29:22.600
When we moved from Los Angeles to Florida, I had about 7,000 volumes.

01:29:22.600 --> 01:29:25.600
I had to discard probably 4,000 of them.

01:29:25.600 --> 01:29:27.600
And then I've built that back up now.

01:29:27.600 --> 01:29:30.600
So I'm probably going to have to go through another round where I put them somewhere else.

01:29:30.600 --> 01:29:34.600
I tend to tab books rather than highlighting them because I can't highlight on Sabbath.

01:29:34.600 --> 01:29:37.600
So I have like the little stickers and I put them in the book.

01:29:37.600 --> 01:29:41.600
So a typical book for me, you can see it on the book club, will be like filled with tabs on the side.

01:29:41.600 --> 01:29:43.600
Things that I want to take.

01:29:43.600 --> 01:29:51.600
Actually, I got a person who I pay to go through and write down in files the quotes that I like from the book.

01:29:51.600 --> 01:29:53.600
So I have those handy.

01:29:53.600 --> 01:29:56.600
Which is a good way for me to remember what it is that I've read.

01:29:56.600 --> 01:30:01.600
Because I read probably somewhere between three and five books a week.

01:30:01.600 --> 01:30:04.600
And then in a good week five.

01:30:04.600 --> 01:30:10.600
And then I write, I read, and then I go pick up my kids from school at 3.30.

01:30:10.600 --> 01:30:12.600
So according to my kids, I have no job.

01:30:12.600 --> 01:30:14.600
I'm there in the mornings until they leave for school.

01:30:14.600 --> 01:30:15.600
I pick them up from school.

01:30:15.600 --> 01:30:19.600
I hang out with them until they go to bed, which is usually 7.30 or so.

01:30:19.600 --> 01:30:21.600
So I'm helping them with their homework and I'm playing with them.

01:30:21.600 --> 01:30:26.600
And I'm taking them on rides in the brand new Tesla, which my son is obsessed with.

01:30:26.600 --> 01:30:28.600
And then I put them to bed.

01:30:28.600 --> 01:30:29.600
And then I sit back down.

01:30:29.600 --> 01:30:30.600
I prep for the next day.

01:30:30.600 --> 01:30:31.600
I go through all those media sources I was talking about.

01:30:31.600 --> 01:30:34.600
Compile kind of a schedule for what I want the show to look like.

01:30:34.600 --> 01:30:35.600
And run a show.

01:30:35.600 --> 01:30:36.600
It's very detail-oriented.

01:30:36.600 --> 01:30:37.600
Nobody writes anything for me.

01:30:37.600 --> 01:30:39.600
I write all my own stuff.

01:30:39.600 --> 01:30:41.600
So every word that comes out of my mouth is my fault.

01:30:41.600 --> 01:30:48.600
And then hopefully I have a couple hours or an hour to hang out with my wife before we go to bed.

01:30:48.600 --> 01:30:50.600
The words you write, do you edit a lot?

01:30:50.600 --> 01:30:52.600
Or does it just come out?

01:30:52.600 --> 01:30:54.600
You're thinking, what are the key ideas I want to express?

01:30:54.600 --> 01:30:56.600
No, I don't tend to edit a lot.

01:30:56.600 --> 01:30:59.600
So thank God I'm able to write extraordinarily quickly.

01:30:59.600 --> 01:31:00.600
So I write very, very fast.

01:31:00.600 --> 01:31:02.600
In fact, in a previous life, I was...

01:31:02.600 --> 01:31:04.600
You also speak fast, so it's similar.

01:31:04.600 --> 01:31:05.600
Yeah, exactly.

01:31:05.600 --> 01:31:06.600
And I speak in paragraphs.

01:31:06.600 --> 01:31:08.600
So it's exactly the same thing.

01:31:08.600 --> 01:31:10.600
In a previous life, I was a ghostwriter.

01:31:10.600 --> 01:31:13.600
So I used to be sort of known as a turnaround specialist in the publishing industry.

01:31:13.600 --> 01:31:16.600
There would be somebody who came to the publisher and says,

01:31:16.600 --> 01:31:17.600
I have three weeks.

01:31:17.600 --> 01:31:19.600
And to get this book done, I don't have a word done.

01:31:19.600 --> 01:31:22.600
And they would call me up and be like, this person needs a book written.

01:31:22.600 --> 01:31:25.600
And so in three weeks, I'd knock out 60,000 words or so.

01:31:25.600 --> 01:31:29.600
Is there something you can say to the process that you follow to think?

01:31:29.600 --> 01:31:31.600
Like how you think about ideas?

01:31:31.600 --> 01:31:36.600
Like stuff is going on in the world and trying to understand what is happening.

01:31:36.600 --> 01:31:37.600
What are the explanations?

01:31:37.600 --> 01:31:39.600
What are the forces behind this?

01:31:39.600 --> 01:31:44.600
Do you have a process or just you wait for the muse to give you the interpretation?

01:31:44.600 --> 01:31:48.600
Well, I mean, I think that I don't think it's a formal process, but because I read.

01:31:48.600 --> 01:31:50.600
So there's two ways to do it.

01:31:50.600 --> 01:31:59.600
One is sometimes, you know, sometimes the daily grind of the news is going to refer back to core principles that are broader and deeper.

01:31:59.600 --> 01:32:05.600
So I thank God because I've read so much on so many different things of a lot of different point of views.

01:32:05.600 --> 01:32:12.600
Then if something breaks and a piece of news breaks, I can immediately sort of channel that into in the mental Rolodex.

01:32:12.600 --> 01:32:19.600
These three big ideas that I think are really important, and then I can talk at length about what those ideas are and I can explicate those.

01:32:19.600 --> 01:32:26.600
And so, you know, for example, when we were talking about must taking over Twitter before and I immediately go to the history of media, right?

01:32:26.600 --> 01:32:33.600
That's that's me tying it into a broader theme on, you know, and I do that, I would say fairly frequently.

01:32:33.600 --> 01:32:39.600
Well, we're talking about, say, subsidization of industry, and I can immediately tie that into.

01:32:39.600 --> 01:32:45.600
OK, what's the history of subsidization in the United States going all the way back to Woodrow Wilson and forward through FDR's industrial policy?

01:32:45.600 --> 01:32:48.600
And how does that tie into sort of broader economic policy internationally?

01:32:48.600 --> 01:32:53.600
So it allows me to tie into bigger themes because what I tend to read is mostly not news.

01:32:53.600 --> 01:32:55.600
What I tend to read is mostly books.

01:32:55.600 --> 01:32:59.600
I would say most of my media diet is actually not the stuff like that's that's the icing on the cake.

01:33:00.600 --> 01:33:10.600
But the actual cake is the hundreds of pages in history, econ, geography that I'm that I'm social science that I'm reading every week.

01:33:10.600 --> 01:33:15.600
And so that that sort of stuff allows me to think more deeply about these things.

01:33:15.600 --> 01:33:18.600
So that's one way of doing it. The other way of doing it is Russia breaks in the news.

01:33:18.600 --> 01:33:22.600
I don't know anything about Russia. I immediately go and I purchase five books about Russia and I read all of them.

01:33:22.600 --> 01:33:34.600
And so one of the unfortunate things about our our the fortunate thing for me and the unfortunate thing about the world is that if the unfortunate thing about the world is you read two books on a subject, you are now considered by the media and expert on the subject.

01:33:34.600 --> 01:33:38.600
So that's, you know, sad and shallow, but that is the way that it is.

01:33:38.600 --> 01:33:42.600
The good news for me is that my job isn't to be a full expert on any of these subjects, and I don't claim to be right.

01:33:42.600 --> 01:33:50.600
I'm not a Russia expert. I know enough on Russia to be able to understand when people talk about Russia, what the system looks like, how it works and all of that.

01:33:50.600 --> 01:33:59.600
And then to explicate that for the common man, which a lot of people who are infused with the expertise can't really do if you're so deep in the weeds that you're like a full on academic expert on a thing.

01:33:59.600 --> 01:34:02.600
Sometimes it's hard to translate that over to a mass audience, which is really my job.

01:34:02.600 --> 01:34:10.600
Well, I think it can actually it's funny with the two books, you can actually get a pretty deep understanding if you read and also think deeply about it.

01:34:10.600 --> 01:34:13.600
But it allows you to approach a thing from first principles.

01:34:13.600 --> 01:34:25.600
A lot of times if you're a quote unquote expert, you get carried away by the momentum of what the field has been thinking about versus like stepping back.

01:34:25.600 --> 01:34:29.600
All right, what is really going on? The challenge is to pick the right two books.

01:34:29.600 --> 01:34:35.600
Right. So that usually what I'll try to find is somebody who knows the topic pretty well and have them recommend or a couple of people and have them recommend books.

01:34:35.600 --> 01:34:37.600
So a couple of years ago, I knew nothing about Bitcoin.

01:34:37.600 --> 01:34:45.600
I was at a conference and a couple of people who you've had on your show actually were there and I asked them, give me your top three books on Bitcoin.

01:34:45.600 --> 01:34:49.600
And so then I went and I read like nine books on Bitcoin.

01:34:49.600 --> 01:34:52.600
And so if you're nine books on Bitcoin, you at least know enough to get by.

01:34:52.600 --> 01:34:59.600
And so that so I can actually explain what Bitcoin is and why it works or why it doesn't work in some cases and what's happening in the markets that way.

01:34:59.600 --> 01:35:02.600
So that that's very, very helpful.

01:35:02.600 --> 01:35:07.600
Well, with Putin as an example, that's a difficult one to find the right books on.

01:35:07.600 --> 01:35:11.600
I think the new czar is the one I read where it was the most objective.

01:35:11.600 --> 01:35:14.600
When I read, I think about Putin was one called Strongman.

01:35:14.600 --> 01:35:20.600
It was very highly critical of Putin, but it gave like a good background on him.

01:35:20.600 --> 01:35:29.600
Yeah, so I'm very skeptical sort of things that are very critical of Putin because it feels like there's activism injected into the history.

01:35:29.600 --> 01:35:36.600
Like the way the rise and fall of the Third Reich is written about Hitler, I like because there's almost not a criticism of Hitler.

01:35:36.600 --> 01:35:42.600
It's a description of Hitler, which is very it's easier to do about a historical figure,

01:35:42.600 --> 01:35:47.600
which with William Shire, with the rise and fall of the Third Reich, it's impressive because he lived through it.

01:35:47.600 --> 01:35:58.600
But it's very tough to find objective descriptions about the history of the man and a country of Putin, of Zelensky, of any difficult Trump is the same.

01:35:58.600 --> 01:36:01.600
And I feel like everybody's the hero villain archetype.

01:36:01.600 --> 01:36:04.600
And it's like either somebody's completely a hero or completely a villain.

01:36:04.600 --> 01:36:09.600
And the truth is pretty much no one is completely a hero or completely a villain.

01:36:09.600 --> 01:36:13.600
People. In fact, I'm not sure that I love descriptions of people as heroes or villains.

01:36:13.600 --> 01:36:18.600
Generally, I think that people tend to do heroic things or do villainous things in the same way that I'm not sure I love descriptions of people as a genius.

01:36:18.600 --> 01:36:20.600
My dad used to say this when I was growing up.

01:36:20.600 --> 01:36:22.600
He used to say they didn't believe that there were geniuses.

01:36:22.600 --> 01:36:27.600
He said he believed that there were people with a genius for something because people, you know, yes,

01:36:27.600 --> 01:36:29.600
there are people who are very high IQ and we call them geniuses.

01:36:29.600 --> 01:36:31.600
But does that mean that they're good at EQ stuff?

01:36:31.600 --> 01:36:34.600
Not necessarily, but there are people who are geniuses at EQ stuff.

01:36:34.600 --> 01:36:39.600
In other words, it would be more specific to say that somebody is a genius at engineering than to say just broad spectrum.

01:36:39.600 --> 01:36:40.600
They're a genius.

01:36:40.600 --> 01:36:43.600
And that does avoid the problem of thinking that they're good at something that they're not good at.

01:36:43.600 --> 01:36:45.600
Right. It's a little more specific.

01:36:45.600 --> 01:36:48.600
So because you read a lot of books, are there can you look back?

01:36:48.600 --> 01:36:51.600
And it's always a tough question because so many it's like your favorite song.

01:36:51.600 --> 01:37:01.600
But are there books that have been influential in your life that are impacting your thinking or maybe ones you go back to that still carry insight for you?

01:37:01.600 --> 01:37:05.600
The Federalist paper is a big one in terms of sort of how American politics works.

01:37:05.600 --> 01:37:12.600
The first econ book that I thought was really great because it was written for teenagers essentially is one called Economics in One Lesson by Henry Hazlitt.

01:37:12.600 --> 01:37:13.600
It's like 150 pages.

01:37:13.600 --> 01:37:15.600
I recommend it to everybody sort of 15 and up.

01:37:15.600 --> 01:37:20.600
It's easier than, say, Thomas Sowell's Basic Econ, which is 400 or 500 pages.

01:37:20.600 --> 01:37:24.600
And it's looking at like macroeconomics, microeconomics, that kind of stuff.

01:37:24.600 --> 01:37:33.600
And then in terms of there's a great book by Carl Truman called Rise and Triumph of the Modern Self, which I think is the best book of the last 10 years.

01:37:33.600 --> 01:37:36.600
That's been sort of impactful on some of the thoughts I've been having lately.

01:37:36.600 --> 01:37:37.600
What's the key idea in there?

01:37:37.600 --> 01:37:43.600
The key idea is that we've shifted the nature of how identity is done in the West from how it was historically done.

01:37:43.600 --> 01:37:53.600
That basically for nearly all of human history, the way that we identify as human beings is as a mix of our biological drives and then how that interacts with the social institutions around us.

01:37:53.600 --> 01:37:58.600
And so when you're a child, you're a bunch of unfettered biological drives and it's your parents job to civilize you.

01:37:58.600 --> 01:38:01.600
And civilize you literally means bring you into civilization, right?

01:38:01.600 --> 01:38:02.600
You learn the rules of the road.

01:38:02.600 --> 01:38:07.600
You learn how to integrate into institutions that already exist and are designed to shape you.

01:38:07.600 --> 01:38:10.600
And it's how you interact with those institutions that makes you you.

01:38:10.600 --> 01:38:11.600
It's not just a set of biological drives.

01:38:11.600 --> 01:38:19.600
And then in the modern world, we've really driven toward the idea that what we are is how we feel on the inside without reference to the outside world.

01:38:19.600 --> 01:38:23.600
And it's the job of the outside world to celebrate and reflect what we think about ourselves on the inside.

01:38:23.600 --> 01:38:30.600
And so what that means is that we are driven now toward fighting institutions because institutions are in positions.

01:38:30.600 --> 01:38:34.600
So everything around us, societal institutions, these are these are things that are crimping our style.

01:38:34.600 --> 01:38:36.600
They're making us not feel the way that we want to feel.

01:38:36.600 --> 01:38:39.600
And if we just destroy those things, then we'll be freer and more liberated.

01:38:39.600 --> 01:38:50.600
It's a it's a it's a I think much deeper model of how to think about why our social politics, particularly moving in a particular direction, is that a ground shift has happened in how people think about themselves.

01:38:50.600 --> 01:38:56.600
And this has had some some somewhat kind of shocking effects in terms of social politics.

01:38:56.600 --> 01:38:59.600
So there's negative consequences in your view of that.

01:38:59.600 --> 01:39:05.600
But is there also a positive consequence of more power, more agency to the individual?

01:39:05.600 --> 01:39:09.600
I think you can make the argument that institutions were weighing too heavily in how people form their identity.

01:39:09.600 --> 01:39:13.600
But I think that what we've done is gone significantly too far on the other side.

01:39:13.600 --> 01:39:19.600
We basically decided to blow up the institutions in favor of unfettered feeling slash identity.

01:39:19.600 --> 01:39:30.600
And I think that that is not only a large mistake, I think it's going to have dire ramifications for everything from suicidal ideation to institutional longevity in politics and in society more broadly.

01:39:30.600 --> 01:39:37.600
So speaking about the nature of self, you've been an outspoken proponent of pro-life.

01:39:37.600 --> 01:39:50.600
Can you can we start by you trying to steal man the case for pro-choice that abortion is not murder and a woman's right to choose is a fundamental human right freedom.

01:39:50.600 --> 01:40:04.600
So I think that the the the only way to steal man the pro-choice case is to and be ideologically consistent is to suggest that there is no interest in the life of the unborn.

01:40:04.600 --> 01:40:08.600
That counter weighs at all freedom of of choice.

01:40:08.600 --> 01:40:14.600
So the so what that means is we can take the full example of sort of the partial example.

01:40:14.600 --> 01:40:25.600
So if we take the full example, what that would mean is that up until point of birth, which is sort of the Democratic Party platform position that there is that a woman's right to choose ought to extend for any reason whatsoever up to point of birth.

01:40:25.600 --> 01:40:28.600
The only way to argue that is that bodily autonomy is the only factor.

01:40:28.600 --> 01:40:32.600
There is no countervailing factor that would ever outweigh bodily autonomy.

01:40:32.600 --> 01:40:35.600
That would be the strongest version of the argument.

01:40:35.600 --> 01:40:44.600
Another version of that argument would be that the reason that bodily autonomy ought to weigh so heavily is because women can't be the equals of men.

01:40:44.600 --> 01:40:49.600
If the this institutes of biology are allowed to decide their futures, right?

01:40:49.600 --> 01:40:59.600
If pregnancy changes women in a way that doesn't change men, it's a form of sex discrimination for women to ever have to go through with pregnancy, which is an argument that was made by Ruth Bader Ginsburg kind of.

01:40:59.600 --> 01:41:00.600
Those are the arguments.

01:41:00.600 --> 01:41:13.600
The kind of softer version is the more I would say emotionally resonant version of the argument, which is that bodily autonomy ought to outweigh the interests of the fetus up till point X.

01:41:13.600 --> 01:41:15.600
And then people have different feelings about what point X looks like.

01:41:15.600 --> 01:41:16.600
Is it up to the point of viability?

01:41:16.600 --> 01:41:17.600
Is it up to the point of the heartbeat?

01:41:17.600 --> 01:41:19.600
Is it up to 12 weeks or 15 weeks?

01:41:19.600 --> 01:41:26.600
And that really is where the American public is where the American public is, broadly speaking, not not state by state where there are various really, really varied opinions.

01:41:26.600 --> 01:41:32.600
But like broadly speaking, it seems like the American public by polling data wants somewhere between a 12 and 15 week abortion restriction.

01:41:32.600 --> 01:41:41.600
And they believe that up until 12 or 15 weeks, there's not enough there for to not be specific, but to be kind of how people feel about it to outweigh a woman's bodily autonomy.

01:41:41.600 --> 01:41:47.600
And then beyond that point, then there is enough of an interest in the life of the preborn child.

01:41:47.600 --> 01:41:51.600
It's developed enough that now we care about it enough that it outweighs a woman's bodily autonomy.

01:41:52.600 --> 01:41:56.600
What's the strongest case for pro-life in your mind?

01:41:56.600 --> 01:42:02.600
I mean, the strongest case for pro-life is that from conception, a human life has been created.

01:42:02.600 --> 01:42:03.600
It is a human life with potential.

01:42:03.600 --> 01:42:09.600
That human life potential with potential now has an independent interest in its own existence.

01:42:09.600 --> 01:42:11.600
If I may just ask a quick question.

01:42:11.600 --> 01:42:15.600
So conception is when a sperm fertilizes an egg?

01:42:15.600 --> 01:42:16.600
Yes.

01:42:16.600 --> 01:42:20.600
OK, just to clarify the biological beginning of what conception is.

01:42:20.600 --> 01:42:22.600
I mean, because that is the beginning of human life.

01:42:22.600 --> 01:42:24.600
Now, there are other standards that people have drawn, right?

01:42:24.600 --> 01:42:27.600
Some people say implantation in the uterus.

01:42:27.600 --> 01:42:32.600
Some people will suggest viability, some people with brain development or heart development.

01:42:32.600 --> 01:42:42.600
But the clear dividing line between a human life exists and a human life does not exist is the biological creation of an independent human life with its own DNA strands and et cetera, which happens at conception.

01:42:42.600 --> 01:42:47.600
Once you acknowledge that there is that independent human life with potential.

01:42:47.600 --> 01:42:50.600
And I keep calling it that because people sometimes say potential human life.

01:42:50.600 --> 01:42:51.600
It's not a potential human life.

01:42:51.600 --> 01:42:55.600
It's a human life that is not developed yet to the full extent that it will develop.

01:42:55.600 --> 01:43:06.600
Once you say that and once you say that it has its own interest, now you have to now the burden of proof is to explain why bodily autonomy ought to allow for the snuffing out of that human life.

01:43:06.600 --> 01:43:12.600
If we believe that human life ought not to be killed for for quote unquote no good reason, you have to come up with a good reason.

01:43:12.600 --> 01:43:14.600
The burden of proof is now shifted.

01:43:14.600 --> 01:43:22.600
Now you will find people who will say, well, the good reason is that it's not sufficiently developed to outweigh the mental trauma or emotional trauma that a woman goes through.

01:43:22.600 --> 01:43:29.600
If, for example, she was raped or the victim of incest and that that is a fairly emotionally resonant argument, but it's not necessarily positive.

01:43:29.600 --> 01:43:40.600
You can you can make the argument that just because something horrific and horrible happened to a woman does not rob the human life of its interest in life.

01:43:40.600 --> 01:43:51.600
One of the big problems in trying to draw any line for the self-interest of life in the in the human life is that it's very difficult to draw any other line that doesn't seem somewhat arbitrary.

01:43:51.600 --> 01:43:56.600
You say that independent heartbeat, you know, well, you know, people have pacemakers.

01:43:56.600 --> 01:44:00.600
If you say brain function, people have various levels of brain function as adults.

01:44:00.600 --> 01:44:03.600
If you say viability, babies are not viable after they are born.

01:44:03.600 --> 01:44:07.600
If I left a newborn baby on a table and did not take care of it, it would be dead in two days.

01:44:07.600 --> 01:44:12.600
So, you know, once you start getting into sort of these lines, it starts to get very fuzzy very quickly.

01:44:12.600 --> 01:44:17.600
And so if you're looking for sort of a bright line moral rule, that would be the bright line moral rule.

01:44:17.600 --> 01:44:19.600
And that's that's sort of the pro-life case.

01:44:19.600 --> 01:44:25.600
Well, there's still mysterious, difficult scientific questions of things like consciousness.

01:44:25.600 --> 01:44:29.600
So what do you does the question of consciousness?

01:44:29.600 --> 01:44:32.600
How does it come into play into this debate?

01:44:32.600 --> 01:44:39.600
So I don't believe that consciousness is the sole criterion by which we judge the self-interest in human life.

01:44:39.600 --> 01:44:43.600
So we are unconscious a good deal of our lives.

01:44:43.600 --> 01:44:46.600
That does not we will be conscious again, right?

01:44:46.600 --> 01:44:51.600
When you're unconscious, when you're asleep, for example, presumably your life is still worth living.

01:44:51.600 --> 01:44:55.600
If somebody came in and killed you, that'd be a serious moral quandary at the very least.

01:44:55.600 --> 01:45:01.600
But the birth of consciousness, the lighting up of the flame, the initial lighting up the flame,

01:45:01.600 --> 01:45:04.600
there does seem to be something special about that.

01:45:04.600 --> 01:45:07.600
And it's a it's a mystery of when that happens.

01:45:07.600 --> 01:45:12.600
Well, I mean, Peter Singer makes the case that basically self-consciousness doesn't exist until you're two and a half.

01:45:12.600 --> 01:45:14.600
So he says that even infanticide should be OK.

01:45:14.600 --> 01:45:16.600
He's a bioethicist over at Princeton.

01:45:16.600 --> 01:45:19.600
So you get into some real dicey territory once you get into conscious.

01:45:19.600 --> 01:45:24.600
Also, the truth is that consciousness is more of a spectrum than it is a than it is a dividing line,

01:45:24.600 --> 01:45:28.600
meaning that there are people with various degrees of brain function.

01:45:29.600 --> 01:45:34.600
We don't actually know how conscious they are, and you can get into eugenic territory pretty quickly

01:45:34.600 --> 01:45:37.600
when we start dividing between lives that are worth living based on levels of consciousness

01:45:37.600 --> 01:45:40.600
and lives that are not worth living based on levels of consciousness.

01:45:40.600 --> 01:45:47.600
Do you find it the the aspect of women's freedom?

01:45:47.600 --> 01:45:51.600
Do you feel the tension between that ability to choose?

01:45:51.600 --> 01:45:57.600
The trajectory of your own life versus the rights of the unborn child?

01:45:57.600 --> 01:46:00.600
In one situation, yes, in one situation, no.

01:46:00.600 --> 01:46:06.600
If you've had sex with a person voluntarily and as a product of that, you are now pregnant.

01:46:06.600 --> 01:46:09.600
No, you've taken an action with a perfectly predictable result.

01:46:09.600 --> 01:46:14.600
Even if you took birth control, this is the way that human beings procreated for literally all of human existence.

01:46:14.600 --> 01:46:16.600
And by the way, also how all mammals procreate.

01:46:16.600 --> 01:46:19.600
So the idea that this was an entirely unforeseen consequence of your activity,

01:46:19.600 --> 01:46:24.600
I find I have less sympathy for you in that particular situation

01:46:24.600 --> 01:46:28.600
because you could have made decisions that would not lead you to this particular impasse.

01:46:28.600 --> 01:46:30.600
In fact, this used to be the basis of marriage, right?

01:46:30.600 --> 01:46:34.600
It was when we were a apparently more terrible society.

01:46:34.600 --> 01:46:39.600
We used to say that people should wait until they get married to have sex, a position that I still hold.

01:46:39.600 --> 01:46:42.600
And the reason for that was because then if you have sex and you produce a child,

01:46:42.600 --> 01:46:45.600
then the child will grow up in a two-parent family with stability.

01:46:46.600 --> 01:46:48.600
So not a ton of sympathy there.

01:46:48.600 --> 01:46:51.600
When it comes to rape and incest, obviously heavy, heavy sympathy.

01:46:51.600 --> 01:46:55.600
And so that's why I think you see, statistically speaking, a huge percentage of Americans,

01:46:55.600 --> 01:46:58.600
including many pro-life Americans, people who consider themselves pro-life,

01:46:58.600 --> 01:47:00.600
would consider exceptions for rape and incest.

01:47:00.600 --> 01:47:05.600
One of the sort of dishonest things that I think happens in abortion debates is arguing from the fringes.

01:47:05.600 --> 01:47:07.600
This tends to happen a lot.

01:47:07.600 --> 01:47:12.600
Pro-choice activists will argue from rape and incest to the other 99.8% of abortions.

01:47:12.600 --> 01:47:16.600
Or you'll see people on the pro-life side argue from partial birth abortion to all of abortion.

01:47:16.600 --> 01:47:21.600
You actually have to take on sort of the mainstream case and then decide whether or not that's acceptable or not.

01:47:21.600 --> 01:47:28.600
But to you, the exception, just ethically, without generalizing it, that is a valid ethically exception.

01:47:28.600 --> 01:47:32.600
I don't hold that there should be an exception for rape or incest because, again,

01:47:32.600 --> 01:47:35.600
I hold by the bright line rule that once a human life with potential exists,

01:47:35.600 --> 01:47:40.600
then it has its own interest in life that cannot be curbed by your self-interest.

01:47:41.600 --> 01:47:45.600
The only exception that I hold by is the same exception that literally all pro-lifers hold by,

01:47:45.600 --> 01:47:47.600
which is the life of the mother is put in danger.

01:47:47.600 --> 01:47:53.600
Such a tough, tough topic because if you believe that that's the line, then we're committing mass murder.

01:47:53.600 --> 01:47:55.600
Or at least mass killing.

01:47:55.600 --> 01:48:02.600
So I would say that murder typically requires a level of mens rea that may be absent in many cases of abortion.

01:48:02.600 --> 01:48:05.600
Because the usual follow-on question is, well, if it's murder, why don't you prosecute the woman?

01:48:05.600 --> 01:48:09.600
And the answer is because the vast majority of people who are having abortions

01:48:09.600 --> 01:48:11.600
don't actually believe that they're killing a person.

01:48:11.600 --> 01:48:16.600
They have a very different view of what is exactly happening.

01:48:16.600 --> 01:48:22.600
So I would say that there are all sorts of interesting hypotheticals that come in to play when it comes to abortion.

01:48:22.600 --> 01:48:25.600
And you can play them any which way.

01:48:25.600 --> 01:48:29.600
But levels, let's put it this way, there are gradations of wrongs.

01:48:29.600 --> 01:48:37.600
I don't think that all abortions are equally blameworthy, even if I would ban virtually all of them.

01:48:38.600 --> 01:48:46.600
I think that they're mitigating circumstances that make, while being wrong, some abortions less morally blameworthy than others.

01:48:46.600 --> 01:48:56.600
I can admit a difference between killing a two-week-old embryo in the womb and stabbing a seven-year-old in the face.

01:48:56.600 --> 01:49:00.600
I can recognize all that while still saying I think that it would be wrong to terminate a pregnancy.

01:49:00.600 --> 01:49:04.600
Do you think the question of when life begins, which I think is a fascinating question,

01:49:05.600 --> 01:49:07.600
is a question of science or a question of religion?

01:49:07.600 --> 01:49:09.600
When life begins, it's a question of science.

01:49:09.600 --> 01:49:16.600
When that life becomes valuable enough for people to want to protect it is going to be a question that is beyond science.

01:49:16.600 --> 01:49:19.600
Science doesn't have moral judgments to make about the value of human life.

01:49:19.600 --> 01:49:23.600
This is one of the problems that Sam Harris and I have had this argument many times, and it's always kind of interesting.

01:49:23.600 --> 01:49:27.600
Because Sam is of the opinion that you can get to ought from is.

01:49:27.600 --> 01:49:29.600
That science says is, therefore we can learn ought.

01:49:29.600 --> 01:49:32.600
So human flourishing is the goal of life.

01:49:32.600 --> 01:49:35.600
And I always say to him, I don't see where you get that from evolutionary biology.

01:49:35.600 --> 01:49:38.600
You can assume it, just say you're assuming it.

01:49:38.600 --> 01:49:45.600
But don't pretend that that is a conclusion that you can draw straight from biological reality itself.

01:49:45.600 --> 01:49:47.600
Because obviously that doesn't exist in the animal world, for example.

01:49:47.600 --> 01:49:50.600
Nobody assumes the innate value of every ant.

01:49:50.600 --> 01:49:55.600
I think I know your answer to this, but let's test it because I think you're going to be wrong.

01:49:55.600 --> 01:49:58.600
So there's a robot behind you.

01:49:58.600 --> 01:50:07.600
Do you think there will be a time in the future when it will be unethical and illegal to kill a robot because they will have sentience?

01:50:07.600 --> 01:50:14.600
My guess is you would say no, Lex, because there's a fundamental difference between humans and robots.

01:50:14.600 --> 01:50:17.600
And I just want to get you on record because I think you'll be wrong.

01:50:17.600 --> 01:50:21.600
I mean, it depends on the level of development, I would assume, of the robots.

01:50:21.600 --> 01:50:28.600
I mean, you're assuming a complexity in the robots that eventually imitates what we in the religious life would call the human soul.

01:50:28.600 --> 01:50:34.600
The ability to choose freely, for example, which I believe is sort of the capacity for human beings.

01:50:34.600 --> 01:50:36.600
The ability to suffer.

01:50:36.600 --> 01:50:49.600
Yeah. If all of that could be proved and not programmed, meaning the freely willed capacity of a machine to do X, Y, or Z.

01:50:49.600 --> 01:50:53.600
You could not pinpoint exactly where it happens in the program.

01:50:53.600 --> 01:50:56.600
Right. It's not deterministic.

01:50:56.600 --> 01:51:01.600
Then it would raise serious moral issues, for sure. I'm not sure I know the answer to that question.

01:51:01.600 --> 01:51:03.600
Are you afraid of that time?

01:51:03.600 --> 01:51:10.600
I'm not sure I'm afraid of that time. I mean, it's any more than I'd be afraid if aliens arrived in the world and had these characteristics.

01:51:10.600 --> 01:51:14.600
Well, there's just a lot of moral complexities, and they don't necessarily have to be in the physical space.

01:51:14.600 --> 01:51:16.600
They can be in the digital space.

01:51:16.600 --> 01:51:21.600
There's an increased sophistication and number of bots on the Internet, including on Twitter.

01:51:21.600 --> 01:51:32.600
As they become more and more intelligent, there's going to be serious questions about what is our moral duty to protect ones that have or claim to have an identity.

01:51:32.600 --> 01:51:36.600
That'll be really interesting. Actually, what I'm afraid of is the opposite happening, meaning that people...

01:51:36.600 --> 01:51:43.600
The worst that should happen is that we develop robots so sophisticated that they appear to have free will, and then we treat them with human dignity.

01:51:43.600 --> 01:51:49.600
That should be the worst that happens. What I'm afraid of is the opposite, is that if we're talking about this particular hypothetical,

01:51:49.600 --> 01:51:53.600
that we develop robots that have all of these apparent abilities, and then we dehumanize them,

01:51:53.600 --> 01:51:58.600
which leads us to also dehumanize the other humans around us, which you could easily see happening.

01:51:58.600 --> 01:52:02.600
The devaluation of life to the point where it doesn't really matter.

01:52:02.600 --> 01:52:07.600
I mean, people have always treated, unfortunately, newly discovered other humans this way.

01:52:07.600 --> 01:52:11.600
So I don't think this is actually a new problem. I think it's a pretty old problem.

01:52:11.600 --> 01:52:13.600
It'll just be interesting when it's made of human hands.

01:52:13.600 --> 01:52:21.600
Yeah, it's an opportunity to celebrate humanity or to bring out the worst in humanity.

01:52:21.600 --> 01:52:26.600
So the derision that naturally happens, like you said, with pointing out the other.

01:52:26.600 --> 01:52:33.600
Let me ask you about climate change. Let's go from the meme to the profound philosophy.

01:52:33.600 --> 01:52:37.600
Okay, the meme is there's a clip of you talking about climate change and saying that...

01:52:37.600 --> 01:52:39.600
The Aquaman meme.

01:52:39.600 --> 01:52:44.600
You said that for the sake of argument, if the water level rises five to ten feet in the next hundred years,

01:52:44.600 --> 01:52:50.600
people will just sell their homes and move. And then the meme is sell to who?

01:52:50.600 --> 01:52:52.600
Can you argue both sides of that?

01:52:52.600 --> 01:52:55.600
The argument that they're making is a straw man. The argument that I'm making is over time.

01:52:55.600 --> 01:52:58.600
I don't mean that if a tsunami is about to hit your house, you can list it on eBay.

01:52:58.600 --> 01:53:03.600
That's not what I mean, obviously. What I mean is that human beings have an extraordinary ability to adapt.

01:53:03.600 --> 01:53:08.600
It's actually our best quality. And that as water levels rise, real estate prices in those areas tends to fall.

01:53:08.600 --> 01:53:13.600
That over time, people tend to abandon those areas. They tend to leave.

01:53:13.600 --> 01:53:16.600
They tend to, right now, sell their houses. And then they tend to move.

01:53:16.600 --> 01:53:19.600
And eventually, those houses will be worthless. And you won't have anybody to sell to.

01:53:19.600 --> 01:53:22.600
But presumably not that many people will be living there by that point,

01:53:22.600 --> 01:53:25.600
which is one of the reasons why the price would be low, because there's no demand.

01:53:25.600 --> 01:53:31.600
So it's over a hundred years, so all of these price dynamics are very gradual, relative to the other price dynamics.

01:53:31.600 --> 01:53:36.600
Correct. That's why the joke of it, of course, is that I'm saying that tomorrow there's a tsunami on your source step.

01:53:37.600 --> 01:53:40.600
And you're like, oh, Bob will buy my house. Bob ain't going to buy your house.

01:53:40.600 --> 01:53:43.600
We all get that. But it's a funny name. I'll admit I laughed at it.

01:53:43.600 --> 01:53:49.600
How is your view on climate change, the human contribution to climate change?

01:53:49.600 --> 01:53:53.600
What should you do in terms of policy to respond to climate change? How has that changed over the years?

01:53:53.600 --> 01:53:59.600
I would say the truth is for years and years, I've believed that climate change was a reality.

01:53:59.600 --> 01:54:04.600
And that anthropogenic climate change is a reality. I don't argue with the IPCC estimates.

01:54:05.600 --> 01:54:09.600
I know climatologists at places like MIT or Caltech, and they know this stuff better than I do.

01:54:09.600 --> 01:54:16.600
So the notion that climate change is just not happening or that human beings have not contributed to climate change, I find doubtful.

01:54:16.600 --> 01:54:19.600
The question is to what extent human beings are contributing to climate change.

01:54:19.600 --> 01:54:21.600
Is it 50 percent? Is it 70 percent? Is it 90 percent?

01:54:21.600 --> 01:54:24.600
I think there's a little bit more play in the joints there, so it's not totally clear.

01:54:24.600 --> 01:54:31.600
The one thing I do know, and this I know with factual accuracy, is that all of the measures that are currently being proposed are unworkable and will not happen.

01:54:31.600 --> 01:54:40.600
So when people say Paris Climate Accords, even if those were imposed, you're talking about lowering the potential trajectory of climate change by a fraction of a degree.

01:54:40.600 --> 01:54:50.600
If you're talking about Green New Deal, net zero by 2050, the carbon is up there in the air and the climate change is going to happen.

01:54:50.600 --> 01:54:56.600
Also, you're assuming that geopolitical dynamics don't exist, so everybody is going to magically get on the same page.

01:54:56.600 --> 01:55:02.600
And we're all going to be imposing massive carbon taxes to get to net zero by 2050.

01:55:02.600 --> 01:55:05.600
I mean, like hundreds of times higher than they currently are.

01:55:05.600 --> 01:55:10.600
And that's not me saying, that's Klaus Schwab saying this of the World Economic Forum, who's a big advocate of exactly this sort of policy.

01:55:10.600 --> 01:55:15.600
And the reality is that we're going to have to accept that at least 1.5 degrees Celsius of climate change is baked into the cake by the end of the century.

01:55:15.600 --> 01:55:19.600
Again, not me talking, William Nordhaus, the economist, who just won the Nobel Prize in this stuff talking.

01:55:19.600 --> 01:55:22.600
And so what that suggests to me is what we've always known.

01:55:22.600 --> 01:55:25.600
Human beings are crap at mitigation and excellence in adaptation.

01:55:25.600 --> 01:55:28.600
We are very bad at mitigating our own faults.

01:55:28.600 --> 01:55:35.600
We are very, very good at adapting to the problems as they exist, which means that all of the estimates that billions will die, that there will be mass starvation,

01:55:35.600 --> 01:55:41.600
that we will see the migration in just a few years of hundreds of millions of people, those are wrong.

01:55:41.600 --> 01:55:43.600
What you'll see is a gradual change of living.

01:55:43.600 --> 01:55:46.600
People will move away from areas that are inundated on the coast.

01:55:46.600 --> 01:55:48.600
You will see people building seawalls.

01:55:48.600 --> 01:55:51.600
You'll see people adapting new technologies to suck carbon out of the air.

01:55:51.600 --> 01:55:53.600
You will see geoengineering.

01:55:53.600 --> 01:55:56.600
This is the sort of stuff that we should be focused on.

01:55:56.600 --> 01:56:03.600
And the sort of bizarre focus on what if we just keep tossing hundreds of billions of dollars at the same three technologies over and over

01:56:03.600 --> 01:56:07.600
in the hopes that if we subsidize it, this will magically make it more efficient.

01:56:07.600 --> 01:56:12.600
I've seen no evidence whatsoever that that is going to be the way that we get ourselves out of this.

01:56:12.600 --> 01:56:13.600
Necessity being the mother of invention.

01:56:13.600 --> 01:56:16.600
I think human beings will adapt because we have adapted and we will continue to adapt.

01:56:16.600 --> 01:56:24.600
So to the degree we invest in the threat of this, it should be into policies that help with the adaptation versus the mitigation.

01:56:24.600 --> 01:56:25.600
Right.

01:56:25.600 --> 01:56:29.600
Seawalls, geoengineering, developing technologies that carbon out of the air.

01:56:29.600 --> 01:56:33.600
Again, if I thought that there was more sort of hope for the green technologies currently in play,

01:56:33.600 --> 01:56:36.600
then subsidization of those technologies I might be a little bit more for.

01:56:36.600 --> 01:56:42.600
But I haven't seen tremendous progress over the course of the last 30 years in the reliability of, for example, wind energy

01:56:42.600 --> 01:56:47.600
or the ability to store solar energy to the extent necessary to actually power a grid.

01:56:47.600 --> 01:56:49.600
What's your thoughts on nuclear energy?

01:56:49.600 --> 01:56:50.600
Nuclear energy is great.

01:56:50.600 --> 01:56:57.600
Nuclear energy is a proven source of energy and we should be radically extending the use of nuclear energy.

01:56:57.600 --> 01:57:02.600
To me, honestly, this is like a litmus test question as to whether you take climate change seriously.

01:57:02.600 --> 01:57:05.600
If you're on right or left and you take climate change seriously, you should be in favor of nuclear energy.

01:57:05.600 --> 01:57:08.600
If you're not, I know that you have other priorities.

01:57:08.600 --> 01:57:14.600
Yeah, the fascinating thing about the climate change debate is the dynamics of the fear mongering over the past few decades

01:57:14.600 --> 01:57:18.600
because some of the nuclear energy was tied up into that somehow.

01:57:18.600 --> 01:57:20.600
There's a lot of fear about nuclear energy.

01:57:20.600 --> 01:57:28.600
It seems like there's a lot of social phenomena, social dynamics involved versus dealing with just science.

01:57:28.600 --> 01:57:30.600
It's interesting to watch.

01:57:31.600 --> 01:57:39.600
On my darker days, it makes me cynical about our ability to use reason and science to deal with the threats of the world.

01:57:39.600 --> 01:57:45.600
I think that our ability to use reason and science to deal with threats of the world is almost a time frame question.

01:57:45.600 --> 01:57:51.600
Again, we're very bad at looking down the road and saying, because people can't handle, for example, even things like compound interest.

01:57:51.600 --> 01:57:56.600
The idea that if I put a dollar in the bank today that 15 years from now that's going to be worth a lot more than a dollar,

01:57:56.600 --> 01:57:58.600
people can't actually see that.

01:57:58.600 --> 01:58:02.600
The idea of let's foresee a problem, then we'll deal with it right now as opposed to 30 years down the road.

01:58:02.600 --> 01:58:05.600
Typically, we let the problem happen and then we solve it.

01:58:05.600 --> 01:58:08.600
It's bloodier and worse than it would have been if we had solved it 30 years ago.

01:58:08.600 --> 01:58:10.600
But it is, in fact, effective.

01:58:10.600 --> 01:58:14.600
Sometimes it turns out the solution that we're proposing 30 years in advance is not effective.

01:58:14.600 --> 01:58:16.600
That can be a major problem as well.

01:58:16.600 --> 01:58:21.600
That's then to steelman the case for fear mongering, for irrational fear mongering.

01:58:21.600 --> 01:58:25.600
We need to be scared shitless in order for us to do anything.

01:58:25.600 --> 01:58:33.600
I'm generally against that, but maybe on a population scale, maybe some of that is necessary.

01:58:33.600 --> 01:58:39.600
For us to respond appropriately to long-term threats, we should be scared shitless.

01:58:39.600 --> 01:58:42.600
I don't think that we can actually do that, though.

01:58:42.600 --> 01:58:46.600
First of all, I think that platonic lies are generally bad.

01:58:46.600 --> 01:58:49.600
And then second of all, I don't think that we actually have the capacity to do this.

01:58:49.600 --> 01:58:54.600
I think that the people who are the elites of our society who get together in rooms and talk about this sort of stuff,

01:58:54.600 --> 01:58:58.600
and I've been in some of those meetings at my synagogue Friday nights, actually.

01:58:58.600 --> 01:59:02.600
I was going to make the joke, but I'm glad you did.

01:59:02.600 --> 01:59:05.600
I've been in Davos-like rooms.

01:59:05.600 --> 01:59:08.600
And when people discuss these sorts of topics and they're like,

01:59:08.600 --> 01:59:12.600
what if we just tell people that it's going to be a disaster with tsunamis and day after tomorrow?

01:59:12.600 --> 01:59:14.600
It's like, you guys don't have that power. You don't.

01:59:14.600 --> 01:59:18.600
And by the way, you dramatically undercut your own power because of COVID to do this sort of stuff.

01:59:18.600 --> 01:59:23.600
Because a lot of the sort of, what if we scare the living hell out of you to the point where you stay in your own house

01:59:23.600 --> 01:59:26.600
for two years and we tell you you can't send your kids to school?

01:59:26.600 --> 01:59:30.600
And then we tell you that the vaccine is going to prevent transmission.

01:59:30.600 --> 01:59:35.600
And then we also tell you that we need to spend $7 trillion in one year and it won't have any inflationary effect.

01:59:35.600 --> 01:59:39.600
And it turns out you're wrong on literally all of those things.

01:59:39.600 --> 01:59:43.600
The last few years have done more to undermine institutional trust than any time in probably American history.

01:59:43.600 --> 01:59:45.600
It's pretty amazing.

01:59:45.600 --> 01:59:48.600
Yeah, I tend to agree with that. The only thing we have to fear is fear itself.

01:59:48.600 --> 01:59:55.600
Let me ask you back to the question of God and a big ridiculous question. Who's God?

01:59:55.600 --> 02:00:03.600
Who is God? So I'm going to use sort of the Aquinas formulation of what God is.

02:00:03.600 --> 02:00:13.600
That if there is a cause of all things, not physical things, if there is a cause underlying the reason of the universe,

02:00:13.600 --> 02:00:15.600
then that is the thing we call God.

02:00:15.600 --> 02:00:19.600
So, not a big guy in the sky with a beard.

02:00:19.600 --> 02:00:25.600
He is the force underlying the logic of the universe, if there is a logic to the universe.

02:00:25.600 --> 02:00:31.600
And he is the creator, in the Judaic view, of that universe.

02:00:31.600 --> 02:00:39.600
And he does have an interest in us living in accordance with the laws of the universe that,

02:00:39.600 --> 02:00:41.600
if you're a religious Jew, are encoded in the Torah.

02:00:41.600 --> 02:00:47.600
But if you're not a religious Jew, it would be encoded in the natural law by sort of Catholic theology.

02:00:47.600 --> 02:00:49.600
Why do you think God created the universe?

02:00:49.600 --> 02:00:55.600
Or as popularly asked, what do you think is the meaning behind it? What's the meaning of life?

02:00:55.600 --> 02:00:57.600
What's the meaning of life?

02:00:57.600 --> 02:01:03.600
So I think that the meaning of life is to fulfill what God made you to do.

02:01:03.600 --> 02:01:05.600
And that is a series of roles.

02:01:05.600 --> 02:01:11.600
I think that human beings, and here you have to look to sort of human nature, rather than looking kind of to big questions.

02:01:11.600 --> 02:01:17.600
I've evolved something that I've really been working on, you know, I'm writing a book about this actually,

02:01:17.600 --> 02:01:20.600
that I call colloquially role theory.

02:01:20.600 --> 02:01:25.600
And basically the idea is that the way that we interact with the world is through a series of roles.

02:01:25.600 --> 02:01:30.600
And those are also the things we find most important and most implementable.

02:01:30.600 --> 02:01:37.600
There's sort of virtue ethics, right, which suggests that if we act in accordance with virtue, like Aristotle,

02:01:37.600 --> 02:01:40.600
then we will be living the most fulfilled and meaningful life.

02:01:40.600 --> 02:01:45.600
And then you have sort of deontological ethics, like Kantian ethics, that it's a rule-based ethic.

02:01:45.600 --> 02:01:49.600
If you follow the rules, then you'll find the meaning of life.

02:01:49.600 --> 02:01:53.600
And then what I'm proposing is that there's something that I would call role ethics,

02:01:53.600 --> 02:01:55.600
which is there are a series of roles that we play across our lives,

02:01:55.600 --> 02:01:58.600
which are also the things that we tend to put on our tombstones and find the most meaningful.

02:01:58.600 --> 02:02:02.600
So when you go to a cemetery, you can see what people found the most meaningful,

02:02:02.600 --> 02:02:05.600
because it's the stuff they put on the stone that has like four words on it, right?

02:02:05.600 --> 02:02:09.600
They're like beloved father, beloved mother, sister, brother.

02:02:09.600 --> 02:02:15.600
And you might have a job once in a while, a creator, a religious person, right?

02:02:15.600 --> 02:02:18.600
These are all roles that have existed across societies and across humanity.

02:02:18.600 --> 02:02:20.600
And those are the things where we actually find meaning.

02:02:20.600 --> 02:02:24.600
And the way that we navigate those roles brings us meaning.

02:02:24.600 --> 02:02:29.600
And I think that God created us in order to fulfill those roles

02:02:29.600 --> 02:02:32.600
for purposes that I can't begin to understand because I ain't him.

02:02:32.600 --> 02:02:38.600
And the more we recognize those roles and the more we live those roles,

02:02:38.600 --> 02:02:40.600
and then we can express freedom within those roles.

02:02:40.600 --> 02:02:42.600
I think that liberty exists inside each of those roles,

02:02:42.600 --> 02:02:44.600
and that's what makes all of our lives different and fun.

02:02:44.600 --> 02:02:47.600
We all parent in different ways, but being a parent is a meaningful role.

02:02:47.600 --> 02:02:53.600
We all have spouses, but how you interact that relationship is what makes your life meaningful and interesting.

02:02:53.600 --> 02:02:57.600
That is what we were put on earth to do.

02:02:57.600 --> 02:03:00.600
And if we perform those roles properly, and those roles do include things like being a creator,

02:03:00.600 --> 02:03:04.600
like we have a creative instinct as human beings, being a creator, being an innovator,

02:03:04.600 --> 02:03:09.600
being a defender of your family, being a social member of your community,

02:03:09.600 --> 02:03:10.600
which is something that we're built to do.

02:03:10.600 --> 02:03:14.600
If we fulfill those roles properly, then we will have made the world a better place than we inherited it.

02:03:14.600 --> 02:03:22.600
And we will also have had the joy of experiencing the sort of flow they talk about in psychology,

02:03:22.600 --> 02:03:25.600
where when you engage in these roles, you actually do feel a flow.

02:03:25.600 --> 02:03:28.600
So these roles are a fundamental part of the human condition?

02:03:28.600 --> 02:03:29.600
Yes.

02:03:29.600 --> 02:03:36.600
So the book you're working on is constructing a system to help us understand these roles?

02:03:36.600 --> 02:03:39.600
Let's assume that all of that's true.

02:03:39.600 --> 02:03:45.600
The real question in the book is how do you construct a flourishing and useful society and politics?

02:03:45.600 --> 02:03:48.600
Ah, so a society level.

02:03:48.600 --> 02:03:51.600
If this is our understanding of a human being, how do we construct a good society?

02:03:51.600 --> 02:03:52.600
Right, exactly.

02:03:52.600 --> 02:03:58.600
Because I think that a lot of political theory is right now based in either J.S. Mill kind of thought,

02:03:58.600 --> 02:04:03.600
which is all that a good politics does is it allows you to wave your hand around until you hit somebody in the face.

02:04:03.600 --> 02:04:09.600
Or Rawlsian thought, which is what if we constructed society in order to achieve the most for the least, essentially?

02:04:09.600 --> 02:04:14.600
What if we constructed society around what actually makes humans the most fulfilled?

02:04:14.600 --> 02:04:19.600
And that is the fulfillment of these particular roles.

02:04:19.600 --> 02:04:21.600
And where does liberty come into that?

02:04:21.600 --> 02:04:23.600
How do you avoid the idea of a tyranny in that?

02:04:23.600 --> 02:04:25.600
You have to be a mother, you must be a father.

02:04:25.600 --> 02:04:27.600
Where does freedom come into that?

02:04:27.600 --> 02:04:30.600
Can you reject those roles totally as a society and be okay?

02:04:30.600 --> 02:04:31.600
The answer probably is not.

02:04:31.600 --> 02:04:39.600
So you need a society that actually promotes and protects those roles, but also protects the freedom inside those roles.

02:04:39.600 --> 02:04:42.600
And that raises a more fundamental question of what exactly liberty is for.

02:04:42.600 --> 02:04:46.600
And I think that both the right and the left actually tend to make a mistake when they discuss liberty.

02:04:47.600 --> 02:04:53.600
The left tends to think that liberty is an ultimate good, that simple choice makes a bad thing good, which is not true.

02:04:53.600 --> 02:04:58.600
And I think the right talks about liberty in almost the same terms sometimes, and I think that's not true either.

02:04:58.600 --> 02:05:03.600
The question is whether liberty is of inherent value or instrumental value.

02:05:03.600 --> 02:05:08.600
Is liberty good in and of itself or is liberty good because it allows you to achieve X, Y, or Z?

02:05:08.600 --> 02:05:12.600
And I've thought about this one a lot, and I tend to come down on the latter side of the aisle.

02:05:12.600 --> 02:05:14.600
I mean, you asked me areas where I've moved.

02:05:14.600 --> 02:05:19.600
It may be an area where I've moved, is that I think when you think more shallowly about politics or maybe more quickly,

02:05:19.600 --> 02:05:21.600
because this is how we talk in America, is about liberties and rights.

02:05:21.600 --> 02:05:27.600
We tend to think that the right is what makes, not like the political right, rights make things good, liberties make things good.

02:05:27.600 --> 02:05:29.600
The question really is what are those rights and liberties for?

02:05:29.600 --> 02:05:34.600
Now, you have to be careful so that that doesn't shade into tyranny, right?

02:05:34.600 --> 02:05:36.600
You can only have liberty to do the thing that I say that you can do.

02:05:36.600 --> 02:05:42.600
But there have to be spheres of liberty that are roiling and interesting and filled with debate,

02:05:42.600 --> 02:05:46.600
but without threatening the chief institutions that surround those liberties.

02:05:46.600 --> 02:05:49.600
Because if you destroy the institutions, the liberties will go, too.

02:05:49.600 --> 02:05:53.600
If you knock down the pillars of the society, the liberties that are on top of those pillars are going to collapse.

02:05:53.600 --> 02:05:58.600
And I think that that's, if people are feeling as though we're on the verge of tyranny, I think that's why.

02:05:58.600 --> 02:06:03.600
This is fascinating, by the way, is an instrumental perspective on liberty.

02:06:03.600 --> 02:06:06.600
That's going to have to give me a lot to think about.

02:06:06.600 --> 02:06:08.600
Let me ask a personal question.

02:06:08.600 --> 02:06:13.600
Was there ever a time that you had a crisis of faith where you questioned your belief in God?

02:06:13.600 --> 02:06:18.600
Sure. And I would less call it a crisis of faith than an ongoing question of faith,

02:06:18.600 --> 02:06:21.600
which I think is, I hope, most religious people.

02:06:21.600 --> 02:06:26.600
And the word Israel, right, in Hebrew, Yisrael, means to struggle with God.

02:06:26.600 --> 02:06:28.600
That's literally what the word means.

02:06:28.600 --> 02:06:34.600
And so the idea of struggling with God, right, if you're Jewish or B'nai Yisrael, right,

02:06:34.600 --> 02:06:38.600
the idea of struggling with God, I think, is endemic to the human condition.

02:06:38.600 --> 02:06:41.600
If you understand what God's doing, then I think you're wrong.

02:06:41.600 --> 02:06:46.600
And if you think that that question doesn't matter, then I think you're also wrong.

02:06:46.600 --> 02:06:48.600
I think that God is a very necessary hypothesis.

02:06:48.600 --> 02:06:53.600
So the struggle with God is life. That is the process of life.

02:06:53.600 --> 02:06:55.600
That's right. Because you're never going to get to that answer.

02:06:55.600 --> 02:06:57.600
Otherwise, you're God and you aren't.

02:06:57.600 --> 02:07:00.600
Why does God allow cruelty and suffering in the world?

02:07:00.600 --> 02:07:02.600
One of the tough questions.

02:07:02.600 --> 02:07:04.600
We're going deep here.

02:07:04.600 --> 02:07:06.600
There's two types of cruelty and suffering.

02:07:06.600 --> 02:07:08.600
So if we're talking about human cruelty and suffering,

02:07:08.600 --> 02:07:13.600
because God does not intervene to prevent people from exercising their free will,

02:07:13.600 --> 02:07:18.600
because to do so would be to deprive human beings of the choice that makes them human.

02:07:18.600 --> 02:07:20.600
This is the sin of the Garden of Eden, basically,

02:07:20.600 --> 02:07:25.600
is that God could make you an angel, in which case you wouldn't have the choice to do the wrong thing.

02:07:25.600 --> 02:07:30.600
But so long as we are going to allow for cause and effect in a universe shaped by your choice,

02:07:30.600 --> 02:07:33.600
cruelty and evil are going to exist.

02:07:33.600 --> 02:07:37.600
And then there's the question of just the natural cruelty and vicissitudes of life.

02:07:37.600 --> 02:07:40.600
And the answer there is I think that God obscures himself.

02:07:40.600 --> 02:07:44.600
I think that if God were to appear in all of his glory to people on a regular basis,

02:07:44.600 --> 02:07:48.600
I think they would make faith, you wouldn't need it.

02:07:48.600 --> 02:07:50.600
There would be no such thing as faith.

02:07:50.600 --> 02:07:52.600
It would just be reality.

02:07:52.600 --> 02:07:55.600
Nobody has to prove to you that the sun rises every day.

02:07:55.600 --> 02:07:58.600
But if God is to allow us the choice to believe in him,

02:07:58.600 --> 02:08:00.600
which is the ultimate choice from a religious point of view,

02:08:00.600 --> 02:08:04.600
then he's going to have to obscure himself behind tragedy and horror and all those other things.

02:08:04.600 --> 02:08:09.600
I mean, this is a fairly well-known Kabbalistic concept called Tsim Tsum in Judaism,

02:08:09.600 --> 02:08:11.600
which is the idea that when God created the universe,

02:08:11.600 --> 02:08:15.600
he sort of withdrew in order to make space for all of these things to happen.

02:08:15.600 --> 02:08:18.600
So God doesn't have an instrumental perspective on liberty.

02:08:18.600 --> 02:08:25.600
In a chief sense, he does, because the best use of liberty is going to be belief in him.

02:08:25.600 --> 02:08:27.600
And you can misuse your liberty, right?

02:08:27.600 --> 02:08:30.600
There will be consequences if you believe in an afterlife,

02:08:30.600 --> 02:08:35.600
or if you believe in sort of a generalized better version of life led by faith,

02:08:35.600 --> 02:08:37.600
then liberty does have a purpose.

02:08:37.600 --> 02:08:40.600
But he also believes that you have to give people, from a cosmic perspective,

02:08:40.600 --> 02:08:45.600
the liberty to do wrong without threatening all the institutions of society.

02:08:45.600 --> 02:08:49.600
I mean, that's why it does say in the Bible that if man sheds blood by man,

02:08:49.600 --> 02:08:50.600
shall his blood be shed, right?

02:08:50.600 --> 02:08:55.600
There are punishments that are in biblical thought for doing things that are wrong.

02:08:55.600 --> 02:08:59.600
So for a human being who lacks the faith in God,

02:08:59.600 --> 02:09:02.600
so if you're an atheist, can you still be a good person?

02:09:02.600 --> 02:09:05.600
Of course, 100%. And there are a lot of religious people who are crappy people.

02:09:05.600 --> 02:09:07.600
How do we understand that tension?

02:09:07.600 --> 02:09:10.600
Well, from a religious perspective, what you would say is that

02:09:10.600 --> 02:09:14.600
it is perfectly plausible to live in accordance with a set of rules

02:09:14.600 --> 02:09:17.600
that don't damage other people without believing in God.

02:09:17.600 --> 02:09:19.600
You just might be understanding the reason for doing that wrong

02:09:19.600 --> 02:09:22.600
is what a religious person would say.

02:09:22.600 --> 02:09:25.600
This is the conversation, again, that I had with Sam, basically,

02:09:25.600 --> 02:09:28.600
is you and I agree on nearly everything when it comes to morality.

02:09:28.600 --> 02:09:31.600
Like, we probably disagree on 15 to 20% of things.

02:09:31.600 --> 02:09:34.600
The other 80% is because you grew up in a Judeo-Christian society, and so do I.

02:09:34.600 --> 02:09:37.600
And we grew up 10 miles from each other around the turn of the millennium.

02:09:37.600 --> 02:09:39.600
So there's that.

02:09:39.600 --> 02:09:44.600
So you can perfectly well be an atheist living a good, moral, decent life,

02:09:44.600 --> 02:09:47.600
because you can live a good, moral, decent life with regard to other people

02:09:47.600 --> 02:09:48.600
without believing in God.

02:09:48.600 --> 02:09:50.600
I don't think you can build a society on that,

02:09:50.600 --> 02:09:55.600
because I think that that relies on the sort of goodness of mankind,

02:09:55.600 --> 02:09:56.600
natural goodness of mankind.

02:09:56.600 --> 02:09:57.600
I don't believe in the natural goodness of mankind.

02:09:57.600 --> 02:09:58.600
You don't?

02:09:58.600 --> 02:09:59.600
No.

02:09:59.600 --> 02:10:01.600
I believe that man is created both sinful

02:10:01.600 --> 02:10:03.600
and with the capacity for sin and the capacity for good.

02:10:03.600 --> 02:10:08.600
But if you let them be on their own, doesn't it mean...

02:10:08.600 --> 02:10:10.600
Without social institutions to shape them,

02:10:10.600 --> 02:10:12.600
I think that that's very likely to go poorly.

02:10:12.600 --> 02:10:13.600
Oh, interesting.

02:10:13.600 --> 02:10:15.600
Well, we came to something we disagree on.

02:10:16.600 --> 02:10:21.600
But that might reflect itself in our approach to Twitter as well.

02:10:21.600 --> 02:10:27.600
I think if humans are left on their own, they tend towards good.

02:10:27.600 --> 02:10:30.600
They definitely have the capacity for good and evil,

02:10:30.600 --> 02:10:35.600
but when left on their own, I tend to believe they're good.

02:10:35.600 --> 02:10:37.600
I think they might be good with limits.

02:10:37.600 --> 02:10:40.600
What I mean by that is that what the evidence I think tends to show

02:10:40.600 --> 02:10:42.600
is that human beings are quite tribal.

02:10:42.600 --> 02:10:46.600
So what you'll end up with is people who are good with their immediate family

02:10:46.600 --> 02:10:47.600
and maybe their immediate neighbors,

02:10:47.600 --> 02:10:49.600
and then when they're threatened by an outside tribe,

02:10:49.600 --> 02:10:50.600
then they kill everyone,

02:10:50.600 --> 02:10:54.600
which is sort of the history of civilization in the pre-civilizational era,

02:10:54.600 --> 02:10:55.600
which was a very violent time.

02:10:55.600 --> 02:10:57.600
Pre-civilizational era was quite violent.

02:10:57.600 --> 02:11:02.600
Do you think on the topic of tribalism in our modern world,

02:11:02.600 --> 02:11:04.600
what are the pros and cons of tribes?

02:11:04.600 --> 02:11:08.600
Is that something where we should try to outgrow as a civilization?

02:11:08.600 --> 02:11:12.600
I don't think it's ever going to be possible to fully outgrow tribalism.

02:11:12.600 --> 02:11:17.600
I think it's a natural human condition to want to be with people who think like you

02:11:17.600 --> 02:11:19.600
or have a common set of beliefs,

02:11:19.600 --> 02:11:22.600
and I think trying to obliterate that in the name of universalism

02:11:22.600 --> 02:11:25.600
likely leads to utopian results that have devastating consequences.

02:11:25.600 --> 02:11:30.600
Utopian sort of universalism has been failing every time it's tried,

02:11:30.600 --> 02:11:34.600
whether you're talking about now it seems to be sort of a liberal universalism,

02:11:34.600 --> 02:11:36.600
which is being rejected by a huge number of people around the world

02:11:36.600 --> 02:11:37.600
in various different cultures,

02:11:37.600 --> 02:11:40.600
or they're talking about religious universalism,

02:11:40.600 --> 02:11:43.600
which typically comes with religious tyranny,

02:11:43.600 --> 02:11:47.600
or they're talking about communistic or a Nazi-esque sort of universalism,

02:11:47.600 --> 02:11:48.600
which comes with mass slaughter.

02:11:48.600 --> 02:11:51.600
So this is, you know, universalism I'm not a believer in.

02:11:51.600 --> 02:11:56.600
I think that you have, you know, some values that are fairly limited

02:11:56.600 --> 02:11:58.600
that all human beings should hold in common,

02:11:58.600 --> 02:12:00.600
and that's pretty much it.

02:12:00.600 --> 02:12:05.600
Like I think that everybody should have the ability to join with their own culture.

02:12:05.600 --> 02:12:07.600
I think how we define tribes is a different thing.

02:12:07.600 --> 02:12:12.600
So I think that tribes should not be defined by innate physical characteristics, for example,

02:12:12.600 --> 02:12:16.600
because I think that thank God as a civilization we've outgrown that,

02:12:16.600 --> 02:12:21.600
and I think that that is a childish way to view the world.

02:12:21.600 --> 02:12:23.600
All the tall people aren't a tribe.

02:12:23.600 --> 02:12:25.600
All the black people aren't a tribe.

02:12:25.600 --> 02:12:29.600
So the tribes should be formed over ideas versus physical characteristics.

02:12:29.600 --> 02:12:32.600
That's right, which is why actually to go back to sort of the beginning of the conversation

02:12:32.600 --> 02:12:37.600
when it comes to Jews, you know, I'm not a big believer in ethnic Judaism, right?

02:12:37.600 --> 02:12:40.600
As a person who takes Judaism seriously,

02:12:40.600 --> 02:12:44.600
Judaism is more to me than you were born with a last name like Berg or Steen.

02:12:44.600 --> 02:12:46.600
And so I've said maybe controversial.

02:12:46.600 --> 02:12:47.600
Hitler would disagree with you.

02:12:47.600 --> 02:12:49.600
He would disagree with me, but that's because he was a tribalist, right,

02:12:49.600 --> 02:12:51.600
who thought in racial terms.

02:12:51.600 --> 02:12:55.600
So maybe robots will help us see humans as one tribe.

02:12:55.600 --> 02:12:56.600
Maybe that...

02:12:56.600 --> 02:12:57.600
This is Reagan's idea, right?

02:12:57.600 --> 02:13:00.600
Reagan said, well, if there's an alien invasion, then we'll all be on the same side.

02:13:00.600 --> 02:13:01.600
So I'll go over to the Soviets and we'll talk about it.

02:13:01.600 --> 02:13:04.600
Some deep truth to that.

02:13:04.600 --> 02:13:07.600
What does it mean to be a good man?

02:13:07.600 --> 02:13:14.600
The various role that a human being takes on in this role theory that you've spoken about.

02:13:14.600 --> 02:13:16.600
What does it mean to be good?

02:13:16.600 --> 02:13:18.600
It means to perform...

02:13:18.600 --> 02:13:20.600
Now I will do Aristotle.

02:13:20.600 --> 02:13:22.600
It means to perform the function well.

02:13:22.600 --> 02:13:25.600
What Aristotle says is the good is not like moral good, moral evil,

02:13:25.600 --> 02:13:27.600
in the way that we tend to think about it.

02:13:27.600 --> 02:13:32.600
He meant that a good cup holds liquid and a good spoon holds soup.

02:13:32.600 --> 02:13:35.600
It means that a thing that is broken can't hold those things, right?

02:13:35.600 --> 02:13:40.600
So the idea of being a good person means that you are fulfilling the function for which you were made.

02:13:40.600 --> 02:13:43.600
It's a teleological view of humanity.

02:13:43.600 --> 02:13:47.600
So if you're a good father, this means that you are bringing up your child in durable values

02:13:47.600 --> 02:13:51.600
that is going to bring them up healthy, capable of protecting themselves

02:13:51.600 --> 02:13:53.600
and passing on the traditional wisdom of the ages to future generations

02:13:53.600 --> 02:13:55.600
while allowing for the capacity for innovation.

02:13:55.600 --> 02:13:57.600
That would be being a good father.

02:13:57.600 --> 02:14:01.600
Being a good spouse would mean protecting and unifying with your spouse

02:14:01.600 --> 02:14:06.600
and building a safe family and a place to raise children.

02:14:06.600 --> 02:14:10.600
Being a good citizen of your community means protecting the fellow citizens of your community

02:14:10.600 --> 02:14:14.600
while incentivizing them to build for themselves.

02:14:14.600 --> 02:14:17.600
It becomes actually much easier to think of how to...

02:14:17.600 --> 02:14:20.600
This is why I like the role theory because it's very hard,

02:14:20.600 --> 02:14:23.600
sort of in virtue theory, to say, be generous.

02:14:23.600 --> 02:14:25.600
Okay, how does that manifest? I don't know what that looks like.

02:14:25.600 --> 02:14:29.600
Sometimes being generous might be being not generous to other people, right?

02:14:29.600 --> 02:14:32.600
When Aristotle says that you should be benevolent.

02:14:32.600 --> 02:14:34.600
What does that mean? This is very vague.

02:14:34.600 --> 02:14:37.600
When I say be a good dad, most people sort of have a gut level understanding

02:14:37.600 --> 02:14:38.600
of what it means to be a good dad.

02:14:38.600 --> 02:14:41.600
Mostly what they have a gut level understanding of what it means to be a really bad dad.

02:14:41.600 --> 02:14:45.600
And so what it means to be a good man is to fulfill those roles,

02:14:45.600 --> 02:14:49.600
as many of them as you can, properly and at full function.

02:14:49.600 --> 02:14:50.600
And that's a very hard job.

02:14:50.600 --> 02:14:54.600
And I've said before that because I engage a lot with the public and all of this,

02:14:54.600 --> 02:14:55.600
the word great comes up a lot.

02:14:55.600 --> 02:14:58.600
What is to be a great leader? What is to be a great person?

02:14:58.600 --> 02:15:00.600
And I've always said to people, it's actually fairly easy to be great.

02:15:00.600 --> 02:15:01.600
It's very difficult to be good.

02:15:01.600 --> 02:15:04.600
There are a lot of very great people who are not very good.

02:15:04.600 --> 02:15:05.600
And there are not a lot of good people.

02:15:05.600 --> 02:15:10.600
And most of them, frankly, most good people die,

02:15:10.600 --> 02:15:13.600
mourn by their family and friends, and two generations later they're forgotten.

02:15:13.600 --> 02:15:16.600
But those are the people who incrementally move the ball forward in the world,

02:15:16.600 --> 02:15:19.600
sometimes much more than the people who are considered great.

02:15:19.600 --> 02:15:25.600
Understand the role in your life that involves being a cup and be damn good at it.

02:15:25.600 --> 02:15:26.600
Exactly. That's right.

02:15:26.600 --> 02:15:27.600
Hold the soup.

02:15:27.600 --> 02:15:28.600
It's very...

02:15:28.600 --> 02:15:30.600
Jordan Peterson have been there.

02:15:30.600 --> 02:15:32.600
It's very like lobster with Jordan Peterson.

02:15:32.600 --> 02:15:33.600
Exactly.

02:15:33.600 --> 02:15:36.600
I think people will quote you for years and years to come on that.

02:15:36.600 --> 02:15:39.600
What advice would you give a lot of young people who look up to you?

02:15:39.600 --> 02:15:43.600
What advice despite their better judgment?

02:15:43.600 --> 02:15:44.600
No, I'm just kidding.

02:15:44.600 --> 02:15:45.600
Maybe.

02:15:45.600 --> 02:15:46.600
I'm just kidding.

02:15:46.600 --> 02:15:47.600
I'm only kidding.

02:15:47.600 --> 02:15:52.600
They seriously look up to you and draw inspiration from your ideas, from your bold thinking.

02:15:52.600 --> 02:15:54.600
What advice would you give to them?

02:15:54.600 --> 02:15:57.600
How to live a life worth living?

02:15:57.600 --> 02:16:01.600
How to have a career they can be proud of?

02:16:01.600 --> 02:16:02.600
And everything like that.

02:16:02.600 --> 02:16:08.600
So, live out the values that you think are really important and seek those values in others

02:16:08.600 --> 02:16:10.600
would be the first piece of advice.

02:16:10.600 --> 02:16:13.600
Second piece of advice, don't go on Twitter until you're 26.

02:16:13.600 --> 02:16:14.600
Why 26?

02:16:14.600 --> 02:16:16.600
Because your brain is fully developed at that point.

02:16:16.600 --> 02:16:22.600
As I said early on, I was on social media and writing columns from the time I was 17.

02:16:22.600 --> 02:16:27.600
It was a great opportunity and as it turns out, a great temptation to say enormous numbers of stupid things.

02:16:27.600 --> 02:16:30.600
When you're young, I mean you're kind of trying out ideas and you're putting them on,

02:16:30.600 --> 02:16:34.600
you're taking them off and social media permanentizes those things and engraves them in stone

02:16:34.600 --> 02:16:37.600
and then that's used against you for the rest of your life.

02:16:37.600 --> 02:16:38.600
So, I tell young people this all the time.

02:16:38.600 --> 02:16:40.600
If you want to be on social media, be on social media, but don't post.

02:16:40.600 --> 02:16:45.600
Like watch if you want to take in information and more importantly, you should read books.

02:16:45.600 --> 02:16:49.600
As far as other advice, I'd say engage in your community.

02:16:49.600 --> 02:16:53.600
There's no substitute for engaging in your community and engage in interpersonal action

02:16:53.600 --> 02:16:56.600
because that will soften you and make you a better person.

02:16:56.600 --> 02:16:58.600
I've become a better person since I got married.

02:16:58.600 --> 02:17:00.600
I've become an even better person since I've had kids.

02:17:00.600 --> 02:17:03.600
So, you can imagine how terrible I was before all these things.

02:17:04.600 --> 02:17:11.600
And engaging your community does allow you to build the things that matter on the most local possible level.

02:17:11.600 --> 02:17:14.600
I mean the outcome by the way of the sort of politics of the politics of fulfillment

02:17:14.600 --> 02:17:16.600
that I was talking about earlier is a lot of localism

02:17:16.600 --> 02:17:18.600
because the roles that I'm talking about are largely local roles.

02:17:18.600 --> 02:17:20.600
So, that stuff has to be protected locally.

02:17:20.600 --> 02:17:24.600
I think we focus way too much in this country and others on like world beating solutions,

02:17:24.600 --> 02:17:27.600
national solutions, solutions that apply to hundreds of millions of people.

02:17:27.600 --> 02:17:30.600
How do we get to the solutions that apply for like five

02:17:30.600 --> 02:17:32.600
and then we get to the solutions that apply to like 20

02:17:32.600 --> 02:17:36.600
and then we get to the solutions that involve 200 people or a thousand people.

02:17:36.600 --> 02:17:37.600
Let's solve that stuff.

02:17:37.600 --> 02:17:41.600
And I think the solutions at the higher level flow bottom up not top down.

02:17:41.600 --> 02:17:44.600
What about mentors and maybe role models?

02:17:44.600 --> 02:17:48.600
Have you had a mentor or maybe people you look up to,

02:17:48.600 --> 02:17:51.600
either you interacted on a local scale like you actually knew them

02:17:51.600 --> 02:17:52.600
or somebody you really looked up to?

02:17:52.600 --> 02:17:53.600
For me, I'm very lucky.

02:17:53.600 --> 02:17:55.600
I grew up in a very solid two-parent household.

02:17:55.600 --> 02:17:57.600
I'm extremely close to my parents.

02:17:57.600 --> 02:18:01.600
I've lived near my parents literally my entire life with the exception of three years of law school.

02:18:01.600 --> 02:18:04.600
And like right now, they live a mile and a half from us.

02:18:04.600 --> 02:18:10.600
What did you learn about life from your parents and your father?

02:18:10.600 --> 02:18:15.600
So many things from my parents.

02:18:15.600 --> 02:18:16.600
That's a hard one.

02:18:16.600 --> 02:18:21.600
I mean, I think the good stuff from my dad is that you should hold true to your values.

02:18:21.600 --> 02:18:24.600
He's very big on you have values, those values are important, hold true to them.

02:18:24.600 --> 02:18:28.600
Did you understand what your values are, what your principles are early on?

02:18:28.600 --> 02:18:29.600
Fairly quickly, yeah.

02:18:30.600 --> 02:18:33.600
And so he was very big on that, which is why, for example,

02:18:33.600 --> 02:18:37.600
I get asked a lot in the Jewish community why I wear a kippah.

02:18:37.600 --> 02:18:39.600
And the answer is it never occurred to me to take off the kippah.

02:18:39.600 --> 02:18:40.600
I always wore it.

02:18:40.600 --> 02:18:42.600
Why would I take it off at any point?

02:18:42.600 --> 02:18:45.600
That's the life that I want to live and that's the way it is.

02:18:45.600 --> 02:18:47.600
So that was a big one from my dad.

02:18:47.600 --> 02:18:48.600
From my mom, practicality.

02:18:48.600 --> 02:18:49.600
My dad is more of a dreamer.

02:18:49.600 --> 02:18:51.600
My mom is much more practical.

02:18:51.600 --> 02:18:56.600
And so the sort of lessons that I learned from my dad are that you can have

02:18:56.600 --> 02:18:59.600
sort of the counter lesson is that you can have a good idea,

02:18:59.600 --> 02:19:02.600
but if you don't have a plan for implementation, then it doesn't end up as reality.

02:19:02.600 --> 02:19:05.600
And I think actually he's learned that better over the course of his life too.

02:19:05.600 --> 02:19:10.600
But my dad, from the time I was very young, he wanted me to engage with other adults

02:19:10.600 --> 02:19:12.600
and he wanted me to learn from other people.

02:19:12.600 --> 02:19:15.600
And one of his rules was if he didn't know something,

02:19:15.600 --> 02:19:18.600
he would find somebody who he thought did know the thing for me to talk to.

02:19:18.600 --> 02:19:19.600
That was a big thing.

02:19:19.600 --> 02:19:21.600
So I'm very lucky.

02:19:21.600 --> 02:19:22.600
I have wonderful parents.

02:19:22.600 --> 02:19:24.600
As far as sort of other mentors, in terms of media,

02:19:24.600 --> 02:19:26.600
Andrew Breitbart was a mentor.

02:19:26.600 --> 02:19:29.600
Andrew obviously, he was kind of known in his latter days,

02:19:29.600 --> 02:19:33.600
I think more for the militancy than when I was very close with him.

02:19:33.600 --> 02:19:37.600
So for somebody like me who doesn't, who knows more about the militancy,

02:19:37.600 --> 02:19:41.600
can you tell me what is a great, what makes him a great man?

02:19:41.600 --> 02:19:44.600
What made Andrew great is that he engaged with everyone.

02:19:44.600 --> 02:19:45.600
I mean everyone.

02:19:45.600 --> 02:19:49.600
So there are videos of him rollerblading down the boulevard

02:19:49.600 --> 02:19:52.600
and people would be protesting and he would literally rollerblade up to them

02:19:52.600 --> 02:19:54.600
and he would say, let's go to lunch together.

02:19:54.600 --> 02:19:55.600
And he would just do this.

02:19:55.600 --> 02:19:56.600
That's actually who Andrew was.

02:19:56.600 --> 02:19:58.600
What was the thinking behind that?

02:19:58.600 --> 02:20:00.600
He was just careless.

02:20:00.600 --> 02:20:02.600
He was much more outgoing than I am actually.

02:20:02.600 --> 02:20:04.600
He was very warm with people.

02:20:04.600 --> 02:20:08.600
For me, I would say that with Andrew, I knew Andrew for,

02:20:08.600 --> 02:20:10.600
let's say I met him when I was 16.

02:20:10.600 --> 02:20:14.600
He passed away when I would have been 28.

02:20:14.600 --> 02:20:16.600
So I knew Andrew for 10, 12 years.

02:20:16.600 --> 02:20:24.600
And people who met Andrew for about 10 minutes knew Andrew 99% as well as I knew Andrew

02:20:24.600 --> 02:20:26.600
because he was just all out front.

02:20:26.600 --> 02:20:28.600
Like everything was out here and he loved talking to people.

02:20:28.600 --> 02:20:29.600
He loved engaging with people.

02:20:29.600 --> 02:20:33.600
And so this made him a lot of fun and unpredictable and fun to watch and all of that.

02:20:33.600 --> 02:20:34.600
And then I think Twitter got to him.

02:20:34.600 --> 02:20:38.600
I think Twitter is, one of the lessons I learned from Andrew is the counter lesson,

02:20:38.600 --> 02:20:40.600
which is Twitter can poison you.

02:20:40.600 --> 02:20:41.600
Twitter can really wreck you.

02:20:41.600 --> 02:20:43.600
If you spend all day on Twitter reading the comments

02:20:43.600 --> 02:20:45.600
and getting angry at people who are talking about you,

02:20:45.600 --> 02:20:47.600
it becomes a very difficult life.

02:20:47.600 --> 02:20:49.600
And I think that in the last year of his life,

02:20:49.600 --> 02:20:53.600
Andrew got very caught up in that because of a series of sort of circumstances.

02:20:53.600 --> 02:20:54.600
It can actually affect your mind.

02:20:54.600 --> 02:20:57.600
It can actually make you resentful, all that kind of stuff.

02:20:57.600 --> 02:20:58.600
I tend to agree with that.

02:20:58.600 --> 02:21:01.600
But the lesson that I learned from Andrew is engage with everybody.

02:21:01.600 --> 02:21:05.600
Take joy in sort of the mission that you're given.

02:21:05.600 --> 02:21:07.600
And you can't always fulfill that.

02:21:07.600 --> 02:21:08.600
Sometimes it's really rough and difficult.

02:21:08.600 --> 02:21:12.600
I'm not going to pretend that it's all fun and rainbows all the time because it isn't.

02:21:12.600 --> 02:21:15.600
And some of the stuff that I have to cover, I don't like.

02:21:15.600 --> 02:21:17.600
And some of the things I have to say, I don't particularly like.

02:21:17.600 --> 02:21:19.600
That happens.

02:21:19.600 --> 02:21:21.600
But that's what I learned from Andrew.

02:21:21.600 --> 02:21:25.600
As far as sort of other mentors, I had some teachers when I was a kid

02:21:25.600 --> 02:21:27.600
who said things that stuck with me.

02:21:27.600 --> 02:21:30.600
I had a fourth grade teacher named Miss Janetti who said,

02:21:30.600 --> 02:21:32.600
don't let potential be written on your tombstone,

02:21:32.600 --> 02:21:34.600
which is a pretty 

02:21:34.600 --> 02:21:35.600
That's a good line.

02:21:35.600 --> 02:21:37.600
It's a great line, particularly to a fourth grader.

02:21:37.600 --> 02:21:41.600
But I had an 11th grade English teacher named Anthony Miller

02:21:41.600 --> 02:21:43.600
who is terrific, really good writer.

02:21:43.600 --> 02:21:46.600
He had studied with James Joyce at Trinity College in Dublin.

02:21:46.600 --> 02:21:50.600
And so he and I really got along and he helped my writing a lot.

02:21:50.600 --> 02:21:52.600
Did you ever have doubt in yourself?

02:21:52.600 --> 02:21:56.600
I mean, especially as you've gotten into the public eye with all the attacks,

02:21:56.600 --> 02:21:58.600
did you ever doubt your ability to stay strong,

02:21:58.600 --> 02:22:02.600
to be able to be a voice of the ideas that you represent?

02:22:02.600 --> 02:22:05.600
You definitely  I doubt my ability to say what I want to say.

02:22:05.600 --> 02:22:08.600
I doubt my ability to handle the emotional blowback of saying it,

02:22:08.600 --> 02:22:10.600
meaning that that's difficult.

02:22:10.600 --> 02:22:13.600
I mean, again, to take just one example,

02:22:13.600 --> 02:22:18.600
in 2016 the ADL measured that I was the number one target of anti-Semitism on planet Earth.

02:22:18.600 --> 02:22:20.600
That's not fun.

02:22:20.600 --> 02:22:21.600
That's unpleasant.

02:22:21.600 --> 02:22:23.600
And when you take critiques, not from anti-Semites,

02:22:23.600 --> 02:22:26.600
but when you take critiques from people generally,

02:22:26.600 --> 02:22:29.600
we talked about near the beginning how you surround yourself

02:22:29.600 --> 02:22:32.600
with people who are going to give you good feedback.

02:22:32.600 --> 02:22:33.600
Sometimes it's hard to tell.

02:22:33.600 --> 02:22:34.600
Sometimes people are giving you feedback.

02:22:34.600 --> 02:22:37.600
You don't know whether it's well motivated or poorly motivated.

02:22:37.600 --> 02:22:39.600
And if you are trying to be a decent person,

02:22:39.600 --> 02:22:41.600
you can't cut off the mechanism of feedback.

02:22:41.600 --> 02:22:45.600
And so what that means is sometimes you take to heart the wrong thing

02:22:45.600 --> 02:22:47.600
or you take it to heart too much.

02:22:47.600 --> 02:22:48.600
You're not light enough about it.

02:22:48.600 --> 02:22:50.600
You take it very, very seriously.

02:22:50.600 --> 02:22:51.600
You lose sleep over it.

02:22:51.600 --> 02:22:53.600
I mean, I can't tell you the number of nights where I've just not slept

02:22:53.600 --> 02:22:55.600
because of some critique somebody's made of me.

02:22:55.600 --> 02:22:57.600
And I've thought to myself, maybe that's right.

02:22:57.600 --> 02:22:58.600
And sometimes it is right.

02:22:58.600 --> 02:22:59.600
And, you know, that's 

02:22:59.600 --> 02:23:02.600
So some of that is good to stew in that criticism,

02:23:02.600 --> 02:23:04.600
but some of that can destroy you.

02:23:04.600 --> 02:23:05.600
Do you have a shortcut?

02:23:05.600 --> 02:23:08.600
So Rogan has talked about taking a lot of mushrooms.

02:23:08.600 --> 02:23:11.600
Since you're not into the mushroom thing,

02:23:11.600 --> 02:23:13.600
what's your escape from that?

02:23:13.600 --> 02:23:16.600
Like when you get low, when you can't sleep?

02:23:16.600 --> 02:23:18.600
Usually writing is a big one for me.

02:23:18.600 --> 02:23:20.600
So the writing for me is cathartic.

02:23:20.600 --> 02:23:21.600
I love writing.

02:23:21.600 --> 02:23:23.600
That is a huge one.

02:23:23.600 --> 02:23:25.600
Spending time with my family.

02:23:25.600 --> 02:23:29.600
Again, I usually have a close circle of friends who I will talk with

02:23:29.600 --> 02:23:31.600
in order to sort of bounce ideas off of them.

02:23:32.600 --> 02:23:35.600
And then once I've kind of talked it through,

02:23:35.600 --> 02:23:37.600
I tend to feel a little bit better.

02:23:37.600 --> 02:23:38.600
Exercise is also a big one.

02:23:38.600 --> 02:23:40.600
I mean, if I go a few days with that exercise,

02:23:40.600 --> 02:23:42.600
I tend to get pretty grumpy pretty quickly.

02:23:42.600 --> 02:23:45.600
I mean, I got to keep the six-pack going somehow, man.

02:23:45.600 --> 02:23:47.600
There you and Rogan agree.

02:23:47.600 --> 02:23:52.600
Well, we haven't, aside from Twitter, mentioned love.

02:23:52.600 --> 02:23:56.600
What's the role of love in the human condition, Ben Shapiro?

02:23:56.600 --> 02:23:58.600
Man, don't get asked for love too much.

02:23:58.600 --> 02:24:00.600
In fact, I was...

02:24:00.600 --> 02:24:03.600
You don't get that question on College Camp.

02:24:03.600 --> 02:24:04.600
No, I typically don't, actually.

02:24:04.600 --> 02:24:07.600
In fact, we were at an event recently.

02:24:07.600 --> 02:24:09.600
It was a Daily Wire event.

02:24:09.600 --> 02:24:12.600
And in the middle of this event was a meet and greet with some of the audience.

02:24:12.600 --> 02:24:15.600
And in the middle of this event, this guy walks by with this girl.

02:24:15.600 --> 02:24:18.600
They're talking, and they're talking to me, and their time kind of runs.

02:24:18.600 --> 02:24:19.600
The security is moving them.

02:24:19.600 --> 02:24:20.600
He says, no, no, no, wait, hold on a minute.

02:24:20.600 --> 02:24:22.600
And he gets down on one knee and he proposes to the girl in front of me.

02:24:22.600 --> 02:24:26.600
And I said to him, this is the weirdest proposal in human history.

02:24:26.600 --> 02:24:28.600
What is happening right now?

02:24:28.600 --> 02:24:30.600
Like, I was your choice of Cupid here?

02:24:30.600 --> 02:24:33.600
So, well, you know, we actually got together because we listened to your show.

02:24:33.600 --> 02:24:36.600
And I said, well, I can perform it like a Jewish marriage right now.

02:24:36.600 --> 02:24:37.600
We're going to need a glass.

02:24:37.600 --> 02:24:39.600
We're going to need some wine.

02:24:39.600 --> 02:24:40.600
It's going to get weird real fast.

02:24:40.600 --> 02:24:44.600
But yeah, so love doctor, I'm typically not asked too much about.

02:24:44.600 --> 02:24:54.600
The role of love is important in binding together human beings who ought to be bound together.

02:24:54.600 --> 02:24:59.600
And the role of respect is even more important in binding together broader groups of people.

02:24:59.600 --> 02:25:03.600
I think one of the mistakes that we make in politics is trying to substitute love for respect or respect for love.

02:25:03.600 --> 02:25:04.600
And I think that's a big mistake.

02:25:04.600 --> 02:25:11.600
So I do not bear tremendous love in the same sense that I do for my family, for random strangers.

02:25:11.600 --> 02:25:12.600
I don't.

02:25:12.600 --> 02:25:13.600
I love my family.

02:25:13.600 --> 02:25:14.600
I love my kids.

02:25:14.600 --> 02:25:16.600
Anybody who tells you they love your kid as much as you love your kid is lying to you.

02:25:16.600 --> 02:25:17.600
It's not true.

02:25:17.600 --> 02:25:21.600
I love my community more than I love other communities.

02:25:21.600 --> 02:25:23.600
I love my state more than I love other states.

02:25:23.600 --> 02:25:25.600
I love my country more than I love other countries.

02:25:25.600 --> 02:25:28.600
That's all normal and that's all good.

02:25:28.600 --> 02:25:34.600
The problem of empathy can be when that becomes so tight-knit that you're not outward-looking,

02:25:34.600 --> 02:25:36.600
that you don't actually have respect for other people.

02:25:36.600 --> 02:25:40.600
So in the local level, you need love in order to protect you and shield you and give you the strength to go forward.

02:25:40.600 --> 02:25:45.600
And then beyond that, you need a lot of respect for people who are not in the circle of love.

02:25:45.600 --> 02:25:54.600
And I think trying to extend love to people who either are not going to love you back or are going to slap you in the face for it

02:25:54.600 --> 02:25:59.600
or who you're just not that close to, it's either it runs the risk of being airsats and fake

02:25:59.600 --> 02:26:03.600
or it can actually be counterproductive in some senses.

02:26:03.600 --> 02:26:13.600
Well, there's some sense in which you could have love for other human beings just based on the humanity that connects everybody.

02:26:14.600 --> 02:26:18.600
So you love this whole project that we're a part of.

02:26:18.600 --> 02:26:23.600
And actually, another thing we disagree on.

02:26:23.600 --> 02:26:32.600
So loving a stranger, like having that basic empathy and compassion towards a stranger, even if it can hurt you,

02:26:32.600 --> 02:26:39.600
I think that to me is what it means to be a good man.

02:26:39.600 --> 02:26:43.600
To live a good life is to have that compassion towards strangers.

02:26:43.600 --> 02:26:48.600
Because to me, it's easy and natural and obvious to love people close to you.

02:26:48.600 --> 02:26:54.600
But to step outside of yourself and to love others, I think that's the fabric of a good society.

02:26:54.600 --> 02:26:56.600
You don't think there's value to that?

02:26:56.600 --> 02:26:57.600
I think there can be.

02:26:57.600 --> 02:27:00.600
But I think we're also discussing love almost in two different senses.

02:27:00.600 --> 02:27:08.600
Meaning that when I talk about love, what I think of immediately is the love I bear for my wife and kids or my parents or my siblings.

02:27:08.600 --> 02:27:10.600
Or the love of my close friends.

02:27:10.600 --> 02:27:17.600
But I think that using that same term to describe how I feel about strangers I think would just be inaccurate.

02:27:17.600 --> 02:27:26.600
And so that's why I'm suggesting that respect might be a more solid and realistic foundation for the way that we treat people far away from us,

02:27:26.600 --> 02:27:27.600
for people who are strangers.

02:27:27.600 --> 02:27:32.600
Respect for their dignity, respect for their priorities, respect for their role in life.

02:27:32.600 --> 02:27:34.600
It might be too much of an ask, in other words.

02:27:34.600 --> 02:27:40.600
There might be the rare human being who's capable of literally loving a homeless man on the street the way that he loves his own family.

02:27:40.600 --> 02:27:48.600
But if you respect the homeless man on the street the way that you respect your own family, because everyone deserves that respect,

02:27:48.600 --> 02:27:57.600
I think that you get to the same end without forcing people into a position of unrealistically expecting themselves to feel a thing they don't feel.

02:27:57.600 --> 02:28:03.600
One of the big questions in religion that comes up is God makes certain requests that you feel certain ways.

02:28:03.600 --> 02:28:07.600
You're supposed to be bismillah, you're supposed to be happy about certain things.

02:28:07.600 --> 02:28:09.600
You're supposed to love thy neighbor as thyself.

02:28:09.600 --> 02:28:12.600
You'll notice that in that statement, it's thy neighbor.

02:28:12.600 --> 02:28:15.600
It's not just generally anyone, it's love thy neighbor.

02:28:15.600 --> 02:28:16.600
In any case...

02:28:16.600 --> 02:28:19.600
I think that extends to anyone that follows you on Twitter.

02:28:19.600 --> 02:28:26.600
Thy neighbor, because God anticipated the social network aspect that is not constrained by geography.

02:28:26.600 --> 02:28:28.600
Yeah, I'm going to differ with you on the interpretation on that.

02:28:28.600 --> 02:28:37.600
But in any case, the kind of extension of love outwards might be too big an ask,

02:28:37.600 --> 02:28:44.600
so maybe we can start with respect and then hopefully out of that respect can grow something more if people earn their way in.

02:28:44.600 --> 02:28:47.600
Because I think that one of the big problems when we're talking about universalism is when people say,

02:28:47.600 --> 02:28:53.600
I'm a world citizen, I love people of the other country as much as I love myself or as much as I love my country,

02:28:53.600 --> 02:29:00.600
it tends to actually lead to an almost crammed-down utopianism that I think can be kind of difficult

02:29:00.600 --> 02:29:05.600
because with love comes a certain expectation of solidarity.

02:29:05.600 --> 02:29:08.600
And I think when you love your family, you love your wife,

02:29:08.600 --> 02:29:13.600
there's a certain level of solidarity that is required inside the home in order to preserve the most loving kind of home.

02:29:13.600 --> 02:29:17.600
And so if you love everybody, then that sort of implies a certain level of solidarity that may not exist.

02:29:18.600 --> 02:29:23.600
So maybe the idea is for me, start with respect and then maybe as people respect each other more,

02:29:23.600 --> 02:29:27.600
then love is an outgrowth of that as opposed to starting with love and then hoping that respect develops.

02:29:27.600 --> 02:29:35.600
Yeah, there's a danger that that word becomes empty and instead is used for dogmatic kind of utopianism.

02:29:35.600 --> 02:29:39.600
I mean, this is the way that, for example, religious theocracies very often work.

02:29:39.600 --> 02:29:42.600
We love you so much, we have to convert you.

02:29:42.600 --> 02:29:44.600
So let's start with respect.

02:29:44.600 --> 02:29:51.600
What I would love to see after our conversation today is to see a Ben Shapiro that continues the growth

02:29:51.600 --> 02:29:55.600
on Twitter of being even more respectful than you've already been

02:29:55.600 --> 02:29:59.600
and maybe one day converting that into love on Twitter.

02:29:59.600 --> 02:30:04.600
That would, if I could see that in this world, that would make me die a happy man.

02:30:04.600 --> 02:30:09.600
Wow, that's a little bit more love in the world for me as a gift for me.

02:30:09.600 --> 02:30:11.600
I'll try to make that happen. I do have one question.

02:30:11.600 --> 02:30:15.600
I'm going to need you to tell me which jokes are okay. Are jokes still okay?

02:30:15.600 --> 02:30:19.600
So yeah, can I just run your Twitter from now on? You just send it to me.

02:30:19.600 --> 02:30:22.600
A hundred percent. I will pre-screen you the jokes.

02:30:22.600 --> 02:30:25.600
And you can tell me if this is a loving joke or if this is a hate-filled, obnoxious joke.

02:30:25.600 --> 02:30:31.600
People will be very surprised by all the heart emojis that are popping up on your Twitter.

02:30:31.600 --> 02:30:35.600
But thank you so much for being bold and fearless and exploring ideas.

02:30:35.600 --> 02:30:40.600
And your Twitter aside, thank you for being just good faith in all the arguments

02:30:40.600 --> 02:30:42.600
and all the conversations you're having with people. It's a huge honor.

02:30:42.600 --> 02:30:45.600
Thank you for talking to me. Thanks for having me. I really appreciate it.

02:30:45.600 --> 02:30:48.600
Thanks for listening to this conversation with Ben Shapiro.

02:30:48.600 --> 02:30:52.600
To support this podcast, please check out our sponsors in the description.

02:30:52.600 --> 02:30:56.600
And now let me leave you with some words from Ben Shapiro himself.

02:30:56.600 --> 02:31:03.600
Freedom of speech and thought matters, especially when it is speech and thought with which we disagree.

02:31:03.600 --> 02:31:09.600
The moment the majority decides to destroy people for engaging a thought it dislikes,

02:31:09.600 --> 02:31:12.600
thought crime becomes a reality.

02:31:12.600 --> 02:31:16.600
Thank you for listening. I hope to see you next time.

