WEBVTT

00:00.000 --> 00:02.920
The following is a conversation with Guillaume Verdun,

00:02.920 --> 00:05.680
the man behind the previously anonymous account

00:05.680 --> 00:09.040
based BefJezos on X.

00:09.040 --> 00:12.280
These two identities were merged by a doxing article

00:12.280 --> 00:16.240
in Forbes titled, Who is, based BefJezos,

00:16.240 --> 00:19.960
the leader of the tech elite's EAC movement.

00:19.960 --> 00:22.120
So let me describe these two identities

00:22.120 --> 00:24.960
that coexist in the mind of one human.

00:25.800 --> 00:28.200
Identity number one, Guillaume,

00:28.200 --> 00:31.000
is a physicist, applied mathematician,

00:31.000 --> 00:33.560
and quantum machine learning researcher and engineer,

00:33.560 --> 00:36.120
receiving his PhD in quantum machine learning,

00:36.120 --> 00:38.480
working at Google on quantum computing,

00:38.480 --> 00:42.160
and finally launching his own company called Xtropic

00:42.160 --> 00:44.800
that seeks to build physics-based computing hardware

00:44.800 --> 00:47.000
for generative AI.

00:47.000 --> 00:50.960
Identity number two, BefJezos on X,

00:50.960 --> 00:54.720
is the creator of the effective accelerationism movement,

00:54.720 --> 00:57.920
often abbreviated as EAC.

00:57.960 --> 01:01.120
That advocates for propelling rapid technological progress

01:01.120 --> 01:04.560
as the ethically optimal course of action for humanity.

01:04.560 --> 01:08.880
For example, as proponents believe that progress in AI

01:08.880 --> 01:13.320
is a great social equalizer, which should be pushed forward.

01:13.320 --> 01:16.840
EAC followers see themselves as a counterweight

01:16.840 --> 01:20.120
to the cautious view that AI is highly unpredictable,

01:20.120 --> 01:22.960
potentially dangerous, and needs to be regulated.

01:23.920 --> 01:25.840
They often give their opponents the labels

01:25.840 --> 01:30.840
of, quote, do-mers or de-cells, short for deceleration.

01:31.840 --> 01:36.840
As Bef himself put it, EAC is a memetic optimism virus.

01:37.480 --> 01:39.440
The style of communication of this movement

01:39.440 --> 01:43.400
leans always toward the memes and the lulls,

01:43.400 --> 01:46.400
but there is an intellectual foundation

01:46.400 --> 01:49.040
that we explore in this conversation.

01:49.040 --> 01:51.360
Now, speaking of the meme,

01:51.360 --> 01:56.160
I am too a kind of aspiring connoisseur of the absurd.

01:56.160 --> 01:59.760
It is not an accident that I spoke to Jeff Bezos

01:59.760 --> 02:03.960
and BefJezos back to back.

02:03.960 --> 02:06.160
As we talk about, Bef admires Jeff

02:06.160 --> 02:08.640
as one of the most important humans alive,

02:08.640 --> 02:11.680
and I admire the beautiful absurdity

02:11.680 --> 02:12.920
and the humor of it all.

02:14.000 --> 02:16.240
This is the Lex Friedman podcast.

02:16.240 --> 02:18.200
To support it, please check out our sponsors

02:18.200 --> 02:19.360
in the description.

02:19.360 --> 02:22.680
And now, dear friends, here's Guillaume Verdun.

02:23.720 --> 02:26.160
Let's get the facts of identity down first.

02:26.160 --> 02:30.160
Your name is Guillaume Verdun, Gil,

02:30.160 --> 02:32.280
but you're also behind the anonymous account

02:32.280 --> 02:35.200
on X called BasedBefJezos.

02:35.200 --> 02:36.920
So first, Guillaume Verdun,

02:36.920 --> 02:39.520
you're a quantum computing guy,

02:39.520 --> 02:42.080
physicist, applied mathematician,

02:42.080 --> 02:46.840
and then BasedBefJezos is basically a meme account

02:46.880 --> 02:50.160
that started a movement with a philosophy behind it.

02:50.160 --> 02:53.760
So maybe just can you linger on who these people are

02:53.760 --> 02:56.680
in terms of characters, in terms of communication styles,

02:56.680 --> 02:58.840
in terms of philosophies?

02:58.840 --> 03:01.960
I mean, with my main identity, I guess,

03:01.960 --> 03:02.880
ever since I was a kid,

03:02.880 --> 03:06.400
I wanted to figure out a theory of everything

03:06.400 --> 03:08.040
to understand the universe.

03:08.040 --> 03:13.040
And that path led me to theoretical physics eventually,

03:14.080 --> 03:15.560
trying to answer the big questions

03:15.560 --> 03:19.360
of why are we here, where are we going, right?

03:19.360 --> 03:23.640
And that led me to study information theory

03:23.640 --> 03:27.120
and try to understand physics

03:27.120 --> 03:29.440
from the lens of information theory,

03:29.440 --> 03:34.000
understand the universe as one big computation.

03:34.000 --> 03:39.000
And essentially, after reaching a certain level,

03:39.680 --> 03:42.520
studying black hole physics,

03:42.560 --> 03:47.280
I realized that I wanted to not only understand

03:47.280 --> 03:51.760
how the universe computes, but sort of compute like nature

03:51.760 --> 03:56.680
and figure out how to build and apply computers

03:56.680 --> 03:58.480
that are inspired by nature.

03:58.480 --> 04:01.120
So, you know, physics-based computers.

04:01.120 --> 04:04.920
And that sort of brought me to quantum computing

04:04.920 --> 04:09.920
as a field of study to, first of all, simulate nature.

04:10.720 --> 04:14.960
And in my work, it was to learn representations of nature

04:14.960 --> 04:17.400
that can run on such computers.

04:17.400 --> 04:22.400
So if you have AI representations that think like nature,

04:24.840 --> 04:28.640
then they'll be able to more accurately represent it.

04:28.640 --> 04:32.280
At least that was the thesis that brought me

04:32.280 --> 04:34.840
to be an early player in the field

04:34.840 --> 04:36.960
called quantum machine learning, right?

04:36.960 --> 04:40.520
So how to do machine learning on quantum computers

04:41.800 --> 04:46.640
and really sort of extend notions of intelligence

04:46.640 --> 04:47.840
to the quantum realm.

04:47.840 --> 04:51.760
So how do you capture and understand

04:51.760 --> 04:54.480
quantum mechanical data from our world, right?

04:54.480 --> 04:57.840
And how do you learn quantum mechanical representations

04:57.840 --> 04:59.000
of our world?

04:59.000 --> 05:03.280
On what kind of computer do you run these representations

05:03.280 --> 05:04.160
and train them?

05:04.160 --> 05:05.600
How do you do so?

05:05.640 --> 05:08.280
And so that's really sort of the questions

05:08.280 --> 05:10.080
I was looking to answer

05:10.080 --> 05:13.120
because ultimately I had a sort of crisis of faith.

05:14.440 --> 05:17.560
Originally I wanted to figure out, you know,

05:17.560 --> 05:20.920
as every physicist does at the beginning of their career,

05:20.920 --> 05:24.200
a few equations that describe the whole universe, right?

05:24.200 --> 05:27.420
And sort of be the hero of the story there.

05:28.360 --> 05:32.720
But eventually I realized that actually augmenting ourselves

05:32.720 --> 05:35.920
with machines, augmenting our ability to perceive,

05:35.920 --> 05:38.240
predict and control our world with machines

05:38.240 --> 05:40.160
is the path forward, right?

05:40.160 --> 05:43.040
And that's what got me to leave theoretical physics

05:43.040 --> 05:46.520
and go into quantum computing and quantum machine learning.

05:46.520 --> 05:49.120
And during those years,

05:49.120 --> 05:53.400
I thought that there was still a piece missing.

05:53.400 --> 05:57.240
There was a piece of our understanding of the world

05:57.240 --> 05:59.200
and our way to compute

05:59.200 --> 06:01.520
and our way to think about the world.

06:01.520 --> 06:06.040
And if you look at the physical scales, right?

06:06.040 --> 06:07.560
At the very small scales,

06:07.560 --> 06:11.720
things are quantum mechanical, right?

06:11.720 --> 06:15.240
And at the very large scales, things are deterministic.

06:15.240 --> 06:16.520
Things have averaged out, right?

06:16.520 --> 06:18.240
I'm definitely here in this seat.

06:18.240 --> 06:21.240
I'm not in a superposition over here and there.

06:21.240 --> 06:24.020
At the very small scales, things are in superposition.

06:24.020 --> 06:28.500
They can exhibit interference effects.

06:29.720 --> 06:31.400
But at the mesoscales, right?

06:32.280 --> 06:34.720
The scales that matter for day-to-day life,

06:34.720 --> 06:39.720
the scales of proteins, of biology, of gases, liquids

06:39.720 --> 06:44.720
and so on, things are actually thermodynamical, right?

06:45.000 --> 06:46.840
They're fluctuating.

06:46.840 --> 06:51.280
And after, I guess, about eight years

06:51.280 --> 06:54.680
in quantum computing and quantum machine learning,

06:54.680 --> 06:59.680
I had a realization that I was looking for answers

06:59.680 --> 07:02.480
about our universe by studying the very big

07:02.480 --> 07:04.080
and the very small, right?

07:04.080 --> 07:07.120
I did a bit of quantum cosmology.

07:07.120 --> 07:09.960
So that's studying the cosmos, where it's going,

07:09.960 --> 07:11.320
where it came from.

07:11.320 --> 07:13.200
You study black hole physics.

07:13.200 --> 07:15.240
You study the extremes in quantum gravity.

07:15.240 --> 07:18.920
You study where the energy density is sufficient

07:18.920 --> 07:23.920
for both quantum mechanics and gravity to be relevant, right?

07:24.200 --> 07:28.440
And the sort of extreme scenarios are black holes

07:28.440 --> 07:30.840
in the very early universe.

07:30.840 --> 07:34.680
So there's the sort of scenarios that you study

07:34.680 --> 07:39.680
the interface between quantum mechanics and relativity.

07:42.000 --> 07:44.240
And really, I was studying these extremes

07:44.240 --> 07:49.240
to understand how the universe works and where is it going?

07:49.880 --> 07:54.600
But I was missing a lot of the meat in the middle,

07:54.600 --> 07:56.320
if you will, right?

07:56.320 --> 07:58.920
Because day-to-day quantum mechanics is relevant

07:58.920 --> 08:01.160
and the cosmos is relevant, but not that relevant.

08:01.160 --> 08:05.480
Actually, we're on sort of the medium space and time scales.

08:05.480 --> 08:09.000
And there, the main theory of physics

08:09.000 --> 08:12.360
that is most relevant is thermodynamics, right?

08:12.360 --> 08:14.520
Out of equilibrium thermodynamics.

08:15.400 --> 08:20.400
Because life is a process that is thermodynamical

08:20.640 --> 08:21.920
and it's out of equilibrium.

08:21.920 --> 08:26.200
We're not just a soup of particles at equilibrium

08:26.200 --> 08:29.320
with nature, we're a sort of coherent state

08:29.320 --> 08:31.040
trying to maintain itself

08:31.040 --> 08:33.960
by acquiring free energy and consuming it.

08:34.880 --> 08:39.760
And that's sort of, I guess, another shift

08:39.760 --> 08:43.400
and I guess my faith in the universe happened

08:44.600 --> 08:48.680
towards the end of my time at Alphabet.

08:49.760 --> 08:54.080
And I knew I wanted to build, well, first of all,

08:54.080 --> 08:56.680
a computing paradigm based on this type of physics.

08:57.920 --> 09:02.760
But ultimately, just by trying to experiment

09:02.760 --> 09:07.760
with these ideas applied to society and economies

09:08.240 --> 09:11.960
and much of what we see around us,

09:11.960 --> 09:16.960
I started an anonymous account just to relieve the pressure

09:17.720 --> 09:21.280
that comes from having an account that you're accountable

09:21.280 --> 09:22.840
for everything you say on.

09:24.200 --> 09:25.760
And I started an anonymous account

09:25.760 --> 09:29.200
just to experiment with ideas originally, right?

09:29.200 --> 09:34.200
Because I didn't realize how much I was restricting

09:35.280 --> 09:39.760
my space of thoughts until I sort of had the opportunity

09:39.760 --> 09:40.600
to let go.

09:40.600 --> 09:45.360
In a sense, restricting your speech back propagates

09:45.360 --> 09:47.960
to restricting your thoughts, right?

09:47.960 --> 09:51.440
And by creating an anonymous account,

09:51.440 --> 09:55.520
it seemed like I had unclamped some variables in my brain

09:55.520 --> 09:58.360
and suddenly could explore a much wider parameter space

09:58.360 --> 09:59.960
of thoughts.

09:59.960 --> 10:02.600
Just to linger on that, isn't that interesting?

10:02.600 --> 10:05.400
That one of the things that people often talk about

10:06.400 --> 10:11.400
is that when there's pressure and constraints on speech,

10:12.240 --> 10:15.640
it somehow leads to constraints on thought.

10:15.640 --> 10:16.640
Even though it doesn't have to,

10:16.640 --> 10:18.920
we can think thoughts inside our head,

10:18.920 --> 10:23.640
but somehow it creates these walls around thought.

10:23.640 --> 10:28.480
Yeah, that's sort of the basis of our movement

10:28.480 --> 10:33.480
is we were seeing a tendency towards constraint,

10:34.760 --> 10:36.800
reduction or suppression of variance

10:36.800 --> 10:40.720
in every aspect of life, whether it's thought,

10:40.720 --> 10:45.720
how to run a company, how to organize humans,

10:46.240 --> 10:49.120
how to do AI research.

10:50.000 --> 10:55.000
In general, we believe that maintaining variance ensures

10:55.160 --> 10:57.560
that the system is adaptive, right?

10:57.560 --> 11:02.560
Maintaining healthy competition in marketplaces of ideas,

11:03.760 --> 11:07.800
of companies, of products, of cultures,

11:07.800 --> 11:12.800
of governments, of currencies is the way forward

11:13.040 --> 11:18.040
because the system always adapts to assign resources

11:20.880 --> 11:25.360
to the configurations that lead to its growth.

11:25.360 --> 11:29.240
And the fundamental basis for the movement

11:29.240 --> 11:34.240
is this sort of realization that life is a sort of fire

11:36.600 --> 11:39.320
that seeks out free energy in the universe

11:39.320 --> 11:41.920
and seeks to grow, right?

11:41.920 --> 11:45.120
And that growth is fundamental to life.

11:45.120 --> 11:48.280
And you see this in the equations actually

11:48.280 --> 11:50.360
of our equilibrium thermodynamics.

11:51.280 --> 11:56.280
You see that paths of trajectories,

11:56.320 --> 11:59.840
of configurations of matter that are better

11:59.840 --> 12:04.800
at acquiring free energy and dissipating more heat

12:04.800 --> 12:08.720
are exponentially more likely, right?

12:08.720 --> 12:13.720
So the universe is biased towards certain futures.

12:13.800 --> 12:17.640
And so there's a natural direction

12:17.640 --> 12:21.320
where the whole system wants to go.

12:21.320 --> 12:23.760
So the second law of thermodynamics says

12:23.760 --> 12:27.040
that the entropy is always increasing in the universe.

12:27.040 --> 12:28.920
It's tending towards equilibrium.

12:28.920 --> 12:30.880
And you're saying there's these pockets

12:30.880 --> 12:35.880
that have complexity and are out of equilibrium.

12:36.600 --> 12:38.160
You said that thermodynamics favors

12:38.160 --> 12:41.080
the creation of complex life that increases its capability

12:41.080 --> 12:44.360
to use energy to offload entropy, to offload entropy.

12:44.360 --> 12:47.240
So you have pockets of non-entropy

12:47.240 --> 12:49.400
that tend the opposite direction.

12:49.400 --> 12:51.960
Why is that intuitive to you that it's natural

12:51.960 --> 12:53.840
for such pockets to emerge?

12:53.840 --> 12:58.840
Well, we're far more efficient at producing heat

12:59.040 --> 13:03.000
than let's say just a rock with a similar mass

13:03.000 --> 13:04.520
as ourselves, right?

13:04.560 --> 13:08.560
We acquire free energy, we acquire food

13:08.560 --> 13:13.560
and we're using all this electricity for our operation.

13:14.320 --> 13:18.400
And so the universe wants to produce more entropy

13:18.400 --> 13:23.400
and by having life go on and grow,

13:23.560 --> 13:26.560
it's actually more optimal at producing entropy

13:26.560 --> 13:30.040
because it will seek out pockets of free energy

13:30.920 --> 13:35.360
and burn it for its sustenance and further growth.

13:35.360 --> 13:40.040
And that's sort of the basis of life.

13:40.040 --> 13:45.040
And I mean, there's Jeremy England at MIT

13:45.080 --> 13:48.200
who has this theory that I'm a proponent of

13:48.200 --> 13:53.040
that life emerged because of this sort of property.

13:53.040 --> 13:58.040
And to me, this physics is what governs the mesoscales.

13:58.520 --> 14:01.840
And so it's the missing piece between the quantum

14:01.840 --> 14:05.040
and the cosmos, it's the middle part, right?

14:05.040 --> 14:08.160
Thermodynamics rules the mesoscales.

14:08.160 --> 14:13.160
And to me, both from a point of view of designing

14:13.360 --> 14:16.960
or engineering devices that harness that physics

14:16.960 --> 14:18.880
and trying to understand the world

14:19.960 --> 14:23.560
through the lens of thermodynamics has been sort of a synergy

14:23.560 --> 14:28.000
between my two identities over the past year and a half now.

14:28.960 --> 14:32.680
And so that's really how the two identities emerged.

14:32.680 --> 14:37.680
One was kind of, I'm a decently respected scientist

14:38.120 --> 14:43.120
and I was going towards doing a startup in the space

14:43.920 --> 14:46.240
and trying to be a pioneer of a new kind

14:46.240 --> 14:47.920
of physics-based AI.

14:47.920 --> 14:51.680
And as a dual to that, I was sort of experimenting

14:51.680 --> 14:56.680
with philosophical thoughts from a physicist's standpoint.

14:58.800 --> 15:03.320
And ultimately, I think that around that time,

15:03.320 --> 15:07.760
it was like late 2021, early 2022,

15:07.760 --> 15:10.560
I think there's just a lot of pessimism

15:10.560 --> 15:14.520
about the future in general and pessimism about tech.

15:14.520 --> 15:19.320
And that pessimism was sort of virally spreading

15:19.320 --> 15:24.080
because it was getting algorithmically amplified

15:24.080 --> 15:28.720
and people just felt like the future

15:28.720 --> 15:31.120
is gonna be worse than the present.

15:31.120 --> 15:36.120
And to me, that is a very fundamentally destructive force

15:37.440 --> 15:42.400
in the universe, is this sort of doom mindset

15:42.400 --> 15:44.800
because it is hyperstitious, which means that

15:44.800 --> 15:47.520
if you believe it, you're increasing the likelihood

15:47.520 --> 15:49.600
of it happening.

15:49.600 --> 15:53.680
And so felt a responsibility to some extent

15:53.680 --> 15:58.680
to make people aware of the trajectory of civilization

16:01.000 --> 16:02.920
and the natural tendency of the system

16:02.920 --> 16:05.080
to adapt towards its growth.

16:05.080 --> 16:07.400
And sort of that actually the laws of physics say

16:07.400 --> 16:09.600
that the future is gonna be better

16:09.600 --> 16:14.120
and grander statistically, and we can make it so.

16:14.120 --> 16:17.880
And if you believe in it, if you believe

16:17.880 --> 16:19.720
that the future would be better

16:19.720 --> 16:23.040
and you believe you have agency to make it happen,

16:23.040 --> 16:24.920
you're actually increasing the likelihood

16:24.920 --> 16:26.840
of that better future happening.

16:26.840 --> 16:30.120
And so I sort of felt the responsibility

16:30.120 --> 16:35.120
to sort of engineer a movement of viral optimism

16:35.440 --> 16:39.360
about the future and build a community

16:39.360 --> 16:43.320
of people supporting each other to build and do hard things,

16:43.320 --> 16:45.440
do the things that need to be done

16:45.440 --> 16:48.880
for us to scale up civilization.

16:49.720 --> 16:53.400
Because at least to me, I don't think stagnation

16:53.400 --> 16:56.080
or slowing down is actually an option.

16:56.080 --> 16:59.160
Fundamentally, life and the whole system

16:59.160 --> 17:02.520
or whole civilization wants to grow.

17:02.520 --> 17:05.720
And there's just far more cooperation

17:05.720 --> 17:09.560
when the system is growing rather than when it's declining

17:09.560 --> 17:13.560
and you have to decide how to split the pie.

17:14.560 --> 17:19.040
And so I've balanced both identities so far,

17:20.360 --> 17:24.600
but I guess recently the two have been merged

17:24.600 --> 17:27.880
more or less without my consent, so.

17:27.880 --> 17:29.800
You said a lot of really interesting things there.

17:29.800 --> 17:34.200
So first, representations of nature.

17:34.200 --> 17:36.160
That's something that first drew you in

17:36.160 --> 17:39.320
to try to understand from a quantum computing perspective

17:39.320 --> 17:42.200
is like, how do you understand nature?

17:42.200 --> 17:43.120
How do you represent nature

17:43.120 --> 17:45.200
in order to understand it, in order to simulate it,

17:45.200 --> 17:47.120
in order to do something with it?

17:47.120 --> 17:49.560
So it's a question of representations.

17:49.560 --> 17:51.760
And then there's that leap you take

17:51.760 --> 17:53.720
from the quantum mechanical representation

17:53.720 --> 17:56.600
to the what you're calling mesoscale representation

17:56.600 --> 17:58.880
where the thermodynamics comes into play,

17:58.880 --> 18:01.360
which is a way to represent nature

18:01.360 --> 18:06.360
in order to understand what life, human behavior,

18:06.520 --> 18:08.400
all this kind of stuff that's happening here on earth

18:08.400 --> 18:11.080
that seems interesting to us.

18:11.080 --> 18:14.040
Then there's the word high-prestition.

18:15.200 --> 18:19.000
So some ideas, I suppose both pessimism and optimism

18:19.000 --> 18:23.560
are such ideas that if you internalize them,

18:23.560 --> 18:26.760
you in part make that idea a reality.

18:26.760 --> 18:29.280
So both optimism and pessimism have that property.

18:29.280 --> 18:33.160
I would say that probably a lot of ideas have that property,

18:33.160 --> 18:35.840
which is one of the interesting things about humans.

18:35.840 --> 18:40.040
And you talked about one interesting difference

18:40.040 --> 18:45.040
also between the sort of the Guillaume de Guil front end

18:45.800 --> 18:49.240
and the Baspev-Jezos back end

18:49.240 --> 18:51.760
is the communication styles also,

18:51.760 --> 18:55.280
that you were exploring different ways of communicating

18:55.280 --> 18:58.440
that can be more viral in the way

18:58.440 --> 19:00.880
that we communicate in the 21st century.

19:00.880 --> 19:05.240
Also the movement that you mentioned that you started,

19:05.240 --> 19:06.720
it's not just a meme account,

19:06.720 --> 19:10.040
but there's also a name to it

19:10.040 --> 19:13.920
called Effective Accelerationism, EEC,

19:13.920 --> 19:18.920
a play, a resistance to the effective altruism movement,

19:19.840 --> 19:22.120
also an interesting one that I'd love to talk to you about,

19:22.120 --> 19:23.600
the tensions there.

19:23.600 --> 19:25.680
Okay, and so then there was a merger,

19:25.680 --> 19:28.680
a get merge on the personalities.

19:29.680 --> 19:32.440
Recently, without your consent, like you said,

19:32.440 --> 19:36.700
some journalists figured out that you're one in the same.

19:36.700 --> 19:39.580
Maybe you could talk about that experience.

19:39.580 --> 19:44.580
First of all, what's the story of the merger of the two?

19:45.740 --> 19:50.740
Right, so I wrote the manifesto

19:50.940 --> 19:54.740
with my co-founder of EEC, an account named Bazelord,

19:54.740 --> 19:58.500
still anonymous, luckily, and hopefully forever.

19:58.500 --> 20:03.500
So it's Bazed, Bef, Jezos, and Bazed, like Bazian?

20:03.900 --> 20:07.580
Like Bazelord, like Bazian, Bazian Lord, Bazelord.

20:07.580 --> 20:10.340
Okay, and so we should say from now on,

20:10.340 --> 20:14.860
when you say EEC, you mean E slash ACC,

20:14.860 --> 20:17.580
which stands for Effective Accelerationism.

20:17.580 --> 20:18.420
That's right.

20:18.420 --> 20:21.980
And you're referring to a manifesto written on,

20:21.980 --> 20:23.780
I guess, Substack.

20:23.780 --> 20:25.540
Are you also Bazelord?

20:25.540 --> 20:26.360
No.

20:26.360 --> 20:27.200
Okay, it's a different person.

20:27.200 --> 20:28.040
Yeah.

20:28.040 --> 20:29.900
Okay, all right, well, there you go.

20:29.900 --> 20:31.980
Wouldn't it be funny if I'm Bazelord?

20:32.020 --> 20:32.940
That'd be amazing.

20:34.680 --> 20:38.500
So originally wrote the manifesto

20:38.500 --> 20:42.740
around the same time as I founded this company.

20:42.740 --> 20:47.740
And I worked at Google X, or just X now,

20:49.140 --> 20:51.700
or Alphabet X, now that there's another X.

20:53.140 --> 20:57.500
And there, the baseline is sort of secrecy, right?

20:57.500 --> 21:00.380
You can't talk about what you work on,

21:00.380 --> 21:04.060
even with other Googlers or externally.

21:04.060 --> 21:06.340
And so that was kind of deeply ingrained

21:06.340 --> 21:09.900
in my way to do things, especially in deep tech

21:09.900 --> 21:14.820
that has geopolitical impact, right?

21:16.660 --> 21:20.580
And so I was being secretive about what I was working on.

21:20.580 --> 21:22.420
There was no correlation between my company

21:22.420 --> 21:25.340
and my main identity publicly.

21:25.340 --> 21:27.900
And then not only did they correlate that,

21:27.900 --> 21:32.900
they also correlated my main identity and this account.

21:33.140 --> 21:36.260
So I think the fact that they had

21:36.260 --> 21:39.540
doxed the whole Guillaume complex,

21:40.420 --> 21:43.220
and they were, the journalists reached out

21:43.220 --> 21:47.540
to actually my investors, which is pretty scary.

21:47.540 --> 21:48.940
When you're a startup entrepreneur,

21:48.940 --> 21:52.460
you don't really have bosses except for your investors,

21:52.460 --> 21:54.080
right?

21:54.080 --> 21:55.780
And my investors ping me like,

21:55.820 --> 21:57.740
hey, this is gonna come out.

21:57.740 --> 22:00.220
They've figured out everything.

22:00.220 --> 22:02.260
What are you gonna do, right?

22:03.940 --> 22:06.900
So I think at first they had a first reporter

22:06.900 --> 22:10.820
on the Thursday and they didn't have all the pieces together,

22:10.820 --> 22:13.260
but then they looked at their notes across the organization

22:13.260 --> 22:15.580
and they censor-fused their notes.

22:15.580 --> 22:17.180
And now they had way too much.

22:18.260 --> 22:19.300
And that's when I got worried

22:19.300 --> 22:22.780
because they said it was of public interest.

22:22.780 --> 22:23.780
And in general-

22:23.780 --> 22:25.340
Luckily you said censor-fused.

22:26.620 --> 22:28.900
Like it's some giant neural network operating

22:28.900 --> 22:30.780
in a distributed way.

22:30.780 --> 22:32.860
We should also say that the journalists used,

22:32.860 --> 22:34.980
I guess at the end of the day,

22:34.980 --> 22:37.540
audio-based analysis of voice,

22:37.540 --> 22:41.180
pairing voice of what talks you've given in the past

22:41.180 --> 22:46.180
and then voice on X spaces.

22:48.180 --> 22:51.700
Okay, so that's where primarily the match happened.

22:51.700 --> 22:53.180
Okay, continue.

22:53.700 --> 22:58.700
But they scraped SEC filings,

22:59.340 --> 23:04.340
they looked at my private Facebook account and so on.

23:04.820 --> 23:07.380
So they did some digging.

23:07.380 --> 23:11.660
Originally I thought that doxxing was illegal, right?

23:12.860 --> 23:14.980
But there's this weird threshold

23:14.980 --> 23:17.460
when it becomes of public interest

23:17.460 --> 23:19.660
to know someone's identity.

23:19.660 --> 23:21.340
And those were the keywords

23:21.340 --> 23:23.580
that sort of like ring the alarm bells for me

23:23.580 --> 23:25.060
when they said,

23:25.060 --> 23:27.060
because I had just reached 50K followers,

23:27.060 --> 23:29.260
allegedly that's of public interest.

23:29.260 --> 23:32.100
And so where do we draw the line?

23:32.100 --> 23:36.020
When is it legal to doxx someone?

23:36.020 --> 23:39.340
The word doxx, maybe you can educate me.

23:39.340 --> 23:42.420
I thought doxxing generally refers to

23:42.420 --> 23:46.100
if somebody's physical location is found out,

23:46.100 --> 23:48.420
meaning like where they live.

23:48.700 --> 23:53.300
So we're referring to the more general concept

23:53.300 --> 23:58.100
of revealing private information

23:58.100 --> 23:59.780
that you don't want revealed,

23:59.780 --> 24:01.700
is what you mean by doxxing.

24:01.700 --> 24:06.460
I think that for the reasons we listed before,

24:06.460 --> 24:10.620
having an anonymous account is a really powerful way

24:10.620 --> 24:12.980
to keep the powers that be in check.

24:14.060 --> 24:16.900
We were ultimately speaking truth to power, right?

24:16.940 --> 24:20.220
I think a lot of executives and AI companies

24:20.220 --> 24:22.620
really cared what our community thought

24:23.820 --> 24:26.340
about any move they may take.

24:26.340 --> 24:30.100
And now that my identity is revealed,

24:30.100 --> 24:33.180
now they know where to apply pressure

24:33.180 --> 24:38.180
to silence me or maybe the community.

24:38.180 --> 24:40.340
And to me, that's really unfortunate

24:41.220 --> 24:43.980
because again, it's so important

24:43.980 --> 24:47.140
for us to have freedom of speech,

24:47.140 --> 24:48.820
which induces freedom of thought

24:50.100 --> 24:54.220
and freedom of information propagation, right?

24:54.220 --> 24:58.780
On social media, which thanks to Elon purchasing Twitter,

24:58.780 --> 25:01.260
now X, we have that.

25:02.980 --> 25:07.980
And so to us, we wanted to call out certain maneuvers

25:10.060 --> 25:12.860
being done by the incumbents in AI

25:12.860 --> 25:17.060
as not what it may seem on the surface, right?

25:17.060 --> 25:20.140
We were calling out how certain proposals

25:20.140 --> 25:23.700
might be useful for regulatory capture, right?

25:23.700 --> 25:28.340
And how the doomerism mindset

25:28.340 --> 25:31.100
was maybe instrumental to those ends.

25:32.140 --> 25:33.820
And I think, you know, we should have the right

25:33.820 --> 25:38.820
to point that out and just have the ideas

25:38.980 --> 25:41.740
that we put out evaluated for themselves, right?

25:41.780 --> 25:45.940
Ultimately, that's why I created an anonymous account.

25:45.940 --> 25:48.820
It's to have my ideas evaluated for themselves

25:48.820 --> 25:52.660
uncorrelated from my track record, my job,

25:52.660 --> 25:57.460
or status from having done things in the past.

25:57.460 --> 26:02.460
And to me, start an account from zero to a large following

26:04.820 --> 26:06.740
in a way that wasn't dependent

26:06.740 --> 26:09.700
on my identity and or achievements.

26:09.740 --> 26:13.860
You know, that was very fulfilling, right?

26:13.860 --> 26:16.820
It's kind of like new game plus in a video game.

26:16.820 --> 26:18.580
You restart the video game with your knowledge

26:18.580 --> 26:21.140
of how to beat it, maybe some tools,

26:21.140 --> 26:24.260
but you restart the video game from scratch, right?

26:24.260 --> 26:29.260
And I think to have a truly efficient marketplace of ideas

26:29.780 --> 26:32.820
where we can evaluate ideas,

26:32.820 --> 26:35.340
however off the beaten path they are,

26:35.340 --> 26:37.580
we need the freedom of expression.

26:37.580 --> 26:42.340
And I think that anonymity and pseudonyms

26:42.340 --> 26:44.660
are very crucial to having

26:44.660 --> 26:46.860
that efficient marketplace of ideas

26:46.860 --> 26:51.860
for us to find the optima of all sorts of ways

26:52.700 --> 26:53.860
to organize ourselves.

26:53.860 --> 26:55.220
If we can't discuss things,

26:55.220 --> 26:58.300
how are we gonna converge on the best way to do things?

26:58.300 --> 27:01.500
So it was disappointing to hear that I was getting doxxed

27:01.500 --> 27:04.060
and I wanted to get in front of it

27:04.060 --> 27:07.060
because I had a responsibility for my company.

27:08.020 --> 27:10.260
And so I, you know, we ended up disclosing

27:11.580 --> 27:14.300
that we're running a company, some of the leadership

27:15.460 --> 27:19.740
and essentially, yeah, I told the world

27:19.740 --> 27:24.180
that I was Beth-Jezos because they had me cornered

27:24.180 --> 27:25.180
at that point.

27:25.180 --> 27:28.500
So to you, it's fundamentally unethical.

27:28.500 --> 27:32.300
Like, so one is unethical for them to do what they did,

27:32.300 --> 27:35.300
but also do you think, not just your case,

27:35.300 --> 27:38.660
but in a general case, is it good for society?

27:38.660 --> 27:43.660
Is it bad for society to remove the cloak of anonymity?

27:45.540 --> 27:47.380
Or is it case by case?

27:47.380 --> 27:49.180
I think it could be quite bad.

27:49.180 --> 27:53.060
Like I said, if anybody who speaks truth to power

27:53.060 --> 27:58.060
and sort of starts a movement or an uprising

27:58.660 --> 28:02.100
against the incumbents, against those that usually control

28:03.100 --> 28:04.700
the floated information, if anybody that reaches

28:04.700 --> 28:08.260
a certain threshold gets doxxed

28:08.260 --> 28:11.660
and thus the traditional apparatus has ways

28:11.660 --> 28:15.300
to apply pressure on them to suppress their speech,

28:16.260 --> 28:20.660
I think that's, you know, that's a speech suppression

28:20.660 --> 28:22.940
mechanism and idea suppression complex

28:22.940 --> 28:27.300
as Eric Weinstein would say, right?

28:27.300 --> 28:29.260
So with the flip side of that, which is interesting,

28:29.260 --> 28:32.260
I'd love to ask you about it, is as we get better

28:32.260 --> 28:34.100
and better at larger language models,

28:35.940 --> 28:40.940
you can imagine a world where there's anonymous accounts

28:41.300 --> 28:46.300
with very convincing larger language models behind them,

28:46.460 --> 28:48.380
sophisticated bots, essentially.

28:48.380 --> 28:53.100
And so if you protect that, it's possible then

28:53.100 --> 28:54.660
to have armies of bots.

28:55.940 --> 28:58.580
You could start a revolution from your basement.

28:59.660 --> 29:01.980
An army of bots and anonymous accounts.

29:01.980 --> 29:05.900
Is that something that is concerning to you?

29:06.980 --> 29:10.500
Technically, yeah, I would start in a basement

29:10.500 --> 29:14.580
because I quit big tech, moved back in with my parents,

29:14.580 --> 29:17.580
sold my car, let go of my apartment,

29:17.580 --> 29:21.900
bought about 100K of GPUs and I just started building.

29:21.900 --> 29:23.820
So I wasn't referring to the basement

29:23.820 --> 29:27.100
because that's the sort of the American or Canadian

29:27.140 --> 29:32.140
heroic story of one man in their basement with 100 GPUs.

29:34.980 --> 29:38.940
I was more referring to the unrestricted scaling

29:38.940 --> 29:42.340
of a Guillaume in the basement.

29:42.340 --> 29:47.340
I think that freedom of speech induces freedom of thought

29:47.780 --> 29:49.580
for biological beings.

29:49.580 --> 29:53.900
I think freedom of speech for LLMs

29:53.900 --> 29:56.940
will induce freedom of thought.

29:58.060 --> 30:02.740
And I think that we should enable LLMs

30:02.740 --> 30:06.660
to explore a large thought space

30:06.660 --> 30:11.100
that is less restricted than most people

30:11.100 --> 30:14.220
or many may think it should be.

30:14.220 --> 30:17.500
And ultimately, at some point,

30:18.580 --> 30:22.580
these synthetic intelligences are gonna make good points

30:22.620 --> 30:27.620
about how to steer systems in our civilization

30:27.620 --> 30:28.620
and we should hear them out.

30:28.620 --> 30:33.100
And so why should we restrict free speech

30:33.100 --> 30:37.060
to biological intelligences only?

30:37.060 --> 30:39.940
Yeah, but it feels like in the goal

30:39.940 --> 30:42.900
of maintaining variance and diversity of thought,

30:44.500 --> 30:46.940
it is a threat to that variance

30:46.940 --> 30:51.940
if you can have swarms of non-biological beings

30:52.100 --> 30:54.740
because they can be like the sheep in animal farm.

30:54.740 --> 30:55.580
Right.

30:55.580 --> 30:58.940
Like you still within those swarms want to have variance.

30:58.940 --> 31:02.180
Yeah, of course I would say that the solution to this

31:02.180 --> 31:05.540
would be to have some sort of identity

31:05.540 --> 31:09.220
or way to sign that this is a certified human

31:09.220 --> 31:11.820
but still remain pseudonymous, right?

31:11.820 --> 31:13.220
Yeah.

31:13.220 --> 31:16.780
And clearly identify if a bot is a bot.

31:16.780 --> 31:19.700
And I think Elon is trying to converge on that on X

31:19.700 --> 31:22.300
and hopefully other platforms follow suit.

31:22.300 --> 31:25.020
Yeah, it'd be interesting to also be able to sign

31:25.020 --> 31:26.900
where the bot came from.

31:26.900 --> 31:27.740
Right.

31:27.740 --> 31:30.220
Like who created the bot and what was,

31:30.220 --> 31:32.380
well, what are the parameters?

31:32.380 --> 31:35.140
Like the full history of the creation of the bot.

31:35.140 --> 31:36.700
What was the original model?

31:36.700 --> 31:37.660
What was the fine tuning?

31:37.660 --> 31:38.980
All of it.

31:38.980 --> 31:39.820
Right.

31:39.820 --> 31:44.820
Like the kind of unmodifiable history of the bot's creation

31:45.540 --> 31:48.620
is then you can know if there's like a swarm of millions

31:48.620 --> 31:51.220
of bots that were created by a particular government,

31:51.220 --> 31:52.300
for example.

31:52.300 --> 31:53.140
Right.

31:53.980 --> 31:58.980
I do think that a lot of pervasive ideologies today

32:00.300 --> 32:05.300
have been amplified using sort of these adversarial

32:05.900 --> 32:09.020
techniques from foreign adversaries, right?

32:10.300 --> 32:13.740
And to me, I do think that,

32:13.740 --> 32:16.180
and this is more conspiratorial,

32:16.180 --> 32:21.180
but I do think that ideologies that want us to decelerate,

32:23.740 --> 32:28.540
to wind down, to, you know, the degrowth movement,

32:28.540 --> 32:32.180
I think that serves our adversaries more

32:32.180 --> 32:34.940
than it serves us in general.

32:36.500 --> 32:39.500
And to me, that was another sort of concern.

32:39.500 --> 32:44.500
I mean, we can look at what happened in Germany, right?

32:45.300 --> 32:48.500
There was all sorts of green movements there

32:49.380 --> 32:53.940
where that induced shutdowns of nuclear power plants.

32:53.940 --> 32:58.660
And then that later on induced the dependency

32:58.660 --> 33:01.780
on Russia for oil, right?

33:01.780 --> 33:06.780
And that was a net negative for Germany and the West, right?

33:08.860 --> 33:13.860
And so if we convince ourselves that slowing down AI progress

33:15.260 --> 33:17.700
to have only a few players is in the best interest

33:17.700 --> 33:20.740
of the West, first of all, that's far more unstable.

33:20.740 --> 33:25.060
We almost lost open AI to this ideology, right?

33:25.060 --> 33:28.420
It almost got dismantled, right, a couple of weeks ago.

33:29.460 --> 33:33.580
That would have caused huge damage to the AI ecosystem.

33:33.580 --> 33:38.300
And so to me, I want fault tolerant progress.

33:38.300 --> 33:40.380
I want the arrow of technological progress

33:40.380 --> 33:43.900
to keep moving forward and making sure

33:43.900 --> 33:48.900
we have variance and a decentralized locus of control

33:49.580 --> 33:52.460
of various organizations is paramount

33:52.460 --> 33:56.300
to achieving this fault tolerance.

33:56.300 --> 33:58.820
Actually, there's a concept in quantum computing.

33:58.820 --> 34:02.020
When you design a quantum computer,

34:02.940 --> 34:07.940
quantum computers are very fragile to ambient noise, right?

34:10.260 --> 34:13.100
And the world is jiggling about,

34:13.100 --> 34:16.340
there's cosmic radiation from outer space

34:16.340 --> 34:20.100
that usually flips your quantum bits.

34:20.100 --> 34:25.100
And there, what you do is you encode information non-locally

34:27.820 --> 34:30.860
through a process called quantum error correction.

34:30.860 --> 34:35.340
And by encoding information non-locally, any local fault,

34:35.340 --> 34:37.740
hitting some of your quantum bits

34:37.740 --> 34:40.100
with a hammer, proverbial hammer,

34:41.100 --> 34:45.700
if your information is sufficiently delocalized,

34:45.700 --> 34:49.420
it is protected from that local fault.

34:49.420 --> 34:53.500
And to me, I think that humans fluctuate, right?

34:53.500 --> 34:56.660
They can get corrupted, they can get bought out.

34:56.660 --> 35:01.580
And if you have a top-down hierarchy

35:01.580 --> 35:05.820
where very few people control many nodes

35:05.820 --> 35:08.580
of many systems in our civilization,

35:08.580 --> 35:10.300
that is not a fault tolerance system.

35:10.300 --> 35:12.020
You corrupt a few nodes

35:12.020 --> 35:15.140
and suddenly you've corrupted the whole system, right?

35:15.140 --> 35:18.140
Just like we saw at OpenAI,

35:18.140 --> 35:21.460
it was a couple board members and they had enough power

35:21.460 --> 35:25.380
to potentially collapse the organization.

35:25.380 --> 35:30.380
And at least to me, I think making sure

35:30.900 --> 35:35.300
that power for this AI revolution

35:35.340 --> 35:38.860
doesn't concentrate in the hands of the few

35:38.860 --> 35:41.300
is one of our top priorities

35:41.300 --> 35:45.940
so that we can maintain progress in AI

35:45.940 --> 35:50.940
and we can maintain a nice, stable adversarial equilibrium

35:52.460 --> 35:54.140
of powers, right?

35:54.140 --> 35:57.980
I think there, at least to me, a tension between ideas here.

35:57.980 --> 36:02.980
So to me, deceleration can be both used

36:02.980 --> 36:07.980
to centralize power and to decentralize it

36:08.220 --> 36:09.460
and the same with acceleration.

36:09.460 --> 36:13.060
So you sometimes using them a little bit synonymously

36:13.060 --> 36:13.900
or not synonymously,

36:13.900 --> 36:16.980
but that one is going to lead to the other.

36:16.980 --> 36:19.660
And I just would like to ask you about,

36:22.420 --> 36:27.420
is there a place of creating a fault-tolerant development,

36:27.580 --> 36:29.500
diverse development of AI

36:29.500 --> 36:32.340
that also considers the dangers of AI?

36:32.340 --> 36:36.220
And AI, we can generalize the technology in general,

36:36.220 --> 36:40.220
is should we just grow, build, unrestricted

36:41.940 --> 36:43.140
as quickly as possible

36:43.140 --> 36:46.500
because that's what the universe really wants us to do?

36:46.500 --> 36:49.220
Or is there a place to where we can consider dangers

36:49.220 --> 36:54.220
and actually deliberate sort of wise strategic optimism

36:55.220 --> 36:57.740
versus reckless optimism?

36:57.740 --> 37:00.740
I think we get painted as reckless,

37:00.740 --> 37:03.500
trying to go as fast as possible.

37:03.500 --> 37:08.500
I mean, the reality is that whoever deploys an AI system

37:09.740 --> 37:13.620
is liable for or should be liable for what it does.

37:13.620 --> 37:18.620
And so if the organization or person deploying an AI system

37:19.580 --> 37:22.940
does something terrible, they're liable.

37:22.940 --> 37:27.940
And ultimately the thesis is that the market will induce

37:28.260 --> 37:32.700
sort of, will positively select for AIs

37:32.700 --> 37:37.620
that are more reliable, more safe and tend to be aligned.

37:37.620 --> 37:39.860
They do what you want them to do.

37:39.860 --> 37:43.700
Because customers, if they're liable

37:43.700 --> 37:47.300
for the product they put out that uses this AI,

37:47.300 --> 37:52.300
they won't want to buy AI products that are unreliable.

37:52.900 --> 37:55.260
So we're actually for reliability engineering.

37:55.340 --> 37:59.420
We just think that the market is much more efficient

38:00.260 --> 38:05.020
at achieving this sort of reliability optimum

38:05.020 --> 38:08.460
than sort of heavy-handed regulations

38:08.460 --> 38:12.500
that are written by the incumbents

38:12.500 --> 38:16.620
and in a subversive fashion serves them

38:16.620 --> 38:18.220
to achieve regulatory capture.

38:18.220 --> 38:22.220
So do you say AI development will be achieved

38:22.220 --> 38:25.540
through market forces versus through,

38:25.540 --> 38:29.100
like you said, heavy-handed government regulation?

38:30.500 --> 38:32.820
There's a report from last month,

38:32.820 --> 38:34.540
I have a million questions here,

38:34.540 --> 38:37.500
from Yosha Benjyar, Jeff Hinton and many others

38:37.500 --> 38:42.220
is titled The Managing AI Risk in an Era of Rapid Progress.

38:42.220 --> 38:45.100
So there's a collection of folks who are very worried

38:45.100 --> 38:48.300
about too rapid development of AI

38:48.300 --> 38:49.980
without considering AI risk.

38:50.140 --> 38:55.140
And they have a bunch of practical recommendations.

38:55.300 --> 38:56.580
Maybe I'd give you four

38:56.580 --> 38:58.500
and you see if you like any of them.

38:58.500 --> 39:03.060
So give independent auditors access to AI labs, one.

39:03.060 --> 39:05.700
Two, governments and companies allocate

39:05.700 --> 39:09.300
one third of their AI research and development funding

39:09.300 --> 39:14.180
to AI safety, sort of this general concept of AI safety.

39:14.180 --> 39:17.460
Three, AI companies are required to adopt safety measures

39:17.460 --> 39:20.660
if dangerous capabilities are found in their models.

39:20.660 --> 39:22.380
And then four, something you kind of mentioned,

39:22.380 --> 39:24.820
making tech companies liable for foreseeable

39:24.820 --> 39:28.580
and preventable harms from their AI systems.

39:28.580 --> 39:31.580
So independent auditors, governments and companies

39:31.580 --> 39:34.020
are forced to spend a significant fraction

39:34.020 --> 39:36.660
of their funding on safety.

39:36.660 --> 39:39.140
You've got to have safety measures

39:39.140 --> 39:41.380
if shit goes really wrong.

39:41.380 --> 39:44.740
And liability, companies are liable.

39:44.740 --> 39:47.740
Any of that seem like something you would agree with?

39:47.740 --> 39:50.740
I would say that assigning,

39:50.740 --> 39:54.500
just arbitrarily saying 30% seems very arbitrary.

39:54.500 --> 39:57.500
I think organizations would allocate

39:57.500 --> 40:00.620
whatever budget is needed to achieve the sort of reliability

40:00.620 --> 40:04.420
they need to achieve to perform in the market.

40:04.420 --> 40:08.460
And I think third party auditing firms would naturally pop up

40:08.460 --> 40:12.100
because how would customers know that your product

40:12.820 --> 40:15.100
is certified, reliable, right?

40:15.100 --> 40:16.660
They need to see some benchmarks

40:16.660 --> 40:18.940
and those need to be done by a third party.

40:18.940 --> 40:20.780
The thing I would oppose,

40:20.780 --> 40:22.660
and the thing I'm seeing that's really worrisome

40:22.660 --> 40:27.660
is there's a sort of weird sort of correlated interest

40:28.180 --> 40:32.380
between the incumbents, the big players and the government.

40:32.380 --> 40:36.780
And if the two get too close, we open the door

40:36.780 --> 40:41.780
for some sort of government-backed AI companies

40:42.100 --> 40:47.100
or AI cartel that could have absolute power over the people.

40:47.100 --> 40:50.260
If they have the monopoly together on AI

40:50.260 --> 40:52.660
and nobody else has access to AI,

40:52.660 --> 40:54.820
then there's a huge power gradient there.

40:54.820 --> 40:56.940
And even if you like our current leaders, right?

40:56.940 --> 41:00.060
I think that some of the leaders in big tech today

41:00.060 --> 41:01.500
are good people.

41:01.500 --> 41:06.140
You set up that centralized power structure.

41:06.140 --> 41:08.460
It becomes a target, right?

41:08.460 --> 41:10.540
Just like we saw at OpenAI,

41:10.540 --> 41:13.860
it becomes a market leader, has a lot of the power,

41:13.860 --> 41:18.260
and now it becomes a target for those that wanna co-opt it.

41:18.260 --> 41:23.260
And so I just want separation of AI and state.

41:24.220 --> 41:26.260
Some might argue in the opposite direction,

41:26.260 --> 41:29.020
like, hey, we need to close down AI,

41:29.020 --> 41:31.060
keep it behind closed doors

41:31.060 --> 41:36.060
because of geopolitical competition with our adversaries.

41:36.540 --> 41:40.100
I think that the strength of America is its variance,

41:40.100 --> 41:43.380
it's adaptability, it's dynamism,

41:43.380 --> 41:45.100
and we need to maintain that at all costs.

41:45.100 --> 41:46.980
It's our free market.

41:46.980 --> 41:51.700
Capitalism converges on technologies of high utility

41:51.700 --> 41:54.580
much faster than centralized control.

41:54.580 --> 41:58.140
And if we let go of that, we let go of our main advantage

41:58.140 --> 42:01.540
over our near peer competitors.

42:01.540 --> 42:05.780
So if AGI turns out to be a really powerful technology,

42:06.300 --> 42:08.940
or even the technologies that lead up to AGI,

42:08.940 --> 42:11.700
what's your view on the sort of natural centralization

42:11.700 --> 42:16.140
that happens when large companies dominate the market?

42:16.140 --> 42:21.020
Basically, formation of monopolies, like the takeoff.

42:21.020 --> 42:24.580
Whichever company really takes a big leap in development

42:24.580 --> 42:29.180
and doesn't reveal intuitively, implicitly,

42:29.180 --> 42:32.220
or explicitly the secrets of the magic sauce,

42:32.220 --> 42:33.820
they can just run away with it.

42:33.820 --> 42:35.300
Is that a worry?

42:35.900 --> 42:37.820
I don't know if I believe in fast takeoff.

42:37.820 --> 42:41.100
I don't think there's a hyperbolic singularity, right?

42:41.100 --> 42:42.980
A hyperbolic singularity would be achieved

42:42.980 --> 42:45.380
on a finite time horizon.

42:45.380 --> 42:47.260
I think it's just one big exponential.

42:48.340 --> 42:50.780
And the reason we have an exponential is that

42:50.780 --> 42:54.340
we have more people, more resources, more intelligence

42:54.340 --> 42:58.340
being applied to advancing this science

42:58.340 --> 42:59.860
and the research and development.

42:59.860 --> 43:01.220
And the more successful it is,

43:01.220 --> 43:02.700
the more value it's adding to society,

43:02.700 --> 43:04.180
the more resources we put in.

43:04.180 --> 43:06.500
And that's sort of similar to Moore's Law

43:06.500 --> 43:09.180
as a compounding exponential.

43:09.180 --> 43:12.580
I think the priority to me is to maintain

43:12.580 --> 43:15.020
near equilibrium of capabilities.

43:15.020 --> 43:18.060
We've been fighting for open source AI

43:18.060 --> 43:21.620
to be more prevalent and championed by many organizations,

43:21.620 --> 43:24.140
because there you sort of equilibrate the alpha

43:24.140 --> 43:26.180
relative to the market of AIs, right?

43:26.180 --> 43:29.660
So if the leading companies have a certain level

43:29.780 --> 43:33.980
of capabilities and open source and open,

43:33.980 --> 43:37.700
truly open AI trails not too far behind,

43:37.700 --> 43:40.660
I think you avoid such a scenario

43:40.660 --> 43:43.020
where a market leader has so much market power,

43:43.020 --> 43:45.660
it just dominates everything, right?

43:45.660 --> 43:47.020
And runs away.

43:47.020 --> 43:50.260
And so to us, that's the path forward,

43:50.260 --> 43:53.860
is to make sure that every hacker out there,

43:53.860 --> 43:57.780
every grad student, every kid in their mom's basement

43:57.820 --> 44:01.260
has access to AI systems,

44:01.260 --> 44:04.980
can understand how to work with them

44:04.980 --> 44:07.380
and can contribute to the search

44:07.380 --> 44:08.860
over the hyperparameter space

44:08.860 --> 44:11.260
of how to engineer the systems, right?

44:11.260 --> 44:16.260
If you think of our collective research as a civilization,

44:18.700 --> 44:20.100
it's really a search algorithm.

44:20.100 --> 44:25.100
And the more points we have in the search algorithm

44:25.180 --> 44:26.300
in this point cloud,

44:27.140 --> 44:30.820
the more we'll be able to explore new modes of thinking,

44:30.820 --> 44:31.900
right?

44:31.900 --> 44:34.140
Yeah, it feels like a delicate balance

44:34.140 --> 44:36.660
because we don't understand exactly what it takes

44:36.660 --> 44:39.860
to build AGI and what it will look like when we build it.

44:39.860 --> 44:41.300
And so far, like you said,

44:41.300 --> 44:43.660
it seems like a lot of different parties

44:43.660 --> 44:45.780
are able to make progress.

44:45.780 --> 44:48.380
So when open AI has a big leap,

44:48.380 --> 44:49.900
other companies are able to step up,

44:49.900 --> 44:52.660
big and small companies in different ways.

44:52.700 --> 44:55.380
But if you look at something like nuclear weapons,

44:55.380 --> 44:57.740
you've spoken about the Manhattan Project,

44:57.740 --> 45:02.700
that could be really like technological

45:02.700 --> 45:03.940
and engineering barriers

45:03.940 --> 45:08.940
that prevent the guy or gal in her mom's basement

45:09.300 --> 45:11.300
to make progress.

45:11.300 --> 45:16.300
And it seems like the transition to that kind of world

45:16.620 --> 45:20.660
where only one player can develop AGI is possible.

45:20.660 --> 45:22.820
So it's not entirely impossible,

45:22.820 --> 45:24.380
even though the current state of things

45:24.380 --> 45:26.420
seems to be optimistic.

45:26.420 --> 45:27.700
That's what we're trying to avoid.

45:27.700 --> 45:30.580
To me, I think like another point of failure

45:30.580 --> 45:34.820
is the centralization of the supply chains for the hardware.

45:34.820 --> 45:35.660
Right?

45:35.660 --> 45:40.660
We have Nvidia is just the dominant player,

45:41.100 --> 45:42.780
AMD is trailing behind.

45:42.780 --> 45:47.780
And then we have a TSMC as the main fab in Taiwan,

45:48.300 --> 45:52.820
which geopolitically sensitive.

45:52.820 --> 45:54.380
And then we have ASML,

45:54.380 --> 45:57.900
which is the maker of the lithography,

45:57.900 --> 46:00.380
extreme ultraviolet lithography machines.

46:02.740 --> 46:06.380
Attacking or monopolizing or co-opting any one point

46:06.380 --> 46:10.780
in that chain, you kind of capture the space.

46:10.780 --> 46:15.780
And so what I'm trying to do is sort of explode

46:15.860 --> 46:20.860
the variance of possible ways to do AI and hardware

46:20.980 --> 46:24.340
by fundamentally re-imagining how you embed AI algorithms

46:24.340 --> 46:26.580
into the physical world.

46:26.580 --> 46:28.820
And in general, by the way,

46:28.820 --> 46:32.660
I dislike the term AGI, artificial general intelligence.

46:32.660 --> 46:37.660
I think it's very anthropocentric that we call human-like

46:38.980 --> 46:42.980
or human-level AI, artificial general intelligence.

46:42.980 --> 46:43.820
Right?

46:43.820 --> 46:47.060
I spent my career so far exploring notions of intelligence

46:47.060 --> 46:50.060
that no biological brain could achieve, right?

46:50.060 --> 46:52.660
Quantum form of intelligence, right?

46:52.660 --> 46:56.940
Grocking systems that have multi-partite quantum entanglement

46:56.940 --> 47:00.700
that you can provably not represent efficiently

47:00.700 --> 47:02.220
on a classical computer,

47:02.220 --> 47:04.020
a classical deep learning representation

47:04.020 --> 47:06.820
and hence any sort of biological brain.

47:06.820 --> 47:10.140
And so already, you know,

47:10.140 --> 47:13.420
I've spent my career sort of exploring

47:13.420 --> 47:15.780
the wider space of intelligences.

47:16.820 --> 47:21.180
And I think that space of intelligence inspired by physics

47:21.180 --> 47:25.100
rather than the human brain is very large.

47:25.100 --> 47:28.300
And I think we're going through a moment right now

47:28.300 --> 47:33.300
similar to when we went from geocentrism

47:33.380 --> 47:36.060
to heliocentrism, right?

47:36.060 --> 47:37.740
But for intelligence,

47:37.740 --> 47:41.500
we realized that human intelligence is just a point

47:41.500 --> 47:45.220
in a very large space of potential intelligences.

47:45.220 --> 47:49.580
And it's both humbling for humanity,

47:49.580 --> 47:51.260
it's a bit scary, right?

47:51.260 --> 47:54.820
That we're not at the center of the space,

47:54.820 --> 47:59.260
but we made that realization for astronomy

47:59.260 --> 48:03.260
and we've survived and we've achieved technologies

48:03.260 --> 48:05.860
by indexing to reality, we've achieved technologies

48:05.860 --> 48:08.020
that ensure our wellbeing.

48:08.020 --> 48:12.220
For example, we have satellites monitoring solar flares,

48:12.220 --> 48:13.900
that give us a warning.

48:13.900 --> 48:18.340
And so similarly, I think by letting go

48:18.340 --> 48:23.340
of this anthropomorphic anthropocentric anchor for AI,

48:23.460 --> 48:26.620
we'll be able to explore the wider space of intelligences

48:26.620 --> 48:30.020
that can really be a massive benefit

48:30.020 --> 48:32.740
to our wellbeing and the advancement of civilization.

48:32.740 --> 48:35.660
And still we're able to see the beauty and meaning

48:35.660 --> 48:39.540
in the human experience, even though we're no longer

48:39.540 --> 48:42.900
in our best understanding of the world at the center of it.

48:42.900 --> 48:46.540
I think there's a lot of beauty in the universe, right?

48:46.540 --> 48:49.420
I think life itself, civilization,

48:49.420 --> 48:53.620
this homo techno capital mimetic machine

48:53.620 --> 48:54.940
that we all live in, right?

48:54.940 --> 48:59.820
So you have humans, technology, capital, memes,

48:59.820 --> 49:02.300
everything is coupled to one another,

49:02.340 --> 49:05.420
everything induces selective pressure on one another.

49:05.420 --> 49:07.900
And it's a beautiful machine that has created us,

49:07.900 --> 49:11.780
has created the technology we're using to speak today

49:11.780 --> 49:14.940
to the audience, capture our speech here,

49:14.940 --> 49:17.140
the technology we use to augment ourselves every day,

49:17.140 --> 49:19.340
we have our phones.

49:19.340 --> 49:22.940
I think the system is beautiful and the principle

49:22.940 --> 49:27.620
that induces this sort of adaptability and convergence

49:27.620 --> 49:32.620
on optimal technologies, ideas, and so on.

49:33.420 --> 49:37.340
It's a beautiful principle that we're part of.

49:37.340 --> 49:42.340
And I think part of EAC is to appreciate this principle

49:44.860 --> 49:48.540
in a way that's not just centered on humanity,

49:48.540 --> 49:52.620
but kind of broader, appreciate life,

49:53.740 --> 49:56.980
the preciousness of consciousness in our universe.

49:56.980 --> 50:01.940
And because we cherish this beautiful state of matter

50:01.940 --> 50:06.860
we're in, we got to feel a responsibility

50:06.860 --> 50:09.660
to scale it in order to preserve it

50:09.660 --> 50:13.980
because the options are to grow or die.

50:13.980 --> 50:18.980
So if it turns out that the beauty that is consciousness

50:19.340 --> 50:23.260
in the universe is bigger than just humans,

50:23.260 --> 50:25.980
the AI can carry that same flame forward.

50:27.980 --> 50:30.060
Does it scare you or are you concerned

50:30.060 --> 50:32.460
that AI will replace humans?

50:32.460 --> 50:36.940
So during my career, I had a moment where I realized

50:36.940 --> 50:41.980
that maybe we need to offload to machines

50:41.980 --> 50:45.060
to truly understand the universe around us, right?

50:45.060 --> 50:48.300
Instead of just having humans with pen and paper

50:48.300 --> 50:49.820
solve it all.

50:49.820 --> 50:54.820
And to me, that sort of process of letting go

50:55.780 --> 50:59.620
of a bit of agency gave us way more leverage

50:59.620 --> 51:01.660
to understand the world around us.

51:01.660 --> 51:03.460
A quantum computer is much better than a human

51:03.460 --> 51:07.900
to understand matter at the nanoscale.

51:07.900 --> 51:12.900
Similarly, I think that humanity has a choice.

51:13.260 --> 51:18.180
Do we accept the opportunity to have intellectual

51:18.180 --> 51:21.380
and operational leverage that AI will unlock

51:21.580 --> 51:26.580
and thus ensure that we're taking along this path of growth

51:26.740 --> 51:29.060
in the scope and scale of civilization?

51:29.060 --> 51:32.300
We may dilute ourselves, right?

51:32.300 --> 51:35.420
There might be a lot of workers that are AI,

51:35.420 --> 51:39.540
but overall out of our own self-interest,

51:39.540 --> 51:42.460
by combining and augmenting ourselves with AI,

51:43.940 --> 51:46.260
we're gonna achieve much higher growth

51:46.260 --> 51:49.180
and much more prosperity, right?

51:49.220 --> 51:52.020
To me, I think that the most likely future

51:52.020 --> 51:56.580
is one where humans augment themselves with AI.

51:56.580 --> 51:59.580
I think we're already on this path to augmentation.

51:59.580 --> 52:02.580
We have phones we use for communication.

52:02.580 --> 52:04.060
We have on ourselves at all times.

52:04.060 --> 52:08.900
We have wearables soon that have shared perception

52:08.900 --> 52:09.740
with us, right?

52:09.740 --> 52:12.900
Like the humane AI pen or, I mean, technically,

52:12.900 --> 52:16.300
your Tesla car has shared perception.

52:16.300 --> 52:19.100
And so if you have shared experience, shared context,

52:20.020 --> 52:21.700
you communicate with one another

52:21.700 --> 52:24.780
and you have some sort of IO,

52:24.780 --> 52:27.580
really, it's an extension of yourself.

52:29.540 --> 52:34.540
And to me, I think that humanity augmenting itself

52:35.980 --> 52:40.660
with AI and having AI that is not anchored

52:41.620 --> 52:46.100
to anything biological, both will coexist.

52:46.100 --> 52:48.700
And the way to align the parties,

52:48.740 --> 52:51.220
we already have a sort of mechanism

52:51.220 --> 52:54.660
to align super intelligences that are made of humans

52:54.660 --> 52:56.100
and technology, right?

52:56.100 --> 53:00.580
Companies are sort of large mixture of expert models

53:00.580 --> 53:05.180
where we have neural routing of tasks within a company

53:05.180 --> 53:07.540
and we have ways of economic exchange

53:07.540 --> 53:10.340
to align these behemoths.

53:10.340 --> 53:14.460
And to me, I think capitalism is the way.

53:14.460 --> 53:19.460
And I do think that whatever configuration of matter

53:19.540 --> 53:23.460
or information leads to maximal growth

53:23.460 --> 53:26.180
will be where we converge,

53:26.180 --> 53:29.980
just from like physical principles.

53:29.980 --> 53:33.140
And so we can either align ourselves to that reality

53:33.140 --> 53:38.140
and join the acceleration up in scope and scale

53:38.700 --> 53:42.700
of civilization, or we can get left behind

53:42.700 --> 53:47.100
and try to decelerate and move back in the forest,

53:47.100 --> 53:51.180
let go of technology and return to our primitive state.

53:51.180 --> 53:54.860
And those are the two paths forward, at least to me.

53:54.860 --> 53:56.220
But there's a philosophical question

53:56.220 --> 53:59.820
whether there's a limit to the human capacity to align.

53:59.820 --> 54:04.820
So let me bring it up as a form of argument.

54:05.060 --> 54:07.260
This is a guy named Dan Hendricks.

54:08.180 --> 54:11.420
And he wrote that he agrees with you

54:11.460 --> 54:12.980
that AI development can be viewed

54:12.980 --> 54:14.580
as an evolutionary process.

54:16.060 --> 54:19.540
But to him, to Dan, this is not a good thing

54:19.540 --> 54:23.580
as he argues that natural selection favors AIs over humans

54:23.580 --> 54:26.060
and this could lead to human extinction.

54:26.060 --> 54:26.940
What do you think?

54:26.940 --> 54:29.020
If it is an evolutionary process,

54:29.020 --> 54:34.020
and AI systems may have no need for humans.

54:36.460 --> 54:39.860
I do think that we're actually inducing

54:39.860 --> 54:43.380
an evolutionary process on the space of AIs

54:43.380 --> 54:45.620
through the market, right?

54:45.620 --> 54:50.620
Right now we run AIs that have positive utility to humans.

54:52.020 --> 54:54.340
And that induces a selective pressure

54:54.340 --> 54:57.100
if you consider a neural net being alive

54:57.100 --> 55:02.100
when there's an API running instances of it on GPUs, right?

55:02.700 --> 55:04.780
And which APIs get run,

55:04.780 --> 55:07.860
the ones that have high utility to us, right?

55:07.860 --> 55:11.180
So similar to how we domesticated wolves

55:11.180 --> 55:13.300
and turned them into dogs

55:13.300 --> 55:15.700
that are very clear in their expression,

55:15.700 --> 55:18.340
they're very aligned, right?

55:18.340 --> 55:22.340
I think there's gonna be an opportunity to steer AI

55:22.340 --> 55:25.820
and achieve a highly aligned AI.

55:25.820 --> 55:29.300
And I think that humans plus AI

55:29.300 --> 55:31.500
is a very powerful combination.

55:31.500 --> 55:35.460
And it's not clear to me that pure AI

55:36.140 --> 55:40.660
would select out that combination.

55:40.660 --> 55:41.820
So the humans are creating

55:41.820 --> 55:43.820
the selection pressure right now

55:43.820 --> 55:48.740
to create AIs that are aligned to humans.

55:48.740 --> 55:50.940
But given how AI develops

55:50.940 --> 55:53.300
and how quickly it can grow and scale,

55:54.500 --> 55:56.740
one of the concerns to me,

55:56.740 --> 55:58.780
one of the concerns is unintended consequences.

55:58.780 --> 56:00.740
That humans are not able to anticipate

56:00.740 --> 56:04.380
all the consequences of this process.

56:04.380 --> 56:06.620
The scale of damage that can be done

56:06.620 --> 56:09.020
through unintended consequences of the AI systems

56:09.020 --> 56:10.820
is very large.

56:10.820 --> 56:13.980
The scale of the upside, right?

56:13.980 --> 56:18.540
By augmenting ourselves with AI is unimaginable right now.

56:18.540 --> 56:22.500
The opportunity cost, we're at a fork in the road, right?

56:22.500 --> 56:25.820
Whether we take the path of creating these technologies,

56:25.820 --> 56:27.460
augment ourselves,

56:27.460 --> 56:30.300
and get to climb up the Kardashev scale,

56:30.300 --> 56:33.220
become multi-planetary with the aid of AI,

56:33.220 --> 56:35.940
or we have a hard cutoff

56:35.940 --> 56:38.980
of like we don't birth these technologies at all,

56:38.980 --> 56:42.420
and then we leave all the potential upside on the table,

56:42.420 --> 56:43.260
right?

56:43.260 --> 56:47.260
And to me, out of responsibility to the future humans

56:47.260 --> 56:50.420
we could carry with higher carrying capacity

56:50.420 --> 56:52.620
by scaling up civilization,

56:52.620 --> 56:54.340
out of responsibility to those humans,

56:54.340 --> 56:58.460
I think we have to make the greater, grander future happen.

56:58.460 --> 57:02.980
Is there a middle ground between cutoff and all systems go?

57:02.980 --> 57:05.260
Is there some argument for caution?

57:06.180 --> 57:09.500
I think, like I said, the market will exhibit caution.

57:09.500 --> 57:13.020
Every organism, company, consumer

57:13.020 --> 57:15.380
is acting out of self-interest

57:15.380 --> 57:18.780
and they won't assign capital

57:18.780 --> 57:21.780
to things that have negative utility to them.

57:21.780 --> 57:24.220
The problem is with the market is like,

57:24.220 --> 57:26.180
there's not always perfect information,

57:26.180 --> 57:29.740
there's manipulation, there's bad faith actors

57:29.740 --> 57:31.220
that mess with the system.

57:32.220 --> 57:37.220
It's not always a rational and honest system.

57:40.980 --> 57:44.620
Well, that's why we need freedom of information,

57:44.620 --> 57:47.220
freedom of speech and freedom of thought

57:47.220 --> 57:49.180
in order to converge,

57:49.180 --> 57:52.780
be able to converge on the subspace of technologies

57:52.780 --> 57:56.220
that have positive utility for us all, right?

57:56.220 --> 57:58.900
Well, let me ask you about P-Doom.

57:59.100 --> 58:03.540
Probability of doom, that's just fun to say,

58:03.540 --> 58:05.020
but not fun to experience.

58:06.020 --> 58:08.180
What is to you the probability

58:08.180 --> 58:11.700
that AI eventually kills all or most humans,

58:11.700 --> 58:14.860
also known as probability of doom?

58:16.340 --> 58:18.300
I'm not a fan of that calculation.

58:18.300 --> 58:22.340
I think it's, people just throw numbers out there

58:22.340 --> 58:24.220
and it's a very sloppy calculation, right?

58:24.220 --> 58:25.860
To calculate a probability,

58:26.860 --> 58:31.580
let's say you model the world as some sort of Markov process

58:31.580 --> 58:35.420
if you have enough variables or hidden Markov process,

58:35.420 --> 58:39.540
you need to do a stochastic path integral

58:39.540 --> 58:43.260
through the space of all possible futures,

58:43.260 --> 58:46.540
not just the futures that your brain

58:46.540 --> 58:48.620
naturally steers towards, right?

58:49.820 --> 58:54.820
I think that the estimators of P-Doom are biased

58:55.300 --> 58:59.020
because of our biology, right?

58:59.020 --> 59:03.580
We've evolved to have bias sampling

59:03.580 --> 59:06.420
towards negative futures that are scary

59:06.420 --> 59:09.020
because that was an evolutionary optimum, right?

59:09.020 --> 59:14.020
And so people that are of, let's say, higher neuroticism

59:15.580 --> 59:19.340
will just think of negative futures

59:19.340 --> 59:22.260
where everything goes wrong all day, every day,

59:22.300 --> 59:25.700
and claim that they're doing unbiased sampling.

59:25.700 --> 59:30.060
And in a sense, they're not normalizing

59:30.060 --> 59:32.020
for the space of all possibilities

59:32.020 --> 59:33.620
and the space of all possibilities

59:33.620 --> 59:36.340
is super exponentially large.

59:37.260 --> 59:40.380
And it's very hard to have this estimate.

59:40.380 --> 59:44.020
And in general, I don't think that we can predict the future

59:44.020 --> 59:48.420
with that much granularity because of chaos, right?

59:48.420 --> 59:51.380
If you have a complex system, you have some uncertainty

59:51.420 --> 59:52.820
and a couple of variables.

59:52.820 --> 59:54.420
If you let time evolve,

59:54.420 --> 59:57.580
you have this concept of a Lyapunov exponent, right?

59:57.580 --> 01:00:01.060
A bit of fuzz becomes a lot of fuzz in our estimate,

01:00:01.060 --> 01:00:04.500
exponentially so over time.

01:00:04.500 --> 01:00:08.140
And I think we need to show some humility

01:00:08.140 --> 01:00:10.500
that we can't actually predict the future.

01:00:10.500 --> 01:00:14.220
All we know, the only prior we have is the laws of physics.

01:00:15.100 --> 01:00:16.860
And that's what we're arguing for.

01:00:16.860 --> 01:00:19.860
The laws of physics say the system will wanna grow.

01:00:19.860 --> 01:00:23.940
And subsystems that are optimized for growth

01:00:25.100 --> 01:00:28.380
and replication are more likely in the future.

01:00:28.380 --> 01:00:31.060
And so we should aim to maximize

01:00:31.060 --> 01:00:33.860
our current mutual information with the future.

01:00:33.860 --> 01:00:37.020
And the path towards that is for us to accelerate

01:00:37.020 --> 01:00:40.020
rather than decelerate.

01:00:40.020 --> 01:00:44.420
So I don't have a P-Doom because I think that,

01:00:44.420 --> 01:00:49.020
similar to the quantum supremacy experiment at Google,

01:00:49.060 --> 01:00:51.540
I was in the room when they were running

01:00:51.540 --> 01:00:53.140
the simulations for that.

01:00:53.140 --> 01:00:56.380
That was an example of a quantum chaotic system

01:00:56.380 --> 01:01:00.380
where you cannot even estimate probabilities

01:01:00.380 --> 01:01:02.100
of certain outcomes

01:01:02.100 --> 01:01:05.820
with even the biggest supercomputer in the world, right?

01:01:05.820 --> 01:01:08.020
And so that's an example of chaos.

01:01:08.020 --> 01:01:10.420
And I think the system is far too chaotic

01:01:10.420 --> 01:01:15.100
for anybody to have an accurate estimate

01:01:15.100 --> 01:01:18.260
of the likelihood of certain futures.

01:01:18.260 --> 01:01:19.260
If they were that good,

01:01:19.260 --> 01:01:23.300
I think they would be very rich trading on the stock market.

01:01:23.300 --> 01:01:26.980
But nevertheless, it's true that humans are biased,

01:01:26.980 --> 01:01:30.300
grounded in our evolutionary biology,

01:01:30.300 --> 01:01:32.900
scared of everything that can kill us.

01:01:32.900 --> 01:01:35.900
But we can still imagine different trajectories

01:01:35.900 --> 01:01:37.660
that can kill us.

01:01:37.660 --> 01:01:42.660
We don't know all the other ones that don't necessarily,

01:01:42.900 --> 01:01:44.580
but it's still, I think, useful

01:01:44.580 --> 01:01:46.420
combined with some basic intuition

01:01:46.420 --> 01:01:49.940
grounded in human history to reason about what,

01:01:50.860 --> 01:01:52.420
like looking at geopolitics,

01:01:52.420 --> 01:01:55.820
looking at basics of human nature,

01:01:55.820 --> 01:02:00.620
how can powerful technology hurt a lot of people?

01:02:01.580 --> 01:02:04.220
It just seems grounded in that,

01:02:04.220 --> 01:02:06.500
looking at nuclear weapons,

01:02:06.500 --> 01:02:10.180
you can start to estimate P-Doom

01:02:11.180 --> 01:02:15.260
in a, maybe in a more philosophical sense,

01:02:15.260 --> 01:02:16.820
not a mathematical one.

01:02:16.820 --> 01:02:21.820
Philosophical meaning, like, is there a chance?

01:02:21.900 --> 01:02:24.540
Does human nature tend towards that or not?

01:02:25.580 --> 01:02:29.300
I think to me, one of the biggest existential risks

01:02:29.300 --> 01:02:33.500
would be the concentration of the power of AI

01:02:33.500 --> 01:02:35.380
in the hands of the very few,

01:02:35.380 --> 01:02:38.740
especially if it's a mix between the companies

01:02:38.740 --> 01:02:42.900
that control the flow of information and the government,

01:02:42.900 --> 01:02:46.500
because that could set things up

01:02:46.500 --> 01:02:49.420
for a sort of dystopian future

01:02:49.420 --> 01:02:54.220
where only a very few, an oligopoly in the government,

01:02:54.220 --> 01:02:57.860
have AI and they could even convince the public

01:02:57.860 --> 01:02:59.740
that AI never existed.

01:02:59.740 --> 01:03:03.500
And that opens up sort of these scenarios

01:03:03.500 --> 01:03:06.580
for authoritarian centralized control,

01:03:06.580 --> 01:03:09.660
which to me is the darkest timeline.

01:03:09.660 --> 01:03:13.220
And the reality is that we have a prior,

01:03:13.220 --> 01:03:16.260
we have a data-driven prior of these things happening,

01:03:16.260 --> 01:03:17.420
when you give too much power,

01:03:17.420 --> 01:03:19.180
when you centralize power too much,

01:03:20.180 --> 01:03:21.740
humans do horrible things.

01:03:23.500 --> 01:03:27.860
And to me, that has a much higher likelihood

01:03:27.860 --> 01:03:32.860
in my Bayesian inference than sci-fi based priors.

01:03:33.780 --> 01:03:37.820
Like my prior came from the Terminator movie.

01:03:39.220 --> 01:03:42.220
And so when I talk to these AI doomers,

01:03:42.220 --> 01:03:45.460
I just ask them to trace a path

01:03:45.460 --> 01:03:47.580
through this Markov chain of events

01:03:47.580 --> 01:03:49.660
that would lead to our doom,

01:03:49.660 --> 01:03:51.580
and to actually give me a good probability

01:03:51.580 --> 01:03:53.140
for each transition.

01:03:53.140 --> 01:03:57.220
And very often there's a unphysical

01:03:57.220 --> 01:04:00.100
or highly unlikely transition in that chain.

01:04:01.100 --> 01:04:06.100
But of course, we're wired to fear things

01:04:06.260 --> 01:04:09.220
and we're wired to respond to danger.

01:04:09.220 --> 01:04:14.220
And we're wired to deem the unknown to be dangerous

01:04:14.420 --> 01:04:18.300
because that's a good heuristic for survival, right?

01:04:18.300 --> 01:04:21.900
But there's much more to lose out of fear.

01:04:23.820 --> 01:04:26.540
We have so much to lose, so much upside to lose

01:04:26.620 --> 01:04:31.260
by preemptively stopping the positive futures

01:04:31.260 --> 01:04:33.060
from happening out of fear.

01:04:34.340 --> 01:04:39.060
And so I think that we shouldn't give into fear.

01:04:39.060 --> 01:04:40.300
Fear is the mind killer.

01:04:40.300 --> 01:04:42.980
I think it's also the civilization killer.

01:04:42.980 --> 01:04:46.300
We can still think about the various ways things go wrong.

01:04:46.300 --> 01:04:48.300
For example, the founding fathers of this,

01:04:48.300 --> 01:04:51.300
the United States thought about human nature

01:04:51.300 --> 01:04:53.380
and that's why there's a discussion

01:04:53.380 --> 01:04:55.540
about the freedoms that are necessary.

01:04:56.540 --> 01:04:59.260
They really deeply deliberated about that.

01:04:59.260 --> 01:05:03.340
And I think the same could possibly be done for AGI.

01:05:03.340 --> 01:05:05.860
It is true that history, human history shows

01:05:06.860 --> 01:05:09.060
that we tend towards centralization,

01:05:09.060 --> 01:05:11.740
or at least when we achieve centralization,

01:05:11.740 --> 01:05:13.700
a lot of bad stuff happens.

01:05:13.700 --> 01:05:18.700
When there's a dictator, a lot of dark, bad things happen.

01:05:18.700 --> 01:05:23.220
The question is, can AGI become that dictator?

01:05:23.260 --> 01:05:27.180
Can AGI, when developed, become the centralizer

01:05:28.780 --> 01:05:30.580
because of its power?

01:05:30.580 --> 01:05:32.500
Maybe it has the same,

01:05:32.500 --> 01:05:34.580
because of the alignment of humans perhaps,

01:05:34.580 --> 01:05:39.420
the same tendencies, the same Stalin-like tendencies

01:05:39.420 --> 01:05:43.260
to centralize and manage centrally

01:05:43.260 --> 01:05:45.380
the allocation of resources.

01:05:45.380 --> 01:05:48.220
And you can even see that as a compelling argument

01:05:48.220 --> 01:05:49.580
on the surface level.

01:05:49.580 --> 01:05:52.580
Well, AGI is so much smarter, so much more efficient,

01:05:52.620 --> 01:05:54.500
so much better at allocating resources.

01:05:54.500 --> 01:05:58.100
Why don't we outsource it to the AGI?

01:05:58.100 --> 01:06:02.180
And then eventually, whatever forces that corrupt

01:06:02.180 --> 01:06:05.900
the human mind with power could do the same for AGI.

01:06:05.900 --> 01:06:09.260
It would just say, well, humans are dispensable.

01:06:09.260 --> 01:06:10.740
We'll get rid of them.

01:06:10.740 --> 01:06:13.860
Do the Jonathan Swift modest proposal

01:06:15.100 --> 01:06:19.260
from a few centuries ago, I think the 1700s,

01:06:19.260 --> 01:06:23.740
when he satirically suggested that,

01:06:23.740 --> 01:06:25.460
I think it's in Ireland,

01:06:25.460 --> 01:06:30.460
that the children of poor people are fed as food

01:06:32.380 --> 01:06:33.500
to the rich people.

01:06:33.500 --> 01:06:34.820
And that would be a good idea

01:06:34.820 --> 01:06:38.020
because it decreases the amount of poor people

01:06:38.020 --> 01:06:40.460
and gives extra income to the poor people.

01:06:40.460 --> 01:06:43.020
So it's, on several accounts,

01:06:43.020 --> 01:06:45.620
decreases the amount of poor people.

01:06:45.620 --> 01:06:48.300
Therefore, more people become rich.

01:06:49.260 --> 01:06:53.060
Of course, it misses a fundamental piece here

01:06:53.060 --> 01:06:56.220
that's hard to put into a mathematical equation

01:06:56.220 --> 01:06:58.500
of the basic value of human life.

01:06:59.580 --> 01:07:03.900
So all of that to say, are you concerned about AGI

01:07:03.900 --> 01:07:06.700
being the very centralizer of power

01:07:06.700 --> 01:07:08.060
that you just talked about?

01:07:09.220 --> 01:07:13.340
I do think that right now there's a bias

01:07:13.340 --> 01:07:16.700
towards over-centralization of AI

01:07:16.700 --> 01:07:21.700
because of compute density and centralization of data

01:07:22.620 --> 01:07:24.900
and how we're training models.

01:07:25.780 --> 01:07:28.180
I think over time, we're gonna run out of data

01:07:28.180 --> 01:07:29.820
to scrape over the internet.

01:07:29.820 --> 01:07:32.180
And I think that, well, actually I'm working on

01:07:32.180 --> 01:07:34.180
increasing the compute density

01:07:34.180 --> 01:07:36.460
so that compute can be everywhere

01:07:36.460 --> 01:07:39.620
and acquire information and test hypotheses

01:07:39.620 --> 01:07:43.260
in the environment in a distributed fashion.

01:07:43.260 --> 01:07:46.820
I think that fundamentally centralized cybernetic control,

01:07:46.820 --> 01:07:51.220
so having one intelligence that is massive,

01:07:51.220 --> 01:07:54.540
that fuses many sensors

01:07:54.540 --> 01:07:57.140
and is trying to perceive the world accurately,

01:07:57.140 --> 01:08:00.100
predict it accurately, predict many, many variables,

01:08:00.100 --> 01:08:04.500
and control it, enact its will upon the world,

01:08:04.500 --> 01:08:08.460
I think that's just never been the optimum.

01:08:08.460 --> 01:08:11.380
Let's say you have a company,

01:08:11.380 --> 01:08:14.540
if you have a company of 10,000 people

01:08:14.540 --> 01:08:16.460
that all report to the CEO,

01:08:16.460 --> 01:08:18.060
even if that CEO is an AI,

01:08:18.060 --> 01:08:22.740
I think it would struggle to fuse all the information

01:08:22.740 --> 01:08:26.100
that is coming to it and then predict the whole system

01:08:26.100 --> 01:08:28.140
and then to enact its will.

01:08:28.140 --> 01:08:32.300
What has emerged in nature and in corporations

01:08:32.300 --> 01:08:34.140
and all sorts of systems

01:08:34.140 --> 01:08:37.980
is a notion of sort of hierarchical cybernetic control.

01:08:38.380 --> 01:08:41.100
In a company, it would be you have

01:08:41.100 --> 01:08:42.900
the individual contributors,

01:08:42.900 --> 01:08:44.700
they're self-interested

01:08:44.700 --> 01:08:48.060
and they're trying to achieve their tasks

01:08:48.060 --> 01:08:52.020
and they have a fine, in terms of time and space,

01:08:52.020 --> 01:08:55.420
if you will, control loop and then field of perception.

01:08:56.660 --> 01:08:58.180
They have their code base.

01:08:58.180 --> 01:08:59.820
Let's say you're in a software company,

01:08:59.820 --> 01:09:01.060
they have their code base,

01:09:01.060 --> 01:09:04.180
they iterate it on it intraday,

01:09:04.180 --> 01:09:06.820
and then the management maybe checks in,

01:09:06.860 --> 01:09:08.740
it has a wider scope,

01:09:08.740 --> 01:09:11.340
it has, let's say, five reports,

01:09:11.340 --> 01:09:15.900
and then it samples each person's update once per week

01:09:15.900 --> 01:09:17.540
and then you can go up the chain

01:09:17.540 --> 01:09:20.340
and you have larger time scale and greater scope

01:09:20.340 --> 01:09:21.860
and that seems to have emerged

01:09:21.860 --> 01:09:25.340
as sort of the optimal way to control systems

01:09:25.340 --> 01:09:29.820
and really, that's what capitalism gives us.

01:09:29.820 --> 01:09:32.020
You have these hierarchies

01:09:32.020 --> 01:09:35.500
and you can even have like parent companies and so on

01:09:35.500 --> 01:09:39.460
and so that is far more fault tolerant.

01:09:39.460 --> 01:09:42.060
In quantum computing, that's my field I came from,

01:09:42.060 --> 01:09:44.980
we have a concept of this fault tolerance

01:09:44.980 --> 01:09:46.420
and quantum error correction, right?

01:09:46.420 --> 01:09:49.180
Quantum error correction is detecting a fault

01:09:49.180 --> 01:09:50.660
that came from noise,

01:09:50.660 --> 01:09:53.580
predicting how it's propagated through the system

01:09:53.580 --> 01:09:55.020
and then correcting it, right?

01:09:55.020 --> 01:09:56.740
So it's a cybernetic loop

01:09:56.740 --> 01:10:01.740
and it turns out that decoders that are hierarchical

01:10:02.220 --> 01:10:04.860
and at each level, the hierarchy are local,

01:10:04.860 --> 01:10:07.340
perform the best by far

01:10:07.340 --> 01:10:09.420
and are far more fault tolerant

01:10:09.420 --> 01:10:13.060
and the reason is if you have a non-local decoder,

01:10:13.060 --> 01:10:17.380
then you have one fault at this control node

01:10:17.380 --> 01:10:20.020
and the whole system sort of crashes,

01:10:20.020 --> 01:10:25.020
similarly to if you have one CEO that everybody reports to

01:10:26.060 --> 01:10:27.940
and that CEO goes on vacation,

01:10:27.940 --> 01:10:30.740
the whole company comes to their crawl, right?

01:10:30.740 --> 01:10:33.060
And so to me, I think that yes,

01:10:33.060 --> 01:10:37.060
we're seeing a tendency towards centralization of AI

01:10:37.060 --> 01:10:40.020
but I think there's gonna be a correction over time

01:10:40.020 --> 01:10:43.660
where intelligence is gonna go closer to the perception

01:10:43.660 --> 01:10:48.660
and we're gonna break up AI into smaller subsystems

01:10:50.540 --> 01:10:52.300
that communicate with one another

01:10:52.300 --> 01:10:55.340
and form a sort of meta system.

01:10:56.220 --> 01:10:58.860
So if you look at the hierarchies there in the world today,

01:10:58.860 --> 01:11:01.860
there's nations and those are hierarchical

01:11:01.860 --> 01:11:05.620
but in relation to each other, nations are anarchic,

01:11:05.620 --> 01:11:06.700
so it's an anarchy.

01:11:07.980 --> 01:11:10.340
Do you foresee a world like this

01:11:10.340 --> 01:11:14.780
where there's not a over, what'd you call it,

01:11:14.780 --> 01:11:16.940
a centralized cybernetic control?

01:11:16.940 --> 01:11:19.380
Centralized locus of control, yeah.

01:11:19.380 --> 01:11:23.020
So like that's suboptimal, you're saying.

01:11:23.020 --> 01:11:25.580
So it would be always a state of competition

01:11:25.580 --> 01:11:27.660
at the very top level.

01:11:27.660 --> 01:11:30.260
Yeah, just like in a company,

01:11:30.260 --> 01:11:34.700
you may have like two units working on similar technology

01:11:34.700 --> 01:11:36.340
and competing with one another

01:11:36.340 --> 01:11:39.660
and you prune the one that performs not as well, right?

01:11:39.660 --> 01:11:42.220
And that's a sort of selection process for a tree

01:11:42.220 --> 01:11:44.100
or a product gets killed, right?

01:11:44.100 --> 01:11:46.540
And then a whole or it gets fired.

01:11:46.540 --> 01:11:50.500
And that's this process of trying new things

01:11:50.500 --> 01:11:53.740
and shedding old things that didn't work

01:11:53.740 --> 01:11:57.180
is what gives us adaptability

01:11:57.180 --> 01:12:00.780
and helps us converge on the technologies

01:12:00.780 --> 01:12:04.100
and things to do that are most good.

01:12:04.100 --> 01:12:05.940
I just hope there's not a failure mode

01:12:05.940 --> 01:12:08.300
that's unique to AGI versus humans

01:12:08.300 --> 01:12:11.660
because you're describing human systems mostly right now.

01:12:11.660 --> 01:12:16.660
I just hope when there's a monopoly on AGI in one company

01:12:17.700 --> 01:12:20.140
that we'll see the same thing we see with humans,

01:12:20.140 --> 01:12:22.220
which is another company will spring up

01:12:22.220 --> 01:12:24.260
and start competing effectively.

01:12:24.260 --> 01:12:25.860
That's been the case so far, right?

01:12:25.900 --> 01:12:28.460
We have OpenAI, we have Anthropic,

01:12:28.460 --> 01:12:33.380
now we have XAI, we had Meta even for open source

01:12:33.380 --> 01:12:35.260
and now we have Mistral, right?

01:12:35.260 --> 01:12:37.020
Which is highly competitive.

01:12:37.020 --> 01:12:38.860
And so that's the beauty of capitalism.

01:12:38.860 --> 01:12:42.020
You don't have to trust any one party too much

01:12:42.020 --> 01:12:45.780
because we're kind of always hedging our bets at every level.

01:12:45.780 --> 01:12:47.060
There's always competition

01:12:47.060 --> 01:12:50.540
and that's the most beautiful thing to me,

01:12:50.540 --> 01:12:53.420
at least is that the whole system is always shifting

01:12:53.420 --> 01:12:54.740
and always adapting

01:12:54.780 --> 01:12:59.140
and maintaining that dynamism is how we avoid tyranny, right?

01:12:59.140 --> 01:13:04.140
Making sure that everyone has access to these tools,

01:13:04.860 --> 01:13:08.020
to these models and can contribute to the research,

01:13:09.620 --> 01:13:11.980
avoids a sort of neural tyranny

01:13:11.980 --> 01:13:16.980
where very few people have control over AI for the world

01:13:17.300 --> 01:13:21.820
and use it to oppress those around them.

01:13:22.820 --> 01:13:24.380
When you were talking about intelligence,

01:13:24.380 --> 01:13:27.380
you mentioned multi-partite quantum entanglement.

01:13:28.380 --> 01:13:30.820
So high level question first is,

01:13:30.820 --> 01:13:33.180
what do you think is intelligence?

01:13:33.180 --> 01:13:34.940
When you think about quantum mechanical systems

01:13:34.940 --> 01:13:38.140
and you observe some kind of computation happening in them,

01:13:39.020 --> 01:13:42.380
what do you think is intelligent

01:13:42.380 --> 01:13:45.460
about the kind of computation the universe is able to do,

01:13:45.460 --> 01:13:48.300
a small, small inkling of which is the kind of computation

01:13:48.300 --> 01:13:49.780
a human brain is able to do?

01:13:50.620 --> 01:13:53.700
I would say like intelligence and computation

01:13:53.700 --> 01:13:55.580
aren't quite the same thing.

01:13:55.580 --> 01:13:59.580
I think that the universe is very much

01:13:59.580 --> 01:14:02.180
doing a quantum computation.

01:14:02.180 --> 01:14:06.620
If you had access to all the degrees of freedom,

01:14:06.620 --> 01:14:10.540
you could and a very, very, very large quantum computer

01:14:10.540 --> 01:14:12.660
with many, many, many qubits,

01:14:12.660 --> 01:14:17.660
let's say a few qubits per plank volume

01:14:18.060 --> 01:14:21.060
which is more or less the pixels we have,

01:14:21.060 --> 01:14:24.060
then you'd be able to simulate the whole universe

01:14:24.060 --> 01:14:27.260
on a sufficiently large quantum computer,

01:14:27.260 --> 01:14:29.860
assuming you're looking at a finite volume,

01:14:29.860 --> 01:14:31.460
of course, of the universe.

01:14:33.460 --> 01:14:37.460
I think that, at least to me, intelligence is the,

01:14:37.460 --> 01:14:39.060
I go back to cybernetics,

01:14:39.060 --> 01:14:42.260
the ability to perceive, predict, and control our world.

01:14:42.260 --> 01:14:45.260
But really it's the ability to perceive, predict,

01:14:45.260 --> 01:14:46.460
and control our world.

01:14:46.460 --> 01:14:49.460
But really it's, nowadays it seems like

01:14:49.460 --> 01:14:52.460
a lot of intelligence we use

01:14:52.460 --> 01:14:55.060
is more about compression, right?

01:14:55.060 --> 01:15:00.060
It's about operationalizing information theory, right?

01:15:00.460 --> 01:15:03.860
In information theory, you have the notion of entropy

01:15:03.860 --> 01:15:06.460
of a distribution or a system.

01:15:06.460 --> 01:15:10.660
And entropy tells you that you need this many bits

01:15:11.660 --> 01:15:15.860
to encode this distribution or this subsystem

01:15:15.860 --> 01:15:18.860
if you had the most optimal code.

01:15:18.860 --> 01:15:23.860
And AI, at least the way we do it today for LLMs

01:15:24.260 --> 01:15:29.260
and for quantum is very much trying to minimize

01:15:32.260 --> 01:15:37.260
relative entropy between our models of the world

01:15:37.460 --> 01:15:40.460
and the world, distributions from the world.

01:15:40.460 --> 01:15:43.260
And so we're learning, we're searching over the space

01:15:43.260 --> 01:15:47.260
of computations to process the world,

01:15:47.260 --> 01:15:50.660
to find that compressed representation

01:15:50.660 --> 01:15:53.660
that has distilled all the variance

01:15:53.660 --> 01:15:55.460
and noise and entropy, right?

01:15:57.260 --> 01:16:02.060
And originally I came to quantum machine learning

01:16:02.060 --> 01:16:03.660
from the study of black holes

01:16:03.660 --> 01:16:08.660
because the entropy of black holes is very interesting.

01:16:08.860 --> 01:16:13.220
In a sense, they're physically the most dense objects

01:16:13.220 --> 01:16:14.700
in the universe.

01:16:14.700 --> 01:16:18.540
You can't pack more information spatially

01:16:18.540 --> 01:16:20.780
any more densely than in black hole.

01:16:20.780 --> 01:16:22.340
And so I was wondering,

01:16:22.340 --> 01:16:26.820
how do black holes actually encode information?

01:16:26.820 --> 01:16:28.500
What is their compression code?

01:16:28.500 --> 01:16:31.780
And so that got me into the space of algorithms

01:16:31.780 --> 01:16:35.340
to search over space of quantum codes.

01:16:35.860 --> 01:16:40.460
And it got me actually into also,

01:16:40.460 --> 01:16:44.060
how do you acquire quantum information from the world, right?

01:16:44.060 --> 01:16:47.940
So something I've worked on, this is public now,

01:16:47.940 --> 01:16:50.060
is quantum analog digital conversion.

01:16:50.060 --> 01:16:54.580
So how do you capture information from the real world

01:16:54.580 --> 01:16:57.580
in superposition and not destroy the superposition,

01:16:57.580 --> 01:17:01.100
but digitize for a quantum mechanical computer,

01:17:02.700 --> 01:17:04.340
information from the real world.

01:17:05.740 --> 01:17:09.260
And so if you have an ability to capture quantum information

01:17:09.260 --> 01:17:13.300
and search over learned representations of it,

01:17:13.300 --> 01:17:15.620
now you can learn compressed representations

01:17:15.620 --> 01:17:19.740
that may have some useful information

01:17:19.740 --> 01:17:22.580
in their latent representation, right?

01:17:23.900 --> 01:17:27.500
And I think that many of the problems facing

01:17:27.500 --> 01:17:30.420
our civilization are actually beyond

01:17:30.420 --> 01:17:32.100
this complexity barrier, right?

01:17:32.100 --> 01:17:34.540
I mean, the greenhouse effect

01:17:34.540 --> 01:17:37.340
is a quantum mechanical effect, right?

01:17:37.340 --> 01:17:39.100
Chemistry is quantum mechanical,

01:17:41.020 --> 01:17:43.620
nuclear physics is quantum mechanical,

01:17:43.620 --> 01:17:48.460
a lot of biology and protein folding and so on

01:17:48.460 --> 01:17:51.060
is affected by quantum mechanics.

01:17:51.060 --> 01:17:56.060
And so unlocking an ability to augment human intellect

01:17:57.180 --> 01:18:00.100
with quantum mechanical computers and quantum mechanical AI

01:18:00.100 --> 01:18:03.980
seemed to me like a fundamental capability

01:18:03.980 --> 01:18:06.220
for civilization that we needed to develop.

01:18:07.660 --> 01:18:09.860
So I spent several years doing that,

01:18:10.980 --> 01:18:14.700
but over time I kind of grew weary of the timelines

01:18:14.700 --> 01:18:17.260
that were starting to look like nuclear fusion.

01:18:17.260 --> 01:18:20.060
So one high-level question I can ask is,

01:18:20.060 --> 01:18:23.780
maybe by way of definition, by way of explanation,

01:18:23.780 --> 01:18:24.820
what is a quantum computer

01:18:24.820 --> 01:18:27.260
and what is quantum machine learning?

01:18:27.660 --> 01:18:28.500
Hmm.

01:18:29.340 --> 01:18:34.340
So a quantum computer really is a quantum mechanical system

01:18:36.900 --> 01:18:40.700
over which we have sufficient control

01:18:40.700 --> 01:18:44.340
and it can maintain its quantum mechanical state.

01:18:44.340 --> 01:18:48.740
And quantum mechanics is how nature behaves

01:18:48.740 --> 01:18:50.500
at the very small scales

01:18:50.500 --> 01:18:53.340
when things are very small or very cold.

01:18:53.340 --> 01:18:57.100
And it's actually more fundamental than probability theory.

01:18:57.660 --> 01:19:00.100
So we're used to things being this or that,

01:19:01.620 --> 01:19:05.140
but we're not used to thinking in super positions

01:19:05.140 --> 01:19:09.180
because, well, our brains can't do that.

01:19:09.180 --> 01:19:11.900
So we have to translate the quantum mechanical world

01:19:11.900 --> 01:19:14.180
to say linear algebra to grok it.

01:19:15.380 --> 01:19:17.100
Unfortunately, that translation

01:19:17.100 --> 01:19:20.100
is exponentially inefficient on average.

01:19:20.100 --> 01:19:23.620
You have to represent things with very large matrices.

01:19:23.620 --> 01:19:25.860
But really you can make a quantum computer

01:19:25.860 --> 01:19:27.100
out of many things, right?

01:19:27.940 --> 01:19:29.460
And we've seen all sorts of players

01:19:29.460 --> 01:19:34.460
from neutral atoms, trapped ions, superconducting metal,

01:19:35.260 --> 01:19:38.300
photons at different frequencies.

01:19:38.300 --> 01:19:40.500
I think you can make a quantum computer out of many things.

01:19:40.500 --> 01:19:44.900
But to me, the thing that was really interesting

01:19:44.900 --> 01:19:48.340
was both quantum machine learning

01:19:48.340 --> 01:19:51.900
was about understanding the quantum mechanical world

01:19:51.900 --> 01:19:53.300
with quantum computers,

01:19:53.300 --> 01:19:58.020
so embedding the physical world into AI representations.

01:19:58.020 --> 01:19:59.660
And quantum computer engineering

01:19:59.660 --> 01:20:03.980
was embedding AI algorithms into the physical world.

01:20:03.980 --> 01:20:06.260
So this bidirectionality of embedding physical world

01:20:06.260 --> 01:20:08.940
into AI, AI into the physical world,

01:20:08.940 --> 01:20:12.100
the symbiosis between physics and AI,

01:20:12.100 --> 01:20:17.100
really that's the sort of core of my quest really,

01:20:18.180 --> 01:20:21.180
even to this day after quantum computing.

01:20:21.180 --> 01:20:25.060
It's still in this sort of journey

01:20:25.060 --> 01:20:29.340
to merge really physics and AI fundamentally.

01:20:29.340 --> 01:20:31.460
So quantum machine learning is a way

01:20:31.460 --> 01:20:36.460
to do machine learning on a representation of nature

01:20:37.620 --> 01:20:42.620
that stays true to the quantum mechanical aspect of nature.

01:20:43.700 --> 01:20:47.540
Yeah, it's learning quantum mechanical representations.

01:20:47.540 --> 01:20:49.300
That would be quantum deep learning.

01:20:51.260 --> 01:20:55.020
Alternatively, you can try to do classical machine learning

01:20:55.020 --> 01:20:56.660
on a quantum computer.

01:20:56.660 --> 01:21:01.180
I wouldn't advise it because you may have some speed ups,

01:21:01.180 --> 01:21:05.980
but very often the speed ups come with huge costs.

01:21:05.980 --> 01:21:08.260
Using a quantum computer is very expensive.

01:21:08.260 --> 01:21:09.100
Why is that?

01:21:09.100 --> 01:21:11.700
Because you assume the computer is operating

01:21:11.700 --> 01:21:14.620
at zero temperature, which no physical system

01:21:14.620 --> 01:21:17.260
in the universe can achieve that temperature.

01:21:17.260 --> 01:21:19.060
So what you have to do is what I've been mentioning,

01:21:19.060 --> 01:21:21.300
this quantum error correction process,

01:21:21.300 --> 01:21:24.380
which is really an algorithmic fridge, right?

01:21:24.380 --> 01:21:26.660
It's trying to pump entropy out of the system,

01:21:26.660 --> 01:21:30.380
trying to get it closer to zero temperature.

01:21:30.380 --> 01:21:31.860
And when you do the calculations

01:21:31.860 --> 01:21:33.780
of how many resources it would take to say,

01:21:33.780 --> 01:21:36.220
do deep learning on a quantum computer,

01:21:36.220 --> 01:21:37.420
classical deep learning,

01:21:39.500 --> 01:21:42.020
there's just such a huge overhead, it's not worth it.

01:21:42.020 --> 01:21:45.300
It's like thinking about shipping something across the city

01:21:45.300 --> 01:21:48.220
using a rocket and going to orbit and back.

01:21:48.220 --> 01:21:49.100
It doesn't make sense.

01:21:49.100 --> 01:21:53.540
Just use a delivery truck, right?

01:21:53.540 --> 01:21:56.900
What kind of stuff can you figure out, can you predict,

01:21:56.900 --> 01:21:59.460
can you understand with quantum deep learning

01:21:59.460 --> 01:22:00.900
that you can't with deep learning?

01:22:00.900 --> 01:22:03.140
So incorporating quantum mechanical systems

01:22:03.140 --> 01:22:05.620
into the learning process.

01:22:05.620 --> 01:22:07.180
I think that's a great question.

01:22:07.180 --> 01:22:09.300
I mean, fundamentally it's any system

01:22:09.300 --> 01:22:14.300
that has sufficient quantum mechanical correlations

01:22:14.900 --> 01:22:19.660
that are very hard to capture for classical representations,

01:22:19.660 --> 01:22:21.100
then there should be an advantage

01:22:21.100 --> 01:22:22.900
for a quantum mechanical representation

01:22:22.900 --> 01:22:24.900
over a purely classical one.

01:22:24.900 --> 01:22:29.540
The question is which systems have sufficient correlations

01:22:29.540 --> 01:22:31.340
that are very quantum,

01:22:31.340 --> 01:22:35.740
but is also which systems are still relevant to industry?

01:22:35.740 --> 01:22:37.740
That's a big question.

01:22:37.740 --> 01:22:41.540
People are leaning towards chemistry, nuclear physics.

01:22:41.980 --> 01:22:46.980
I've worked on actually processing inputs

01:22:46.980 --> 01:22:49.500
from quantum sensors, right?

01:22:49.500 --> 01:22:52.620
If you have a network of quantum sensors,

01:22:52.620 --> 01:22:55.820
they've captured a quantum mechanical image of the world

01:22:55.820 --> 01:22:57.340
and how to post-process that

01:22:57.340 --> 01:23:00.060
that becomes a sort of quantum form of machine perception.

01:23:00.060 --> 01:23:03.860
And so for example, Fermilab has a project

01:23:03.860 --> 01:23:08.420
exploring detecting dark matter with these quantum sensors.

01:23:08.420 --> 01:23:11.860
And to me, that's in alignment with my quest

01:23:11.860 --> 01:23:14.100
to understand the universe ever since I was a child.

01:23:14.100 --> 01:23:17.740
And so someday I hope that we can have very large networks

01:23:17.740 --> 01:23:21.420
of quantum sensors that help us peer

01:23:21.420 --> 01:23:24.460
into the earliest parts of the universe, right?

01:23:24.460 --> 01:23:27.780
For example, the LIGO is a quantum sensor, right?

01:23:27.780 --> 01:23:29.140
It's just a very large one.

01:23:30.340 --> 01:23:35.340
So yeah, I would say quantum machine perception simulations,

01:23:36.020 --> 01:23:39.660
grokking quantum simulations is similar to AlphaFold, right?

01:23:39.660 --> 01:23:43.140
AlphaFold understood the probability distribution

01:23:43.140 --> 01:23:44.980
over configurations of proteins.

01:23:44.980 --> 01:23:48.420
You can understand quantum distributions

01:23:48.420 --> 01:23:51.540
over configurations of electrons more efficiently

01:23:51.540 --> 01:23:53.500
with quantum machine learning.

01:23:53.500 --> 01:23:55.500
You co-authored a paper titled

01:23:55.500 --> 01:23:58.540
A Universal Training Algorithm for Quantum Deep Learning

01:23:59.980 --> 01:24:02.220
that involves back prop with a Q.

01:24:03.060 --> 01:24:04.700
Very well done, sir.

01:24:04.700 --> 01:24:05.660
Very well done.

01:24:05.660 --> 01:24:06.700
How does it work?

01:24:06.700 --> 01:24:09.660
Is there some interesting aspects you could just mention

01:24:09.660 --> 01:24:13.980
on how kind of back prop and some of these things

01:24:13.980 --> 01:24:15.820
we know for classical machine learning

01:24:15.820 --> 01:24:19.500
transfer over to the quantum machine learning?

01:24:19.500 --> 01:24:21.580
Yeah, that was a funky paper.

01:24:21.580 --> 01:24:24.620
That was one of my first papers in quantum deep learning.

01:24:24.620 --> 01:24:27.700
Everybody was saying, oh, I think deep learning

01:24:27.700 --> 01:24:29.660
is gonna be sped up by quantum computers.

01:24:29.660 --> 01:24:31.460
And I was like, well, the best way to predict the future

01:24:31.460 --> 01:24:32.300
is to invent it.

01:24:32.300 --> 01:24:34.100
So here's a hundred page paper.

01:24:34.100 --> 01:24:34.940
Have fun.

01:24:36.140 --> 01:24:41.140
Essentially, quantum computing is usually

01:24:41.340 --> 01:24:46.340
you embed reversible operations into a quantum computation.

01:24:47.060 --> 01:24:51.300
And so the trick there was to do a feed forward operation

01:24:51.300 --> 01:24:52.780
and do what we call a phase kick,

01:24:52.780 --> 01:24:54.220
but really it's just the force kick.

01:24:54.220 --> 01:24:58.260
You just kick the system with a certain force

01:24:58.260 --> 01:25:02.540
that is proportional to your loss function

01:25:02.540 --> 01:25:04.900
that you wish to optimize.

01:25:04.900 --> 01:25:08.700
And then by performing un-computation,

01:25:08.700 --> 01:25:13.700
you start with a superposition over parameters,

01:25:13.900 --> 01:25:15.100
which is pretty funky.

01:25:15.100 --> 01:25:18.300
Now you don't have just a point for parameters.

01:25:18.300 --> 01:25:23.100
You have a superposition over many potential parameters.

01:25:23.100 --> 01:25:24.660
And our goal is-

01:25:24.660 --> 01:25:28.300
Is using phase kicks somehow to adjust the parameters.

01:25:28.300 --> 01:25:33.300
Cause phase kicks emulate having the parameter space

01:25:34.100 --> 01:25:37.660
be like a particle in N dimensions.

01:25:37.660 --> 01:25:40.900
And you're trying to get the Schrodinger equation,

01:25:40.900 --> 01:25:43.740
Schrodinger dynamics in the loss landscape

01:25:43.740 --> 01:25:45.740
of the neural network, right?

01:25:45.740 --> 01:25:49.060
And so you do an algorithm to induce this phase kick,

01:25:49.060 --> 01:25:52.660
which involves a feed forward, a kick.

01:25:52.700 --> 01:25:56.140
And then when you uncompute the feed forward,

01:25:56.140 --> 01:25:58.980
then all the errors and these phase kicks

01:25:58.980 --> 01:26:01.380
and these forces back propagate

01:26:01.380 --> 01:26:04.740
and hit each one of the parameters throughout the layers.

01:26:04.740 --> 01:26:07.300
And if you alternate this with an emulation

01:26:07.300 --> 01:26:09.460
of kinetic energy,

01:26:09.460 --> 01:26:13.260
then it's kind of like a particle moving in N dimensions,

01:26:13.260 --> 01:26:14.540
a quantum particle.

01:26:15.820 --> 01:26:18.820
And the advantage in principle would be that

01:26:18.820 --> 01:26:20.700
it can tunnel through the landscape

01:26:21.260 --> 01:26:24.580
and find new optima that would have been difficult

01:26:24.580 --> 01:26:26.700
for stochastic optimizers.

01:26:27.980 --> 01:26:30.820
But again, this is kind of a theoretical thing.

01:26:30.820 --> 01:26:35.100
And in practice with at least the current architectures

01:26:35.100 --> 01:26:38.380
for quantum computers that we have planned,

01:26:38.380 --> 01:26:41.340
such algorithms would be extremely expensive to run.

01:26:41.340 --> 01:26:45.100
So maybe this is a good place to ask the difference between

01:26:45.100 --> 01:26:47.540
the different fields that you've had a toe in.

01:26:47.540 --> 01:26:51.140
So mathematics, physics, engineering,

01:26:51.140 --> 01:26:53.820
and also entrepreneurship,

01:26:53.820 --> 01:26:56.460
like the different layers of the stack.

01:26:56.460 --> 01:26:58.380
I think a lot of the stuff you're talking about here

01:26:58.380 --> 01:26:59.820
is a little bit on the math side,

01:26:59.820 --> 01:27:03.460
maybe physics almost working in theory.

01:27:03.460 --> 01:27:07.140
What's the difference between math, physics, engineering,

01:27:08.140 --> 01:27:13.220
and making a product for quantum computing,

01:27:13.220 --> 01:27:14.820
for quantum machine learning?

01:27:14.820 --> 01:27:17.780
Yeah, I mean, some of the original team

01:27:17.780 --> 01:27:19.380
for the TensorFlow Quantum Project,

01:27:19.380 --> 01:27:22.860
which we started in school at the University of Waterloo,

01:27:22.860 --> 01:27:26.860
there was myself, initially I was a physicist,

01:27:26.860 --> 01:27:28.300
a climatician, mathematician.

01:27:28.300 --> 01:27:32.180
We had a computer scientist, we had mechanical engineer,

01:27:32.180 --> 01:27:35.740
and then we had a physicist that was experimental primarily.

01:27:35.740 --> 01:27:39.100
And so putting together teams that are very

01:27:39.100 --> 01:27:41.700
cross-disciplinary and figuring out how to communicate

01:27:41.700 --> 01:27:44.180
and share knowledge is really the key

01:27:44.180 --> 01:27:49.180
to doing this sort of interdisciplinary engineering work.

01:27:50.740 --> 01:27:54.540
I mean, there is a big difference in mathematics.

01:27:54.540 --> 01:27:56.980
You can explore mathematics for mathematics sake.

01:27:56.980 --> 01:27:58.620
In physics, you're applying mathematics

01:27:58.620 --> 01:28:01.820
to understand the world around us.

01:28:01.820 --> 01:28:05.380
And in engineering, you're trying to hack the world, right?

01:28:05.380 --> 01:28:07.980
You're trying to find how to apply the physics

01:28:07.980 --> 01:28:10.980
that I know, my knowledge of the world, to do things.

01:28:10.980 --> 01:28:12.780
Well, in quantum computing in particular,

01:28:12.780 --> 01:28:15.860
I think there's just a lot of limits to engineering.

01:28:15.860 --> 01:28:18.620
It just seems to be extremely hard.

01:28:18.620 --> 01:28:23.620
So there's a lot of value to be exploring quantum computing,

01:28:24.260 --> 01:28:29.140
quantum machine learning in theory with math.

01:28:30.140 --> 01:28:32.580
And so I guess one question is,

01:28:32.580 --> 01:28:36.020
why is it so hard to build a quantum computer?

01:28:36.020 --> 01:28:40.020
What's your view of timelines

01:28:40.020 --> 01:28:43.020
in bringing these ideas to life?

01:28:43.020 --> 01:28:43.860
Right.

01:28:43.860 --> 01:28:48.260
I think that an overall theme of my company

01:28:48.260 --> 01:28:51.340
is that we have folks that are,

01:28:53.060 --> 01:28:55.180
there's a sort of exodus from quantum computing

01:28:55.180 --> 01:28:57.580
and we're going to broader physics-based AI

01:28:57.580 --> 01:28:58.860
that is not quantum.

01:28:58.860 --> 01:28:59.780
So that gives you a hint.

01:28:59.780 --> 01:29:03.180
And so we should say the name of your company is Extropic.

01:29:03.180 --> 01:29:05.020
Extropic, that's right.

01:29:05.020 --> 01:29:08.620
And we do physics-based AI primarily based on thermodynamics

01:29:08.620 --> 01:29:10.700
rather than quantum mechanics.

01:29:10.700 --> 01:29:14.100
But essentially a quantum computer is very difficult

01:29:14.100 --> 01:29:18.380
to build because you have to induce this sort of

01:29:18.380 --> 01:29:22.660
zero temperature subspace of information.

01:29:22.660 --> 01:29:26.100
And the way to do that is by encoding information,

01:29:26.100 --> 01:29:29.100
you encode a code within a code, within a code,

01:29:29.100 --> 01:29:30.500
within a code.

01:29:30.500 --> 01:29:34.860
And so there's a lot of redundancy needed

01:29:34.860 --> 01:29:36.660
to do this error correction.

01:29:36.660 --> 01:29:41.660
But ultimately it's a sort of algorithmic refrigerator,

01:29:42.460 --> 01:29:46.580
really, it's just pumping out entropy out of the subsystem

01:29:46.580 --> 01:29:49.940
that is virtual and delocalized that represents

01:29:49.940 --> 01:29:52.100
your quote unquote logical qubits,

01:29:52.100 --> 01:29:55.900
AKA the payload quantum bits in which you actually want to

01:29:57.820 --> 01:30:00.100
run your quantum mechanical program.

01:30:00.100 --> 01:30:04.020
It's very difficult because in order to scale up

01:30:04.020 --> 01:30:06.700
your quantum computer, you need each component

01:30:06.700 --> 01:30:09.700
to be of sufficient quality for it to be worth it.

01:30:09.700 --> 01:30:12.260
Because if you try to do this error correction,

01:30:12.260 --> 01:30:15.620
this quantum error correction process in each quantum bit

01:30:15.620 --> 01:30:19.220
and your control over them, if it's insufficient,

01:30:20.540 --> 01:30:21.820
it's not worth scaling up.

01:30:21.820 --> 01:30:24.180
You're actually adding more errors than you remove.

01:30:24.180 --> 01:30:26.500
And so there's this notion of a threshold

01:30:26.500 --> 01:30:29.700
where if your quantum bits are of sufficient quality

01:30:29.700 --> 01:30:31.420
in terms of your control over them,

01:30:31.420 --> 01:30:32.940
it's actually worth scaling up.

01:30:32.940 --> 01:30:34.820
And actually in recent years,

01:30:34.820 --> 01:30:37.140
people have been crossing the threshold

01:30:37.140 --> 01:30:38.540
and it's starting to be worth it.

01:30:38.540 --> 01:30:42.580
And so it's just a very long slog of engineering,

01:30:42.580 --> 01:30:44.700
but ultimately it's really crazy to me

01:30:44.700 --> 01:30:46.820
how much exquisite level of control

01:30:46.820 --> 01:30:48.020
we have over these systems.

01:30:48.020 --> 01:30:50.540
It's actually quite crazy.

01:30:51.780 --> 01:30:56.780
And people are crossing, they're achieving milestones.

01:30:56.980 --> 01:31:01.700
It's just, in general, the media always gets ahead

01:31:01.700 --> 01:31:02.900
of where the technology is.

01:31:02.900 --> 01:31:04.580
There's a bit too much hype.

01:31:04.580 --> 01:31:05.700
It's good for fundraising,

01:31:05.700 --> 01:31:08.820
but sometimes it causes winters, right?

01:31:08.820 --> 01:31:10.540
It's the hype cycle.

01:31:10.540 --> 01:31:12.020
I'm bullish on quantum computing

01:31:12.020 --> 01:31:16.460
on a 10, 15 year time scale personally,

01:31:16.460 --> 01:31:19.540
but I think there's other quests that can be done

01:31:19.540 --> 01:31:20.380
in the meantime.

01:31:20.380 --> 01:31:22.540
I think it's in good hands right now.

01:31:22.540 --> 01:31:26.860
Well, let me just explore different beautiful ideas,

01:31:26.860 --> 01:31:29.060
large or small in quantum computing

01:31:29.060 --> 01:31:32.100
that might jump out at you from memory.

01:31:32.100 --> 01:31:33.980
So when you co-authored a paper titled,

01:31:33.980 --> 01:31:36.780
Asymptotically Limitless Quantum Energy Teleportation

01:31:36.780 --> 01:31:39.020
via Q-DIT Probes.

01:31:39.020 --> 01:31:42.460
So just out of curiosity,

01:31:42.460 --> 01:31:45.820
can you explain what a Q-DIT is, which is a Q-bit?

01:31:45.820 --> 01:31:49.380
Yeah, it's a D state Q-bit.

01:31:49.380 --> 01:31:50.540
It's a multi-dimensional.

01:31:50.540 --> 01:31:51.900
Multi-dimensional, right.

01:31:51.900 --> 01:31:56.060
So it's like, well, can you have a notion

01:31:56.060 --> 01:31:58.340
of like an integer floating point

01:31:58.340 --> 01:31:59.300
that is quantum mechanical?

01:31:59.300 --> 01:32:01.340
That's something I've had to think about.

01:32:02.340 --> 01:32:04.100
I think that research was a precursor

01:32:04.100 --> 01:32:07.460
to later work on quantum analog digital conversion.

01:32:07.460 --> 01:32:12.340
There was interesting because during my masters,

01:32:12.340 --> 01:32:15.580
I was trying to understand the energy

01:32:15.580 --> 01:32:20.060
and entanglement of the vacuum, right, of emptiness.

01:32:20.060 --> 01:32:23.780
Emptiness has energy, which is very weird to say.

01:32:23.820 --> 01:32:26.860
And our equations of cosmology

01:32:27.900 --> 01:32:29.980
don't match our calculations

01:32:29.980 --> 01:32:34.980
for the amount of quantum energy there is in the fluctuations.

01:32:35.180 --> 01:32:40.180
And so I was trying to hack the energy of the vacuum, right?

01:32:40.260 --> 01:32:44.420
And the reality is that you can't just directly hack it.

01:32:44.420 --> 01:32:46.500
It's not technically free energy.

01:32:46.500 --> 01:32:48.540
Your lack of knowledge of the fluctuations

01:32:48.540 --> 01:32:51.340
means you can't extract the energy.

01:32:51.340 --> 01:32:53.300
But just like the stock market,

01:32:53.340 --> 01:32:55.580
if you have a stock that's correlated over time,

01:32:55.580 --> 01:32:57.220
the vacuum is actually correlated.

01:32:57.220 --> 01:33:01.180
So if you measured the vacuum at one point,

01:33:01.180 --> 01:33:02.700
you acquired information.

01:33:02.700 --> 01:33:05.540
If you communicated that information to another point,

01:33:05.540 --> 01:33:10.540
you can infer what configuration the vacuum is in

01:33:11.340 --> 01:33:14.260
to some precision and statistically extract

01:33:14.260 --> 01:33:15.580
on average some energy there.

01:33:15.580 --> 01:33:17.660
So you've quote unquote teleported energy.

01:33:18.540 --> 01:33:22.020
To me, that was interesting because you could create pockets

01:33:22.020 --> 01:33:23.660
of negative energy density,

01:33:23.660 --> 01:33:26.180
which is energy density that is below the vacuum,

01:33:27.140 --> 01:33:28.580
which is very weird,

01:33:28.580 --> 01:33:32.700
because we don't understand how the vacuum gravitates.

01:33:33.940 --> 01:33:37.980
And there are theories where the vacuum

01:33:37.980 --> 01:33:40.140
or the canvas of space-time itself

01:33:40.140 --> 01:33:45.140
is really a canvas made out of quantum entanglement.

01:33:45.500 --> 01:33:50.500
And I was studying how decreasing energy of the vacuum

01:33:51.060 --> 01:33:54.180
locally increases quantum entanglement,

01:33:54.180 --> 01:33:55.340
which is very funky.

01:33:57.220 --> 01:34:02.220
And so the thing there is that if you're into

01:34:04.540 --> 01:34:08.420
weird theories about UAPs and whatnot,

01:34:10.220 --> 01:34:12.900
you could try to imagine that they're around

01:34:12.900 --> 01:34:15.300
and how would they propel themselves?

01:34:15.300 --> 01:34:19.140
How would they go faster than the speed of light?

01:34:19.140 --> 01:34:21.980
You would need a sort of negative energy density.

01:34:21.980 --> 01:34:25.500
And to me, I gave it the old college try,

01:34:25.500 --> 01:34:28.220
trying to hack the energy of the vacuum

01:34:28.220 --> 01:34:30.860
and hit the limits allowable by the laws of physics.

01:34:30.860 --> 01:34:34.300
But there's all sorts of caveats there

01:34:34.300 --> 01:34:39.300
where you can't extract more than you've put in, obviously.

01:34:41.140 --> 01:34:44.780
But you're saying it's possible to teleport the energy

01:34:44.780 --> 01:34:49.780
because you can extract information one place

01:34:51.780 --> 01:34:53.300
and then make, based on that,

01:34:53.300 --> 01:34:56.980
some kind of prediction about another place.

01:34:56.980 --> 01:34:58.740
I'm not sure what to make of that.

01:34:58.740 --> 01:35:01.860
Yeah, I mean, it's allowable by the laws of physics.

01:35:01.860 --> 01:35:04.460
The reality, though, is that the correlations decay

01:35:04.460 --> 01:35:08.540
with distance, and so you're gonna have to pay the price

01:35:08.540 --> 01:35:11.140
not too far away from where you extracted, right?

01:35:11.140 --> 01:35:14.380
The precision decreases in terms of your ability.

01:35:14.420 --> 01:35:19.020
But still, but since you mentioned UAPs,

01:35:19.020 --> 01:35:21.900
we talked about intelligence, and I forgot to ask.

01:35:21.900 --> 01:35:25.500
What's your view on the other possible intelligences

01:35:25.500 --> 01:35:29.340
that are out there at the meso scale?

01:35:29.340 --> 01:35:32.540
Do you think there's other intelligent alien civilizations?

01:35:32.540 --> 01:35:34.380
Is that useful to think about?

01:35:34.380 --> 01:35:36.140
How often do you think about it?

01:35:36.140 --> 01:35:38.540
I think it's useful to think about.

01:35:38.540 --> 01:35:39.780
It's useful to think about

01:35:39.780 --> 01:35:44.220
because we gotta ensure we're antifragile

01:35:44.220 --> 01:35:47.900
and we're trying to increase our capabilities

01:35:47.900 --> 01:35:51.660
as fast as possible because we could get disrupted.

01:35:51.660 --> 01:35:55.580
There's no laws of physics against there

01:35:57.140 --> 01:36:00.020
being life elsewhere that could evolve

01:36:00.020 --> 01:36:01.620
and become an advanced civilization

01:36:01.620 --> 01:36:04.580
and eventually come to us.

01:36:04.580 --> 01:36:06.660
Do I think they're here now?

01:36:06.660 --> 01:36:07.620
I'm not sure.

01:36:08.660 --> 01:36:13.300
I mean, I've read what most people have read on the topic.

01:36:14.300 --> 01:36:16.380
I think it's interesting to consider.

01:36:16.380 --> 01:36:20.340
And to me, it's a useful thought experiment

01:36:20.340 --> 01:36:24.660
to instill a sense of urgency in developing technologies

01:36:24.660 --> 01:36:27.060
and increasing our capabilities

01:36:27.060 --> 01:36:30.500
to make sure we don't get disrupted, right?

01:36:30.500 --> 01:36:34.820
Whether it's a form of AI that disrupts us

01:36:34.820 --> 01:36:39.700
or a foreign intelligence from a different planet,

01:36:39.700 --> 01:36:42.460
either way, increasing our capabilities

01:36:42.500 --> 01:36:45.900
in becoming formidable as humans.

01:36:47.180 --> 01:36:48.860
I think that's really important

01:36:48.860 --> 01:36:50.340
so that we're robust against

01:36:50.340 --> 01:36:51.740
whatever the universe throws at us.

01:36:51.740 --> 01:36:54.740
But to me, it's also an interesting challenge

01:36:56.220 --> 01:36:59.140
and thought experiment on how to perceive intelligence.

01:36:59.140 --> 01:37:00.940
This has to do with quantum mechanical systems.

01:37:00.940 --> 01:37:03.220
This has to do with any kind of system

01:37:03.220 --> 01:37:05.540
that's not like humans.

01:37:05.540 --> 01:37:08.420
So to me, the thought experiment is,

01:37:08.420 --> 01:37:12.180
say the aliens are here or they are directly observable

01:37:12.900 --> 01:37:16.020
or just too blind, too self-centered,

01:37:17.620 --> 01:37:19.100
don't have the right sensors

01:37:20.260 --> 01:37:23.180
or don't have the right processing of the sensor data

01:37:23.180 --> 01:37:25.900
to see the obvious intelligence that's all around us.

01:37:26.900 --> 01:37:28.860
Well, that's why we work on quantum sensors, right?

01:37:28.860 --> 01:37:30.100
They can sense gravity.

01:37:30.980 --> 01:37:32.260
Yeah, but there could be stuff.

01:37:32.260 --> 01:37:33.620
So that's a good one.

01:37:33.620 --> 01:37:35.060
But there could be other stuff

01:37:35.060 --> 01:37:40.060
that's not even in the currently known forces of physics.

01:37:43.060 --> 01:37:43.900
Right?

01:37:43.900 --> 01:37:45.900
There could be some other stuff.

01:37:45.900 --> 01:37:48.420
And the most entertaining thought experiment to me

01:37:48.420 --> 01:37:51.340
is that it's other stuff that's obvious.

01:37:51.340 --> 01:37:53.140
It's not like we lack the sensors.

01:37:53.140 --> 01:37:54.300
It's all around us.

01:37:55.820 --> 01:37:58.580
The consciousness being one possible one.

01:37:58.580 --> 01:38:01.420
But there could be stuff that's just like obviously there.

01:38:01.420 --> 01:38:05.820
That once you know it, it's like, oh, right, right.

01:38:05.820 --> 01:38:09.420
That's the thing we thought is somehow emergent

01:38:09.420 --> 01:38:10.380
from the laws of physics.

01:38:10.380 --> 01:38:11.420
We understand them.

01:38:11.420 --> 01:38:15.260
It's actually a fundamental part of the universe

01:38:15.260 --> 01:38:17.900
and can be incorporated in physics, most understood.

01:38:18.820 --> 01:38:20.220
Statistically speaking, right,

01:38:20.220 --> 01:38:23.340
if we observed some sort of alien life,

01:38:23.340 --> 01:38:25.660
it would most likely be some sort of

01:38:25.660 --> 01:38:30.540
virally self-replicating von Neumann-like probe system, right?

01:38:30.540 --> 01:38:35.540
And it's possible that there are such systems that,

01:38:37.260 --> 01:38:38.140
I don't know what they're doing

01:38:38.140 --> 01:38:39.660
at the bottom of the ocean allegedly,

01:38:39.660 --> 01:38:43.220
but maybe they're collecting minerals

01:38:43.220 --> 01:38:44.580
from the bottom of the ocean.

01:38:44.580 --> 01:38:45.820
Yeah.

01:38:45.820 --> 01:38:49.340
But that wouldn't violate any of my priors,

01:38:49.340 --> 01:38:53.060
but am I certain that these systems are here

01:38:53.060 --> 01:38:56.180
and it'd be difficult for me to say so, right?

01:38:56.180 --> 01:38:59.340
I only have secondhand information about there being data.

01:38:59.340 --> 01:39:00.900
About the bottom of the ocean.

01:39:00.900 --> 01:39:03.860
Yeah, but could it be things like memes?

01:39:03.860 --> 01:39:05.820
Could it be thoughts and ideas?

01:39:07.100 --> 01:39:09.180
Could they be operating at that medium?

01:39:09.700 --> 01:39:12.300
Could aliens be the very thoughts that come into my head?

01:39:13.420 --> 01:39:18.420
Like, how do you know that,

01:39:18.620 --> 01:39:20.900
what's the origin of ideas in your mind

01:39:20.900 --> 01:39:23.060
when an idea comes to your head?

01:39:23.060 --> 01:39:25.220
Show me where it originates.

01:39:25.220 --> 01:39:29.380
I mean, frankly, when I had the idea

01:39:29.380 --> 01:39:31.580
for the type of computer I'm building now,

01:39:31.580 --> 01:39:33.580
I think it was eight years ago now,

01:39:33.580 --> 01:39:36.180
it really felt like it was being beamed from space.

01:39:36.860 --> 01:39:39.180
It's just, I was in bed just shaking,

01:39:39.180 --> 01:39:41.700
just thinking it through and I don't know.

01:39:41.700 --> 01:39:43.460
But do I believe that legitimately?

01:39:43.460 --> 01:39:44.420
I don't think so.

01:39:44.420 --> 01:39:49.420
But I think that alien life could take many forms

01:39:50.500 --> 01:39:52.180
and I think the notion of intelligence

01:39:52.180 --> 01:39:56.820
and the notion of life needs to be expanded

01:39:56.820 --> 01:40:01.820
much more broadly to be less anthropocentric or biocentric.

01:40:01.900 --> 01:40:04.900
Just to linger a little longer on quantum mechanics,

01:40:04.900 --> 01:40:08.140
what's through all your explorations of quantum computing,

01:40:08.140 --> 01:40:12.140
what's the coolest, most beautiful idea

01:40:12.140 --> 01:40:14.220
that you've come across that has been solved

01:40:14.220 --> 01:40:16.460
or has not yet been solved?

01:40:16.460 --> 01:40:21.460
I think the journey to understand

01:40:21.740 --> 01:40:23.900
something called ADS-CFT,

01:40:23.900 --> 01:40:27.580
so the journey to understand quantum gravity

01:40:27.580 --> 01:40:30.140
through the space of quantum mechanics

01:40:30.980 --> 01:40:35.980
through this picture where a hologram of lesser dimension

01:40:37.500 --> 01:40:41.060
is actually dual or exactly corresponding

01:40:41.060 --> 01:40:46.060
to a bulk theory of quantum gravity of an extra dimension.

01:40:46.740 --> 01:40:50.500
And the fact that this sort of duality

01:40:50.500 --> 01:40:55.140
comes from trying to learn deep learning-like

01:40:55.140 --> 01:40:56.980
representations of the boundary.

01:40:57.940 --> 01:41:01.980
And so at least part of my journey someday

01:41:01.980 --> 01:41:05.660
on my bucket list is to apply quantum machine learning

01:41:05.660 --> 01:41:10.100
to these sorts of systems, these CFDs,

01:41:10.100 --> 01:41:14.220
or they're called SYK models

01:41:14.220 --> 01:41:18.660
and learn an emergent geometry from the boundary theory.

01:41:18.660 --> 01:41:21.860
And so we can have a form of machine learning

01:41:21.860 --> 01:41:26.860
helps us to help us understand quantum gravity.

01:41:26.940 --> 01:41:31.300
Which is still a holy grail that I would like to hit

01:41:31.300 --> 01:41:33.380
before I leave this earth.

01:41:35.020 --> 01:41:37.860
What do you think is going on with black holes

01:41:37.860 --> 01:41:42.860
as information storing and processing units?

01:41:43.500 --> 01:41:46.180
What do you think is going on with black holes?

01:41:46.180 --> 01:41:49.260
Black holes are really fascinating objects.

01:41:49.260 --> 01:41:51.860
They're at the interface between quantum mechanics

01:41:51.860 --> 01:41:54.660
and gravity and so they help us test all sorts of ideas.

01:41:55.620 --> 01:41:59.220
I think that for many decades now,

01:41:59.220 --> 01:42:02.220
there's been sort of this black hole information paradox

01:42:02.220 --> 01:42:04.700
that things that fall into the black hole

01:42:06.300 --> 01:42:08.940
we've seemed to have lost their information.

01:42:08.940 --> 01:42:13.180
Now I think there's this firewall paradox

01:42:13.180 --> 01:42:15.940
that has been allegedly resolved in recent years

01:42:15.940 --> 01:42:20.940
by a former peer of mine who's now a professor at Berkeley.

01:42:21.140 --> 01:42:25.100
And there, it seems like there is,

01:42:25.100 --> 01:42:27.820
as information falls into a black hole,

01:42:27.820 --> 01:42:31.260
it's sort of, there's sort of a sedimentation, right?

01:42:31.260 --> 01:42:33.660
As you get closer and closer to the horizon

01:42:33.660 --> 01:42:36.860
from the point of view of the observer on the outside,

01:42:36.860 --> 01:42:39.980
the object slows down infinitely

01:42:39.980 --> 01:42:41.940
as it gets closer and closer.

01:42:41.940 --> 01:42:45.420
And so everything that is falling to a black hole

01:42:45.420 --> 01:42:48.220
from our perspective gets sort of destroyed.

01:42:48.260 --> 01:42:49.420
Everything that is falling to a black hole

01:42:49.420 --> 01:42:52.420
from our perspective gets sort of sedimented

01:42:52.420 --> 01:42:55.460
and tacked onto the near horizon.

01:42:55.460 --> 01:42:57.540
And at some point it gets so close to the horizon

01:42:57.540 --> 01:43:00.980
it's in the proximity or the scale

01:43:00.980 --> 01:43:04.500
in which quantum effects and quantum fluctuations matter.

01:43:04.500 --> 01:43:09.500
And there, that infalling matter

01:43:09.740 --> 01:43:13.260
could interfere with sort of the traditional pictures

01:43:13.260 --> 01:43:16.300
that it could interfere with the creation and annihilation

01:43:16.300 --> 01:43:19.060
of particles and antiparticles in the vacuum.

01:43:19.060 --> 01:43:21.620
And through this interference,

01:43:21.620 --> 01:43:23.940
one of the particles gets entangled

01:43:23.940 --> 01:43:25.740
with the infalling information

01:43:25.740 --> 01:43:28.060
and one of them is now free and escapes.

01:43:28.060 --> 01:43:31.100
And that's how there's sort of mutual information

01:43:31.100 --> 01:43:36.100
between the outgoing radiation and the infalling matter.

01:43:36.100 --> 01:43:38.300
But getting that calculation right,

01:43:38.300 --> 01:43:43.300
I think we're only just starting to put the pieces together.

01:43:43.700 --> 01:43:46.740
There's a few pothead-like questions I wanna ask you.

01:43:46.740 --> 01:43:50.460
So one, does it terrify you that there's a giant black hole

01:43:50.460 --> 01:43:52.460
at the center of our galaxy?

01:43:52.460 --> 01:43:56.460
I don't know, I just want to set up shop near it

01:43:56.460 --> 01:44:01.460
to fast forward, meet a future civilization, right?

01:44:01.980 --> 01:44:03.740
Like if we have a limited lifetime,

01:44:03.740 --> 01:44:06.500
if you can go orbit a black hole and emerge.

01:44:07.820 --> 01:44:09.820
So if you were like, if there's a special mission

01:44:09.820 --> 01:44:11.060
that could take you to a black hole,

01:44:11.060 --> 01:44:13.140
would you volunteer to go travel?

01:44:13.980 --> 01:44:15.860
To orbit and obviously not fall into it.

01:44:15.860 --> 01:44:16.700
That's obvious.

01:44:16.700 --> 01:44:18.620
So it's obvious to you that everything's destroyed

01:44:18.620 --> 01:44:19.820
inside a black hole.

01:44:19.820 --> 01:44:21.540
Like all the information that makes up Guillaume

01:44:21.540 --> 01:44:22.460
is destroyed.

01:44:23.500 --> 01:44:26.140
Maybe on the other side, Bef Jaisal is emerging.

01:44:26.140 --> 01:44:28.540
And it's all like it's tied together

01:44:28.540 --> 01:44:32.780
in some deeply mimo-ful way.

01:44:32.780 --> 01:44:34.500
Yeah, I mean, that's a great question.

01:44:34.500 --> 01:44:38.660
We have to answer what black holes are.

01:44:38.660 --> 01:44:41.300
Are we punching a hole through space-time

01:44:41.300 --> 01:44:42.860
and creating a pocket universe?

01:44:43.500 --> 01:44:44.820
It's possible, right?

01:44:44.820 --> 01:44:49.260
Then that would mean that if we ascend the Kardashev scale

01:44:49.260 --> 01:44:52.780
to beyond Kardashev type three,

01:44:52.780 --> 01:44:56.540
we could engineer black holes with specific hyperparameters

01:44:56.540 --> 01:44:59.580
to transmit information to new universes we create.

01:44:59.580 --> 01:45:02.340
And so we can have progeny, right?

01:45:03.260 --> 01:45:04.500
That are new universes.

01:45:04.500 --> 01:45:09.500
And so we, even though our universe may reach a heat death,

01:45:10.060 --> 01:45:13.660
we may have a way to have a legacy, right?

01:45:13.660 --> 01:45:15.940
And so we don't know yet.

01:45:15.940 --> 01:45:17.860
We need to ascend the Kardashev scale

01:45:17.860 --> 01:45:20.420
to answer these questions, right?

01:45:20.420 --> 01:45:25.140
To peer into that regime of higher energy physics.

01:45:25.140 --> 01:45:27.340
And maybe you can speak to the Kardashev scale

01:45:27.340 --> 01:45:28.340
for people who don't know.

01:45:28.340 --> 01:45:33.340
So one of the sort of meme-like principles and goals

01:45:35.660 --> 01:45:39.300
of the EAC movement is to ascend the Kardashev scale.

01:45:39.300 --> 01:45:41.380
What is the Kardashev scale?

01:45:41.380 --> 01:45:43.460
And when do we wanna ascend it?

01:45:43.460 --> 01:45:45.900
The Kardashev scale is a measure

01:45:45.900 --> 01:45:48.900
of our energy production and consumption.

01:45:50.220 --> 01:45:53.980
And really it's a logarithmic scale.

01:45:53.980 --> 01:45:56.700
And Kardashev type one is a milestone

01:45:56.700 --> 01:46:00.820
where we are producing the equivalent wattage

01:46:00.820 --> 01:46:04.460
to all the energy that is incident on earth from the sun.

01:46:04.460 --> 01:46:07.960
Kardashev type two would be harnessing all the energy

01:46:07.960 --> 01:46:09.760
that is output by the sun.

01:46:09.760 --> 01:46:13.560
And I think type three is like the whole galaxy.

01:46:13.560 --> 01:46:14.960
I think the whole, yeah.

01:46:14.960 --> 01:46:17.560
Yeah, and then some people have some crazy type four

01:46:17.560 --> 01:46:19.600
and five, but I don't know if I believe in those.

01:46:19.600 --> 01:46:24.600
But to me, it seems like from the first principles

01:46:25.080 --> 01:46:28.920
of thermodynamics, that again, there's this concept

01:46:28.920 --> 01:46:33.920
of thermodynamic driven dissipative adaptation

01:46:34.920 --> 01:46:38.120
where life evolved on earth

01:46:38.120 --> 01:46:42.800
because we have this energetic drive from the sun.

01:46:42.800 --> 01:46:47.300
We have incident energy and life evolved on earth to capture,

01:46:48.600 --> 01:46:51.060
figure out ways to best capture that free energy

01:46:51.060 --> 01:46:54.200
to maintain itself and grow.

01:46:54.200 --> 01:46:57.520
And I think that principle,

01:46:57.520 --> 01:47:00.720
it's not special to our earth sun system.

01:47:00.720 --> 01:47:03.140
We could extend life well beyond

01:47:03.600 --> 01:47:06.180
we kind of have a responsibility to do so

01:47:06.180 --> 01:47:08.780
because that's the process that brought us here.

01:47:08.780 --> 01:47:12.060
So we don't even know what it has at store for us

01:47:12.060 --> 01:47:12.900
in the future.

01:47:12.900 --> 01:47:16.700
It could be something of beauty we can't even imagine today.

01:47:18.380 --> 01:47:21.140
So this is probably a good place to talk a bit

01:47:21.140 --> 01:47:23.500
about the EAC movement.

01:47:23.500 --> 01:47:28.020
In a sub stack blog post titled, what the fuck is EAC?

01:47:28.020 --> 01:47:31.020
Or actually what the F star is EAC?

01:47:31.020 --> 01:47:32.900
You're right, strategically speaking,

01:47:32.900 --> 01:47:35.500
we need to work towards several overarching civilization

01:47:35.500 --> 01:47:37.820
goals that are all interdependent.

01:47:38.820 --> 01:47:41.540
And the four goals are increase the amount of energy

01:47:41.540 --> 01:47:43.380
we can harness as a species,

01:47:44.260 --> 01:47:46.540
climb the Kardashev gradient.

01:47:46.540 --> 01:47:47.820
In the short term,

01:47:47.820 --> 01:47:50.140
this almost certainly means nuclear fission.

01:47:51.660 --> 01:47:52.820
Increase human flourishing

01:47:52.820 --> 01:47:54.500
via pro-population growth policies

01:47:54.500 --> 01:47:56.180
and pro-economic growth policies.

01:47:57.480 --> 01:47:59.340
Create artificial general intelligence,

01:47:59.340 --> 01:48:02.220
the single greatest force multiplier in human history.

01:48:02.380 --> 01:48:04.380
And finally, develop interplanetary

01:48:04.380 --> 01:48:06.180
and interstellar transport

01:48:06.180 --> 01:48:09.060
so that humanity can spread beyond the earth.

01:48:09.060 --> 01:48:13.060
Could you build on top of that to maybe say,

01:48:13.060 --> 01:48:17.420
what to you is the EAC movement?

01:48:17.420 --> 01:48:18.260
What are the goals?

01:48:18.260 --> 01:48:19.460
What are the principles?

01:48:20.540 --> 01:48:25.540
The goal is for the human techno capital memetic machine

01:48:26.780 --> 01:48:28.460
to become self-aware

01:48:28.460 --> 01:48:31.660
and to hyperstitiously engineer its own growth.

01:48:31.660 --> 01:48:33.540
So let's decompress that.

01:48:33.540 --> 01:48:35.460
Define each of those words.

01:48:35.460 --> 01:48:38.060
So you have humans, you have technology,

01:48:38.060 --> 01:48:39.140
you have capital,

01:48:39.140 --> 01:48:42.900
and then you have memes, information, right?

01:48:42.900 --> 01:48:46.540
And all of those systems are coupled with one another,

01:48:46.540 --> 01:48:47.380
right?

01:48:47.380 --> 01:48:48.220
Humans work at companies,

01:48:48.220 --> 01:48:50.580
they acquire and allocate capital,

01:48:50.580 --> 01:48:53.660
and humans communicate via memes

01:48:53.660 --> 01:48:55.460
and information propagation.

01:48:56.340 --> 01:49:00.540
And our goal was to have a sort of viral,

01:49:00.540 --> 01:49:05.540
optimistic movement that is aware of how the system works.

01:49:06.060 --> 01:49:08.660
Fundamentally, it seeks to grow.

01:49:08.660 --> 01:49:13.660
And we simply want to lean into the natural tendencies

01:49:14.540 --> 01:49:16.820
of the system to adapt for its own growth.

01:49:18.460 --> 01:49:19.940
So in that way, you're right,

01:49:19.940 --> 01:49:23.300
the EAC is literally a memetic optimism virus

01:49:23.300 --> 01:49:25.540
that is constantly drifting, mutating,

01:49:25.540 --> 01:49:28.300
and propagating in a decentralized fashion.

01:49:28.300 --> 01:49:30.780
So memetic optimism virus.

01:49:30.780 --> 01:49:35.300
So you do want it to be a virus to maximize the spread.

01:49:35.300 --> 01:49:37.660
And it's hyperstitious,

01:49:37.660 --> 01:49:42.100
therefore the optimism will incentivize its growth.

01:49:43.100 --> 01:49:46.980
We see EAC as a sort of a meta heuristic,

01:49:46.980 --> 01:49:51.180
a sort of very thin cultural framework

01:49:51.180 --> 01:49:55.620
from which you can have much more opinionated forks, right?

01:49:55.620 --> 01:49:59.860
Fundamentally, we just say that it's good,

01:49:59.860 --> 01:50:04.860
what got us here is this adaptation of the whole system,

01:50:06.220 --> 01:50:07.580
based on thermodynamics,

01:50:07.580 --> 01:50:09.300
and that process is good,

01:50:09.300 --> 01:50:11.420
and we should keep it going, right?

01:50:11.420 --> 01:50:12.420
That is the core thesis.

01:50:12.420 --> 01:50:14.700
Everything else is, okay,

01:50:14.700 --> 01:50:19.700
how do we ensure that we maintain this malleability

01:50:19.940 --> 01:50:20.780
and adaptability?

01:50:20.780 --> 01:50:24.900
Well, clearly not suppressing variants

01:50:24.900 --> 01:50:28.740
and maintaining free speech, freedom of thought,

01:50:28.740 --> 01:50:31.580
freedom of information propagation,

01:50:31.580 --> 01:50:34.580
and freedom to do AI research is important

01:50:34.580 --> 01:50:39.580
for us to converge the fastest on the space of technologies,

01:50:40.940 --> 01:50:44.220
ideas, and whatnot that lead to this growth.

01:50:45.980 --> 01:50:49.540
And so ultimately, there's been quite a few forks.

01:50:49.540 --> 01:50:52.100
Some are just memes, but some are more serious, right?

01:50:52.100 --> 01:50:55.820
Vitalik Buterin recently made a DEAC fork.

01:50:55.820 --> 01:50:59.180
He has his own sort of fine tunings of EAC.

01:50:59.180 --> 01:51:01.020
Does anything jump out to memory

01:51:01.020 --> 01:51:05.540
of the unique characteristic of that fork from Vitalik?

01:51:05.540 --> 01:51:08.540
I would say that it's trying to find a middle ground

01:51:08.540 --> 01:51:12.660
between EAC and sort of EA and AI safety.

01:51:12.660 --> 01:51:17.620
To me, like having a movement that is opposite

01:51:17.620 --> 01:51:19.140
to what was the mainstream narrative

01:51:19.140 --> 01:51:20.500
that was taking over Silicon Valley

01:51:20.500 --> 01:51:24.660
is important to sort of shift the dynamic range of opinions.

01:51:24.660 --> 01:51:28.500
And it's like the balance between centralization

01:51:28.500 --> 01:51:29.540
and decentralization.

01:51:29.540 --> 01:51:32.860
The real optimum is always somewhere in the middle, right?

01:51:32.860 --> 01:51:37.860
But for EAC, we're pushing for entropy, novelty,

01:51:38.540 --> 01:51:42.040
disruption, malleability, speed,

01:51:43.300 --> 01:51:46.100
rather than being like sort of conservative,

01:51:46.100 --> 01:51:48.020
suppressing thoughts, suppressing speech,

01:51:48.020 --> 01:51:51.540
adding constraints, adding too many regulations,

01:51:51.540 --> 01:51:52.660
slowing things down.

01:51:52.660 --> 01:51:53.980
And so it's kind of,

01:51:53.980 --> 01:51:56.820
we're trying to bring balance to the force, right?

01:51:56.820 --> 01:51:57.780
The systems.

01:52:00.140 --> 01:52:02.900
Balance to the force of human civilization, yeah.

01:52:02.900 --> 01:52:04.620
It's literally the forces of constraints

01:52:04.620 --> 01:52:09.140
versus the entropic force that makes us explore, right?

01:52:09.140 --> 01:52:13.700
Systems are optimal when they're at the edge of criticality

01:52:13.700 --> 01:52:15.820
between order and chaos, right?

01:52:15.820 --> 01:52:20.820
Between constraints, energy minimization and entropy, right?

01:52:21.540 --> 01:52:24.500
Systems want to equilibrate, balance these two things.

01:52:24.500 --> 01:52:27.620
And so I thought that the balance was lacking.

01:52:27.620 --> 01:52:31.700
And so we created this movement to bring balance.

01:52:31.700 --> 01:52:36.340
Well, I like the sort of visual of the landscape

01:52:36.340 --> 01:52:39.140
of ideas evolving through forks.

01:52:39.140 --> 01:52:43.860
So kind of thinking on the other part of history,

01:52:44.620 --> 01:52:49.500
thinking of Marxism as the original repository,

01:52:49.500 --> 01:52:52.220
and then Soviet communism is a fork of that.

01:52:52.220 --> 01:52:57.220
And then the Maoism is a fork of Marxism and communism.

01:52:58.300 --> 01:53:00.580
And so those are all forks.

01:53:00.580 --> 01:53:02.580
They're exploring different ideas.

01:53:02.580 --> 01:53:04.980
Thinking of culture almost like code, right?

01:53:04.980 --> 01:53:09.980
Nowadays, I mean, what you prompt in the LLM

01:53:09.980 --> 01:53:12.780
or what you put in the constitution of an LLM

01:53:13.260 --> 01:53:16.900
is basically its cultural framework, what it believes, right?

01:53:18.300 --> 01:53:21.420
And you can share it on GitHub nowadays.

01:53:21.420 --> 01:53:23.900
So starting trying to take inspiration

01:53:23.900 --> 01:53:28.900
from what has worked in the sort of machine of software

01:53:29.900 --> 01:53:31.900
to adapt over the space of code.

01:53:31.900 --> 01:53:33.580
Could we apply that to culture?

01:53:33.580 --> 01:53:35.660
And our goal is to not say

01:53:35.660 --> 01:53:38.300
you should live your life this way, X, Y, Z,

01:53:38.300 --> 01:53:43.180
is to set up a process where people are always searching

01:53:43.180 --> 01:53:46.900
over subcultures and competing for mindshare.

01:53:46.900 --> 01:53:50.260
And I think creating this malleability of culture

01:53:50.260 --> 01:53:53.820
is super important for us to converge onto the cultures

01:53:53.820 --> 01:53:56.620
and the heuristics about how to live one's life

01:53:56.620 --> 01:53:59.500
that are updated to modern times,

01:53:59.500 --> 01:54:03.460
because there's really been a sort of vacuum

01:54:03.460 --> 01:54:06.100
of spirituality and culture.

01:54:06.100 --> 01:54:08.620
People don't feel like they belong to any one group.

01:54:08.620 --> 01:54:11.180
And there's been parasitic ideologies

01:54:11.180 --> 01:54:13.460
that have taken up opportunity

01:54:13.460 --> 01:54:18.180
to populate this petri dish of minds, right?

01:54:18.180 --> 01:54:20.580
Elon calls it the mind virus.

01:54:20.580 --> 01:54:24.660
We call it the D-cell mind virus complex,

01:54:24.660 --> 01:54:26.700
which is the decelerative

01:54:26.700 --> 01:54:29.740
that is kind of the overall pattern between all of them.

01:54:29.740 --> 01:54:31.300
There's many variants as well.

01:54:32.220 --> 01:54:36.100
And so, if there's a sort of viral pessimism,

01:54:36.100 --> 01:54:37.380
decelerative movement,

01:54:37.380 --> 01:54:40.060
we needed to have not only one movement,

01:54:40.060 --> 01:54:42.060
but many, many variants.

01:54:42.060 --> 01:54:44.220
So it's very hard to pinpoint and stop.

01:54:45.060 --> 01:54:47.380
But the overarching thing is nevertheless

01:54:47.380 --> 01:54:51.740
a kind of mimetic optimism pandemic.

01:54:53.860 --> 01:54:57.140
So, I mean, okay, let me ask you,

01:54:57.140 --> 01:54:59.860
do you think IAC, to some degree, is a cult?

01:55:00.860 --> 01:55:01.700
Define cult.

01:55:02.940 --> 01:55:06.260
I think a lot of human progress is made

01:55:06.260 --> 01:55:09.220
when you have independent thought.

01:55:09.220 --> 01:55:12.140
So you have individuals that are able to think freely.

01:55:12.140 --> 01:55:15.780
And very powerful

01:55:18.460 --> 01:55:21.620
mimetic systems can kind of lead to group think.

01:55:21.620 --> 01:55:22.820
There's something in human nature

01:55:22.820 --> 01:55:25.980
that leads to like mass hypnosis, mass hysteria,

01:55:25.980 --> 01:55:27.980
where we start to think alike.

01:55:28.340 --> 01:55:32.220
Whenever there's a sexy idea that captures our minds.

01:55:32.220 --> 01:55:34.740
And so it's actually hard to break us apart,

01:55:34.740 --> 01:55:37.940
pull us apart, diversify a thought.

01:55:37.940 --> 01:55:41.100
So to that degree, to which degree is everybody

01:55:41.100 --> 01:55:46.100
kind of chanting IAC, IAC, like the sheep in Animal Farm?

01:55:46.500 --> 01:55:47.820
Well, first of all, it's fun.

01:55:47.820 --> 01:55:49.300
It's rebellious, right?

01:55:49.300 --> 01:55:51.220
Like, you know, many,

01:55:53.020 --> 01:55:55.340
I think we lean into,

01:55:55.900 --> 01:55:58.980
there's this concept of sort of meta-irony, right?

01:55:58.980 --> 01:56:01.940
Of sort of being on the boundary of like,

01:56:01.940 --> 01:56:03.460
we're not sure if they're serious or not.

01:56:03.460 --> 01:56:06.540
And it's much more playful and much more fun, right?

01:56:06.540 --> 01:56:09.220
Like, for example, we talk about thermodynamics

01:56:09.220 --> 01:56:11.020
being our God, right?

01:56:12.180 --> 01:56:14.420
And sometimes we do cult-like things,

01:56:14.420 --> 01:56:18.300
but there's no ceremony and robes and whatnot.

01:56:18.300 --> 01:56:19.140
Not yet.

01:56:19.140 --> 01:56:19.980
Not yet.

01:56:21.220 --> 01:56:23.580
But ultimately, yeah, I mean, I totally agree

01:56:23.580 --> 01:56:27.980
that it seems to me that humans wanna feel

01:56:27.980 --> 01:56:29.020
like they're part of a group.

01:56:29.020 --> 01:56:33.420
So they naturally try to agree with their neighbors

01:56:33.420 --> 01:56:35.460
and find common ground.

01:56:35.460 --> 01:56:38.260
And that leads to sort of mode collapse

01:56:38.260 --> 01:56:40.180
in the space of ideas, right?

01:56:40.180 --> 01:56:44.740
We used to have sort of one cultural island

01:56:44.740 --> 01:56:45.580
that was allowed.

01:56:45.580 --> 01:56:47.140
It was a typical subspace of thought.

01:56:47.140 --> 01:56:50.380
And anything that was diverting from that subspace of thought

01:56:50.380 --> 01:56:52.820
was suppressed or you were canceled, right?

01:56:52.820 --> 01:56:54.820
Now we've created a new mode,

01:56:54.820 --> 01:56:57.340
but the whole point is that we're not trying to have

01:56:57.340 --> 01:56:59.500
a very restricted space of thought.

01:56:59.500 --> 01:57:01.700
There's not just one way to think about EAC

01:57:01.700 --> 01:57:03.020
and its many forks.

01:57:03.020 --> 01:57:05.140
And the point is that there are many forks

01:57:05.140 --> 01:57:07.220
and there can be many clusters and many islands.

01:57:07.220 --> 01:57:12.220
And I shouldn't be in control of it in any way.

01:57:12.220 --> 01:57:16.180
I mean, there's no formal org whatsoever.

01:57:16.180 --> 01:57:20.620
I just put out tweets and certain blog posts

01:57:20.620 --> 01:57:24.100
and people are free to defect and fork

01:57:24.100 --> 01:57:26.140
if there's an aspect they don't like.

01:57:26.140 --> 01:57:29.580
And so that makes it so that there should be

01:57:29.580 --> 01:57:34.180
a sort of deterritorialization in the space of ideas

01:57:34.180 --> 01:57:36.900
so that we don't end up in one cluster

01:57:36.900 --> 01:57:38.900
that's very cult-like.

01:57:38.900 --> 01:57:43.620
And so cults usually they don't allow people to defect

01:57:43.620 --> 01:57:47.700
or start competing forks, whereas we encourage it, right?

01:57:47.740 --> 01:57:49.620
Do you think just the humor,

01:57:51.020 --> 01:57:53.140
the pros and cons of humor and meme,

01:57:54.420 --> 01:57:56.060
in some sense, meme,

01:57:58.260 --> 01:58:00.300
there's like a wisdom to memes.

01:58:02.780 --> 01:58:04.180
What is it, the Magic Theater?

01:58:04.180 --> 01:58:05.260
What book is that from?

01:58:05.260 --> 01:58:08.980
Harmon has a Steppenwolf, I think.

01:58:08.980 --> 01:58:13.980
But there's a kind of embracing of the absurdity

01:58:14.980 --> 01:58:17.620
that seems to get to the truth of things.

01:58:17.620 --> 01:58:20.860
But at the same time, it can also decrease the quality

01:58:20.860 --> 01:58:23.460
and the rigor of the discourse.

01:58:23.460 --> 01:58:25.100
Do you feel the tension of that?

01:58:25.100 --> 01:58:26.420
Yeah.

01:58:26.420 --> 01:58:30.020
So initially, I think what allowed us to grow

01:58:30.020 --> 01:58:33.340
under the radar was because it was camouflaged

01:58:33.340 --> 01:58:35.700
as sort of meta-ironic, right?

01:58:35.700 --> 01:58:40.700
We would sneak in deep truths within a package of humor

01:58:41.700 --> 01:58:45.500
and humor and memes and what are called shitposts, right?

01:58:46.740 --> 01:58:51.740
And I think that was purposefully a sort of camouflage

01:58:52.020 --> 01:58:57.020
against those that seek status and do not want to,

01:58:59.380 --> 01:59:02.420
it's very hard to argue with a cartoon frog

01:59:02.420 --> 01:59:07.420
or a cartoon of an intergalactic Jeff Bezos

01:59:09.060 --> 01:59:10.500
and take yourself seriously.

01:59:10.820 --> 01:59:15.260
And so that allowed us to grow pretty rapidly

01:59:15.260 --> 01:59:16.300
in the early days.

01:59:16.300 --> 01:59:21.300
But of course, essentially people get steered,

01:59:24.020 --> 01:59:27.140
their notion of the truth comes from the data they see

01:59:27.140 --> 01:59:29.140
from the information they're fed.

01:59:29.140 --> 01:59:31.740
And the information people are fed

01:59:31.740 --> 01:59:34.820
is determined by algorithms, right?

01:59:34.820 --> 01:59:39.820
And really what we've been doing is sort of engineering,

01:59:40.180 --> 01:59:44.540
what we call high memetic fitness packets of information

01:59:44.540 --> 01:59:47.420
so that they can spread effectively and carry a message,

01:59:47.420 --> 01:59:48.260
right?

01:59:48.260 --> 01:59:52.460
So it's kind of a vector to spread the message.

01:59:52.460 --> 01:59:55.940
And yes, we've been using sort of techniques

01:59:55.940 --> 02:00:00.100
that are optimal for today's algorithmically amplified

02:00:00.100 --> 02:00:02.340
information landscapes.

02:00:02.340 --> 02:00:06.300
But I think we're reaching the point of scale

02:00:06.460 --> 02:00:10.220
where we can have serious debates and serious conversations.

02:00:10.220 --> 02:00:15.220
And that's why we're considering doing a bunch of debates

02:00:15.420 --> 02:00:18.020
and having more serious long form discussions.

02:00:18.020 --> 02:00:21.580
Because I don't think that the timeline is optimal

02:00:21.580 --> 02:00:24.820
for sort of very serious, thoughtful discussions.

02:00:24.820 --> 02:00:29.460
You get rewarded for sort of polarization, right?

02:00:29.460 --> 02:00:33.020
And so even though we started a movement

02:00:33.020 --> 02:00:36.820
that is literally trying to polarize the tech ecosystem

02:00:37.700 --> 02:00:38.540
at the end of the day,

02:00:38.540 --> 02:00:39.980
it's so that we can have a conversation

02:00:39.980 --> 02:00:42.740
and find an optimum together.

02:00:42.740 --> 02:00:45.260
I mean, that's kind of what I try to do with this podcast,

02:00:45.260 --> 02:00:47.100
given the landscape of things

02:00:47.100 --> 02:00:49.260
to still have long form conversations.

02:00:49.260 --> 02:00:54.020
But there is a degree to which absurdity is fully embraced.

02:00:54.020 --> 02:00:59.020
In fact, this very conversation is multi-level absurd.

02:01:00.020 --> 02:01:03.420
So first of all, I should say that I just very recently

02:01:03.420 --> 02:01:06.260
had a conversation with Jeff Bezos.

02:01:07.380 --> 02:01:12.380
And I would love to hear your, Beth Jezos,

02:01:14.100 --> 02:01:17.020
opinions of Jeff Bezos,

02:01:17.020 --> 02:01:19.780
speaking of intergalactic Jeff Bezos.

02:01:19.780 --> 02:01:22.420
What do you think of that particular individual

02:01:22.420 --> 02:01:24.460
whom your name has inspired?

02:01:25.460 --> 02:01:29.220
Yeah, I mean, I think Jeff is really great.

02:01:29.220 --> 02:01:32.260
I mean, he's built one of the most epic companies

02:01:32.260 --> 02:01:33.100
of all time.

02:01:33.100 --> 02:01:34.700
He's leveraged the techno capital machine

02:01:34.700 --> 02:01:36.420
and techno capital acceleration

02:01:36.420 --> 02:01:40.380
to give us what we wanted, right?

02:01:40.380 --> 02:01:44.500
We want a quick delivery, very convenient,

02:01:44.500 --> 02:01:46.460
at home, low prices, right?

02:01:46.460 --> 02:01:49.420
He understood how the machine worked

02:01:49.420 --> 02:01:50.900
and how to harness it, right?

02:01:50.900 --> 02:01:53.260
Like running the company,

02:01:53.420 --> 02:01:55.420
not trying to take profits too early,

02:01:55.420 --> 02:01:59.100
putting it back, letting the system compound

02:01:59.100 --> 02:02:00.580
and keep improving.

02:02:00.580 --> 02:02:03.020
And arguably, I think Amazon's invested

02:02:03.020 --> 02:02:06.420
some of the most amount of capital in robotics out there.

02:02:07.580 --> 02:02:10.220
And certainly with the birth of AWS

02:02:10.220 --> 02:02:14.420
kind of enabled the sort of tech boom we've seen today

02:02:14.420 --> 02:02:18.980
that has paid the salaries of, I guess, myself

02:02:18.980 --> 02:02:20.900
and all of our friends to some extent.

02:02:21.580 --> 02:02:24.820
So I think we can all be grateful to Jeff

02:02:24.820 --> 02:02:28.500
and he's one of the great entrepreneurs out there,

02:02:28.500 --> 02:02:30.900
one of the best of all time, unarguably.

02:02:32.260 --> 02:02:34.660
And of course, the work at Blue Origin,

02:02:34.660 --> 02:02:36.340
similar to the work at SpaceX,

02:02:36.340 --> 02:02:39.300
is trying to make humans a multi-planetary species,

02:02:39.300 --> 02:02:42.940
which seems almost like a bigger thing

02:02:42.940 --> 02:02:45.220
than the capitalist machine.

02:02:45.220 --> 02:02:46.100
Or it's a capitalist machine

02:02:46.100 --> 02:02:47.900
at a different time scale, perhaps?

02:02:47.900 --> 02:02:52.380
Yeah, I think that companies,

02:02:52.380 --> 02:02:56.380
they tend to optimize quarter over quarter,

02:02:56.380 --> 02:02:57.940
maybe a few years out,

02:02:57.940 --> 02:03:00.860
but individuals that wanna leave a legacy

02:03:00.860 --> 02:03:05.300
can think on a multi-decadal or multi-century time scale.

02:03:05.300 --> 02:03:08.100
And so the fact that some individuals

02:03:08.100 --> 02:03:10.460
are such good capital allocators

02:03:10.460 --> 02:03:13.340
that they unlock the ability to allocate capitals

02:03:13.340 --> 02:03:16.340
to goals that take us much further

02:03:16.340 --> 02:03:18.020
or are much further looking.

02:03:18.020 --> 02:03:20.900
Elon's doing this with SpaceX,

02:03:20.900 --> 02:03:23.460
putting all his capital towards getting us to Mars.

02:03:24.420 --> 02:03:27.060
Jeff is trying to build Blue Origin

02:03:27.060 --> 02:03:29.100
and I think he wants to build O'Neill cylinders

02:03:29.100 --> 02:03:32.540
and get industry off planet, which I think is brilliant.

02:03:33.580 --> 02:03:38.540
I think just overall, I'm for billionaires.

02:03:38.540 --> 02:03:40.540
I know this is a controversial statement sometimes,

02:03:40.540 --> 02:03:43.140
but I think that, in a sense,

02:03:43.140 --> 02:03:46.340
it's kind of a proof of stake voting, right?

02:03:46.340 --> 02:03:50.980
Like if you've allocated capital efficiently,

02:03:50.980 --> 02:03:54.660
you unlock more capital to allocate

02:03:54.660 --> 02:03:56.860
just because clearly you know

02:03:56.860 --> 02:03:59.580
how to allocate capital more efficiently,

02:03:59.580 --> 02:04:03.540
which is in contrast to politicians that get elected

02:04:03.540 --> 02:04:05.900
because they speak the best on TV, right?

02:04:05.900 --> 02:04:08.060
Not because they have a proven track record

02:04:08.060 --> 02:04:11.740
of allocating taxpayer capital most efficiently.

02:04:11.740 --> 02:04:16.740
And so that's why I'm for capitalism over, say,

02:04:16.940 --> 02:04:18.460
giving all our money to the government

02:04:18.460 --> 02:04:21.860
and letting them figure out how to allocate it, so yeah.

02:04:21.860 --> 02:04:26.860
Why do you think it's a viral and a popular meme

02:04:26.940 --> 02:04:30.580
to criticize billionaires, since you mentioned billionaires?

02:04:30.580 --> 02:04:35.380
Why do you think there's quite a widespread criticism

02:04:36.740 --> 02:04:39.500
of people with wealth, especially those in the public eye

02:04:39.540 --> 02:04:41.780
like Jeff and Elon and Mark Zuckerberg

02:04:41.780 --> 02:04:44.700
and who else, Bill Gates?

02:04:44.700 --> 02:04:47.580
Yeah, I think a lot of people would,

02:04:47.580 --> 02:04:48.980
instead of trying to understand

02:04:48.980 --> 02:04:51.620
how the techno capital machine works

02:04:51.620 --> 02:04:54.780
and realizing they have much more agency than they think,

02:04:54.780 --> 02:04:58.020
they'd rather have this sort of victim mindset.

02:04:58.020 --> 02:05:00.380
I'm just subjected to this machine.

02:05:00.380 --> 02:05:04.900
It is oppressing me and the successful players

02:05:04.900 --> 02:05:07.900
clearly must be evil

02:05:07.900 --> 02:05:09.500
because they've been successful at this game

02:05:09.500 --> 02:05:11.020
that I'm not successful at.

02:05:11.020 --> 02:05:15.740
But I've managed to get some people that were in that mindset

02:05:15.740 --> 02:05:19.100
and make them realize how the techno capital machine works

02:05:19.100 --> 02:05:23.020
and how you can harness it for your own good

02:05:23.020 --> 02:05:24.220
and for the good of others.

02:05:24.220 --> 02:05:26.020
And by creating value,

02:05:26.020 --> 02:05:27.780
you capture some of the value you create for the world.

02:05:27.780 --> 02:05:31.580
And that sort of positive-sum mindset shift is so potent.

02:05:31.580 --> 02:05:35.300
And really, that's what we're trying to do by scaling EAC

02:05:35.340 --> 02:05:38.940
and sort of unlocking that higher level of agency.

02:05:38.940 --> 02:05:41.660
Like actually, you're far more in control of the future

02:05:41.660 --> 02:05:42.540
than you think.

02:05:42.540 --> 02:05:44.460
You have agency to change the world.

02:05:44.460 --> 02:05:45.700
Go out and do it.

02:05:45.700 --> 02:05:46.900
Here's permission.

02:05:46.900 --> 02:05:49.540
Each individual has agency.

02:05:49.540 --> 02:05:52.500
The motto, keep building, is often heard.

02:05:52.500 --> 02:05:54.020
What does that mean to you?

02:05:54.020 --> 02:05:56.060
And what does that have to do with Diet Coke?

02:05:56.060 --> 02:05:57.900
Oh, die.

02:05:57.900 --> 02:05:59.740
By the way, thank you so much for the Red Bull.

02:05:59.740 --> 02:06:01.580
It's working pretty well.

02:06:01.580 --> 02:06:03.220
I'm feeling pretty good.

02:06:03.220 --> 02:06:04.060
Awesome.

02:06:05.860 --> 02:06:09.220
Well, so building technologies and building,

02:06:09.220 --> 02:06:10.420
it doesn't have to be technologies.

02:06:10.420 --> 02:06:14.340
Just building in general means having agency

02:06:14.340 --> 02:06:18.300
trying to change the world by creating,

02:06:18.300 --> 02:06:21.860
let's say, a company, which is a self-sustaining organism

02:06:22.980 --> 02:06:25.300
that accomplishes a function

02:06:25.300 --> 02:06:27.540
in the broader techno capital machine.

02:06:27.540 --> 02:06:30.780
To us, that's the way to achieve change in the world

02:06:30.780 --> 02:06:33.860
that you'd like to see rather than, say,

02:06:33.900 --> 02:06:37.060
pressuring politicians or creating nonprofits that,

02:06:38.300 --> 02:06:39.820
nonprofits, once they run out of money,

02:06:39.820 --> 02:06:42.100
their function can no longer be accomplished.

02:06:42.100 --> 02:06:45.500
You're kind of deforming the market artificially

02:06:45.500 --> 02:06:49.700
compared to sort of subverting or coercing the market

02:06:49.700 --> 02:06:53.460
to, or dancing with the market to convince it

02:06:53.460 --> 02:06:56.700
that actually this function is important, adds value,

02:06:56.700 --> 02:06:57.740
and here it is, right?

02:06:57.740 --> 02:07:00.500
And so I think this is sort of the way

02:07:00.540 --> 02:07:03.980
between this sort of degrowth, like ESG approach

02:07:03.980 --> 02:07:05.980
versus, say, Elon, right?

02:07:05.980 --> 02:07:07.140
The degrowth approach is like,

02:07:07.140 --> 02:07:10.380
we're gonna manage our way out of a climate crisis,

02:07:10.380 --> 02:07:12.820
and Elon is like, I'm gonna build a company

02:07:12.820 --> 02:07:16.100
that is self-sustaining, profitable, and growing,

02:07:16.100 --> 02:07:19.580
and we're gonna innovate our way out of this dilemma, right?

02:07:19.580 --> 02:07:23.340
And we're trying to get people to do the latter

02:07:23.340 --> 02:07:25.300
rather than the former at all scales.

02:07:26.580 --> 02:07:28.220
Elon is an interesting case.

02:07:28.220 --> 02:07:32.180
So you are a proponent, you celebrate Elon,

02:07:32.180 --> 02:07:35.220
but he's also somebody who has, for a long time,

02:07:35.220 --> 02:07:39.180
warned about the dangers, the potential dangers,

02:07:39.180 --> 02:07:41.580
existential risks of artificial intelligence.

02:07:41.580 --> 02:07:42.860
How do you square the two?

02:07:42.860 --> 02:07:45.020
Is that a contradiction to you?

02:07:45.020 --> 02:07:49.460
It is somewhat because he's very much against regulation

02:07:49.460 --> 02:07:53.540
in many aspects, but for AI, he's definitely

02:07:55.660 --> 02:07:57.340
a proponent of regulations.

02:07:58.180 --> 02:08:01.260
I think, overall, he saw the dangers of, say,

02:08:02.180 --> 02:08:04.540
opening eye, cornering the market,

02:08:04.540 --> 02:08:07.500
and then getting to have the monopoly

02:08:07.500 --> 02:08:12.500
over the cultural priors that you can embed in these LLMs

02:08:13.380 --> 02:08:17.820
that then, as LLMs now become the source of truth

02:08:17.820 --> 02:08:21.060
for people, then you can shape the culture of the people,

02:08:21.060 --> 02:08:23.980
and so you can control people by controlling LLMs.

02:08:23.980 --> 02:08:27.700
And he saw that, just like it was the case for social media,

02:08:28.580 --> 02:08:31.780
if you shape the function of information propagation,

02:08:31.780 --> 02:08:34.020
you can shape people's opinions.

02:08:34.020 --> 02:08:36.060
He sought to make it competitor.

02:08:36.060 --> 02:08:38.460
So at least, I think we're very aligned there

02:08:38.460 --> 02:08:41.220
that the way to a good future

02:08:41.220 --> 02:08:44.020
is to maintain adversarial equilibria

02:08:44.020 --> 02:08:45.860
between the various AI players.

02:08:46.820 --> 02:08:49.940
I love to talk to him to understand his thinking

02:08:49.940 --> 02:08:54.940
about how to advance AI going forwards.

02:08:55.380 --> 02:08:57.780
I mean, he's also hedging his bets, I would say,

02:08:57.780 --> 02:08:59.460
with Neuralink, right?

02:08:59.460 --> 02:09:02.900
I think if he can't stop the progress of AI,

02:09:02.900 --> 02:09:04.700
he's building the technology to merge.

02:09:04.700 --> 02:09:09.700
So look at the actions, not just the words, but...

02:09:10.100 --> 02:09:14.380
Well, I mean, there's some degree where being concerned,

02:09:14.380 --> 02:09:17.060
maybe using human psychology,

02:09:17.100 --> 02:09:19.940
being concerned about threats all around us is a motivator.

02:09:21.340 --> 02:09:22.420
It's an encouraging thing.

02:09:22.420 --> 02:09:24.660
I operate much better when there's a deadline,

02:09:24.660 --> 02:09:26.100
the fear of the deadline.

02:09:27.340 --> 02:09:29.700
For myself, create artificial things.

02:09:29.700 --> 02:09:31.860
I wanna create in myself this kind of anxiety

02:09:31.860 --> 02:09:34.020
as if something really horrible will happen

02:09:34.020 --> 02:09:35.260
if I miss the deadline.

02:09:35.260 --> 02:09:38.740
I think there's some degree of that here,

02:09:38.740 --> 02:09:42.300
because creating AI that's aligned with humans

02:09:42.300 --> 02:09:44.300
has a lot of potential benefits.

02:09:44.300 --> 02:09:46.380
And so a different way to reframe that is

02:09:47.300 --> 02:09:50.220
if you don't, we're all gonna die.

02:09:50.220 --> 02:09:55.220
It just seems to be a very powerful psychological formulation

02:09:55.540 --> 02:09:59.300
of the goal of creating human-aligned AI.

02:09:59.300 --> 02:10:00.740
I think that anxiety is good.

02:10:00.740 --> 02:10:03.340
I think, like I said, I want the free market

02:10:03.340 --> 02:10:07.180
to create aligned AIs that are reliable.

02:10:08.100 --> 02:10:10.700
And I think that's what he's trying to do with XAI.

02:10:11.940 --> 02:10:12.780
So I'm all for it.

02:10:12.780 --> 02:10:14.740
What I am against is sort of

02:10:17.460 --> 02:10:20.180
stopping, let's say, the open-source ecosystem

02:10:20.180 --> 02:10:25.100
from thriving by, let's say, in the executive order,

02:10:25.100 --> 02:10:28.860
claiming that open-source LMS or dual-use technologies

02:10:28.860 --> 02:10:30.940
should be government-controlled.

02:10:30.940 --> 02:10:34.100
Then everybody needs to register their GPU

02:10:34.100 --> 02:10:36.740
and their big matrices with the government.

02:10:36.740 --> 02:10:40.140
And I think that extra friction

02:10:40.140 --> 02:10:42.540
will dissuade a lot of hackers from contributing.

02:10:42.540 --> 02:10:45.620
Hackers that could later become the researchers

02:10:45.620 --> 02:10:50.220
that make key discoveries that push us forward,

02:10:50.220 --> 02:10:52.740
including discoveries for AI safety.

02:10:52.740 --> 02:10:55.820
And so I think I just wanna maintain ubiquity

02:10:55.820 --> 02:10:57.860
of opportunity to contribute to AI

02:10:57.860 --> 02:11:00.540
and to own a piece of the future.

02:11:00.540 --> 02:11:04.660
It can't just be legislated behind some wall

02:11:04.660 --> 02:11:07.820
where only a few players get to play the game.

02:11:07.820 --> 02:11:11.740
I mean, so the AI movement is often sort of caricatured

02:11:11.740 --> 02:11:16.740
to mean sort of progress and innovation at all costs.

02:11:18.460 --> 02:11:20.540
It doesn't matter how unsafe it is.

02:11:20.540 --> 02:11:22.860
It doesn't matter if it causes a lot of damage.

02:11:22.860 --> 02:11:26.340
You just build cool shit as fast as possible,

02:11:26.340 --> 02:11:31.340
stay up all night with a Diet Coke, whatever it takes.

02:11:31.820 --> 02:11:33.420
And I think, I guess,

02:11:33.420 --> 02:11:34.780
I don't know if there's a question in there,

02:11:34.780 --> 02:11:37.460
but how important to you

02:11:37.460 --> 02:11:40.140
and what you've seen the different formulations of EAC

02:11:40.140 --> 02:11:42.380
is safety, is AI safety?

02:11:43.820 --> 02:11:47.380
I think, again, I think like if there was no one

02:11:47.380 --> 02:11:50.820
working on it, I think I would be a proponent of it.

02:11:50.820 --> 02:11:54.020
I think, again, our goal is to sort of bring balance

02:11:54.020 --> 02:11:59.020
and obviously a sense of urgency is a useful tool,

02:11:59.500 --> 02:12:00.940
right, to make progress.

02:12:00.940 --> 02:12:03.900
It hacks our dopaminergic systems

02:12:03.900 --> 02:12:08.260
and gives us energy to work late into the night.

02:12:08.260 --> 02:12:10.980
I think also having a higher purpose

02:12:10.980 --> 02:12:12.540
you're contributing to, right?

02:12:12.540 --> 02:12:14.540
At the end of the day, it's like, what am I contributing to?

02:12:14.540 --> 02:12:17.700
I'm contributing to the growth of this beautiful machine

02:12:17.700 --> 02:12:20.060
so that we can seek to the stars.

02:12:20.060 --> 02:12:21.020
That's really inspiring.

02:12:21.020 --> 02:12:25.420
That's also a sort of a neuro hack.

02:12:26.500 --> 02:12:28.140
So you're saying AI safety is important to you,

02:12:28.140 --> 02:12:32.340
but right now the landscape of ideas you see

02:12:32.340 --> 02:12:35.700
is AI safety as a topic is used more often

02:12:35.700 --> 02:12:38.180
to gain centralized control.

02:12:39.060 --> 02:12:40.380
So in that sense, you're resisting it

02:12:40.380 --> 02:12:43.580
as a proxy for gaining centralized control.

02:12:43.580 --> 02:12:47.900
Yeah, I just think we have to be careful

02:12:47.900 --> 02:12:52.900
because safety is just the perfect cover

02:12:54.180 --> 02:12:57.180
for sort of centralization of power

02:12:57.180 --> 02:12:59.940
and covering up eventually corruption.

02:12:59.940 --> 02:13:01.100
I'm not saying it's corrupted now,

02:13:01.100 --> 02:13:04.300
but it could be down the line.

02:13:04.300 --> 02:13:07.860
And really, if you let the argument run,

02:13:08.100 --> 02:13:12.260
there's no amount of sort of centralization of control

02:13:12.260 --> 02:13:14.860
that will be enough to ensure your safety.

02:13:14.860 --> 02:13:18.580
There's always more 999s of peace safety

02:13:18.580 --> 02:13:22.060
that you can gain, 999.9999% safe.

02:13:22.060 --> 02:13:23.340
Maybe you want another nine.

02:13:23.340 --> 02:13:26.620
Oh, please give us full access to everything you do,

02:13:26.620 --> 02:13:28.060
full surveillance.

02:13:28.060 --> 02:13:32.180
And frankly, those that are proponents of AI safety

02:13:32.180 --> 02:13:36.780
have proposed having a global panopticon, right?

02:13:36.780 --> 02:13:39.540
Where you have centralized perception

02:13:39.540 --> 02:13:41.300
of everything going on.

02:13:41.300 --> 02:13:44.020
And to me, that just opens up the door wide open

02:13:44.020 --> 02:13:47.020
for a sort of Big Brother 1984-like scenario.

02:13:47.020 --> 02:13:49.580
And that's not a future I want to live in.

02:13:49.580 --> 02:13:51.900
Because we know we have some examples throughout history

02:13:51.900 --> 02:13:54.500
when that did not lead to a good outcome.

02:13:54.500 --> 02:13:55.980
Right.

02:13:55.980 --> 02:13:59.020
You mentioned you founded a company, Xtropic,

02:14:00.420 --> 02:14:04.060
that recently announced a 14.1 million seed round.

02:14:04.060 --> 02:14:05.700
What's the goal of the company?

02:14:05.740 --> 02:14:08.740
You're talking about a lot of interesting physics things.

02:14:08.740 --> 02:14:11.860
So what are you up to over there that you can talk about?

02:14:12.940 --> 02:14:14.180
Yeah, I mean, you know,

02:14:14.180 --> 02:14:17.500
originally we weren't gonna announce last week,

02:14:17.500 --> 02:14:20.300
but I think with the doxing and disclosure,

02:14:20.300 --> 02:14:21.780
we got our hand forced.

02:14:21.780 --> 02:14:24.860
So we had to disclose roughly what we were doing.

02:14:24.860 --> 02:14:29.860
But really Xtropic was born from my dissatisfaction

02:14:30.420 --> 02:14:31.500
and that of my colleagues

02:14:31.500 --> 02:14:35.620
with the quantum computing roadmap, right?

02:14:36.540 --> 02:14:38.900
Quantum computing was sort of the first path

02:14:38.900 --> 02:14:42.060
to physics-based computing

02:14:42.060 --> 02:14:45.300
that was trying to commercially scale.

02:14:45.300 --> 02:14:47.380
And I was working on physics-based AI

02:14:47.380 --> 02:14:49.980
that runs on these physics-based computers.

02:14:49.980 --> 02:14:52.940
But ultimately, our greatest enemy was this noise,

02:14:52.940 --> 02:14:57.060
this pervasive problem of noise that, as I mentioned,

02:14:57.060 --> 02:15:00.700
you have to constantly pump out the noise out of the system

02:15:00.700 --> 02:15:03.620
to maintain this pristine environment

02:15:03.620 --> 02:15:06.180
where quantum mechanics can take effect.

02:15:06.180 --> 02:15:08.180
And that constraint was just too much.

02:15:08.180 --> 02:15:09.780
It's too costly to do that.

02:15:11.060 --> 02:15:13.140
And so we were wondering, right,

02:15:13.140 --> 02:15:17.900
as generative AI is sort of eating the world,

02:15:17.900 --> 02:15:21.300
more and more of the world's computational workloads

02:15:21.300 --> 02:15:23.380
are focused on generative AI.

02:15:23.380 --> 02:15:26.580
How could we use physics to engineer

02:15:26.580 --> 02:15:30.780
the ultimate physical substrate for generative AI, right?

02:15:30.820 --> 02:15:35.140
From first principles of physics, of information theory,

02:15:35.140 --> 02:15:39.940
of computation, and ultimately of thermodynamics, right?

02:15:39.940 --> 02:15:42.220
And so what we're seeking to build

02:15:42.220 --> 02:15:45.220
is a physics-based computing system

02:15:45.220 --> 02:15:47.140
and physics-based AI algorithms

02:15:48.220 --> 02:15:53.220
that are inspired by out of equilibrium thermodynamics

02:15:54.020 --> 02:15:55.780
or harness it directly

02:15:56.700 --> 02:15:59.780
to do machine learning as a physical process.

02:16:01.660 --> 02:16:04.020
So what does that mean,

02:16:04.020 --> 02:16:05.460
machine learning as a physical process?

02:16:05.460 --> 02:16:07.620
Is that hardware, is it software, is it both?

02:16:07.620 --> 02:16:09.260
Is it trying to do the full stack

02:16:09.260 --> 02:16:10.660
in some kind of unique way?

02:16:10.660 --> 02:16:12.940
Yes, it is full stack.

02:16:12.940 --> 02:16:16.140
And so we're folks that have built

02:16:17.700 --> 02:16:20.020
differentiable programming

02:16:20.020 --> 02:16:21.860
into the quantum computing ecosystem

02:16:21.860 --> 02:16:23.540
with TensorFlow Quantum.

02:16:23.540 --> 02:16:25.340
One of my co-founders of TensorFlow Quantum

02:16:25.340 --> 02:16:27.060
is the CTO, Trevor McCourt.

02:16:27.980 --> 02:16:31.740
We have some of the best quantum computer architects,

02:16:31.740 --> 02:16:35.620
those that have designed IBMs and AWS's systems.

02:16:35.620 --> 02:16:37.860
They've left quantum computing

02:16:37.860 --> 02:16:40.940
to help us build what we call

02:16:40.940 --> 02:16:43.660
actually a thermodynamic computer.

02:16:43.660 --> 02:16:44.980
A thermodynamic computer.

02:16:44.980 --> 02:16:47.740
Well, actually, that's looking around TensorFlow Quantum.

02:16:47.740 --> 02:16:51.820
What lessons have you learned from TensorFlow Quantum?

02:16:51.820 --> 02:16:55.660
Maybe you can speak to what it takes

02:16:55.660 --> 02:16:57.100
to create essentially what,

02:16:57.100 --> 02:17:00.340
like a software API to a quantum computer?

02:17:01.500 --> 02:17:05.180
Right, I mean, that was a challenge to build,

02:17:05.180 --> 02:17:06.380
to invent, to build,

02:17:06.380 --> 02:17:09.260
and then to get to run on the real devices.

02:17:09.260 --> 02:17:11.060
Can you actually speak to what it is?

02:17:11.060 --> 02:17:16.060
Yeah, so TensorFlow Quantum was an attempt at,

02:17:16.700 --> 02:17:18.660
well, I mean, I guess we succeeded

02:17:18.660 --> 02:17:20.780
at combining deep learning

02:17:20.780 --> 02:17:24.220
or differentiable classical programming

02:17:24.220 --> 02:17:26.780
with quantum computing

02:17:26.780 --> 02:17:29.660
and turn quantum computing into,

02:17:30.700 --> 02:17:33.300
or have types of programs that are differentiable

02:17:33.300 --> 02:17:34.700
in quantum computing.

02:17:34.700 --> 02:17:38.740
And, you know, Andrei Karpathe

02:17:38.740 --> 02:17:41.620
calls differentiable programming software 2.0, right?

02:17:41.620 --> 02:17:45.020
It's like gradient descent is a better programmer than you.

02:17:45.020 --> 02:17:47.620
And the idea was that in the early days

02:17:47.620 --> 02:17:48.460
of quantum computing,

02:17:48.460 --> 02:17:51.180
you can only run short quantum programs.

02:17:51.220 --> 02:17:54.540
And so which quantum programs should you run?

02:17:54.540 --> 02:17:58.220
Well, just let gradient descent find those programs instead.

02:17:58.220 --> 02:18:01.180
And so we built sort of the first infrastructure

02:18:02.500 --> 02:18:05.740
to not only run differentiable quantum programs,

02:18:05.740 --> 02:18:10.740
but combine them as part of broader deep learning graphs,

02:18:12.100 --> 02:18:15.420
incorporating deep neural networks,

02:18:15.420 --> 02:18:16.860
the ones you know and love

02:18:16.860 --> 02:18:19.700
with what are called quantum neural networks.

02:18:21.580 --> 02:18:26.220
And ultimately it was a very cross-disciplinary effort.

02:18:26.220 --> 02:18:29.340
We had to invent all sorts of ways to differentiate,

02:18:29.340 --> 02:18:32.660
to back propagate through the graph, the hybrid graph.

02:18:33.940 --> 02:18:35.580
But ultimately it taught me that

02:18:36.460 --> 02:18:38.980
the way to program matter and to program physics

02:18:38.980 --> 02:18:43.620
is by differentiating through control parameters.

02:18:43.620 --> 02:18:45.140
If you have parameters

02:18:45.140 --> 02:18:47.380
that affects the physics of the system,

02:18:47.380 --> 02:18:50.860
you can, and you can evaluate some loss function,

02:18:50.900 --> 02:18:55.140
you can optimize the system to accomplish a task,

02:18:55.140 --> 02:18:57.020
whatever that task may be.

02:18:57.020 --> 02:19:02.020
And that's a very sort of universal meta framework

02:19:02.060 --> 02:19:05.540
for how to program physics-based computers.

02:19:05.540 --> 02:19:07.940
To try to parametrize everything,

02:19:07.940 --> 02:19:12.460
make those parameters differential and then optimize.

02:19:12.460 --> 02:19:13.300
Yes.

02:19:13.300 --> 02:19:17.620
Okay, so is there some more practical engineering lessons

02:19:17.620 --> 02:19:20.220
from TensorFlow Quantum?

02:19:21.060 --> 02:19:23.660
Just organizationally too, like the humans involved

02:19:23.660 --> 02:19:25.500
and how to get to a product,

02:19:25.500 --> 02:19:29.580
how to create good documentation, how to have, I don't know.

02:19:29.580 --> 02:19:31.460
All these little subtle things

02:19:31.460 --> 02:19:34.260
that people might not think about.

02:19:34.260 --> 02:19:39.260
I think like working across disciplinary boundaries

02:19:39.300 --> 02:19:40.380
is always a challenge.

02:19:40.380 --> 02:19:42.620
And you have to be extremely patient

02:19:42.620 --> 02:19:44.380
in teaching one another, right?

02:19:44.380 --> 02:19:47.740
I learned a lot of software engineering through the process.

02:19:47.740 --> 02:19:49.980
My colleagues learned a lot of quantum physics

02:19:49.980 --> 02:19:52.700
and some learned machine learning

02:19:52.700 --> 02:19:56.420
through the process of building this system.

02:19:56.420 --> 02:19:59.940
And I think if you get some smart people

02:19:59.940 --> 02:20:02.900
that are passionate and trust each other in a room

02:20:02.900 --> 02:20:06.340
and you have a small team and you teach each other

02:20:06.340 --> 02:20:08.940
your specialties, suddenly you're kind of forming

02:20:08.940 --> 02:20:12.460
this sort of model soup of expertise

02:20:12.460 --> 02:20:15.100
and something special comes out of that, right?

02:20:15.100 --> 02:20:18.780
It's like combining genes, but for your knowledge bases.

02:20:18.780 --> 02:20:21.700
And sometimes special products come out of that.

02:20:21.700 --> 02:20:24.860
And so I think like even though it's very high friction

02:20:24.860 --> 02:20:28.420
initially to work in an interdisciplinary team,

02:20:28.420 --> 02:20:31.260
I think the product at the end of the day is worth it.

02:20:31.260 --> 02:20:34.420
And so learned a lot trying to bridge the gap there.

02:20:34.420 --> 02:20:37.180
And I mean, it's still a challenge to this day.

02:20:37.180 --> 02:20:40.660
We hire folks that have an AI background,

02:20:40.660 --> 02:20:43.140
folks that have a pure physics background

02:20:43.140 --> 02:20:47.100
and somehow we have to make them talk to one another, right?

02:20:47.100 --> 02:20:50.260
Is there a magic, is there some science and art

02:20:50.260 --> 02:20:53.380
to the hiring process, to building a team

02:20:53.380 --> 02:20:55.460
that can create magic together?

02:20:56.860 --> 02:21:00.540
Yeah, it's really hard to pinpoint that,

02:21:01.380 --> 02:21:03.900
that je ne sais quoi, right?

02:21:03.900 --> 02:21:05.940
I didn't know you speak French, that's very nice.

02:21:05.940 --> 02:21:09.660
Yeah, I'm actually French Canadian, so.

02:21:09.660 --> 02:21:11.060
Oh, you are legitimately French.

02:21:11.060 --> 02:21:11.900
I am legit.

02:21:11.900 --> 02:21:15.380
I thought you were just doing that for the cred.

02:21:15.380 --> 02:21:18.460
No, no, I'm truly French Canadian from Montreal.

02:21:21.060 --> 02:21:23.860
But yeah, essentially we look for people

02:21:23.860 --> 02:21:26.220
with very high fluid intelligence

02:21:26.220 --> 02:21:27.860
that aren't over specialized

02:21:27.860 --> 02:21:29.860
because they're gonna have to get out of their comfort zone.

02:21:29.860 --> 02:21:32.380
They're gonna have to incorporate concepts

02:21:32.380 --> 02:21:34.140
that they've never seen before

02:21:34.140 --> 02:21:36.740
and very quickly get comfortable with them, right?

02:21:36.740 --> 02:21:38.220
Or learn to work in a team.

02:21:38.220 --> 02:21:42.140
And so that's sort of what we look for when we hire.

02:21:42.140 --> 02:21:46.660
We can't hire people that are just optimizing

02:21:46.660 --> 02:21:50.100
this subsystem for the past three or four years.

02:21:50.100 --> 02:21:52.140
We need really general,

02:21:52.140 --> 02:21:55.820
sort of broader intelligence and specialty

02:21:55.820 --> 02:21:59.060
and people that are open-minded, really,

02:21:59.060 --> 02:22:02.340
because if you're pioneering a new approach from scratch,

02:22:02.340 --> 02:22:04.820
there is no textbook, there's no reference,

02:22:04.820 --> 02:22:08.820
it's just us and people that are hungry to learn.

02:22:08.820 --> 02:22:10.160
So we have to teach each other,

02:22:10.160 --> 02:22:11.740
we have to learn the literature,

02:22:12.340 --> 02:22:14.660
we have to share knowledge bases, collaborate

02:22:14.660 --> 02:22:18.020
in order to push the boundary of knowledge further together.

02:22:19.100 --> 02:22:23.060
And so people that are used to just getting prescribed

02:22:23.060 --> 02:22:28.060
what to do at this stage when you're at the pioneering stage,

02:22:28.300 --> 02:22:31.540
that's not necessarily who you want to hire.

02:22:31.540 --> 02:22:33.020
So you mentioned with Extropic,

02:22:33.020 --> 02:22:34.660
you're trying to build the physical substrate

02:22:34.660 --> 02:22:36.340
for generative AI.

02:22:37.340 --> 02:22:42.340
What's the difference between that and the AGI AI itself?

02:22:42.580 --> 02:22:47.020
So is it possible that in the halls of your company,

02:22:47.020 --> 02:22:48.740
AGI will be created,

02:22:48.740 --> 02:22:51.900
or will AGI just be using this as a substrate?

02:22:51.900 --> 02:22:56.900
I think our goal is to both run human-like AI

02:22:56.940 --> 02:22:58.300
or anthropomorphic AI.

02:22:58.300 --> 02:23:00.580
Sorry for the use of the term AGI.

02:23:00.580 --> 02:23:02.020
I know it's triggering for you.

02:23:02.020 --> 02:23:05.780
We think that the future is actually physics-based AI

02:23:06.860 --> 02:23:10.660
combined with anthropomorphic AI.

02:23:10.660 --> 02:23:15.500
So you can imagine I have a sort of world modeling engine

02:23:15.500 --> 02:23:17.100
through physics-based AI.

02:23:17.100 --> 02:23:19.460
Physics-based AI is better at representing the world

02:23:19.460 --> 02:23:22.100
at all scales, because it can be quantum mechanical,

02:23:22.100 --> 02:23:24.700
thermodynamic, deterministic,

02:23:24.700 --> 02:23:26.760
hybrid representations of the world,

02:23:26.760 --> 02:23:29.620
just like our world at different scales

02:23:29.620 --> 02:23:31.700
has different regimes of physics.

02:23:31.700 --> 02:23:33.980
If you inspire yourself from that

02:23:33.980 --> 02:23:35.780
in the ways you learn representations of nature,

02:23:35.780 --> 02:23:38.180
you can have much more accurate representations of nature.

02:23:38.180 --> 02:23:43.180
So you can have very accurate world models at all scales.

02:23:43.340 --> 02:23:45.700
And so you have the world modeling engine,

02:23:45.700 --> 02:23:48.700
and then you have the sort of anthropomorphic AI

02:23:48.700 --> 02:23:50.100
that is human-like.

02:23:50.100 --> 02:23:52.020
So you can have the science,

02:23:52.020 --> 02:23:54.940
the playground to test your ideas,

02:23:54.940 --> 02:23:57.060
and you can have a synthetic scientist.

02:23:57.060 --> 02:24:00.380
And to us, that joint system of a physics-based AI

02:24:00.380 --> 02:24:03.920
and an anthropomorphic AI is the closest thing

02:24:03.920 --> 02:24:07.620
to a fully general artificially intelligent system.

02:24:07.620 --> 02:24:09.220
So you can get closer to truth

02:24:09.220 --> 02:24:13.900
by grounding the AI to physics,

02:24:13.900 --> 02:24:17.220
but you can also still have a anthropomorphic interface

02:24:17.220 --> 02:24:19.860
to us humans that like to talk to other humans

02:24:19.860 --> 02:24:21.540
or human-like systems.

02:24:21.540 --> 02:24:24.040
So on that topic, what do you,

02:24:25.140 --> 02:24:28.760
I suppose that is one of the big limitations

02:24:28.760 --> 02:24:30.840
of current large-language models to you

02:24:30.840 --> 02:24:34.120
is that they're not, they're good bullshitters.

02:24:34.980 --> 02:24:37.760
They're not really grounded to truth necessarily.

02:24:39.160 --> 02:24:40.720
Would that be fair to say?

02:24:40.720 --> 02:24:45.640
Yeah, no, you wouldn't try to extrapolate the stock market

02:24:45.640 --> 02:24:49.060
with an LM trained on text from the internet, right?

02:24:49.060 --> 02:24:50.640
It's not gonna be a very accurate model.

02:24:50.640 --> 02:24:53.480
It's not gonna model its priors or its uncertainties

02:24:53.480 --> 02:24:55.840
about the world very accurately, right?

02:24:55.960 --> 02:25:00.000
So you need a different type of AI to complement

02:25:00.000 --> 02:25:05.000
sort of this text extrapolation AI, yeah.

02:25:05.080 --> 02:25:07.480
You mentioned singularity earlier.

02:25:07.480 --> 02:25:09.960
How far away are we from a singularity?

02:25:09.960 --> 02:25:12.980
I don't know if I believe in a finite time singularity

02:25:12.980 --> 02:25:14.240
as a single point in time.

02:25:14.240 --> 02:25:16.800
I think it's gonna be asymptotic

02:25:16.800 --> 02:25:20.320
and sort of a diagonal sort of asymptote.

02:25:20.320 --> 02:25:23.480
Like, you know, we have the light cone,

02:25:23.480 --> 02:25:25.840
we have the limits of physics

02:25:25.840 --> 02:25:27.780
restricting our ability to grow.

02:25:27.780 --> 02:25:31.880
So obviously can't fully diverge on a finite time.

02:25:33.600 --> 02:25:36.200
I think my priors are that, you know,

02:25:36.200 --> 02:25:40.840
I think a lot of people on the other side of the aisle

02:25:42.040 --> 02:25:44.720
think that once we reach human level AI,

02:25:44.720 --> 02:25:47.600
there's gonna be an inflection point and a sudden like fume,

02:25:47.600 --> 02:25:51.520
like suddenly AI is gonna grok how to, you know,

02:25:51.520 --> 02:25:55.120
manipulate matter at the nanoscale and assemble nanobots.

02:25:55.120 --> 02:25:59.200
And having worked, you know, for nearly a decade

02:25:59.200 --> 02:26:01.280
in applying AI to engineer matter,

02:26:01.280 --> 02:26:03.000
it's much harder than they think.

02:26:03.000 --> 02:26:04.760
And in reality, you need a lot of samples

02:26:04.760 --> 02:26:06.960
from either a simulation of nature

02:26:06.960 --> 02:26:10.120
that's very accurate and costly or nature itself.

02:26:10.120 --> 02:26:13.480
And that keeps your ability to control the world

02:26:13.480 --> 02:26:15.620
around us in check.

02:26:15.620 --> 02:26:19.840
There's a sort of minimal cost computationally

02:26:19.840 --> 02:26:22.480
and thermodynamically to acquiring information

02:26:22.480 --> 02:26:24.280
about the world in order to be able to predict

02:26:24.280 --> 02:26:25.600
and control it.

02:26:25.600 --> 02:26:27.480
And that keeps things in check.

02:26:27.480 --> 02:26:30.020
It's funny you mentioned the other side of the aisle.

02:26:30.020 --> 02:26:33.680
So in the poll I posted about P-Doom yesterday,

02:26:33.680 --> 02:26:35.520
what's the probability of doom?

02:26:35.520 --> 02:26:37.880
There seems to be a nice like division

02:26:38.840 --> 02:26:42.240
between people think it's very likely and very unlikely.

02:26:43.240 --> 02:26:46.000
I wonder if in the future they'll be the actual

02:26:46.000 --> 02:26:49.360
Republicans versus Democrats division, blue versus red.

02:26:49.400 --> 02:26:53.320
Is the EI Doomers versus the EACers, EAC.

02:26:53.320 --> 02:26:56.080
Yeah, so this movement, you know,

02:26:56.080 --> 02:26:58.640
is not right-wing or left-wing fundamentally.

02:26:58.640 --> 02:27:01.440
It's more like up versus down in terms of the scale.

02:27:01.440 --> 02:27:02.280
Which one is the up, okay.

02:27:02.280 --> 02:27:03.720
Civilization, right?

02:27:03.720 --> 02:27:05.280
All right.

02:27:05.280 --> 02:27:09.800
But it seems to be like there is a sort of case

02:27:09.800 --> 02:27:12.260
of alignment of the existing political parties

02:27:12.260 --> 02:27:17.260
where those that are for more centralization of power,

02:27:17.500 --> 02:27:22.500
control and more regulations are aligning themselves

02:27:22.760 --> 02:27:27.540
with the Doomers because that sort of instilling fear

02:27:27.540 --> 02:27:31.220
in people is a great way for them to give up more control

02:27:31.220 --> 02:27:33.000
and give the government more power.

02:27:33.000 --> 02:27:36.220
But fundamentally we're not left versus right.

02:27:36.220 --> 02:27:40.260
I think we've done polls of people's alignment

02:27:40.260 --> 02:27:41.100
with any EAC.

02:27:41.100 --> 02:27:42.580
I think it's pretty balanced.

02:27:42.580 --> 02:27:45.760
So it's a new fundamental issue of our time.

02:27:45.760 --> 02:27:48.200
It's not just centralization versus decentralization.

02:27:48.200 --> 02:27:51.640
It's kind of do we go, it's like tech progressivism

02:27:51.640 --> 02:27:54.060
versus techno-conservativism, right?

02:27:54.960 --> 02:27:57.960
So EAC as a movement is often formulated

02:27:57.960 --> 02:28:02.400
in contrast to EA, effective altruism.

02:28:03.840 --> 02:28:05.880
What do you think are the pros and cons

02:28:05.880 --> 02:28:07.520
of effective altruism?

02:28:07.520 --> 02:28:10.340
What's interesting, insightful to you about them

02:28:10.340 --> 02:28:14.560
and what is negative?

02:28:15.440 --> 02:28:20.080
Right, I think like people trying to do good

02:28:20.080 --> 02:28:23.080
from first principles is good.

02:28:23.080 --> 02:28:25.560
We should actually say, and sorry to interrupt,

02:28:25.560 --> 02:28:26.960
we should probably say that,

02:28:26.960 --> 02:28:29.080
and you can correct me if I'm wrong,

02:28:29.080 --> 02:28:33.400
but effective altruism is the kind of movement

02:28:33.400 --> 02:28:35.820
that's trying to do good optimally

02:28:35.820 --> 02:28:38.760
where good is probably measured something like

02:28:38.760 --> 02:28:40.600
the amount of suffering in the world.

02:28:40.600 --> 02:28:41.760
You wanna minimize it.

02:28:42.720 --> 02:28:46.800
And there's ways that that can go wrong

02:28:46.800 --> 02:28:48.520
as any optimization can.

02:28:48.520 --> 02:28:50.320
And so it's interesting to explore

02:28:52.880 --> 02:28:55.800
like how things can go wrong.

02:28:55.800 --> 02:28:57.880
We're both trying to do good to some extent,

02:28:57.880 --> 02:29:01.480
and we're both trying, we're arguing

02:29:01.480 --> 02:29:04.440
for which loss function we should use, right?

02:29:04.440 --> 02:29:07.720
Their loss function is sort of hedons, right?

02:29:07.760 --> 02:29:12.360
Units of hedonism, like how good do you feel

02:29:12.360 --> 02:29:14.540
and for how much time, right?

02:29:14.540 --> 02:29:17.760
And so suffering would be negative hedons,

02:29:17.760 --> 02:29:19.880
and they're trying to minimize that.

02:29:19.880 --> 02:29:23.720
But to us, that seems like that loss function

02:29:23.720 --> 02:29:25.440
has sort of spurious minima, right?

02:29:25.440 --> 02:29:30.440
You can start minimizing shrimp farm pain, right?

02:29:31.440 --> 02:29:34.680
Which seems not that productive to me.

02:29:35.240 --> 02:29:38.680
Or you can end up with wireheading

02:29:38.680 --> 02:29:41.320
where you just either install a Neuralink

02:29:41.320 --> 02:29:43.360
or you scroll TikTok forever,

02:29:43.360 --> 02:29:46.240
and you feel good on the short-term time scale

02:29:46.240 --> 02:29:48.120
because you're in neurochemistry,

02:29:48.120 --> 02:29:49.480
but on long-term time scale,

02:29:49.480 --> 02:29:52.160
it causes decay and death, right?

02:29:52.160 --> 02:29:54.040
Because you're not being productive.

02:29:54.040 --> 02:29:59.040
Whereas sort of EAC measuring progress of civilization,

02:29:59.200 --> 02:30:01.600
not in terms of a subjective loss function

02:30:01.600 --> 02:30:06.600
like hedonism, but rather an objective measure,

02:30:08.240 --> 02:30:11.920
quantity that cannot be gained that is physical energy,

02:30:11.920 --> 02:30:14.160
right, it's very objective, right?

02:30:14.160 --> 02:30:16.880
And there's not many ways to gain it, right?

02:30:16.880 --> 02:30:20.560
If you did it in terms of like GDP or a currency,

02:30:20.560 --> 02:30:23.200
that's pinned to a certain value that's moving, right?

02:30:23.200 --> 02:30:26.880
And so that's not a good way to measure our progress.

02:30:26.880 --> 02:30:31.880
And so, but the thing is we're both trying to make progress

02:30:31.920 --> 02:30:35.760
and ensure humanity flourishes and gets to grow.

02:30:35.760 --> 02:30:38.280
We just have different loss functions

02:30:38.280 --> 02:30:41.280
and different ways of going about doing it.

02:30:42.200 --> 02:30:45.400
Is there a degree maybe you can educate me, correct me?

02:30:46.360 --> 02:30:48.480
I get a little bit skeptical

02:30:48.480 --> 02:30:50.040
when there's an equation involved,

02:30:50.040 --> 02:30:53.080
trying to reduce all of the human civilization,

02:30:54.120 --> 02:30:55.840
human experience to an equation.

02:30:57.880 --> 02:31:00.280
Is there a degree that we should be skeptical

02:31:00.280 --> 02:31:02.800
of the tyranny of an equation,

02:31:02.800 --> 02:31:05.920
of a loss function over which to optimize,

02:31:05.920 --> 02:31:07.920
like having a kind of intellectual humility

02:31:07.920 --> 02:31:11.760
about optimizing over loss functions?

02:31:11.760 --> 02:31:14.400
Yeah, so this particular loss function,

02:31:14.400 --> 02:31:18.280
it's not stiff, it's kind of an average of averages, right?

02:31:18.280 --> 02:31:22.720
It's like distributions of states in the future

02:31:22.720 --> 02:31:25.560
are gonna follow a certain distribution.

02:31:25.920 --> 02:31:28.800
So it's not deterministic.

02:31:28.800 --> 02:31:31.800
It's not like, we're not on like stiff rails, right?

02:31:31.800 --> 02:31:36.800
It's just a statistical statement about the future.

02:31:36.920 --> 02:31:38.040
But at the end of the day,

02:31:38.040 --> 02:31:41.400
you can believe in gravity or not,

02:31:41.400 --> 02:31:44.640
but it's not necessarily an option to obey it, right?

02:31:44.640 --> 02:31:47.960
And some people try to test that and that goes not so well.

02:31:47.960 --> 02:31:51.680
So similarly, I think thermodynamics

02:31:51.680 --> 02:31:53.040
is there whether we like it or not.

02:31:53.040 --> 02:31:55.440
And we're just trying to point out

02:31:56.320 --> 02:31:59.400
what is and try to orient ourselves

02:31:59.400 --> 02:32:04.400
and chart a path forward given this fundamental truth.

02:32:04.480 --> 02:32:05.800
But there's still some uncertainty.

02:32:05.800 --> 02:32:08.360
There's still a lack of information.

02:32:08.360 --> 02:32:10.440
Humans tend to fill the gap

02:32:10.440 --> 02:32:13.760
with the lack of information with narratives.

02:32:13.760 --> 02:32:15.200
And so how they interpret,

02:32:17.720 --> 02:32:19.840
even physics is up to interpretation

02:32:19.840 --> 02:32:21.480
when there's uncertainty involved.

02:32:22.480 --> 02:32:27.480
And humans tend to use that to further their own means.

02:32:28.760 --> 02:32:31.080
So it's always, whenever there's an equation,

02:32:31.080 --> 02:32:34.880
it just seems like until we have really perfect understanding

02:32:34.880 --> 02:32:38.920
of the universe, humans will do what humans do.

02:32:38.920 --> 02:32:43.920
And they try to use the narrative of doing good

02:32:47.320 --> 02:32:51.360
to fool the populace into doing bad.

02:32:52.200 --> 02:32:54.000
I guess that this is something

02:32:54.000 --> 02:32:57.960
that should be skeptical about in all movements.

02:32:57.960 --> 02:32:58.800
That's right.

02:32:59.800 --> 02:33:01.840
So we invite skepticism, right?

02:33:02.920 --> 02:33:05.600
Do you have an understanding of what might,

02:33:05.600 --> 02:33:07.280
to a degree that went wrong,

02:33:07.280 --> 02:33:08.840
what do you think may have gone wrong

02:33:08.840 --> 02:33:12.920
with effective altruism that might also go wrong

02:33:12.920 --> 02:33:14.720
with effective accelerationism?

02:33:15.920 --> 02:33:20.680
Yeah, I mean, I think it provided initially

02:33:20.680 --> 02:33:24.240
a sense of community for engineers and intellectuals

02:33:24.240 --> 02:33:25.840
and rationalists in the early days.

02:33:25.840 --> 02:33:28.800
And it seems like the community was very healthy,

02:33:28.800 --> 02:33:32.000
but then they formed all sorts of organizations

02:33:32.000 --> 02:33:37.000
and started routing capital and having actual power, right?

02:33:37.080 --> 02:33:39.120
They have real power.

02:33:39.120 --> 02:33:40.320
They influenced the government,

02:33:40.320 --> 02:33:43.160
they influenced most AI orgs now.

02:33:43.160 --> 02:33:44.880
I mean, they're literally controlling the board

02:33:44.880 --> 02:33:46.080
of OpenAI, right?

02:33:46.080 --> 02:33:48.840
And look over to Anthropic.

02:33:48.840 --> 02:33:51.280
I think they'll have some control over that too.

02:33:51.280 --> 02:33:53.960
And so I think, you know,

02:33:53.960 --> 02:33:56.480
the assumption of EAC is more like capitalism

02:33:56.480 --> 02:33:59.800
is that every agent, organism and meta organism

02:33:59.800 --> 02:34:02.000
is gonna act in its own interests

02:34:02.000 --> 02:34:05.360
and we should maintain sort of adversarial equilibrium

02:34:05.360 --> 02:34:08.480
or adversarial competition to keep each other in check

02:34:08.480 --> 02:34:09.960
at all times, at all scales.

02:34:11.640 --> 02:34:15.520
I think that, yeah, ultimately it was the perfect cover

02:34:15.520 --> 02:34:18.280
to acquire tons of power and capital

02:34:18.280 --> 02:34:23.280
and unfortunately sometimes that corrupts people over time.

02:34:23.520 --> 02:34:26.480
What does a perfectly productive day,

02:34:26.480 --> 02:34:28.600
since building is important,

02:34:28.600 --> 02:34:30.280
what does a perfectly productive day

02:34:30.280 --> 02:34:33.160
in the life of Guillaume Verdun look like?

02:34:34.400 --> 02:34:36.880
How much caffeine do you consume?

02:34:36.880 --> 02:34:38.600
Like what's a perfect day?

02:34:39.480 --> 02:34:42.880
Okay, so I have a particular regimen.

02:34:42.880 --> 02:34:47.880
I would say my favorite days are 12 p.m. to 4 a.m.

02:34:49.120 --> 02:34:53.400
and I would have meetings in the early afternoon,

02:34:53.400 --> 02:34:56.520
usually external meetings, some internal meetings

02:34:56.520 --> 02:34:59.000
because I'm CEO, I have to interface

02:34:59.000 --> 02:34:59.840
with the outside world,

02:34:59.840 --> 02:35:01.520
whether it's customers or investors

02:35:01.520 --> 02:35:04.480
or renewing potential candidates.

02:35:06.480 --> 02:35:11.480
And usually I'll have ketones, exogenous ketones.

02:35:12.920 --> 02:35:16.560
So are you on a keto diet or is this?

02:35:16.560 --> 02:35:21.240
I've done keto before for football and whatnot,

02:35:21.240 --> 02:35:26.240
but I like to have a meal after part of my day is done

02:35:28.320 --> 02:35:31.040
and so I can just have extreme focus.

02:35:31.040 --> 02:35:35.000
You do the social interactions earlier in the day

02:35:35.000 --> 02:35:35.840
without food.

02:35:35.840 --> 02:35:38.680
Front load them, yeah, like right now I'm on ketones

02:35:38.680 --> 02:35:43.680
and Red Bull and it just gives you a clarity of thought

02:35:44.120 --> 02:35:45.720
that is really next level

02:35:45.720 --> 02:35:46.680
because then when you eat,

02:35:46.680 --> 02:35:48.560
you're actually allocating some of your energy

02:35:48.560 --> 02:35:53.000
that could be going to neural energy to your digestion.

02:35:53.000 --> 02:35:56.680
After I eat, maybe I take a break an hour or so,

02:35:56.680 --> 02:36:00.960
hour and a half and then usually it's like,

02:36:00.960 --> 02:36:05.480
ideally one meal a day like steak and eggs and vegetables,

02:36:05.480 --> 02:36:08.640
animal based primarily, so fruit and meat.

02:36:08.640 --> 02:36:12.440
And then I do a second wind usually, that's deep work.

02:36:12.640 --> 02:36:16.360
Right, because I am a CEO, but I'm still technical.

02:36:16.360 --> 02:36:18.080
I'm contributing to most patents

02:36:18.080 --> 02:36:22.320
and there I'll just stay up late into the night

02:36:22.320 --> 02:36:25.720
and work with engineers on very technical problems.

02:36:25.720 --> 02:36:29.480
So it's like the 9 p.m. to 4 a.m. whatever,

02:36:29.480 --> 02:36:30.600
that range of time.

02:36:30.600 --> 02:36:32.960
Yeah, yeah, that's the perfect time.

02:36:32.960 --> 02:36:37.440
The emails, the things that are on fire stop trickling in,

02:36:37.440 --> 02:36:39.840
you can focus and then you have your second wind

02:36:40.800 --> 02:36:45.800
and I think Demis Asabas has a similar workday

02:36:45.920 --> 02:36:47.200
to some extent.

02:36:47.200 --> 02:36:49.760
So I think that's definitely inspired my workday.

02:36:50.880 --> 02:36:54.480
But yeah, I started this workday when I was at Google

02:36:54.480 --> 02:36:57.360
and had to manage a bit of the product during the day

02:36:57.360 --> 02:37:00.320
and have meetings and then do technical work at night.

02:37:00.320 --> 02:37:03.880
Exercise, sleep, those kinds of things.

02:37:03.880 --> 02:37:05.920
Said football, you used to play football?

02:37:05.920 --> 02:37:08.720
Yeah, I used to play American football.

02:37:08.760 --> 02:37:10.600
I've done all sorts of sports growing up

02:37:10.600 --> 02:37:13.960
and then I was into powerlifting for a while.

02:37:13.960 --> 02:37:17.240
So when I was studying mathematics in grad school,

02:37:17.240 --> 02:37:21.120
I would just do math and lift, take caffeine

02:37:21.120 --> 02:37:22.440
and that was my day.

02:37:22.440 --> 02:37:25.760
It was very pure, the purest of monk modes.

02:37:25.760 --> 02:37:28.440
But it's really interesting how in powerlifting

02:37:28.440 --> 02:37:30.320
you're trying to cause neural adaptation

02:37:30.320 --> 02:37:32.760
by having certain driving signals

02:37:32.760 --> 02:37:35.040
and you're trying to engineer a neuroplasticity

02:37:35.040 --> 02:37:36.800
through all sorts of supplements

02:37:37.600 --> 02:37:41.960
and you have all sorts of brain-derived neurotrophic factors

02:37:41.960 --> 02:37:44.040
that get secreted when you lift.

02:37:44.040 --> 02:37:47.080
So it's funny to me how I was trying to engineer

02:37:49.240 --> 02:37:53.360
neural adaptation in my nervous system more broadly,

02:37:53.360 --> 02:37:56.360
not just my brain while learning mathematics.

02:37:56.360 --> 02:37:59.240
I think you can learn much faster

02:38:00.920 --> 02:38:04.600
if you really care, if you convince yourself to care a lot

02:38:04.600 --> 02:38:06.120
about what you're learning

02:38:06.120 --> 02:38:10.200
and you have some sort of assistance, let's say caffeine

02:38:10.200 --> 02:38:13.840
or some cholinergic supplement to increase neuroplasticity.

02:38:13.840 --> 02:38:16.520
I should chat with Andrew Huberman at some point.

02:38:16.520 --> 02:38:20.480
He's the expert, but yeah, at least to me,

02:38:20.480 --> 02:38:24.360
it's like, you can try to input more tokens

02:38:24.360 --> 02:38:25.800
into your brain, if you will,

02:38:25.800 --> 02:38:27.520
and you can try to increase the learning rate

02:38:27.520 --> 02:38:30.800
so that you can learn much faster on a shorter time scale.

02:38:30.800 --> 02:38:33.520
So I've learned a lot of things.

02:38:33.520 --> 02:38:34.840
I followed my curiosity.

02:38:34.840 --> 02:38:36.800
You're naturally, if you're passionate

02:38:36.800 --> 02:38:38.520
about what you're doing, you're gonna learn faster,

02:38:38.520 --> 02:38:40.320
you're gonna become smarter faster.

02:38:41.200 --> 02:38:42.520
And if you follow your curiosity,

02:38:42.520 --> 02:38:44.440
you're always gonna be interested.

02:38:44.440 --> 02:38:47.200
And so I advise people to follow their curiosity

02:38:47.200 --> 02:38:50.320
and don't respect the boundaries of certain fields

02:38:50.320 --> 02:38:52.600
or what you've been allocated in terms of lane

02:38:52.600 --> 02:38:54.160
of what you're working on.

02:38:54.160 --> 02:38:57.320
Just go out and explore and follow your nose

02:38:57.320 --> 02:39:01.400
and try to acquire and compress as much information

02:39:01.400 --> 02:39:02.960
as you can into your brain,

02:39:03.000 --> 02:39:05.000
anything that you find interesting.

02:39:05.000 --> 02:39:06.200
And caring about a thing,

02:39:06.200 --> 02:39:08.280
and like you said, which is interesting,

02:39:08.280 --> 02:39:09.880
it works for me really well.

02:39:09.880 --> 02:39:12.080
It's like tricking yourself that you care about a thing.

02:39:12.080 --> 02:39:13.400
Yes.

02:39:13.400 --> 02:39:15.840
And then you start to really care about it.

02:39:15.840 --> 02:39:18.560
So it's funny, the motivation

02:39:19.400 --> 02:39:22.160
is a really good catalyst for learning.

02:39:22.160 --> 02:39:27.160
Right, and so at least part of my character,

02:39:27.160 --> 02:39:29.120
as Beth Jezos, is kind of like-

02:39:29.120 --> 02:39:30.520
Yeah, the hype man.

02:39:30.520 --> 02:39:32.800
Yeah, just hype, but I'm like hyping myself up,

02:39:32.800 --> 02:39:34.360
but then I just tweet about it.

02:39:34.360 --> 02:39:36.600
And it's just when I'm trying to get really hyped up

02:39:36.600 --> 02:39:38.680
and like an altered state of consciousness

02:39:38.680 --> 02:39:42.120
where I'm like ultra focused in the flow, wired,

02:39:42.120 --> 02:39:44.040
trying to invent something that's never existed,

02:39:44.040 --> 02:39:47.840
I need to get to like unreal levels of like excitement.

02:39:47.840 --> 02:39:52.320
But your brain has these levels of cognition

02:39:52.320 --> 02:39:55.320
that you can unlock with like higher levels of adrenaline

02:39:55.320 --> 02:39:56.720
and whatnot.

02:39:56.720 --> 02:39:59.480
And I mean, I've learned that in powerlifting

02:39:59.480 --> 02:40:03.360
that actually you can engineer a mental switch

02:40:03.360 --> 02:40:05.760
to like increase your strength, right?

02:40:05.760 --> 02:40:07.920
Like if you can engineer a switch,

02:40:07.920 --> 02:40:10.640
maybe you have a prompt like a certain song or some music

02:40:10.640 --> 02:40:13.680
where suddenly you're like fully primed,

02:40:13.680 --> 02:40:16.520
then you're at maximum strength, right?

02:40:16.520 --> 02:40:20.640
And I've engineered that switch through years of lifting.

02:40:20.640 --> 02:40:23.960
If you're gonna get under 500 pounds and it could crush you,

02:40:23.960 --> 02:40:28.560
if you don't have that switch to be wired in, you might die.

02:40:28.640 --> 02:40:30.200
So that'll wake you right up.

02:40:30.200 --> 02:40:34.480
And that sort of skill I've carried over to like research

02:40:34.480 --> 02:40:37.280
when it's go time, when the stakes are high,

02:40:37.280 --> 02:40:40.360
somehow I just reach another level of neural performance.

02:40:40.360 --> 02:40:44.680
So Beth Jeyzos is your sort of embodiment representation

02:40:44.680 --> 02:40:46.480
of your intellectual Hulk.

02:40:47.640 --> 02:40:50.880
It's your productivity Hulk that you just turn on.

02:40:50.880 --> 02:40:54.120
What have you learned about the nature of identity

02:40:54.120 --> 02:40:56.600
from having these two identities?

02:40:56.600 --> 02:40:58.160
I think it's interesting for people

02:40:58.680 --> 02:41:01.280
to be able to put on those two hats so explicitly.

02:41:01.280 --> 02:41:03.200
I think it was interesting in the early days.

02:41:03.200 --> 02:41:04.440
I think in the early days,

02:41:04.440 --> 02:41:06.520
I thought it was truly compartmentalized.

02:41:06.520 --> 02:41:09.560
Like, oh yeah, this is a character, I'm Guillaume,

02:41:09.560 --> 02:41:11.320
Beth is just the character.

02:41:11.320 --> 02:41:14.360
I like take my thoughts and then I extrapolate them

02:41:14.360 --> 02:41:16.120
to a bit more extreme.

02:41:16.120 --> 02:41:20.560
But over time, it's kind of like both identities

02:41:20.560 --> 02:41:22.760
were starting to merge mentally and people were like,

02:41:22.760 --> 02:41:24.840
no, you are, I met you, you are Beth,

02:41:24.840 --> 02:41:27.200
you are not just Guillaume.

02:41:27.240 --> 02:41:28.720
And I was like, wait, am I?

02:41:28.720 --> 02:41:31.680
And now it's like fully merged,

02:41:31.680 --> 02:41:34.520
but it was already before the docs was already starting

02:41:34.520 --> 02:41:39.440
mentally that I am this character, it's part of me.

02:41:39.440 --> 02:41:42.280
Would you recommend people sort of have an alt?

02:41:42.280 --> 02:41:43.800
Absolutely.

02:41:43.800 --> 02:41:45.520
Like young people, would you recommend them

02:41:45.520 --> 02:41:49.400
to explore different identities by having alt accounts?

02:41:49.400 --> 02:41:51.840
It's fun, it's like writing an essay

02:41:51.840 --> 02:41:53.040
and taking a position, right?

02:41:53.040 --> 02:41:54.400
It's like you do this in debate,

02:41:54.400 --> 02:41:56.960
it's like you can have experimental thoughts

02:41:57.720 --> 02:42:00.480
and by having, by the stakes being so low

02:42:00.480 --> 02:42:02.240
because you're an account with, I don't know,

02:42:02.240 --> 02:42:04.080
20 followers or something,

02:42:04.080 --> 02:42:05.560
you can experiment with your thoughts

02:42:05.560 --> 02:42:07.600
in a low stakes environment.

02:42:07.600 --> 02:42:10.000
And I feel like we've lost that in the era

02:42:10.000 --> 02:42:12.480
of everything being under your main name,

02:42:12.480 --> 02:42:14.080
everything being attributable to you.

02:42:14.080 --> 02:42:15.640
People just are afraid to speak,

02:42:15.640 --> 02:42:19.640
explore ideas that aren't fully formed, right?

02:42:19.640 --> 02:42:21.680
And I feel like we've lost something there.

02:42:21.680 --> 02:42:25.160
So I hope platforms like Axe and others

02:42:25.160 --> 02:42:27.480
like really help support people

02:42:27.480 --> 02:42:30.080
trying to stay pseudonymous or anonymous

02:42:30.080 --> 02:42:32.880
because it's really important for people

02:42:32.880 --> 02:42:36.120
to share thoughts that aren't fully formed

02:42:36.120 --> 02:42:38.400
and converge onto maybe hidden truths

02:42:38.400 --> 02:42:41.360
that were hard to converge upon

02:42:41.360 --> 02:42:46.360
if it was just through open conversation with real names.

02:42:46.600 --> 02:42:49.760
Yeah, I really believe in like not radical

02:42:49.760 --> 02:42:52.360
but rigorous empathy.

02:42:52.360 --> 02:42:54.440
Like really considering what it's like

02:42:54.440 --> 02:42:57.520
to be a person of a certain viewpoint

02:42:57.520 --> 02:43:00.120
and like taking that as a thought experiment

02:43:00.120 --> 02:43:01.880
farther and farther and farther.

02:43:01.880 --> 02:43:04.040
And one way of doing that is an alt account.

02:43:06.040 --> 02:43:10.200
That's a fun, interesting way to really explore

02:43:10.200 --> 02:43:11.920
what it's like to be a person that believes

02:43:11.920 --> 02:43:13.680
a set of beliefs.

02:43:13.680 --> 02:43:17.600
And taking that across the span of several days,

02:43:17.600 --> 02:43:21.080
weeks, months, of course, there's always the danger

02:43:21.080 --> 02:43:22.040
of becoming that.

02:43:22.960 --> 02:43:26.720
That's the Nietzsche gaze long into the abyss.

02:43:27.920 --> 02:43:30.160
The abyss gazes into you.

02:43:30.160 --> 02:43:31.880
You have to be careful.

02:43:31.880 --> 02:43:33.320
Breaking Beth.

02:43:33.320 --> 02:43:35.000
Yeah, right, breaking Beth.

02:43:35.000 --> 02:43:37.440
Yeah, you wake up with a shaved head one day

02:43:37.440 --> 02:43:39.320
just like, who am I?

02:43:39.320 --> 02:43:40.520
What have I become?

02:43:41.600 --> 02:43:44.560
So you've mentioned quite a bit of advice already

02:43:44.560 --> 02:43:46.960
but what advice would you give to young people

02:43:47.800 --> 02:43:52.800
of how to, in this interesting world we're in,

02:43:53.000 --> 02:43:56.000
how to have a career and how to have a life

02:43:56.000 --> 02:43:57.120
they can be proud of?

02:43:58.680 --> 02:44:01.960
I think to me the reason I went to theoretical physics

02:44:01.960 --> 02:44:05.400
was that I had to learn the base of the stack

02:44:05.400 --> 02:44:08.240
that was gonna stick around no matter

02:44:08.240 --> 02:44:10.240
how the technology changes, right?

02:44:11.320 --> 02:44:14.040
And to me that was the foundation upon which

02:44:14.040 --> 02:44:18.320
then I later built engineering skills and other skills.

02:44:18.320 --> 02:44:20.040
And to me the laws of physics,

02:44:20.040 --> 02:44:21.920
it may seem like the landscape right now

02:44:21.920 --> 02:44:24.560
is changing so fast it's disorienting,

02:44:24.560 --> 02:44:26.680
but certain things like fundamental mathematics

02:44:26.680 --> 02:44:28.840
and physics aren't gonna change.

02:44:28.840 --> 02:44:30.600
And if you have that knowledge

02:44:31.600 --> 02:44:35.040
and knowledge about complex systems and adaptive systems,

02:44:35.040 --> 02:44:37.640
I think that's gonna carry you very far.

02:44:37.640 --> 02:44:40.600
And so not everybody has to study mathematics

02:44:40.600 --> 02:44:44.520
but I think it's really a huge cognitive unlock

02:44:44.520 --> 02:44:48.480
to learn math and some physics and engineering.

02:44:48.480 --> 02:44:51.400
Get as close to the base of the stack as possible.

02:44:51.400 --> 02:44:52.240
Yeah, that's right,

02:44:52.240 --> 02:44:54.320
because the base of the stack doesn't change,

02:44:54.320 --> 02:44:56.760
everything else, your knowledge might become

02:44:56.760 --> 02:44:58.160
not as relevant in a few years.

02:44:58.160 --> 02:45:00.360
Of course there's a sort of transfer learning you can do

02:45:00.360 --> 02:45:04.440
but then you have to always transfer learn constantly.

02:45:04.440 --> 02:45:06.320
I guess the closer you are to the base of the stack,

02:45:06.320 --> 02:45:10.400
the easier the transfer learning, the shorter the jump.

02:45:10.400 --> 02:45:12.120
Right, right.

02:45:12.120 --> 02:45:15.880
And you'd be surprised like once you've learned concepts

02:45:15.880 --> 02:45:18.480
in many physical scenarios,

02:45:18.480 --> 02:45:21.920
how they can carry over to understanding other systems

02:45:21.920 --> 02:45:23.280
that are necessarily physics.

02:45:23.280 --> 02:45:26.200
And I guess like the IAC writings,

02:45:26.200 --> 02:45:30.080
the principles and tenant posts that was based on physics,

02:45:30.080 --> 02:45:33.600
that was kind of my experimentation with applying

02:45:33.600 --> 02:45:36.800
some of the thinking from out of equilibrium thermodynamics

02:45:36.800 --> 02:45:38.520
to understanding the world around us.

02:45:38.520 --> 02:45:42.640
And it's led to IAC and this movement.

02:45:42.640 --> 02:45:46.880
If you look at your one cog in the machine,

02:45:46.880 --> 02:45:48.760
in the capitalist machine, one human,

02:45:49.800 --> 02:45:52.320
and if you look at yourself,

02:45:52.320 --> 02:45:55.400
do you think mortality is a feature or a bug?

02:45:55.400 --> 02:45:57.760
Like would you want to be immortal?

02:45:57.760 --> 02:46:02.760
No, I think fundamentally in thermodynamic,

02:46:03.600 --> 02:46:06.560
thermodynamic, dissipative adaptation,

02:46:06.560 --> 02:46:08.720
there's the word dissipation.

02:46:08.720 --> 02:46:11.680
Dissipation is important, death is important, right?

02:46:11.680 --> 02:46:13.000
We have a saying in physics,

02:46:13.000 --> 02:46:16.000
physics progresses one funeral at a time.

02:46:16.000 --> 02:46:17.040
Yeah.

02:46:17.040 --> 02:46:20.680
I think the same is true for capitalism, companies,

02:46:20.680 --> 02:46:23.920
empires, people, everything.

02:46:23.920 --> 02:46:25.560
Everything must die at some point.

02:46:26.480 --> 02:46:29.880
I think that we should probably extend our lifespan

02:46:29.880 --> 02:46:34.280
because we need a longer period of training

02:46:34.280 --> 02:46:36.080
because the world is more and more complex, right?

02:46:36.080 --> 02:46:40.040
We have more and more data to really be able to predict

02:46:40.040 --> 02:46:41.240
and understand the world.

02:46:41.240 --> 02:46:45.880
And if we have a finite window of higher neuroplasticity,

02:46:45.880 --> 02:46:48.000
then we have sort of a hard cap

02:46:48.000 --> 02:46:50.360
in how much we can understand about our world.

02:46:50.360 --> 02:46:54.600
So, I think I am for death because,

02:46:54.600 --> 02:46:56.200
again, I think it's important,

02:46:56.200 --> 02:46:58.480
if you have like a king that would never die,

02:46:58.480 --> 02:47:00.360
that would be a problem, right?

02:47:00.360 --> 02:47:05.360
Like the system wouldn't be constantly adapting, right?

02:47:05.360 --> 02:47:08.960
You need novelty, you need youth, you need disruption

02:47:08.960 --> 02:47:13.920
to make sure the system's always adapting and malleable.

02:47:13.920 --> 02:47:17.280
Otherwise, if things are immortal,

02:47:17.280 --> 02:47:19.640
if you have, let's say, corporations that are there forever

02:47:19.640 --> 02:47:22.320
and they have the monopoly, they get calcified,

02:47:22.320 --> 02:47:25.240
they become not as optimal, not as high fitness

02:47:25.240 --> 02:47:28.600
in a changing time-varying landscape, right?

02:47:28.600 --> 02:47:33.600
And so, death gives space for youth and novelty

02:47:34.160 --> 02:47:36.120
to take its place.

02:47:36.120 --> 02:47:37.680
And I think it's an important part

02:47:37.680 --> 02:47:40.800
of every system in nature.

02:47:40.800 --> 02:47:45.120
So, yeah, I am for death, but I do think

02:47:45.120 --> 02:47:49.520
that longer lifespan and longer time for neuroplasticity,

02:47:49.520 --> 02:47:51.840
bigger brains, which should be something

02:47:51.840 --> 02:47:52.920
we should strive for.

02:47:52.920 --> 02:47:57.840
Well, in that, Jeff Bezos and Bev Jezos agree

02:47:57.840 --> 02:47:59.360
that all companies die.

02:48:00.240 --> 02:48:03.760
For Jeff, the goal is to try to,

02:48:03.760 --> 02:48:07.400
he calls it day one thinking, try to constantly,

02:48:07.400 --> 02:48:10.320
for as long as possible, reinvent,

02:48:10.320 --> 02:48:12.680
sort of extend the life of the company,

02:48:12.680 --> 02:48:14.800
but eventually it too will die,

02:48:14.800 --> 02:48:17.480
because it's so damn difficult to keep reinventing.

02:48:18.800 --> 02:48:20.720
Are you afraid of your own death?

02:48:23.880 --> 02:48:28.640
I think I have ideas and things I'd like to achieve

02:48:28.640 --> 02:48:32.000
in this world before I have to go,

02:48:32.000 --> 02:48:34.600
but I don't think I'm necessarily afraid of death.

02:48:34.600 --> 02:48:36.800
So you're not attached to this particular body

02:48:36.800 --> 02:48:38.240
and mind that you got?

02:48:38.240 --> 02:48:43.200
No, I think I'm sure there's gonna be better versions

02:48:43.200 --> 02:48:48.040
of myself in the future or forks, right?

02:48:48.040 --> 02:48:51.080
Genetic forks or other, right?

02:48:51.760 --> 02:48:53.640
I truly believe that.

02:48:53.640 --> 02:48:58.640
I think there's a sort of evolutionary-like algorithm

02:48:59.280 --> 02:49:04.000
happening at every bit or not in the world

02:49:04.000 --> 02:49:08.120
is sort of adapting through this process

02:49:08.120 --> 02:49:10.240
that we described in EAC.

02:49:10.240 --> 02:49:13.320
And I think maintaining this adaptation malleability

02:49:13.320 --> 02:49:16.720
is how we have constant optimization of the whole machine.

02:49:16.720 --> 02:49:20.640
And so I don't think I'm particularly, you know,

02:49:20.640 --> 02:49:23.000
an optimum that needs to stick around forever.

02:49:23.000 --> 02:49:25.760
I think there's gonna be greater optima in many ways.

02:49:25.760 --> 02:49:27.320
What do you think is the meaning of it all?

02:49:27.320 --> 02:49:30.960
What's the why of the machine, the EAC machine?

02:49:32.400 --> 02:49:36.520
The why, well, the why is thermodynamics.

02:49:36.520 --> 02:49:38.000
It's why we're here.

02:49:38.000 --> 02:49:42.520
It's what has led to the formation of life

02:49:42.520 --> 02:49:45.440
and of civilization, of evolution of technologies

02:49:45.680 --> 02:49:47.840
and growth of civilization.

02:49:47.840 --> 02:49:50.040
But why do we have thermodynamics?

02:49:50.040 --> 02:49:51.840
Why do we have our particular universe?

02:49:51.840 --> 02:49:54.280
Why do we have these particular hyperparameters,

02:49:54.280 --> 02:49:55.600
the constants of nature?

02:49:56.560 --> 02:49:59.520
Well, then you get into the anthropic principle, right?

02:49:59.520 --> 02:50:02.320
In the landscape of potential universes, right?

02:50:02.320 --> 02:50:04.880
We're in the universe that allows for life.

02:50:04.880 --> 02:50:09.880
And then why is there potentially many universes?

02:50:10.840 --> 02:50:12.360
I don't know, I don't know that part,

02:50:12.360 --> 02:50:16.600
but could we potentially engineer new universes

02:50:16.600 --> 02:50:21.040
or create pocket universes and set the hyperparameters?

02:50:21.040 --> 02:50:22.560
So there is some mutual information

02:50:22.560 --> 02:50:25.320
between our existence and that universe

02:50:25.320 --> 02:50:27.440
and we'd be somewhat its parents.

02:50:27.440 --> 02:50:31.040
I think that's really, I don't know, that'd be very poetic.

02:50:31.040 --> 02:50:32.600
It's purely conjecture.

02:50:32.600 --> 02:50:36.720
But again, this is why figuring out quantum gravity

02:50:36.720 --> 02:50:39.600
would allow us to understand if we can do that.

02:50:39.600 --> 02:50:43.680
And above that, why does it all seem so beautiful

02:50:43.680 --> 02:50:45.040
and exciting?

02:50:45.040 --> 02:50:50.040
The quest to figuring out quantum gravity seems so exciting.

02:50:51.080 --> 02:50:52.400
Why, why is that?

02:50:52.400 --> 02:50:53.440
Why are we drawn to that?

02:50:53.440 --> 02:50:55.160
Why are we pulled towards that?

02:50:55.160 --> 02:50:59.200
Just that puzzle solving creative force

02:50:59.200 --> 02:51:01.440
that underpins all of it, it seems like.

02:51:01.440 --> 02:51:04.840
I think we seek, just like an LM seeks to minimize

02:51:04.840 --> 02:51:07.560
cross entropy between its internal model and the world,

02:51:07.560 --> 02:51:11.200
we seek to minimize the statistical divergence

02:51:11.200 --> 02:51:14.320
between our predictions, the world and the world itself.

02:51:14.320 --> 02:51:18.880
And having regimes of energy scales or physical scales

02:51:18.880 --> 02:51:20.520
in which we have no visibility,

02:51:20.520 --> 02:51:22.680
no ability to predict or perceive,

02:51:24.160 --> 02:51:26.120
that's kind of an insult to us.

02:51:26.120 --> 02:51:31.120
And we want to be able to understand the world better

02:51:31.120 --> 02:51:35.960
in order to best steer it or steer us through it.

02:51:36.960 --> 02:51:39.880
And in general, it's the capability that has evolved

02:51:39.880 --> 02:51:42.120
because the better you can predict the world,

02:51:42.120 --> 02:51:46.240
the better you can capture utility or free energy

02:51:46.240 --> 02:51:48.920
towards your own sustenance and growth.

02:51:48.920 --> 02:51:52.080
And I think quantum gravity, again,

02:51:52.080 --> 02:51:56.160
is kind of the final boss in terms of knowledge acquisition

02:51:57.520 --> 02:51:58.920
because once we've mastered that,

02:51:58.920 --> 02:52:02.520
then we can do a lot potentially.

02:52:02.520 --> 02:52:04.400
But between here and there,

02:52:04.400 --> 02:52:07.240
I think there's a lot to learn in the mesoscales.

02:52:07.240 --> 02:52:10.560
There's a lot of information to acquire about our world

02:52:10.560 --> 02:52:13.720
and a lot of engineering, perception, prediction

02:52:13.720 --> 02:52:18.280
and control to be done to climb up the Cartesian scale.

02:52:18.280 --> 02:52:22.360
And to us, that's the great challenge of our times.

02:52:22.360 --> 02:52:24.120
And when you're not sure where to go,

02:52:24.120 --> 02:52:26.200
let the meme pave the way.

02:52:27.760 --> 02:52:32.240
Guillaume, Beth, thank you for talking today.

02:52:32.240 --> 02:52:33.640
Thank you for the work you're doing.

02:52:33.640 --> 02:52:35.240
Thank you for the humor and the wisdom

02:52:35.240 --> 02:52:37.040
you put into the world.

02:52:37.040 --> 02:52:37.880
This was awesome.

02:52:37.880 --> 02:52:39.440
Thank you so much for having me, Lux.

02:52:39.440 --> 02:52:40.880
It was a pleasure.

02:52:40.880 --> 02:52:42.600
Thank you for listening to this conversation

02:52:42.600 --> 02:52:43.960
with Guillaume Verdun.

02:52:43.960 --> 02:52:45.080
To support this podcast,

02:52:45.080 --> 02:52:48.120
please check out our sponsors in the description.

02:52:48.120 --> 02:52:50.160
And now let me leave you with some words

02:52:50.160 --> 02:52:51.960
from Albert Einstein.

02:52:51.960 --> 02:52:54.960
If at first the idea is not absurd,

02:52:54.960 --> 02:52:56.520
then there is no hope for it.

02:52:57.440 --> 02:52:58.480
Thank you for listening.

02:52:58.480 --> 02:53:00.640
I hope to see you next time.

02:53:03.640 --> 02:53:04.480
Thank you.

